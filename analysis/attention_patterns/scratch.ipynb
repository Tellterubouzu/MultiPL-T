{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da24c203-a034-4a5a-bdfd-6c85ebd5bb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elleven/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6e368dd6-d8dd-46a5-9c73-3f49c6127251",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bigcode/starcoderbase-1b\", use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbbdb8f1-fc8e-4942-8680-b369ae2aac66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.05k/1.05k [00:00<00:00, 10.8MB/s]\n",
      "Downloading model.safetensors: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.55G/4.55G [06:43<00:00, 11.3MB/s]\n",
      "Downloading (…)neration_config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 111/111 [00:00<00:00, 491kB/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"bigcode/starcoderbase-1b\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5a7c46a6-8b31-474d-ab05-ce75d6253b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "-- Task\n",
    "-- We are given two strings s and c, you have to deleted all the characters in s \n",
    "-- that are equal to any character in c\n",
    "-- then check if the result string is palindrome.\n",
    "-- A string is called palindrome if it reads the same backward as forward.\n",
    "-- You should return a tuple containing the result string and True/False for the check.\n",
    "--\n",
    "-- Example\n",
    "-- For s = \"abcde\", c = \"ae\", the result should be ('bcd',False)\n",
    "-- For s = \"abcdef\", c = \"b\" the result should be ('acdef',False)\n",
    "-- For s = \"abcdedcba\", c = \"ab\", the result should be ('cdedc',True)\n",
    "local function reverse_delete(s, c)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "40e1d5dd-de12-4735-89a3-0d52db46a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_end_tok_i(tokenizer, enc, stop_seqs=[\"\\nend\", \"\\n--\"]):\n",
    "    def stop_in_enc(enc):\n",
    "        dec = tokenizer.decode(enc)\n",
    "        for stop in stop_seqs:\n",
    "            if stop in dec:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "        \n",
    "    i = 0\n",
    "    \n",
    "    while i < len(enc) - 1 and not stop_in_enc(enc[:i]):\n",
    "        i += 1\n",
    "\n",
    "    return i\n",
    "    \n",
    "    \n",
    "toks = tokenizer.encode(PROMPT, return_tensors=\"pt\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "b7f3250f-44ab-424a-9f0f-6b11b13ae092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "out = model.generate(toks, do_sample=True, max_new_tokens=150, temperature=0.2, top_p=0.95, stopping_criteria=stopping_criteria)\n",
    "end_tok = find_end_tok_i(tokenizer, out[0][len(toks[0])-1:]) + len(toks[0])\n",
    "out = out[0][:end_tok-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "138eeb53-4996-43a1-8368-d09f7b8a0b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Task\n",
      "-- We are given two strings s and c, you have to deleted all the characters in s \n",
      "-- that are equal to any character in c\n",
      "-- then check if the result string is palindrome.\n",
      "-- A string is called palindrome if it reads the same backward as forward.\n",
      "-- You should return a tuple containing the result string and True/False for the check.\n",
      "--\n",
      "-- Example\n",
      "-- For s = \"abcde\", c = \"ae\", the result should be ('bcd',False)\n",
      "-- For s = \"abcdef\", c = \"b\" the result should be ('acdef',False)\n",
      "-- For s = \"abcdedcba\", c = \"ab\", the result should be ('cdedc',True)\n",
      "local function reverse_delete(s, c)\n",
      "\tlocal result = \"\"\n",
      "\tfor i = 1, #s do\n",
      "\t\tif s:sub(i, i) ~= c then\n",
      "\t\t\tresult = result.. s:sub(i, i)\n",
      "\t\tend\n",
      "\tend\n",
      "\treturn result, true\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "bf3a79c5-4d45-40b1-9182-6ac496286fe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "torch.Size([16, 229, 229])\n"
     ]
    }
   ],
   "source": [
    "enc = model(out, output_attentions=True)\n",
    "attns = enc[\"attentions\"]\n",
    "# quite a deep tensor...\n",
    "layer_i = 0\n",
    "batch_i = 0 # we only have one prompt\n",
    "attn_head_i = 0\n",
    "print(end_tok)\n",
    "# attns[layer_i][batch_i][attn_head_i][end_tok]\n",
    "\n",
    "# get last layer attns\n",
    "last_layer_attns = attns[-1][batch_i]\n",
    "print(last_layer_attns.size())\n",
    "last_layer_attns_head_mean = last_layer_attns.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "dee1c769-67fc-4399-bedc-4c5aa3a71566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "f8ee2519-a60c-4faa-aa3e-eb31c5a4e5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "1c622696-a84b-472a-a168-f935197acfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00033501291181892157"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(last_layer_attns_head_mean[-1].detach().cpu().numpy()).describe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "c0d0d036-c846-4ba9-b9f0-06cf704c9c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\n",
      "\u001b[91m--\u001b[92m Task\u001b[91m\n",
      "\u001b[91m--\u001b[91m We\u001b[92m are\u001b[92m given\u001b[93m two\u001b[92m strings\u001b[93m s\u001b[93m and\u001b[93m c\u001b[92m,\u001b[92m you\u001b[93m have\u001b[92m to\u001b[93m deleted\u001b[93m all\u001b[93m the\u001b[93m characters\u001b[93m in\u001b[93m s\u001b[92m \u001b[91m\n",
      "\u001b[93m--\u001b[92m that\u001b[93m are\u001b[93m equal\u001b[97m to\u001b[97m any\u001b[93m character\u001b[93m in\u001b[93m c\u001b[91m\n",
      "\u001b[92m--\u001b[93m then\u001b[93m check\u001b[97m if\u001b[97m the\u001b[93m result\u001b[93m string\u001b[93m is\u001b[91m pal\u001b[92mindrome\u001b[91m.\u001b[91m\n",
      "\u001b[92m--\u001b[92m A\u001b[97m string\u001b[93m is\u001b[93m called\u001b[92m pal\u001b[93mindrome\u001b[97m if\u001b[97m it\u001b[93m reads\u001b[97m the\u001b[97m same\u001b[93m backward\u001b[97m as\u001b[93m forward\u001b[91m.\u001b[91m\n",
      "\u001b[92m--\u001b[92m You\u001b[92m should\u001b[93m return\u001b[93m a\u001b[93m tuple\u001b[93m containing\u001b[93m the\u001b[93m result\u001b[97m string\u001b[97m and\u001b[92m True\u001b[92m/\u001b[93mFalse\u001b[93m for\u001b[93m the\u001b[93m check\u001b[91m.\u001b[91m\n",
      "\u001b[93m--\u001b[91m\n",
      "\u001b[92m--\u001b[92m Example\u001b[92m\n",
      "\u001b[92m--\u001b[93m For\u001b[97m s\u001b[92m =\u001b[92m \"\u001b[92mabc\u001b[92mde\u001b[92m\",\u001b[93m c\u001b[97m =\u001b[97m \"\u001b[97mae\u001b[97m\",\u001b[97m the\u001b[93m result\u001b[93m should\u001b[97m be\u001b[97m ('\u001b[93mbcd\u001b[97m',\u001b[91mFalse\u001b[92m)\u001b[92m\n",
      "\u001b[93m--\u001b[97m For\u001b[97m s\u001b[97m =\u001b[97m \"\u001b[97mabcdef\u001b[93m\",\u001b[97m c\u001b[97m =\u001b[97m \"\u001b[97mb\u001b[97m\"\u001b[97m the\u001b[93m result\u001b[97m should\u001b[97m be\u001b[97m ('\u001b[97mac\u001b[97mdef\u001b[92m',\u001b[91mFalse\u001b[92m)\u001b[91m\n",
      "\u001b[97m--\u001b[97m For\u001b[97m s\u001b[97m =\u001b[97m \"\u001b[97mabc\u001b[97mded\u001b[97mcba\u001b[97m\",\u001b[97m c\u001b[91m =\u001b[97m \"\u001b[97mab\u001b[97m\",\u001b[97m the\u001b[97m result\u001b[97m should\u001b[97m be\u001b[97m ('\u001b[97mc\u001b[97mded\u001b[93mc\u001b[93m',\u001b[92mTrue\u001b[92m)\u001b[91m\n",
      "\u001b[91mlocal\u001b[91m function\u001b[91m reverse\u001b[91m_\u001b[91mdelete\u001b[91m(\u001b[91ms\u001b[92m,\u001b[91m c\u001b[91m)\u001b[91m\n",
      "\u001b[91m\t\u001b[91mlocal\u001b[91m result\u001b[91m =\u001b[91m \"\"\u001b[91m\n",
      "\u001b[91m\t\u001b[91mfor\u001b[91m i\u001b[92m =\u001b[91m \u001b[91m1\u001b[92m,\u001b[92m #\u001b[92ms\u001b[91m do\u001b[91m\n",
      "\t\u001b[92m\t\u001b[92mif\u001b[93m s\u001b[92m:\u001b[92msub\u001b[93m(\u001b[92mi\u001b[93m,\u001b[92m i\u001b[91m)\u001b[93m ~=\u001b[92m c\u001b[91m then\u001b[91m\n",
      "\t\t\u001b[92m\t\u001b[92mresult\u001b[93m =\u001b[92m result\u001b[92m..\u001b[92m s\u001b[93m:\u001b[92msub\u001b[93m(\u001b[92mi\u001b[93m,\u001b[92m i\u001b[91m)\u001b[91m\n",
      "\t\u001b[91m\t\u001b[91mend\u001b[91m\n",
      "\u001b[91m\t\u001b[91mend\u001b[91m\n",
      "\u001b[92m\t\u001b[92mreturn\u001b[91m result\u001b[92m,\u001b[91m true\u001b[91m\n",
      "\u001b[91mend"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# colors for visualizing attn\n",
    "color_red = '\\033[91m'\n",
    "color_green = '\\033[92m'\n",
    "color_yellow = '\\033[93m'\n",
    "color_grey = '\\033[97m'\n",
    "\n",
    "def color_tok(attn, distr) -> str:\n",
    "    if attn < distr[\"25%\"]:\n",
    "        return color_grey\n",
    "    elif attn < distr[\"50%\"]:\n",
    "        return color_yellow\n",
    "    elif attn < distr[\"75%\"]:\n",
    "        return color_green\n",
    "    else:\n",
    "        return color_red\n",
    "    \n",
    "\n",
    "def visualize_attn(tokenizer, out, meaned_attns):\n",
    "    distr = pd.DataFrame(meaned_attns.detach().cpu().numpy()).describe()[0]\n",
    "    for i, tok in enumerate(out):\n",
    "        color = color_tok(meaned_attns[i], distr)\n",
    "        print(f\"{color}{tokenizer.decode(tok)}\", end=\"\")\n",
    "\n",
    "visualize_attn(tokenizer, out, last_layer_attns_head_mean[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13603ebe-d0b0-4192-bbd4-16b8e69c20eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
