{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da24c203-a034-4a5a-bdfd-6c85ebd5bb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elleven/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6e368dd6-d8dd-46a5-9c73-3f49c6127251",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bigcode/starcoderbase-1b\", use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbbdb8f1-fc8e-4942-8680-b369ae2aac66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.05k/1.05k [00:00<00:00, 10.8MB/s]\n",
      "Downloading model.safetensors: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.55G/4.55G [06:43<00:00, 11.3MB/s]\n",
      "Downloading (…)neration_config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 111/111 [00:00<00:00, 491kB/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"bigcode/starcoderbase-1b\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5a7c46a6-8b31-474d-ab05-ce75d6253b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "-- Task\n",
    "-- We are given two strings s and c, you have to deleted all the characters in s \n",
    "-- that are equal to any character in c\n",
    "-- then check if the result string is palindrome.\n",
    "-- A string is called palindrome if it reads the same backward as forward.\n",
    "-- You should return a tuple containing the result string and True/False for the check.\n",
    "--\n",
    "-- Example\n",
    "-- For s = \"abcde\", c = \"ae\", the result should be ('bcd',False)\n",
    "-- For s = \"abcdef\", c = \"b\" the result should be ('acdef',False)\n",
    "-- For s = \"abcdedcba\", c = \"ab\", the result should be ('cdedc',True)\n",
    "local function reverse_delete(s, c)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "40e1d5dd-de12-4735-89a3-0d52db46a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_end_tok_i(tokenizer, enc, stop_seqs=[\"\\nend\", \"\\n--\"]):\n",
    "    def stop_in_enc(enc):\n",
    "        dec = tokenizer.decode(enc)\n",
    "        for stop in stop_seqs:\n",
    "            if stop in dec:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "        \n",
    "    i = 0\n",
    "    \n",
    "    while i < len(enc) - 1 and not stop_in_enc(enc[:i]):\n",
    "        i += 1\n",
    "\n",
    "    return i\n",
    "    \n",
    "    \n",
    "toks = tokenizer.encode(PROMPT, return_tensors=\"pt\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b7f3250f-44ab-424a-9f0f-6b11b13ae092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "out = model.generate(toks, do_sample=True, max_new_tokens=150, temperature=0.2, top_p=0.95, stopping_criteria=stopping_criteria)\n",
    "end_tok = find_end_tok_i(tokenizer, out[0][len(toks[0])-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "138eeb53-4996-43a1-8368-d09f7b8a0b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Task\n",
      "-- We are given two strings s and c, you have to deleted all the characters in s \n",
      "-- that are equal to any character in c\n",
      "-- then check if the result string is palindrome.\n",
      "-- A string is called palindrome if it reads the same backward as forward.\n",
      "-- You should return a tuple containing the result string and True/False for the check.\n",
      "--\n",
      "-- Example\n",
      "-- For s = \"abcde\", c = \"ae\", the result should be ('bcd',False)\n",
      "-- For s = \"abcdef\", c = \"b\" the result should be ('acdef',False)\n",
      "-- For s = \"abcdedcba\", c = \"ab\", the result should be ('cdedc',True)\n",
      "local function reverse_delete(s, c)\n",
      "\tlocal result = \"\"\n",
      "\tfor i = 1, #s do\n",
      "\t\tif s:sub(i, i) ~= c:sub(1, 1) then\n",
      "\t\t\tresult = result.. s:sub(i, i)\n",
      "\t\tend\n",
      "\tend\n",
      "\treturn result, true\n",
      "end\n",
      "\n",
      "-- Solution\n",
      "-- Time: O(n)\n",
      "-- Space: O(1)\n",
      "function reverse_delete(s, c)\n",
      "\tlocal result = \"\"\n",
      "\tfor i = 1, #s do\n",
      "\t\tif s:sub(i, i) ~= c:sub(1, 1) then\n",
      "\t\t\tresult = result.. s:sub(i, i)\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bf3a79c5-4d45-40b1-9182-6ac496286fe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([256.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = model(out, output_attentions=True)\n",
    "attns = enc[\"attentions\"]\n",
    "# quite a deep tensor...\n",
    "layer_i = 0\n",
    "batch_i = 0 # we only have one prompt\n",
    "attn_head_i = 0\n",
    "print(end_tok)\n",
    "attns[layer_i][batch_i][attn_head_i][end_tok+30]\n",
    "\n",
    "# sum all layers\n",
    "s_layer = attns[0][batch_i]\n",
    "for i in range(1, len(attns[layer_i][batch_i])):\n",
    "    s_layer += attns[i][batch_i]\n",
    "\n",
    "# sum all heads\n",
    "summed = s_layer[0]\n",
    "for i in range(1, len(s_layer)):\n",
    "    summed += s_layer[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6110e68c-a34f-482d-86d6-4d9cede36451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([191.0103,   5.0398,   7.3868,   9.1133,   8.0260,  11.1349,  14.6481,\n",
       "          9.6409,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f83f869-2850-416f-b4ca-705322b7ef40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a708e92b-5413-448b-a1e8-d4987f61f5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
