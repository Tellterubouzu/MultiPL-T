{"name": "HumanEval_100473_bit_ceil", "language": "lua", "prompt": "-- Calculate the smallest power of 2 not smaller than n.\nlocal function bit_ceil(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_100473_bit_ceil.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = bit_ceil\n    lu.assertEquals(candidate(28), 32)\n    lu.assertEquals(candidate(10), 16)\n    lu.assertEquals(candidate(8), 8)\n    lu.assertEquals(candidate(13), 16)\n    lu.assertEquals(candidate(31), 32)\n    lu.assertEquals(candidate(22), 32)\n    lu.assertEquals(candidate(7), 8)\n    lu.assertEquals(candidate(20), 32)\n    lu.assertEquals(candidate(26), 32)\n    lu.assertEquals(candidate(12), 16)\n    lu.assertEquals(candidate(3), 4)\n    lu.assertEquals(candidate(19), 32)\n    lu.assertEquals(candidate(16), 16)\n    lu.assertEquals(candidate(23), 32)\n    lu.assertEquals(candidate(4), 4)\n    lu.assertEquals(candidate(9), 16)\n    lu.assertEquals(candidate(17), 32)\n    lu.assertEquals(candidate(24), 32)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(0), 1)\n    lu.assertEquals(candidate(15), 16)\n    lu.assertEquals(candidate(27), 32)\n    lu.assertEquals(candidate(25), 32)\n    lu.assertEquals(candidate(11), 16)\n    lu.assertEquals(candidate(6), 8)\n    lu.assertEquals(candidate(14), 16)\n    lu.assertEquals(candidate(5), 8)\n    lu.assertEquals(candidate(30), 32)\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(21), 32)\n    lu.assertEquals(candidate(18), 32)\n    lu.assertEquals(candidate(29), 32)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_100527_ell2ang", "language": "lua", "prompt": "-- Convert the given ell(s) to its analogous angular scale(s) in arcmins.\n-- Return the angular scale(s) in arcmins corresponding to the Fourier mode \n-- ell(s).\n-- Parameters\n-- ----------\n-- ell: value, array of values\n--     The ell mode(s).\n-- Returns\n-- -------\n-- a: float, array of floats\n--     The angular scale(s) corresponding to ell.\nlocal function ell2ang(ell)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_100527_ell2ang.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = ell2ang\n    lu.assertEquals(candidate(1), 10800)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_101579_about_me", "language": "lua", "prompt": "-- Return the most important thing about a person.\n-- Parameters\n-- ----------\n-- your_name\n--     A string indicating the name of the person.\nlocal function about_me(your_name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_101579_about_me.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = about_me\n    lu.assertEquals(candidate('Jose'), 'The wise Jose loves Python.')\n    lu.assertEquals(candidate('<NAME>'), 'The wise <NAME> loves Python.')\n    lu.assertEquals(candidate('Peter'), 'The wise Peter loves Python.')\n    lu.assertEquals(candidate('Donald'), 'The wise Donald loves Python.')\n    lu.assertEquals(candidate('Bob'), 'The wise Bob loves Python.')\n    lu.assertEquals(candidate('Bernhard'), 'The wise Bernhard loves Python.')\n    lu.assertEquals(candidate('Abraham'), 'The wise Abraham loves Python.')\n    lu.assertEquals(candidate('Bob'), 'The wise Bob loves Python.')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_101630_maybe_quote", "language": "lua", "prompt": "--  Enclose the string argument in single quotes if it looks like it needs it.\n-- Spaces and quotes will trigger; single quotes in the argument are escaped.\n-- This is only used to compose the --print output so need only satisfy shlex.\nlocal function maybe_quote(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_101630_maybe_quote.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = maybe_quote\n    lu.assertEquals(candidate('foo bar'), \"'foo bar'\")\n    lu.assertEquals(candidate('x'), 'x')\n    lu.assertEquals(candidate('fo\\\\\"o'), '\\'fo\\\\\\\\\"o\\'')\n    lu.assertEquals(candidate('a\\\\tb'), \"'a\\\\\\\\tb'\")\n    lu.assertEquals(candidate('fo\"o'), '\\'fo\"o\\'')\n    lu.assertEquals(candidate('Hello World!'), \"'Hello World!'\")\n    lu.assertEquals(candidate('a   b'), \"'a   b'\")\n    lu.assertEquals(candidate('a'), 'a')\n    lu.assertEquals(candidate('ab c\\\\'), \"'ab c\\\\\\\\'\")\n    lu.assertEquals(candidate('Hello World?'), \"'Hello World?'\")\n    lu.assertEquals(candidate('fo\\\\\\\\o'), \"'fo\\\\\\\\\\\\\\\\o'\")\n    lu.assertEquals(candidate('\\\\'), \"'\\\\\\\\'\")\n    lu.assertEquals(candidate('a\\\\nb\\\\tc'), \"'a\\\\\\\\nb\\\\\\\\tc'\")\n    lu.assertEquals(candidate('foo bar'), \"'foo bar'\")\n    lu.assertEquals(candidate(' x'), \"' x'\")\n    lu.assertEquals(candidate('fo o'), \"'fo o'\")\n    lu.assertEquals(candidate('Hello World?'), \"'Hello World?'\")\n    lu.assertEquals(candidate('fo\\\\\\\\\\\\o'), \"'fo\\\\\\\\\\\\\\\\\\\\\\\\o'\")\n    lu.assertEquals(candidate('ab c'), \"'ab c'\")\n    lu.assertEquals(candidate('a\\\\nb'), \"'a\\\\\\\\nb'\")\n    lu.assertEquals(candidate('x '), \"'x '\")\n    lu.assertEquals(candidate('a  b'), \"'a  b'\")\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('\"'), '\\'\"\\'')\n    lu.assertEquals(candidate('foo'), 'foo')\n    lu.assertEquals(candidate('Hello \"World\"!'), '\\'Hello \"World\"!\\'')\n    lu.assertEquals(candidate('Hello World!'), \"'Hello World!'\")\n    lu.assertEquals(candidate('a b'), \"'a b'\")\n    lu.assertEquals(candidate('hello'), 'hello')\n    lu.assertEquals(candidate('abc'), 'abc')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_101962_is_categorical", "language": "lua", "prompt": "-- Checks whether the variable type for the\n-- variable of interest is categorical.\nlocal function is_categorical(var_type)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_101962_is_categorical.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_categorical\n    lu.assertEquals(candidate(None), false)\n    lu.assertEquals(candidate('string'), false)\n    lu.assertEquals(candidate('date'), false)\n    lu.assertEquals(candidate('number'), false)\n    lu.assertEquals(candidate('categorical'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_10216_split3", "language": "lua", "prompt": "-- Split text in 3 parts: before pat1, between, and after pat2.\nlocal function split3(text, pat1, pat2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_10216_split3.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = split3\n    lu.assertEquals(candidate('a:b:c', ':', ':'), {'a', 'b', 'c'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_10218_parts", "language": "lua", "prompt": "-- https://stackoverflow.com/a/52698110\nlocal function parts(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_10218_parts.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parts\n    lu.assertEquals(candidate(0, 4), {0, 0, 0, 0})\n    lu.assertEquals(candidate(3, 2), {2, 1})\n    lu.assertEquals(candidate(11, 2), {6, 5})\n    lu.assertEquals(candidate(10, 1), {10})\n    lu.assertEquals(candidate(4, 2), {2, 2})\n    lu.assertEquals(candidate(0, 10), {0, 0, 0, 0, 0, 0, 0, 0, 0, 0})\n    lu.assertEquals(candidate(4, 3), {2, 1, 1})\n    lu.assertEquals(candidate(10, 3), {4, 3, 3})\n    lu.assertEquals(candidate(5, 3), {2, 2, 1})\n    lu.assertEquals(candidate(0, 2), {0, 0})\n    lu.assertEquals(candidate(2, 3), {1, 1, 0})\n    lu.assertEquals(candidate(0, 1), {0})\n    lu.assertEquals(candidate(1, 1), {1})\n    lu.assertEquals(candidate(2, 2), {1, 1})\n    lu.assertEquals(candidate(10, 2), {5, 5})\n    lu.assertEquals(candidate(4, 1), {4})\n    lu.assertEquals(candidate(6, 3), {2, 2, 2})\n    lu.assertEquals(candidate(1, 4), {1, 0, 0, 0})\n    lu.assertEquals(candidate(1, 2), {1, 0})\n    lu.assertEquals(candidate(1, 3), {1, 0, 0})\n    lu.assertEquals(candidate(3, 1), {3})\n    lu.assertEquals(candidate(5, 1), {5})\n    lu.assertEquals(candidate(100, 10), {10, 10, 10, 10, 10, 10, 10, 10, 10, 10})\n    lu.assertEquals(candidate(99, 10), {10, 10, 10, 10, 10, 10, 10, 10, 10, 9})\n    lu.assertEquals(candidate(0, 3), {0, 0, 0})\n    lu.assertEquals(candidate(2, 1), {2})\n    lu.assertEquals(candidate(3, 3), {1, 1, 1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_102630_get_last_step_id", "language": "lua", "prompt": "-- Returns the id of the last step in |steps|.\nlocal function get_last_step_id(steps)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_102630_get_last_step_id.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_last_step_id\n    lu.assertEquals(candidate({{['id'] = 's1'}, {['id'] = 's2'}, {['id'] = 's3'}}), 's3')\n    lu.assertEquals(candidate({{['id'] = 's1'}}), 's1')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_102704_bit_length", "language": "lua", "prompt": "-- Measure the length of the number in bits.\n-- :param num: The number to measure.\n-- :return:    The minimal amount of bits needed to represent the number.\nlocal function bit_length(num)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_102704_bit_length.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = bit_length\n    lu.assertEquals(candidate(6), 3)\n    lu.assertEquals(candidate(281474976710656), 49)\n    lu.assertEquals(candidate(27), 5)\n    lu.assertEquals(candidate(255), 8)\n    lu.assertEquals(candidate(8), 4)\n    lu.assertEquals(candidate(65535), 16)\n    lu.assertEquals(candidate(13), 4)\n    lu.assertEquals(candidate(12), 4)\n    lu.assertEquals(candidate(14), 4)\n    lu.assertEquals(candidate(128), 8)\n    lu.assertEquals(candidate(5), 3)\n    lu.assertEquals(candidate(11), 4)\n    lu.assertEquals(candidate(30), 5)\n    lu.assertEquals(candidate(281474976710655), 48)\n    lu.assertEquals(candidate(1099511627775), 40)\n    lu.assertEquals(candidate(0), 1)\n    lu.assertEquals(candidate(256), 9)\n    lu.assertEquals(candidate(7), 3)\n    lu.assertEquals(candidate(1023), 10)\n    lu.assertEquals(candidate(23), 5)\n    lu.assertEquals(candidate(15), 4)\n    lu.assertEquals(candidate(4294967297), 33)\n    lu.assertEquals(candidate(9), 4)\n    lu.assertEquals(candidate(29), 5)\n    lu.assertEquals(candidate(4294967295), 32)\n    lu.assertEquals(candidate(1099511627776), 41)\n    lu.assertEquals(candidate(28), 5)\n    lu.assertEquals(candidate(16777216), 25)\n    lu.assertEquals(candidate(16), 5)\n    lu.assertEquals(candidate(17), 5)\n    lu.assertEquals(candidate(10), 4)\n    lu.assertEquals(candidate(20), 5)\n    lu.assertEquals(candidate(32), 6)\n    lu.assertEquals(candidate(25), 5)\n    lu.assertEquals(candidate(22), 5)\n    lu.assertEquals(candidate(1099511627777), 41)\n    lu.assertEquals(candidate(21), 5)\n    lu.assertEquals(candidate(31), 5)\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(1024), 11)\n    lu.assertEquals(candidate(19), 5)\n    lu.assertEquals(candidate(18), 5)\n    lu.assertEquals(candidate(127), 7)\n    lu.assertEquals(candidate(1025), 11)\n    lu.assertEquals(candidate(65536), 17)\n    lu.assertEquals(candidate(3), 2)\n    lu.assertEquals(candidate(33), 6)\n    lu.assertEquals(candidate(24), 5)\n    lu.assertEquals(candidate(16777215), 24)\n    lu.assertEquals(candidate(4), 3)\n    lu.assertEquals(candidate(16777217), 25)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(26), 5)\n    lu.assertEquals(candidate(4294967296), 33)\n    lu.assertEquals(candidate(65537), 17)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_103381_get_cindex", "language": "lua", "prompt": "-- ******NOTE; CAUTION******\n-- This code is from the original repository of \"DeepDTA; Bioinformatics\"\n-- Now the get_cindex is invalid (order dependent of given pairs).\n-- We will use lifelines.utils for \nlocal function get_cindex(Y, P)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_103381_get_cindex.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_cindex\n    lu.assertEquals(candidate({1, 0, 0, 0, 1, 1, 0, 0}, {1, 0, 0, 0, 1, 1, 0, 0}), 1.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_103969_split_compound", "language": "lua", "prompt": "-- Split a possibly compound format string into segments.\n-- >>> split_compound('bold_underline_bright_blue_on_red')\n-- ['bold', 'underline', 'bright_blue', 'on_red']\nlocal function split_compound(compound)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_103969_split_compound.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = split_compound\n    lu.assertEquals(candidate('foo_bar'), {'foo', 'bar'})\n    lu.assertEquals(candidate('bold_underline_bright_blue_on_red'), {'bold', 'underline', 'bright_blue', 'on_red'})\n    lu.assertEquals(candidate('bold_underline'), {'bold', 'underline'})\n    lu.assertEquals(candidate('underline_bright_blue_on_red'), {'underline', 'bright_blue', 'on_red'})\n    lu.assertEquals(candidate('bold'), {'bold'})\n    lu.assertEquals(candidate('underline_on_red'), {'underline', 'on_red'})\n    lu.assertEquals(candidate('bold_underline_bright_blue_on_red'), {'bold', 'underline', 'bright_blue', 'on_red'})\n    lu.assertEquals(candidate('bold_underline_bright_green'), {'bold', 'underline', 'bright_green'})\n    lu.assertEquals(candidate('on_red'), {'on_red'})\n    lu.assertEquals(candidate('underline'), {'underline'})\n    lu.assertEquals(candidate('foo_on_bar'), {'foo', 'on_bar'})\n    lu.assertEquals(candidate('on_green'), {'on_green'})\n    lu.assertEquals(candidate('foo_bar_baz'), {'foo', 'bar', 'baz'})\n    lu.assertEquals(candidate('foo'), {'foo'})\n    lu.assertEquals(candidate('bold'), {'bold'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_104481_compliment", "language": "lua", "prompt": "-- [finds the complimentary strand of dna \"pattern\"]\n-- Args:\n--     pattern ([string]): [dna strand of which compliment is found]\n-- Returns:\n--     [string]: [compliment of dna pattern: A -> T, G -> C, T -> A, C -> G]\nlocal function compliment(pattern)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_104481_compliment.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = compliment\n    lu.assertEquals(candidate('T'), 'A')\n    lu.assertEquals(candidate('A'), 'T')\n    lu.assertEquals(candidate('C'), 'G')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('G'), 'C')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_104902__escape", "language": "lua", "prompt": "-- Basic html escaping.\nlocal function _escape(txt)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_104902__escape.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _escape\n    lu.assertEquals(candidate('&'), '&amp;')\n    lu.assertEquals(candidate('hello'), 'hello')\n    lu.assertEquals(candidate('foo<bar>'), 'foo&lt;bar&gt;')\n    lu.assertEquals(candidate('<html>'), '&lt;html&gt;')\n    lu.assertEquals(candidate('<world>hello&'), '&lt;world&gt;hello&amp;')\n    lu.assertEquals(candidate('<&>'), '&lt;&amp;&gt;')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('world'), 'world')\n    lu.assertEquals(candidate('<hello>'), '&lt;hello&gt;')\n    lu.assertEquals(candidate('<hello/>'), '&lt;hello/&gt;')\n    lu.assertEquals(candidate('<html>'), '&lt;html&gt;')\n    lu.assertEquals(candidate('&<hello/>'), '&amp;&lt;hello/&gt;')\n    lu.assertEquals(candidate('&<hello>'), '&amp;&lt;hello&gt;')\n    lu.assertEquals(candidate('<world/>'), '&lt;world/&gt;')\n    lu.assertEquals(candidate('&<world>hello'), '&amp;&lt;world&gt;hello')\n    lu.assertEquals(candidate('foo<bar/>'), 'foo&lt;bar/&gt;')\n    lu.assertEquals(candidate('hello'), 'hello')\n    lu.assertEquals(candidate('hello'), 'hello')\n    lu.assertEquals(candidate('&<world/>'), '&amp;&lt;world/&gt;')\n    lu.assertEquals(candidate('<hello>world&'), '&lt;hello&gt;world&amp;')\n    lu.assertEquals(candidate('>'), '&gt;')\n    lu.assertEquals(candidate('<'), '&lt;')\n    lu.assertEquals(candidate('&<world>'), '&amp;&lt;world&gt;')\n    lu.assertEquals(candidate('&<>'), '&amp;&lt;&gt;')\n    lu.assertEquals(candidate('&<hello>world'), '&amp;&lt;hello&gt;world')\n    lu.assertEquals(candidate('<world>'), '&lt;world&gt;')\n    lu.assertEquals(candidate('&<>'), '&amp;&lt;&gt;')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_105314_user_match", "language": "lua", "prompt": "-- Return True if this is the user we are looking for.\n-- Compares a user structure from a Gerrit record to a username (or email\n-- address). All users match if the username is None.\nlocal function user_match(user, username)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_105314_user_match.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = user_match\n    lu.assertEquals(candidate({['username'] = 'foo'}, 'bar'), false)\n    lu.assertEquals(candidate({['username'] = 'foo'}, 'foo'), true)\n    lu.assertEquals(candidate({['email'] = '<EMAIL>'}, '<EMAIL>'), false)\n    lu.assertEquals(candidate({['username'] = 'foo', ['email'] = '<EMAIL>'}, 'bar'), false)\n    lu.assertEquals(candidate({['username'] = 'foo', ['email'] = '<EMAIL>'}, 'foo'), true)\n    lu.assertEquals(candidate({['username'] = 'foo', ['email'] = '<EMAIL>'}, '<EMAIL>'), false)\n    lu.assertEquals(candidate({['username'] = 'foo'}, None), true)\n    lu.assertEquals(candidate({['username'] = 'alice'}, 'bob'), false)\n    lu.assertEquals(candidate({['username'] = 'alice'}, None), true)\n    lu.assertEquals(candidate({['username'] = 'alice'}, 'alice'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_105342_get_month", "language": "lua", "prompt": "--     convert from a month string to a month integer.\nlocal function get_month(month)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_105342_get_month.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_month\n    lu.assertEquals(candidate('Nov'), 11)\n    lu.assertEquals(candidate('Jan'), 1)\n    lu.assertEquals(candidate('Jun'), 6)\n    lu.assertEquals(candidate('Sep'), 9)\n    lu.assertEquals(candidate('Oct'), 10)\n    lu.assertEquals(candidate('Apr'), 4)\n    lu.assertEquals(candidate('Mar'), 3)\n    lu.assertEquals(candidate('Feb'), 2)\n    lu.assertEquals(candidate('Aug'), 8)\n    lu.assertEquals(candidate('Dec'), 12)\n    lu.assertEquals(candidate('Jul'), 7)\n    lu.assertEquals(candidate('May'), 5)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_105509_normalize_case", "language": "lua", "prompt": "-- Convert `text' to lower case.\nlocal function normalize_case(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_105509_normalize_case.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = normalize_case\n    lu.assertEquals(candidate('Hi there!'), 'hi there!')\n    lu.assertEquals(candidate('a b C'), 'a b c')\n    lu.assertEquals(candidate('1 2 3 4 5'), '1 2 3 4 5')\n    lu.assertEquals(candidate('THAT'), 'that')\n    lu.assertEquals(candidate('none'), 'none')\n    lu.assertEquals(candidate('12345'), '12345')\n    lu.assertEquals(candidate('I like pie.'), 'i like pie.')\n    lu.assertEquals(candidate('Hello world!'), 'hello world!')\n    lu.assertEquals(candidate('None'), 'none')\n    lu.assertEquals(candidate('abc'), 'abc')\n    lu.assertEquals(candidate('this'), 'this')\n    lu.assertEquals(candidate(None), 'none')\n    lu.assertEquals(candidate('AbC'), 'abc')\n    lu.assertEquals(candidate('hi there!'), 'hi there!')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('Hey You!'), 'hey you!')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_105531_bisect_right", "language": "lua", "prompt": "-- Locates the first element in a sorted array that is larger than a given value.\n-- It has the same interface as https://docs.python.org/3/library/bisect.html#bisect.bisect_right .\n-- :param sorted_collection: some ascending sorted collection with comparable items\n-- :param item: item to bisect\n-- :param lo: lowest index to consider (as in sorted_collection[lo:hi])\n-- :param hi: past the highest index to consider (as in sorted_collection[lo:hi])\n-- :return: index i such that all values in sorted_collection[lo:i] are <= item and all values in sorted_collection[i:hi] are > item.\n-- Examples:\n-- >>> bisect_right([0, 5, 7, 10, 15], 0)\n-- 1\n-- >>> bisect_right([0, 5, 7, 10, 15], 15)\n-- 5\n-- >>> bisect_right([0, 5, 7, 10, 15], 6)\n-- 2\n-- >>> bisect_right([0, 5, 7, 10, 15], 15, 1, 3)\n-- 3\n-- >>> bisect_right([0, 5, 7, 10, 15], 6, 2)\n-- 2\nlocal function bisect_right(sorted_collection, item, lo, hi)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_105531_bisect_right.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = bisect_right\n    lu.assertEquals(candidate({0, 5, 7, 10, 15}, 6, 2), 2)\n    lu.assertEquals(candidate({0, 5, 7, 10, 15}, 15, 1, 3), 3)\n    lu.assertEquals(candidate({0, 5, 7, 10, 15}, 0), 1)\n    lu.assertEquals(candidate({0, 5, 7, 10, 15}, 15, 1, 3), 3)\n    lu.assertEquals(candidate({0, 5, 7, 10, 15}, 15, 3), 5)\n    lu.assertEquals(candidate({0, 5, 7, 10, 15}, 15), 5)\n    lu.assertEquals(candidate({0, 5, 7, 10, 15}, 0), 1)\n    lu.assertEquals(candidate({0, 5, 7, 10, 15}, 6), 2)\n    lu.assertEquals(candidate({0, 5, 7, 10, 15}, 6), 2)\n    lu.assertEquals(candidate({0, 5, 7, 10, 15}, 15), 5)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_105585_concat_key_value", "language": "lua", "prompt": "-- concat keys and values of dict containing strings elements\n-- into a list\n-- Parameters\n-- ----------\n-- str_dict: dict\n--     dict to process\n--     {key1: value1, key2: value2}\n-- Returns\n-- -------\n-- list\n--     ['key1 value1', 'key2 value2']\nlocal function concat_key_value(str_dict)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_105585_concat_key_value.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = concat_key_value\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({['key3'] = 'value3', ['key4'] = 'value4'}), {'key3 value3', 'key4 value4'})\n    lu.assertEquals(candidate({['k1'] = 'v1', ['k2'] = 'v2', ['k3'] = 'v3', ['k4'] = 'v4', ['k5'] = 'v5'}), {'k1 v1', 'k2 v2', 'k3 v3', 'k4 v4', 'k5 v5'})\n    lu.assertEquals(candidate({['k1'] = 'v1'}), {'k1 v1'})\n    lu.assertEquals(candidate({['k1'] = 'v1', ['k2'] = 'v2', ['k3'] = 'v3'}), {'k1 v1', 'k2 v2', 'k3 v3'})\n    lu.assertEquals(candidate({['key5'] = 'value5', ['key6'] = 'value6'}), {'key5 value5', 'key6 value6'})\n    lu.assertEquals(candidate({['k1'] = 'v1', ['k2'] = 'v2', ['k3'] = 'v3', ['k4'] = 'v4'}), {'k1 v1', 'k2 v2', 'k3 v3', 'k4 v4'})\n    lu.assertEquals(candidate({['k1'] = 'v1', ['k2'] = 'v2', ['k3'] = 'v3', ['k4'] = 'v4', ['k5'] = 'v5', ['k6'] = 'v6'}), {'k1 v1', 'k2 v2', 'k3 v3', 'k4 v4', 'k5 v5', 'k6 v6'})\n    lu.assertEquals(candidate({['key7'] = 'value7', ['key8'] = 'value8'}), {'key7 value7', 'key8 value8'})\n    lu.assertEquals(candidate({['k1'] = 'v1', ['k2'] = 'v2'}), {'k1 v1', 'k2 v2'})\n    lu.assertEquals(candidate({['key1'] = 'value1', ['key2'] = 'value2'}), {'key1 value1', 'key2 value2'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_105820_jaccard_dependency", "language": "lua", "prompt": "-- calculate the direction of dependence of 2 experiments \n-- if exp1 is parent of exp2 return 0 \n--                 otherwise return 1\nlocal function jaccard_dependency(exp1, exp2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_105820_jaccard_dependency.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = jaccard_dependency\n    lu.assertEquals(candidate({'word1', 'word2'}, {'word1', 'word3'}), 0)\n    lu.assertEquals(candidate({'word1', 'word2'}, {'word2', 'word2'}), 0)\n    lu.assertEquals(candidate({'word1', 'word2'}, {'word1', 'word1'}), 0)\n    lu.assertEquals(candidate({'word1', 'word2'}, {'word1', 'word2'}), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_106177__divides", "language": "lua", "prompt": "-- divide 1-w\n-- (i.e. a1+a2*w -> (1-w)^k * (x+y*w))\nlocal function _divides(a1, a2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_106177__divides.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _divides\n    lu.assertEquals(candidate(0, 1), {0, 1, 0})\n    lu.assertEquals(candidate(1, 0), {1, 0, 0})\n    lu.assertEquals(candidate(1, 2), {0, 1, 1})\n    lu.assertEquals(candidate(0, 0), {0, 0, 0})\n    lu.assertEquals(candidate(1, 1), {1, 1, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_106375_calib_time", "language": "lua", "prompt": "-- Given a list of normalized triggers, return the time (acquisition) clock\n-- when the calibration trigger was displayed.\nlocal function calib_time(normalized_triggers)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_106375_calib_time.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = calib_time\n    lu.assertEquals(candidate({{10, 'calibration_trigger'}}), 10)\n    lu.assertEquals(candidate({{1, 'other_stim'}, {2, 'calibration_trigger'}, {3, 'calibration_trigger'}, {4, 'other_stim'}}), 2)\n    lu.assertEquals(candidate({{0, 'other_stim'}, {1, 'other_stim'}, {2, 'other_stim'}, {3, 'other_stim'}, {4, 'calibration_trigger'}}), 4)\n    lu.assertEquals(candidate({{0, 'calibration_trigger'}, {1, 'other_stim'}, {2, 'calibration_trigger'}, {3, 'other_stim'}, {4, 'other_stim'}}), 0)\n    lu.assertEquals(candidate({{0, 'calibration_trigger'}, {1, 'calibration_trigger'}, {2, 'other_stim'}, {3, 'other_stim'}}), 0)\n    lu.assertEquals(candidate({{5, 'calibration_trigger'}, {6, 'not_calibration_trigger'}}), 5)\n    lu.assertEquals(candidate({{0, 'other_stim'}, {1, 'other_stim'}, {2, 'calibration_trigger'}, {3, 'other_stim'}, {4, 'other_stim'}}), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_106887_symmetric_residue", "language": "lua", "prompt": "-- Return the residual mod m such that it is within half of the modulus.\n-- >>> symmetric_residue(1, 6)\n-- 1\n-- >>> symmetric_residue(4, 6)\n-- -2\nlocal function symmetric_residue(a, m)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_106887_symmetric_residue.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = symmetric_residue\n    lu.assertEquals(candidate(1, 13), 1)\n    lu.assertEquals(candidate(10, 11), -1)\n    lu.assertEquals(candidate(1, 6), 1)\n    lu.assertEquals(candidate(4, 6), -2)\n    lu.assertEquals(candidate(1, 11), 1)\n    lu.assertEquals(candidate(1, 10), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_107516_extract_uri_schema", "language": "lua", "prompt": "--  Extract schema of given uri \nlocal function extract_uri_schema(uri)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_107516_extract_uri_schema.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = extract_uri_schema\n    lu.assertEquals(candidate('https://example.com:80'), 'https')\n    lu.assertEquals(candidate('http://'), 'http')\n    lu.assertEquals(candidate('http://www.google.com/something?a=1'), 'http')\n    lu.assertEquals(candidate('ftp://a.com/p?a=1'), 'ftp')\n    lu.assertEquals(candidate('ssh://example.com'), 'ssh')\n    lu.assertEquals(candidate(None), None)\n    lu.assertEquals(candidate('http://google.com'), 'http')\n    lu.assertEquals(candidate('http://example.com'), 'http')\n    lu.assertEquals(candidate('https://foo.bar'), 'https')\n    lu.assertEquals(candidate('http://a.com'), 'http')\n    lu.assertEquals(candidate('https://:1234'), 'https')\n    lu.assertEquals(candidate('https://'), 'https')\n    lu.assertEquals(candidate('https://foo.bar/baz?qux=1'), 'https')\n    lu.assertEquals(candidate('https://a.com/p?a=1'), 'https')\n    lu.assertEquals(candidate('https://a.com/'), 'https')\n    lu.assertEquals(candidate('telnet://example.com'), 'telnet')\n    lu.assertEquals(candidate('ftp://google.com'), 'ftp')\n    lu.assertEquals(candidate('http://a.com/p?a=1'), 'http')\n    lu.assertEquals(candidate('https://foo.bar/baz?qux=1#quux'), 'https')\n    lu.assertEquals(candidate('file:///path/to/file.ext'), 'file')\n    lu.assertEquals(candidate('ftp://a.com'), 'ftp')\n    lu.assertEquals(candidate('https://www.google.com'), 'https')\n    lu.assertEquals(candidate('http://www.google.com'), 'http')\n    lu.assertEquals(candidate('a.com'), None)\n    lu.assertEquals(candidate('ftp://www.google.com/something'), 'ftp')\n    lu.assertEquals(candidate('https://a.com'), 'https')\n    lu.assertEquals(candidate('https:///:1234'), 'https')\n    lu.assertEquals(candidate('https://a.com:1234/'), 'https')\n    lu.assertEquals(candidate('ldaps://example.com'), 'ldaps')\n    lu.assertEquals(candidate('https://www.google.com/something'), 'https')\n    lu.assertEquals(candidate('foo:bar'), 'foo')\n    lu.assertEquals(candidate('https://google.com'), 'https')\n    lu.assertEquals(candidate('http://www.google.com/something'), 'http')\n    lu.assertEquals(candidate('https://a.com:1234'), 'https')\n    lu.assertEquals(candidate('https://www.google.com/something?a=1'), 'https')\n    lu.assertEquals(candidate('foo:bar:baz:qux?quux#corge?grault'), 'foo')\n    lu.assertEquals(candidate('ftp://a.com:1234'), 'ftp')\n    lu.assertEquals(candidate('foo:bar:baz:qux'), 'foo')\n    lu.assertEquals(candidate('https:///'), 'https')\n    lu.assertEquals(candidate('ldap://example.com'), 'ldap')\n    lu.assertEquals(candidate('foo:bar:baz:qux?quux#corge?grault#garply'), 'foo')\n    lu.assertEquals(candidate('file://localhost/path/to/something.txt'), 'file')\n    lu.assertEquals(candidate('mailto:<EMAIL>'), 'mailto')\n    lu.assertEquals(candidate('https://foo.bar/baz'), 'https')\n    lu.assertEquals(candidate('https://example.com'), 'https')\n    lu.assertEquals(candidate('foo:bar:baz'), 'foo')\n    lu.assertEquals(candidate('http:///'), 'http')\n    lu.assertEquals(candidate('https://example.com:443'), 'https')\n    lu.assertEquals(candidate('http://a.com/'), 'http')\n    lu.assertEquals(candidate('foo:bar:baz:qux?quux'), 'foo')\n    lu.assertEquals(candidate('foo:bar:baz:qux?quux#corge'), 'foo')\n    lu.assertEquals(candidate('ftp://www.google.com/something?a=1'), 'ftp')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_107566_hour_min_sec", "language": "lua", "prompt": "-- Convert seconds into a more readable hh:mm:ss representation\n-- :secs Number of seconds\n-- :hms Hours:Minutes:Seconds representation, rather than the default seconds.\nlocal function hour_min_sec(secs, hms)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_107566_hour_min_sec.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = hour_min_sec\n    lu.assertEquals(candidate(86399), '23:59:59')\n    lu.assertEquals(candidate(10), '0:10')\n    lu.assertEquals(candidate(3601), '1:00:01')\n    lu.assertEquals(candidate(7200), '2:00:00')\n    lu.assertEquals(candidate(3660), '1:01:00')\n    lu.assertEquals(candidate(7199), '1:59:59')\n    lu.assertEquals(candidate(None), '_:__')\n    lu.assertEquals(candidate(100), '1:40')\n    lu.assertEquals(candidate(61), '1:01')\n    lu.assertEquals(candidate(3610), '1:00:10')\n    lu.assertEquals(candidate(3600), '1:00:00')\n    lu.assertEquals(candidate(3), '0:03')\n    lu.assertEquals(candidate(3721), '1:02:01')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_107578_preprocessText", "language": "lua", "prompt": "--     This script parses text and removes stop words\nlocal function preprocessText(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_107578_preprocessText.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = preprocessText\n    lu.assertEquals(candidate('hello @name?'), 'hello name')\n    lu.assertEquals(candidate('hello @name;'), 'hello name')\n    lu.assertEquals(candidate('hello @name/'), 'hello name')\n    lu.assertEquals(candidate('@'), '')\n    lu.assertEquals(candidate(\"I'm\"), 'im')\n    lu.assertEquals(candidate(\"I'll\"), 'ill')\n    lu.assertEquals(candidate('hello @name!'), 'hello name')\n    lu.assertEquals(candidate('hello @name_'), 'hello name')\n    lu.assertEquals(candidate('hello @name'), 'hello name')\n    lu.assertEquals(candidate('hello @name:'), 'hello name')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('hello @name+'), 'hello name')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_10767_regenerate_response", "language": "lua", "prompt": "-- Unique message generator.\n-- Args:\n--     db_entry (dict?): Stored response from the database that has already been created.\n-- Returns:\n--     JSON string which contains the message response\nlocal function regenerate_response(db_entry)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_10767_regenerate_response.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = regenerate_response\n    lu.assertEquals(candidate({['wallet_address'] = '0x12345', ['contract_address'] = '0x67890', ['tokenId'] = '3', ['random_str'] = '98765', ['message'] = 'Hello World!'}), {['wallet_address'] = '0x12345', ['contract_address'] = '0x67890', ['tokenId'] = '3', ['random_str'] = '98765', ['message'] = 'Hello World!'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_107867_bottom_up_partition_problem", "language": "lua", "prompt": "-- Parameters\n-- ----------\n-- numbers : list of integers\n-- Returns\n-- -------\n-- bool\n--     Boolean representing whether subsets exist which are equal to each other\n-- >>> bottom_up_partition_problem([1, 2, 3, 4])\n-- True\nlocal function bottom_up_partition_problem(numbers)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_107867_bottom_up_partition_problem.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = bottom_up_partition_problem\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6}), false)\n    lu.assertEquals(candidate(list(range(100, 0, -1))), true)\n    lu.assertEquals(candidate({1, 1, 1, 1, 5, 6}), false)\n    lu.assertEquals(candidate({2, 2, 1, 1}), true)\n    lu.assertEquals(candidate({1, 1, 3, 4, 5, 6}), true)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5}), false)\n    lu.assertEquals(candidate({10, 7, 8, 9}), true)\n    lu.assertEquals(candidate({1, 2, 3, 5}), false)\n    lu.assertEquals(candidate({1, 2, 3, 4}), true)\n    lu.assertEquals(candidate({100000}), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_108043_nearly_equal", "language": "lua", "prompt": "-- A helper function to determine whether two floats are nearly equal.\n-- Can be replaced by math.isclose in Py3\nlocal function nearly_equal(a, b, sig_fig)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_108043_nearly_equal.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = nearly_equal\n    lu.assertEquals(candidate(1e-09, 1e-09), true)\n    lu.assertEquals(candidate(0.123456789, 0.1234567891, 3), true)\n    lu.assertEquals(candidate(12345678900.0, 12345678900.0), true)\n    lu.assertEquals(candidate(0.12345, 0.12346, 7), false)\n    lu.assertEquals(candidate(0.123456789, 0.1234567891, 5), true)\n    lu.assertEquals(candidate(2.5, 2.5, 1), true)\n    lu.assertEquals(candidate(0.12345, 0.12346, 3), true)\n    lu.assertEquals(candidate(1e-09, 2e-09, 1), true)\n    lu.assertEquals(candidate(1.25, 1.25), true)\n    lu.assertEquals(candidate(1e-09, 2e-09, 0), true)\n    lu.assertEquals(candidate(1e-09, 2e-09, 5), true)\n    lu.assertEquals(candidate(2.5, 2.5, 3), true)\n    lu.assertEquals(candidate(1e-09, 1e-09, 5), true)\n    lu.assertEquals(candidate(0.12345, 0.12346, 6), false)\n    lu.assertEquals(candidate(2.5, 2.5, 1), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_10822_isIrrelevantManualRules", "language": "lua", "prompt": "-- Hand-crafted rules to remove paragraphs or entire documents from job advertisements\n-- :param s: String\n-- :param cdoc: List of parts of document (String)\n-- :returns: Boolean (ie. True if removal is needed), list of parts of documents (String), length of irrelevant parts\nlocal function isIrrelevantManualRules(s, cdoc)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_10822_isIrrelevantManualRules.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = isIrrelevantManualRules\n    lu.assertEquals(candidate('Job Responsibilities', {'Job Responsibilities', \"We're hiring\"}), {false, {'Job Responsibilities', \"We're hiring\"}, 0})\n    lu.assertEquals(candidate('Why Work with Us', {'About the Job', \"We're hiring\"}), {false, {'About the Job', \"We're hiring\"}, 0})\n    lu.assertEquals(candidate('What We Do', {'What We Do', \"We're hiring\"}), {false, {'What We Do', \"We're hiring\"}, 0})\n    lu.assertEquals(candidate('Why Work with Us', {'Why Work with Us', \"We're hiring\"}), {false, {'Why Work with Us', \"We're hiring\"}, 0})\n    lu.assertEquals(candidate('What We Offer', {'What We Offer', \"We're hiring\"}), {false, {'What We Offer', \"We're hiring\"}, 0})\n    lu.assertEquals(candidate('a b c d e f g h i j k l m n o p q r s t u v w x y z 1 2 3 4 5 6 7 8 9 0', {'1', '2', '3', '4', '5', '6', '7', '8', '9', '0'}), {false, {'1', '2', '3', '4', '5', '6', '7', '8', '9', '0'}, 0})\n    lu.assertEquals(candidate('What We Do', {'About the Job', \"We're hiring\"}), {false, {'About the Job', \"We're hiring\"}, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_109004_temp_to_str", "language": "lua", "prompt": "--     converts temperature from format 0.1 to format 0.100 by adding three places after decimal\nlocal function temp_to_str(temp)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_109004_temp_to_str.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = temp_to_str\n    lu.assertEquals(candidate(-12.345), '-12.345')\n    lu.assertEquals(candidate(0.001), '0.001')\n    lu.assertEquals(candidate(0.1), '0.100')\n    lu.assertEquals(candidate(0.01), '0.010')\n    lu.assertEquals(candidate(1.1), '1.100')\n    lu.assertEquals(candidate(123.456), '123.456')\n    lu.assertEquals(candidate(0.1), '0.100')\n    lu.assertEquals(candidate(2.0), '2.000')\n    lu.assertEquals(candidate(0.0), '0.000')\n    lu.assertEquals(candidate(12.345), '12.345')\n    lu.assertEquals(candidate(0.12), '0.120')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_109336_all_is_same", "language": "lua", "prompt": "--     Test that all elements in a vector are the same\nlocal function all_is_same(vec)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_109336_all_is_same.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = all_is_same\n    lu.assertEquals(candidate({1, 1}), true)\n    lu.assertEquals(candidate({1, 1, 1, 1, 1, 1, 1}), true)\n    lu.assertEquals(candidate({1, 1, 1}), true)\n    lu.assertEquals(candidate({}), true)\n    lu.assertEquals(candidate({1, 1, 1, 1, 1}), true)\n    lu.assertEquals(candidate({1}), true)\n    lu.assertEquals(candidate({1, 1, 1, 2}), false)\n    lu.assertEquals(candidate({1, 1, 1, 1, 1, 1}), true)\n    lu.assertEquals(candidate({1, 1, 1, 1}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_109878__to_initials", "language": "lua", "prompt": "--     Given a state, returns its initials\nlocal function _to_initials(state)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_109878__to_initials.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _to_initials\n    lu.assertEquals(candidate('American Samoa'), 'AS')\n    lu.assertEquals(candidate('Indiana'), 'IN')\n    lu.assertEquals(candidate('Guam'), 'GU')\n    lu.assertEquals(candidate('Georgia'), 'GA')\n    lu.assertEquals(candidate('Kentucky'), 'KY')\n    lu.assertEquals(candidate('Maryland'), 'MD')\n    lu.assertEquals(candidate('Alabama'), 'AL')\n    lu.assertEquals(candidate('Hawaii'), 'HI')\n    lu.assertEquals(candidate('Texas'), 'TX')\n    lu.assertEquals(candidate('Arizona'), 'AZ')\n    lu.assertEquals(candidate('Arkansas'), 'AR')\n    lu.assertEquals(candidate('Louisiana'), 'LA')\n    lu.assertEquals(candidate('Connecticut'), 'CT')\n    lu.assertEquals(candidate('Maine'), 'ME')\n    lu.assertEquals(candidate('Iowa'), 'IA')\n    lu.assertEquals(candidate('Florida'), 'FL')\n    lu.assertEquals(candidate('District of Columbia'), 'DC')\n    lu.assertEquals(candidate('Colorado'), 'CO')\n    lu.assertEquals(candidate('California'), 'CA')\n    lu.assertEquals(candidate('Alaska'), 'AK')\n    lu.assertEquals(candidate('Kansas'), 'KS')\n    lu.assertEquals(candidate('Delaware'), 'DE')\n    lu.assertEquals(candidate('Illinois'), 'IL')\n    lu.assertEquals(candidate('Idaho'), 'ID')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_110506_fish", "language": "lua", "prompt": "-- Transform a list of fish represented by their time-to-spawn state into a list of the\n-- number of fish in each state indexed by their time-to-spawn.\n-- Under this strategy, the example input [3, 4, 3, 1, 2] would be transformed into\n-- [0, 1, 1, 2, 1, 0, 0, 0, 0].\nlocal function fish(fs)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_110506_fish.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fish\n    lu.assertEquals(candidate(list()), {0, 0, 0, 0, 0, 0, 0, 0, 0})\n    lu.assertEquals(candidate({3, 4, 3, 1, 2}), {0, 1, 1, 2, 1, 0, 0, 0, 0})\n    lu.assertEquals(candidate({3, 4, 3, 1, 2}), {0, 1, 1, 2, 1, 0, 0, 0, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_110590_check_hcl", "language": "lua", "prompt": "-- >>> check_hcl(\"#333333\")\n-- True\n-- >>> check_hcl(\"#eeeee\")\n-- False\n-- >>> check_hcl(\"3eeeee\")\n-- False\nlocal function check_hcl(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_110590_check_hcl.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = check_hcl\n    lu.assertEquals(candidate('#123abc'), true)\n    lu.assertEquals(candidate('#333333'), true)\n    lu.assertEquals(candidate('#123abz'), false)\n    lu.assertEquals(candidate('eeeee'), false)\n    lu.assertEquals(candidate('#eeeee'), false)\n    lu.assertEquals(candidate('#eeeee'), false)\n    lu.assertEquals(candidate('123abc'), false)\n    lu.assertEquals(candidate('3eeeee'), false)\n    lu.assertEquals(candidate('#333333'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_110596_discretisation_length", "language": "lua", "prompt": "-- Returns the length of a linspace where there are N points with d intermediate (in-between) points.\nlocal function discretisation_length(N, d)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_110596_discretisation_length.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = discretisation_length\n    lu.assertEquals(candidate(5, 5), 25)\n    lu.assertEquals(candidate(1, 1), 1)\n    lu.assertEquals(candidate(2, 3), 5)\n    lu.assertEquals(candidate(3, 2), 7)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_11081_gcd_looping_with_divrem", "language": "lua", "prompt": "-- Computes the greatest common divisor of two numbers by getting remainder from division in a\n-- loop.\n-- :param int m: First number.\n-- :param int n: Second number.\n-- :returns: GCD as a number.\nlocal function gcd_looping_with_divrem(m, n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_11081_gcd_looping_with_divrem.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = gcd_looping_with_divrem\n    lu.assertEquals(candidate(100000, 1), 1)\n    lu.assertEquals(candidate(1, 3), 1)\n    lu.assertEquals(candidate(2, 5), 1)\n    lu.assertEquals(candidate(15, 5), 5)\n    lu.assertEquals(candidate(1, 7), 1)\n    lu.assertEquals(candidate(1, 6), 1)\n    lu.assertEquals(candidate(1, 1), 1)\n    lu.assertEquals(candidate(1, 100000), 1)\n    lu.assertEquals(candidate(2, 4), 2)\n    lu.assertEquals(candidate(2, 8), 2)\n    lu.assertEquals(candidate(10, 20), 10)\n    lu.assertEquals(candidate(1, 4), 1)\n    lu.assertEquals(candidate(2, 0), 2)\n    lu.assertEquals(candidate(1, 9), 1)\n    lu.assertEquals(candidate(42, 12), 6)\n    lu.assertEquals(candidate(2, 3), 1)\n    lu.assertEquals(candidate(2, 6), 2)\n    lu.assertEquals(candidate(3, 6), 3)\n    lu.assertEquals(candidate(20, 10), 10)\n    lu.assertEquals(candidate(3, 3), 3)\n    lu.assertEquals(candidate(5, 15), 5)\n    lu.assertEquals(candidate(1000, 900), 100)\n    lu.assertEquals(candidate(2, 7), 1)\n    lu.assertEquals(candidate(4, 3), 1)\n    lu.assertEquals(candidate(100000, 100000), 100000)\n    lu.assertEquals(candidate(10, 15), 5)\n    lu.assertEquals(candidate(1, 5), 1)\n    lu.assertEquals(candidate(2, 1), 1)\n    lu.assertEquals(candidate(1, 8), 1)\n    lu.assertEquals(candidate(2, 9), 1)\n    lu.assertEquals(candidate(15, 10), 5)\n    lu.assertEquals(candidate(5, 6), 1)\n    lu.assertEquals(candidate(10, 5), 5)\n    lu.assertEquals(candidate(1, 0), 1)\n    lu.assertEquals(candidate(2, 2), 2)\n    lu.assertEquals(candidate(3, 2), 1)\n    lu.assertEquals(candidate(1, 2), 1)\n    lu.assertEquals(candidate(10, 3), 1)\n    lu.assertEquals(candidate(12, 15), 3)\n    lu.assertEquals(candidate(5, 10), 5)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_110834_get_overlap", "language": "lua", "prompt": "--     report overlap of coordinates\nlocal function get_overlap(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_110834_get_overlap.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_overlap\n    lu.assertEquals(candidate({1, 5}, {8, 8}), 0)\n    lu.assertEquals(candidate({1, 5}, {7, 8}), 0)\n    lu.assertEquals(candidate({1, 5}, {3, 4}), 1)\n    lu.assertEquals(candidate({0, 2}, {1, 5}), 1)\n    lu.assertEquals(candidate({1, 4}, {4, 6}), 0)\n    lu.assertEquals(candidate({1, 5}, {6, 8}), 0)\n    lu.assertEquals(candidate({1, 3}, {3, 4}), 0)\n    lu.assertEquals(candidate({1, 4}, {2, 3}), 1)\n    lu.assertEquals(candidate({1, 4}, {-2, -1}), 0)\n    lu.assertEquals(candidate({3, 4}, {1, 3}), 0)\n    lu.assertEquals(candidate({1, 5}, {6, 7}), 0)\n    lu.assertEquals(candidate({2, 4}, {1, 3}), 1)\n    lu.assertEquals(candidate({3, 4}, {1, 5}), 1)\n    lu.assertEquals(candidate({1, 3}, {2, 4}), 1)\n    lu.assertEquals(candidate({4, 6}, {1, 4}), 0)\n    lu.assertEquals(candidate({-1, 0}, {0, 1}), 0)\n    lu.assertEquals(candidate({-1, -1}, {1, 4}), 0)\n    lu.assertEquals(candidate({2, 3}, {1, 4}), 1)\n    lu.assertEquals(candidate({1, 2}, {3, 4}), 0)\n    lu.assertEquals(candidate({1, 5}, {0, 2}), 1)\n    lu.assertEquals(candidate({5, 9}, {8, 11}), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_111495_scale_vars", "language": "lua", "prompt": "--     Scale a variable sequence.\nlocal function scale_vars(var_seq, scale)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_111495_scale_vars.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = scale_vars\n    lu.assertEquals(candidate(list(range(1, 6)), 5), {5, 10, 15, 20, 25})\n    lu.assertEquals(candidate({1, 2, 3}, 5), {5, 10, 15})\n    lu.assertEquals(candidate(list(range(1, 6)), 10), {10, 20, 30, 40, 50})\n    lu.assertEquals(candidate({1, 2, 3}, -1), {-1, -2, -3})\n    lu.assertEquals(candidate({1, 2, 3}, 10), {10, 20, 30})\n    lu.assertEquals(candidate({2, 3}, 4), {8, 12})\n    lu.assertEquals(candidate({1, 2, 3}, 0), {0, 0, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_1122_get_bit", "language": "lua", "prompt": "-- retrieve bit value from byte at provided index\nlocal function get_bit(byteval, index)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_1122_get_bit.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_bit\n    lu.assertEquals(candidate(254, 3), true)\n    lu.assertEquals(candidate(0, 5), false)\n    lu.assertEquals(candidate(0, 4), false)\n    lu.assertEquals(candidate(0, 1), false)\n    lu.assertEquals(candidate(2, 0), 0)\n    lu.assertEquals(candidate(0, 0), false)\n    lu.assertEquals(candidate(1, 5), false)\n    lu.assertEquals(candidate(0, 6), false)\n    lu.assertEquals(candidate(128, 1), false)\n    lu.assertEquals(candidate(254, 0), false)\n    lu.assertEquals(candidate(1, 1), false)\n    lu.assertEquals(candidate(0, 5), false)\n    lu.assertEquals(candidate(0, 2), false)\n    lu.assertEquals(candidate(2, 1), true)\n    lu.assertEquals(candidate(32, 0), false)\n    lu.assertEquals(candidate(1, 3), false)\n    lu.assertEquals(candidate(2, 0), false)\n    lu.assertEquals(candidate(128, 0), false)\n    lu.assertEquals(candidate(32, 1), false)\n    lu.assertEquals(candidate(0, 7), false)\n    lu.assertEquals(candidate(0, 0), false)\n    lu.assertEquals(candidate(0, 3), false)\n    lu.assertEquals(candidate(1, 0), true)\n    lu.assertEquals(candidate(2, 2), false)\n    lu.assertEquals(candidate(0, 6), false)\n    lu.assertEquals(candidate(254, 2), true)\n    lu.assertEquals(candidate(128, 7), 1)\n    lu.assertEquals(candidate(64, 0), false)\n    lu.assertEquals(candidate(255, 2), true)\n    lu.assertEquals(candidate(128, 7), true)\n    lu.assertEquals(candidate(2, 2), 0)\n    lu.assertEquals(candidate(1, 3), false)\n    lu.assertEquals(candidate(255, 1), true)\n    lu.assertEquals(candidate(2, 3), 0)\n    lu.assertEquals(candidate(0, 4), false)\n    lu.assertEquals(candidate(0, 7), false)\n    lu.assertEquals(candidate(16, 0), false)\n    lu.assertEquals(candidate(255, 5), true)\n    lu.assertEquals(candidate(4, 1), false)\n    lu.assertEquals(candidate(16, 1), false)\n    lu.assertEquals(candidate(1, 0), true)\n    lu.assertEquals(candidate(255, 6), true)\n    lu.assertEquals(candidate(0, 2), false)\n    lu.assertEquals(candidate(1, 2), false)\n    lu.assertEquals(candidate(1, 6), false)\n    lu.assertEquals(candidate(8, 0), false)\n    lu.assertEquals(candidate(254, 6), true)\n    lu.assertEquals(candidate(1, 4), false)\n    lu.assertEquals(candidate(254, 1), true)\n    lu.assertEquals(candidate(4, 0), false)\n    lu.assertEquals(candidate(0, 1), false)\n    lu.assertEquals(candidate(0, 3), false)\n    lu.assertEquals(candidate(255, 7), true)\n    lu.assertEquals(candidate(255, 3), true)\n    lu.assertEquals(candidate(2, 0), false)\n    lu.assertEquals(candidate(1, 0), 1)\n    lu.assertEquals(candidate(1, 7), false)\n    lu.assertEquals(candidate(8, 1), false)\n    lu.assertEquals(candidate(2, 1), true)\n    lu.assertEquals(candidate(1, 1), false)\n    lu.assertEquals(candidate(1, 2), false)\n    lu.assertEquals(candidate(254, 5), true)\n    lu.assertEquals(candidate(2, 3), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_112319_find_divisor", "language": "lua", "prompt": "-- Find all divisor of an integer\n-- Args:\n--     x (int)\n-- Returns:\n--     list: list of divisor\nlocal function find_divisor(x)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_112319_find_divisor.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = find_divisor\n    lu.assertEquals(candidate(1), {1})\n    lu.assertEquals(candidate(0), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_112396_process_args", "language": "lua", "prompt": "-- Basic kwarg handler to process input list of keyword arguments from the \n-- commandline and return a dictionary of values.\n-- Parameters\n-- ----------\n-- args : LIST\n--     List of kwargs from command line.\n-- Returns\n-- -------\n-- args_dict : DICT\n--     Dictionary of kwargs, split by '=' sign.\nlocal function process_args(args)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_112396_process_args.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = process_args\n    lu.assertEquals(candidate({'candidate', 'in_filename=test.csv'}), {['in_filename'] = 'test.csv'})\n    lu.assertEquals(candidate({'candidate', 'in_filename=test.csv', 'in_column=a', 'out_column=b'}), {['in_filename'] = 'test.csv', ['in_column'] = 'a', ['out_column'] = 'b'})\n    lu.assertEquals(candidate({'prog', 'a=b', 'c=d'}), {['a'] = 'b', ['c'] = 'd'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_11241_match_with_batchsize", "language": "lua", "prompt": "-- Function used by modify_datasets below to match return the integer closest to lim\n-- which is multiple of batchsize, i.e., lim%batchsize=0.\nlocal function match_with_batchsize(lim, batchsize)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_11241_match_with_batchsize.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = match_with_batchsize\n    lu.assertEquals(candidate(17, 4), 16)\n    lu.assertEquals(candidate(2, 1), 2)\n    lu.assertEquals(candidate(16, 2), 16)\n    lu.assertEquals(candidate(1, 1), 1)\n    lu.assertEquals(candidate(13, 4), 12)\n    lu.assertEquals(candidate(200, 100), 200)\n    lu.assertEquals(candidate(10, 1), 10)\n    lu.assertEquals(candidate(19, 4), 16)\n    lu.assertEquals(candidate(16, 4), 16)\n    lu.assertEquals(candidate(3, 6), 0)\n    lu.assertEquals(candidate(5, 5), 5)\n    lu.assertEquals(candidate(10, 6), 6)\n    lu.assertEquals(candidate(4, 2), 4)\n    lu.assertEquals(candidate(4, 4), 4)\n    lu.assertEquals(candidate(10, 3), 9)\n    lu.assertEquals(candidate(4, 1), 4)\n    lu.assertEquals(candidate(20, 4), 20)\n    lu.assertEquals(candidate(3, 1), 3)\n    lu.assertEquals(candidate(2, 2), 2)\n    lu.assertEquals(candidate(3, 3), 3)\n    lu.assertEquals(candidate(12, 4), 12)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_112930_numPointsInSpans", "language": "lua", "prompt": "-- >>> numPointsInSpans([(1, 3)])\n-- 3\n-- >>> numPointsInSpans([(1, 3), (5, 7)])\n-- 6\n-- >>> numPointsInSpans([(1, 3), (3, 5)])\n-- 5\n-- >>> numPointsInSpans([(1, 3), (2, 5)])\n-- 5\nlocal function numPointsInSpans(spans)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_112930_numPointsInSpans.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = numPointsInSpans\n    lu.assertEquals(candidate({{1, 3}, {3, 5}}), 5)\n    lu.assertEquals(candidate({{1, 3}, {5, 7}}), 6)\n    lu.assertEquals(candidate({{1, 3}}), 3)\n    lu.assertEquals(candidate({{1, 3}, {5, 7}}), 6)\n    lu.assertEquals(candidate({{1, 3}, {2, 5}}), 5)\n    lu.assertEquals(candidate({{1, 3}, {2, 5}}), 5)\n    lu.assertEquals(candidate({{1, 3}, {3, 5}}), 5)\n    lu.assertEquals(candidate({{1, 3}}), 3)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_113074_linearized_best_response", "language": "lua", "prompt": "-- A linearization of the best-response of the weights to some hyperparameter at some point.\n-- :param y: The hyperparameter to evaluate the linearization at.\n-- :return: The linearized best-response.\nlocal function linearized_best_response(y)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_113074_linearized_best_response.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = linearized_best_response\n    lu.assertEquals(candidate(0.5), -0.5)\n    lu.assertEquals(candidate(1.0), -1.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_113300__get_alignments_skipped_bad_char_rule", "language": "lua", "prompt": "-- Get the number of alignments that can be skipped according to bad\n-- character rule in Boyer Moore's exact matching algorithm\n-- >>> _get_alignments_skipped_bad_char_rule(\"C\", \"ATCTTTATCATA\")\n-- 3\n-- >>> _get_alignments_skipped_bad_char_rule(\"G\", \"ATCTTTATCATA\")\n-- 12\n-- >>> _get_alignments_skipped_bad_char_rule(\"T\", \"GTAGCGGC\")\n-- 6\n-- >>> _get_alignments_skipped_bad_char_rule(\"C\", \"GTAGC\")\n-- 0\n-- >>> _get_alignments_skipped_bad_char_rule(\"C\", \"GT\")\n-- 2\nlocal function _get_alignments_skipped_bad_char_rule(mismatched_char, pattern_prefix)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_113300__get_alignments_skipped_bad_char_rule.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _get_alignments_skipped_bad_char_rule\n    lu.assertEquals(candidate('G', 'ATCTTTATCATA'), 12)\n    lu.assertEquals(candidate('C', 'GTAGC'), 0)\n    lu.assertEquals(candidate('C', 'GTAGC'), 0)\n    lu.assertEquals(candidate('C', 'GT'), 2)\n    lu.assertEquals(candidate('T', 'GTAGCGGC'), 6)\n    lu.assertEquals(candidate('C', 'GT'), 2)\n    lu.assertEquals(candidate('T', 'GTAGCGGC'), 6)\n    lu.assertEquals(candidate('C', 'ATCTTTATCATA'), 3)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_113934_color_distance", "language": "lua", "prompt": "--  Compute absolute difference between 3-channels. \nlocal function color_distance(rgb1, rgb2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_113934_color_distance.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = color_distance\n    lu.assertEquals(candidate({255, 255, 255}, {254, 254, 254}), 3)\n    lu.assertEquals(candidate({255, 255, 255}, {254, 255, 254}), 2)\n    lu.assertEquals(candidate({0, 0, 0}, {0, 0, 0}), 0)\n    lu.assertEquals(candidate({255, 255, 255}, {255, 255, 255}), 0)\n    lu.assertEquals(candidate({255, 255, 255}, {255, 254, 255}), 1)\n    lu.assertEquals(candidate({0, 0, 0}, {0, 1, 2}), 3)\n    lu.assertEquals(candidate({255, 255, 255}, {255, 255, 254}), 1)\n    lu.assertEquals(candidate({255, 255, 255}, {254, 254, 255}), 2)\n    lu.assertEquals(candidate({10, 10, 10}, {10, 10, 10}), 0)\n    lu.assertEquals(candidate({255, 255, 255}, {254, 255, 255}), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_114068_format_value", "language": "lua", "prompt": "-- When scraping indexable content from the search API, we joined\n-- organisation and topic titles with pipes. Since we are combining\n-- all the columns together here we need to make sure these get treated as\n-- separate words.\nlocal function format_value(value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_114068_format_value.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = format_value\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('foo|bar'), 'foo bar')\n    lu.assertEquals(candidate('foo|bar|baz'), 'foo bar baz')\n    lu.assertEquals(candidate('A|B'), 'A B')\n    lu.assertEquals(candidate('Foo Bar'), 'Foo Bar')\n    lu.assertEquals(candidate('foo'), 'foo')\n    lu.assertEquals(candidate('Foo'), 'Foo')\n    lu.assertEquals(candidate('Foo|Bar|Baz'), 'Foo Bar Baz')\n    lu.assertEquals(candidate('Foo|Bar'), 'Foo Bar')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_114884_parse_duration", "language": "lua", "prompt": "-- Parses duration value string 'Xhr', 'Ymin' or 'Zsec' and returns (X::Y::Z) as seconds\nlocal function parse_duration(row)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_114884_parse_duration.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_duration\n    lu.assertEquals(candidate('6hr'), 21600)\n    lu.assertEquals(candidate('5min'), 300)\n    lu.assertEquals(candidate('1hr 30min'), 5400)\n    lu.assertEquals(candidate('6sec'), 6)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_114921_generate_wms_and_wfs_query_urls", "language": "lua", "prompt": "-- Generate WMS and WFS query URLs for individual data layers.\nlocal function generate_wms_and_wfs_query_urls(wms, wms_base, wfs, wfs_base)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_114921_generate_wms_and_wfs_query_urls.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = generate_wms_and_wfs_query_urls\n    lu.assertEquals(candidate({'1', '2'}, '{0}?request=GetCapabilities', {['3'] = '4'}, '{1}?service=WFS&version=1.0.0&request=GetFeature&typeName={0}&outputFormat=SHAPE-ZIP'), {'1?request=GetCapabilities', '2?request=GetCapabilities', '4?service=WFS&version=1.0.0&request=GetFeature&typeName=3&outputFormat=SHAPE-ZIP'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_115127_plusone", "language": "lua", "prompt": "-- add 1 to a\nlocal function plusone(a)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_115127_plusone.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = plusone\n    lu.assertEquals(candidate(3000), 3001)\n    lu.assertEquals(candidate(6), 7)\n    lu.assertEquals(candidate(10), 11)\n    lu.assertEquals(candidate(30), 31)\n    lu.assertEquals(candidate(3), 4)\n    lu.assertEquals(candidate(300000), 300001)\n    lu.assertEquals(candidate(5), 6)\n    lu.assertEquals(candidate(30000000000), 30000000001)\n    lu.assertEquals(candidate(8), 9)\n    lu.assertEquals(candidate(4), 5)\n    lu.assertEquals(candidate(-1), 0)\n    lu.assertEquals(candidate(3000000000), 3000000001)\n    lu.assertEquals(candidate(2), 3)\n    lu.assertEquals(candidate(3000000000000), 3000000000001)\n    lu.assertEquals(candidate(3000000), 3000001)\n    lu.assertEquals(candidate(1), 2)\n    lu.assertEquals(candidate(30000), 30001)\n    lu.assertEquals(candidate(300000000), 300000001)\n    lu.assertEquals(candidate(300), 301)\n    lu.assertEquals(candidate(30000000), 30000001)\n    lu.assertEquals(candidate(0), 1)\n    lu.assertEquals(candidate(300000000000), 300000000001)\n    lu.assertEquals(candidate(7), 8)\n    lu.assertEquals(candidate(9), 10)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_116084_trans", "language": "lua", "prompt": "-- transformation between 2 tiles\n-- [n,m] -> [n',m']\nlocal function trans(n, m)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_116084_trans.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = trans\n    lu.assertEquals(candidate(2, 5), {2, 5, false})\n    lu.assertEquals(candidate(0, 12), {0, 12, false})\n    lu.assertEquals(candidate(0, 0), {0, 0, false})\n    lu.assertEquals(candidate(0, 2), {0, 2, false})\n    lu.assertEquals(candidate(14, 2), {14, 2, false})\n    lu.assertEquals(candidate(0, 1), {0, 1, false})\n    lu.assertEquals(candidate(3, 5), {3, 5, false})\n    lu.assertEquals(candidate(1, 1), {0, 2, true})\n    lu.assertEquals(candidate(1, 0), {0, 1, false})\n    lu.assertEquals(candidate(4, 5), {4, 5, false})\n    lu.assertEquals(candidate(6, 2), {6, 2, false})\n    lu.assertEquals(candidate(3, 2), {3, 2, false})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_116189_convert_time", "language": "lua", "prompt": "--     Convert time into a years, hours, minute, seconds thing.\nlocal function convert_time(_time)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_116189_convert_time.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = convert_time\n    lu.assertEquals(candidate(172800), '2 days')\n    lu.assertEquals(candidate(0), '0 seconds')\n    lu.assertEquals(candidate(86399), '23 hours 59 minutes 59 seconds')\n    lu.assertEquals(candidate(3), '3 seconds')\n    lu.assertEquals(candidate(7200), '2 hours')\n    lu.assertEquals(candidate(0), '0 seconds')\n    lu.assertEquals(candidate(59), '59 seconds')\n    lu.assertEquals(candidate(120), '2 minutes')\n    lu.assertEquals(candidate(3599), '59 minutes 59 seconds')\n    lu.assertEquals(candidate(1209600), '2 weeks')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_116230_hash_function", "language": "lua", "prompt": "-- Hash function for calculating signature matrix\n-- :return hash number for each row number\nlocal function hash_function(num_row, a, b, m)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_116230_hash_function.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = hash_function\n    lu.assertEquals(candidate(3, 1, 3, 4), 2)\n    lu.assertEquals(candidate(4, 3, 1, 6), 1)\n    lu.assertEquals(candidate(10, 2, 5, 6), 1)\n    lu.assertEquals(candidate(7, 1, 1, 2), 0)\n    lu.assertEquals(candidate(4, 2, 5, 6), 1)\n    lu.assertEquals(candidate(1, 3, 1, 6), 4)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_117035_getR", "language": "lua", "prompt": "-- Returns the matrix R as in the canonical form [[Q,R],[0,I]]\n-- m is the input matrix, t is the list of the transient states,\n-- a is the list of the absorbing states.\nlocal function getR(m, t, a)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_117035_getR.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = getR\n    lu.assertEquals(candidate({{0, 1, 0}, {1, 0, 1}, {0, 1, 0}}, {0}, {1, 2}), {{1, 0}})\n    lu.assertEquals(candidate({{0, 1, 0}, {1, 0, 1}, {0, 1, 0}}, {}, {1, 2}), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_117164_PEER_cmd", "language": "lua", "prompt": "--     Command to execute PEER covariate correction. Be sure to use r-4.0.3\nlocal function PEER_cmd(PEER_exec_path, phenotype_file, covariates_file, num_peer, output_prefix, output_dir)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_117164_PEER_cmd.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = PEER_cmd\n    lu.assertEquals(candidate('peer.R', 'peer_test_phenotype_file.txt', 'peer_test_covariates_file.txt', 100, 'peer_test_output_prefix', 'peer_test_output_dir'), 'time Rscript peer.R peer_test_phenotype_file.txt peer_test_output_prefix 100 -o peer_test_output_dir --covariates peer_test_covariates_file.txt')\n    lu.assertEquals(candidate('/home/user/PEER/PEER/peer.R', '/home/user/PEER/PEER/peer_example/pheno1.csv', '/home/user/PEER/PEER/peer_example/covar1.csv', 10, '10_peer', '/home/user/PEER/PEER/peer_example/out'), 'time Rscript /home/user/PEER/PEER/peer.R /home/user/PEER/PEER/peer_example/pheno1.csv 10_peer 10 -o /home/user/PEER/PEER/peer_example/out --covariates /home/user/PEER/PEER/peer_example/covar1.csv')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_117496_is_leap", "language": "lua", "prompt": "--  https://stackoverflow.com/a/30714165 \nlocal function is_leap(year)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_117496_is_leap.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_leap\n    lu.assertEquals(candidate(2019), false)\n    lu.assertEquals(candidate(2401), false)\n    lu.assertEquals(candidate(1900), false)\n    lu.assertEquals(candidate(2012), true)\n    lu.assertEquals(candidate(2100), false)\n    lu.assertEquals(candidate(2800), true)\n    lu.assertEquals(candidate(1988), true)\n    lu.assertEquals(candidate(1999), false)\n    lu.assertEquals(candidate(2801), false)\n    lu.assertEquals(candidate(2021), false)\n    lu.assertEquals(candidate(2900), false)\n    lu.assertEquals(candidate(2004), true)\n    lu.assertEquals(candidate(2001), false)\n    lu.assertEquals(candidate(2400), true)\n    lu.assertEquals(candidate(3000), false)\n    lu.assertEquals(candidate(2000), true)\n    lu.assertEquals(candidate(2008), true)\n    lu.assertEquals(candidate(2020), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_118038__textTypeForDefStyleName", "language": "lua", "prompt": "--  ' ' for code\n-- 'c' for comments\n-- 'b' for block comments\n-- 'h' for here documents\nlocal function _textTypeForDefStyleName(attribute, defStyleName)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_118038__textTypeForDefStyleName.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _textTypeForDefStyleName\n    lu.assertEquals(candidate('string', 'dsString'), 's')\n    lu.assertEquals(candidate('char', 'dsChar'), 's')\n    lu.assertEquals(candidate('comment', 'dsComment'), 'c')\n    lu.assertEquals(candidate('block', 'dsComment'), 'b')\n    lu.assertEquals(candidate('here', 'dsOthers'), 'h')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_118563_parse_centrifuge", "language": "lua", "prompt": "-- Parse a line in a Centrifuge mapping file.\n-- Parameters\n-- ----------\n-- line : str\n--     Line to parse.\n-- Returns\n-- -------\n-- tuple of (str, str, int, int)\n--     Query, subject, score, length.\n-- Notes\n-- -----\n-- Centrifuge output format:\n--     readID, seqID, taxID, score, 2ndBestScore, hitLength, queryLength,\n--     numMatches\n-- .. _Centrifuge manual:\n--     https://ccb.jhu.edu/software/centrifuge/manual.shtml\nlocal function parse_centrifuge(line)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_118563_parse_centrifuge.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_centrifuge\n    lu.assertEquals(candidate('readID,seqID,taxID,score,2ndBestScore,hitLength,queryLength,numMatches'), None)\n    lu.assertEquals(candidate('1\\tseq1\\t1\\t500\\t2\\t1000\\t2000\\t3'), {'1', 'seq1', 500, 1000})\n    lu.assertEquals(candidate('read1\\tseq2\\t1\\t123\\t456\\t100\\t200\\t3'), {'read1', 'seq2', 123, 100})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_118723_replace_newlines", "language": "lua", "prompt": "--     remove newlines\nlocal function replace_newlines(html_str)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_118723_replace_newlines.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = replace_newlines\n    lu.assertEquals(candidate('<html><body><p>This is a paragraph.</p> This is another.</body></html>'), '<html><body><p>This is a paragraph.</p> This is another.</body></html>')\n    lu.assertEquals(candidate('<html><head><title>test</title></head><body>test\\n1</body></html>'), '<html><head><title>test</title></head><body>test\\n1</body></html>')\n    lu.assertEquals(candidate('<html><head><title>test</title></head><body>test\\n1\\n2\\n3\\n4\\n5</body></html>'), '<html><head><title>test</title></head><body>test\\n1\\n2\\n3\\n4\\n5</body></html>')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_119408_get_content_type", "language": "lua", "prompt": "-- getting content_type via file_type.\n-- :param file_extension\n-- :return: content_type\nlocal function get_content_type(file_extension)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_119408_get_content_type.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_content_type\n    lu.assertEquals(candidate('jpg'), 'image/jpeg')\n    lu.assertEquals(candidate('jpeg'), 'image/jpeg')\n    lu.assertEquals(candidate('docx'), 'application/vnd.openxmlformats-officedocument.wordprocessingml.document')\n    lu.assertEquals(candidate('png'), 'image/png')\n    lu.assertEquals(candidate('doc'), 'application/msword')\n    lu.assertEquals(candidate('bmp'), 'image/bmp')\n    lu.assertEquals(candidate('pdf'), 'application/pdf')\n    lu.assertEquals(candidate('text'), 'text/plain')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_120250_is_contained_in", "language": "lua", "prompt": "-- Is the first region contained in the second.\n-- :param frst: a tuple representing the first region\n--              with chromosome, start, end as the first\n--              3 columns\n-- :param scnd: a tuple representing the second region\n--              with chromosome, start, end as the first\n--              3 columns\n-- :return: True or False\nlocal function is_contained_in(frst, scnd)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_120250_is_contained_in.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_contained_in\n    lu.assertEquals(candidate({'chr1', 1, 100}, {'chr1', 1, 150}), true)\n    lu.assertEquals(candidate({'1', 10, 15}, {'1', 10, 20}), true)\n    lu.assertEquals(candidate({'1', 0, 2}, {'1', 0, 1}), false)\n    lu.assertEquals(candidate({'chr1', 1, 100}, {'chr1', 50, 150}), false)\n    lu.assertEquals(candidate({'1', 10, 15}, {'1', 12, 16}), false)\n    lu.assertEquals(candidate({'1', 0, 1}, {'1', 0, 1}), true)\n    lu.assertEquals(candidate({'chr1', 1, 100}, {'chr1', 1, 200}), true)\n    lu.assertEquals(candidate({'1', 10, 15}, {'1', 9, 9}), false)\n    lu.assertEquals(candidate({'1', 10, 15}, {'1', 15, 16}), false)\n    lu.assertEquals(candidate({'1', 10, 15}, {'1', 9, 14}), false)\n    lu.assertEquals(candidate({'1', 10, 15}, {'1', 9, 8}), false)\n    lu.assertEquals(candidate({'1', 10, 15}, {'1', 15, 15}), false)\n    lu.assertEquals(candidate({'1', 10, 15}, {'1', 16, 16}), false)\n    lu.assertEquals(candidate({'1', 0, 1}, {'2', 0, 2}), false)\n    lu.assertEquals(candidate({'1', 0, 2}, {'1', 0, 2}), true)\n    lu.assertEquals(candidate({'1', 0, 2}, {'1', 1, 2}), false)\n    lu.assertEquals(candidate({'1', 10, 15}, {'1', 10, 15}), true)\n    lu.assertEquals(candidate({'1', 0, 1}, {'1', 0, 2}), true)\n    lu.assertEquals(candidate({'1', 10, 15}, {'1', 10, 10}), false)\n    lu.assertEquals(candidate({'chr2', 1, 100}, {'chr1', 1, 100}), false)\n    lu.assertEquals(candidate({'chr1', 1, 100}, {'chr1', 1, 100}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_120570_IsEven", "language": "lua", "prompt": "-- Returns a Z3 condition for if an Int is even\nlocal function IsEven(i)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_120570_IsEven.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = IsEven\n    lu.assertEquals(candidate(-1), false)\n    lu.assertEquals(candidate(4), true)\n    lu.assertEquals(candidate(5), false)\n    lu.assertEquals(candidate(-2), true)\n    lu.assertEquals(candidate(8), true)\n    lu.assertEquals(candidate(2), true)\n    lu.assertEquals(candidate(1), false)\n    lu.assertEquals(candidate(7), false)\n    lu.assertEquals(candidate(9), false)\n    lu.assertEquals(candidate(6), true)\n    lu.assertEquals(candidate(0), true)\n    lu.assertEquals(candidate(3), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_120905_fibonacci", "language": "lua", "prompt": "-- Method that prints the fibonacci sequence until the n-th number\nlocal function fibonacci(n_terms)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_120905_fibonacci.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fibonacci\n    lu.assertEquals(candidate(12), 144)\n    lu.assertEquals(candidate(2), 1)\n    lu.assertEquals(candidate(13), 233)\n    lu.assertEquals(candidate(24), 46368)\n    lu.assertEquals(candidate(16), 987)\n    lu.assertEquals(candidate(25), 75025)\n    lu.assertEquals(candidate(20), 6765)\n    lu.assertEquals(candidate(28), 317811)\n    lu.assertEquals(candidate(11), 89)\n    lu.assertEquals(candidate(29), 514229)\n    lu.assertEquals(candidate(30), 832040)\n    lu.assertEquals(candidate(19), 4181)\n    lu.assertEquals(candidate(3), 2)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(18), 2584)\n    lu.assertEquals(candidate(5), 5)\n    lu.assertEquals(candidate(4), 3)\n    lu.assertEquals(candidate(8), 21)\n    lu.assertEquals(candidate(21), 10946)\n    lu.assertEquals(candidate(15), 610)\n    lu.assertEquals(candidate(9), 34)\n    lu.assertEquals(candidate(10), 55)\n    lu.assertEquals(candidate(6), 8)\n    lu.assertEquals(candidate(7), 13)\n    lu.assertEquals(candidate(22), 17711)\n    lu.assertEquals(candidate(14), 377)\n    lu.assertEquals(candidate(23), 28657)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(26), 121393)\n    lu.assertEquals(candidate(27), 196418)\n    lu.assertEquals(candidate(17), 1597)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_121456__GenerateMakePrivateGetter", "language": "lua", "prompt": "-- Internal helper method to actually get the data. It calls the DLL and passes the correct data to it.\n-- It then returns that value back to ML.NET.\nlocal function _GenerateMakePrivateGetter(return_type, variable_names, function_name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_121456__GenerateMakePrivateGetter.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _GenerateMakePrivateGetter\n    lu.assertEquals(candidate('System.Single', {'x'}, 'Foo'), '\\n\\nprivate Delegate MakeGetter(DataViewRow input, int iinfo)\\n{\\nValueGetter<System.Single> result = (ref System.Single dst) =>\\n{\\nvar xVal =  _parent._x.GetValue(input);\\ndst = Foo(xVal);\\n};\\n\\nreturn result;\\n}')\n    lu.assertEquals(candidate('System.Single', {'x', 'y', 'z'}, 'Foo'), '\\n\\nprivate Delegate MakeGetter(DataViewRow input, int iinfo)\\n{\\nValueGetter<System.Single> result = (ref System.Single dst) =>\\n{\\nvar xVal =  _parent._x.GetValue(input);\\nvar yVal =  _parent._y.GetValue(input);\\nvar zVal =  _parent._z.GetValue(input);\\ndst = Foo(xVal, yVal, zVal);\\n};\\n\\nreturn result;\\n}')\n    lu.assertEquals(candidate('System.Single', {'x', 'y'}, 'Foo'), '\\n\\nprivate Delegate MakeGetter(DataViewRow input, int iinfo)\\n{\\nValueGetter<System.Single> result = (ref System.Single dst) =>\\n{\\nvar xVal =  _parent._x.GetValue(input);\\nvar yVal =  _parent._y.GetValue(input);\\ndst = Foo(xVal, yVal);\\n};\\n\\nreturn result;\\n}')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_121971_months_of_gregorian_calendar", "language": "lua", "prompt": "-- Months of the Gregorian calendar.\n-- Parameters\n-- ----------\n-- year : int, optional\n--     (dummy value).\n-- Returns\n-- -------\n-- out : dict\n--     integers as keys, months of the Gregorian calendar as values.\n-- Notes\n-- -----\n-- Appropriate for use as 'year_cycles' function in :class:`Calendar`.\n-- This module has a built-in calendar with months only:\n-- :data:`CalMonthsOnly`.\nlocal function months_of_gregorian_calendar(year)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_121971_months_of_gregorian_calendar.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = months_of_gregorian_calendar\n    lu.assertEquals(candidate(2000), {[1] = 'January', [2] = 'February', [3] = 'March', [4] = 'April', [5] = 'May', [6] = 'June', [7] = 'July', [8] = 'August', [9] = 'September', [10] = 'October', [11] = 'November', [12] = 'December'})\n    lu.assertEquals(candidate(2009), {[1] = 'January', [2] = 'February', [3] = 'March', [4] = 'April', [5] = 'May', [6] = 'June', [7] = 'July', [8] = 'August', [9] = 'September', [10] = 'October', [11] = 'November', [12] = 'December'})\n    lu.assertEquals(candidate(2020), {[1] = 'January', [2] = 'February', [3] = 'March', [4] = 'April', [5] = 'May', [6] = 'June', [7] = 'July', [8] = 'August', [9] = 'September', [10] = 'October', [11] = 'November', [12] = 'December'})\n    lu.assertEquals(candidate(1999), {[1] = 'January', [2] = 'February', [3] = 'March', [4] = 'April', [5] = 'May', [6] = 'June', [7] = 'July', [8] = 'August', [9] = 'September', [10] = 'October', [11] = 'November', [12] = 'December'})\n    lu.assertEquals(candidate(2002), {[1] = 'January', [2] = 'February', [3] = 'March', [4] = 'April', [5] = 'May', [6] = 'June', [7] = 'July', [8] = 'August', [9] = 'September', [10] = 'October', [11] = 'November', [12] = 'December'})\n    lu.assertEquals(candidate(2001), {[1] = 'January', [2] = 'February', [3] = 'March', [4] = 'April', [5] = 'May', [6] = 'June', [7] = 'July', [8] = 'August', [9] = 'September', [10] = 'October', [11] = 'November', [12] = 'December'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_122909_limit_count", "language": "lua", "prompt": "-- Handling of the optional \"count\" parameter, common in many commands.\n-- Parameters:\n--   - count     -- desired number of elements\n--   - on_device -- number of elements on device\n-- If count is None or 0 return what's on device\n-- If count > 0 use count, unless it is more than what's on device. \n-- If count < 0 that means \"abs(count) less than what's on device\n-- Typical usage: \n--    count = limit_count(count, mc.mgrp_get_count())\nlocal function limit_count(count, on_device)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_122909_limit_count.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = limit_count\n    lu.assertEquals(candidate(-10, -10), 0)\n    lu.assertEquals(candidate(-2, 0), 0)\n    lu.assertEquals(candidate(3, 0), 0)\n    lu.assertEquals(candidate(None, 2), 2)\n    lu.assertEquals(candidate(10, 10), 10)\n    lu.assertEquals(candidate(None, 1), 1)\n    lu.assertEquals(candidate(None, 0), 0)\n    lu.assertEquals(candidate(0, -10), 0)\n    lu.assertEquals(candidate(3, 2), 2)\n    lu.assertEquals(candidate(-3, 1), 0)\n    lu.assertEquals(candidate(1, 10), 1)\n    lu.assertEquals(candidate(-1, 0), 0)\n    lu.assertEquals(candidate(3, 1), 1)\n    lu.assertEquals(candidate(10, 0), 0)\n    lu.assertEquals(candidate(None, 10), 10)\n    lu.assertEquals(candidate(-1, 10), 9)\n    lu.assertEquals(candidate(-3, 2), 0)\n    lu.assertEquals(candidate(-10, 10), 0)\n    lu.assertEquals(candidate(0, 0), 0)\n    lu.assertEquals(candidate(-2, 2), 0)\n    lu.assertEquals(candidate(1, 0), 0)\n    lu.assertEquals(candidate(None, 5), 5)\n    lu.assertEquals(candidate(2, 2), 2)\n    lu.assertEquals(candidate(10, 1), 1)\n    lu.assertEquals(candidate(-1, 2), 1)\n    lu.assertEquals(candidate(2, 0), 0)\n    lu.assertEquals(candidate(-3, 0), 0)\n    lu.assertEquals(candidate(2, 1), 1)\n    lu.assertEquals(candidate(10, 5), 5)\n    lu.assertEquals(candidate(1, 1), 1)\n    lu.assertEquals(candidate(-2, 1), 0)\n    lu.assertEquals(candidate(10, 2), 2)\n    lu.assertEquals(candidate(1, 2), 1)\n    lu.assertEquals(candidate(-10, 0), 0)\n    lu.assertEquals(candidate(0, -5), 0)\n    lu.assertEquals(candidate(-5, 0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_122974_distManhattan", "language": "lua", "prompt": "--  calcule la distance de Manhattan entre le tuple \n-- p1 et le tuple p2\nlocal function distManhattan(p1, p2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_122974_distManhattan.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = distManhattan\n    lu.assertEquals(candidate({1, 1}, {0, 0}), 2)\n    lu.assertEquals(candidate({-1, -1}, {-1, -1}), 0)\n    lu.assertEquals(candidate({0, 0}, {1, 2}), 3)\n    lu.assertEquals(candidate({-1, -1}, {1, -1}), 2)\n    lu.assertEquals(candidate({-1, 0}, {0, -1}), 2)\n    lu.assertEquals(candidate({-1, -1}, {1, 1}), 4)\n    lu.assertEquals(candidate({1, 1}, {1, 1}), 0)\n    lu.assertEquals(candidate({0, 0}, {1, 1}), 2)\n    lu.assertEquals(candidate({-1, 1}, {1, 1}), 2)\n    lu.assertEquals(candidate({1, 1}, {-1, -1}), 4)\n    lu.assertEquals(candidate({1, 0}, {0, 1}), 2)\n    lu.assertEquals(candidate({-2, 0}, {2, 0}), 4)\n    lu.assertEquals(candidate({0, 0}, {3, 3}), 6)\n    lu.assertEquals(candidate({1, 1}, {-1, -1}), 4)\n    lu.assertEquals(candidate({0, 0}, {-1, -1}), 2)\n    lu.assertEquals(candidate({0, 0}, {3, 4}), 7)\n    lu.assertEquals(candidate({0, 0}, {-1, -1}), 2)\n    lu.assertEquals(candidate({0, 0}, {1, 1}), 2)\n    lu.assertEquals(candidate({100, 100}, {0, 0}), 200)\n    lu.assertEquals(candidate({0, 0}, {0, 1}), 1)\n    lu.assertEquals(candidate({0, 0}, {100, 100}), 200)\n    lu.assertEquals(candidate({1, 1}, {0, 0}), 2)\n    lu.assertEquals(candidate({0, 0}, {0, 0}), 0)\n    lu.assertEquals(candidate({0, 0}, {-2, -2}), 4)\n    lu.assertEquals(candidate({1, 1}, {2, 2}), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_123440_is_power_of_2", "language": "lua", "prompt": "-- Returns True if an integer is a power of 2. Only works for x > 0.\nlocal function is_power_of_2(val)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_123440_is_power_of_2.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_power_of_2\n    lu.assertEquals(candidate(4), true)\n    lu.assertEquals(candidate(17), false)\n    lu.assertEquals(candidate(26), false)\n    lu.assertEquals(candidate(6), false)\n    lu.assertEquals(candidate(22), false)\n    lu.assertEquals(candidate(25), false)\n    lu.assertEquals(candidate(7), false)\n    lu.assertEquals(candidate(1), true)\n    lu.assertEquals(candidate(14), false)\n    lu.assertEquals(candidate(10), false)\n    lu.assertEquals(candidate(65), false)\n    lu.assertEquals(candidate(18), false)\n    lu.assertEquals(candidate(21), false)\n    lu.assertEquals(candidate(11), false)\n    lu.assertEquals(candidate(2), true)\n    lu.assertEquals(candidate(15), false)\n    lu.assertEquals(candidate(13), false)\n    lu.assertEquals(candidate(16), true)\n    lu.assertEquals(candidate(12), false)\n    lu.assertEquals(candidate(23), false)\n    lu.assertEquals(candidate(27), false)\n    lu.assertEquals(candidate(19), false)\n    lu.assertEquals(candidate(9), false)\n    lu.assertEquals(candidate(8), true)\n    lu.assertEquals(candidate(64), true)\n    lu.assertEquals(candidate(5), false)\n    lu.assertEquals(candidate(3), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_123581_htmlentities", "language": "lua", "prompt": "-- Escape chars in the text for HTML presentation\n-- Args:\n--   text (str): subject to replace\n-- Returns:\n--   str : result of replacement\nlocal function htmlentities(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_123581_htmlentities.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = htmlentities\n    lu.assertEquals(candidate('>'), '&gt;')\n    lu.assertEquals(candidate('a < b'), 'a &lt; b')\n    lu.assertEquals(candidate('<'), '&lt;')\n    lu.assertEquals(candidate('\"'), '&quot;')\n    lu.assertEquals(candidate('Testing & testing'), 'Testing &amp; testing')\n    lu.assertEquals(candidate('Testing & testing > testing < testing'), 'Testing &amp; testing &gt; testing &lt; testing')\n    lu.assertEquals(candidate('a & b'), 'a &amp; b')\n    lu.assertEquals(candidate('I have a new line of text\\n'), 'I have a new line of text\\n')\n    lu.assertEquals(candidate('a > b'), 'a &gt; b')\n    lu.assertEquals(candidate('&'), '&amp;')\n    lu.assertEquals(candidate(\"'\"), '&#39;')\n    lu.assertEquals(candidate('I have a new line of text'), 'I have a new line of text')\n    lu.assertEquals(candidate('Testing'), 'Testing')\n    lu.assertEquals(candidate('Testing & testing > testing <'), 'Testing &amp; testing &gt; testing &lt;')\n    lu.assertEquals(candidate('a \" b'), 'a &quot; b')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_123984_decimal_to_hexadecimal", "language": "lua", "prompt": "-- Return hexadecimal version of the specified decimal number.\nlocal function decimal_to_hexadecimal(number)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_123984_decimal_to_hexadecimal.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = decimal_to_hexadecimal\n    lu.assertEquals(candidate(7), '7')\n    lu.assertEquals(candidate(5), '5')\n    lu.assertEquals(candidate(10), 'a')\n    lu.assertEquals(candidate(3), '3')\n    lu.assertEquals(candidate(15), 'f')\n    lu.assertEquals(candidate(257), '101')\n    lu.assertEquals(candidate(1), '1')\n    lu.assertEquals(candidate(32767), '7fff')\n    lu.assertEquals(candidate(255), 'ff')\n    lu.assertEquals(candidate(0), '0')\n    lu.assertEquals(candidate(25), '19')\n    lu.assertEquals(candidate(255), 'ff')\n    lu.assertEquals(candidate(10), 'a')\n    lu.assertEquals(candidate(12345), '3039')\n    lu.assertEquals(candidate(11), 'b')\n    lu.assertEquals(candidate(100), '64')\n    lu.assertEquals(candidate(16), '10')\n    lu.assertEquals(candidate(256), '100')\n    lu.assertEquals(candidate(174), 'ae')\n    lu.assertEquals(candidate(0), '0')\n    lu.assertEquals(candidate(256), '100')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_12403_degrees_to_meters", "language": "lua", "prompt": "-- 111195 = (Earth mean radius)*PI/180\n-- (supposedly 'maximum error using this method is ~ 0.1%')\n-- :see: https://stackoverflow.com/questions/12204834/get-distance-in-meters-instead-of-degrees-in-spatialite\nlocal function degrees_to_meters(degrees)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_12403_degrees_to_meters.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = degrees_to_meters\n    lu.assertEquals(candidate(6), 667170)\n    lu.assertEquals(candidate(10000), 1111950000)\n    lu.assertEquals(candidate(3), 333585)\n    lu.assertEquals(candidate(10), 1111950)\n    lu.assertEquals(candidate(5), 555975)\n    lu.assertEquals(candidate(4), 444780)\n    lu.assertEquals(candidate(1), 111195)\n    lu.assertEquals(candidate(1000), 111195000)\n    lu.assertEquals(candidate(100000), 11119500000)\n    lu.assertEquals(candidate(100), 11119500)\n    lu.assertEquals(candidate(2), 222390)\n    lu.assertEquals(candidate(0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_125020__is_temp_garbage", "language": "lua", "prompt": "-- Is this a Microsoft Office temp file?\nlocal function _is_temp_garbage(filename)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_125020__is_temp_garbage.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _is_temp_garbage\n    lu.assertEquals(candidate('c:\\\\users\\\\someone\\\\somefile.docx~123.tmp'), true)\n    lu.assertEquals(candidate('c:\\\\users\\\\someone\\\\somefile.docx~123.tmp~123'), false)\n    lu.assertEquals(candidate('c:\\\\users\\\\someone\\\\somefile.docx~1'), false)\n    lu.assertEquals(candidate('c:\\\\users\\\\someone\\\\somefile.docx.tmp'), true)\n    lu.assertEquals(candidate('c:\\\\users\\\\someone\\\\somefile.docx~123'), false)\n    lu.assertEquals(candidate('c:\\\\users\\\\someone\\\\somefile.docx~123.tmp~123.tmp'), true)\n    lu.assertEquals(candidate('c:\\\\users\\\\someone\\\\somefile.docx'), false)\n    lu.assertEquals(candidate('c:\\\\users\\\\someone\\\\~somefile.docx'), false)\n    lu.assertEquals(candidate('c:\\\\users\\\\someone\\\\somefile.docx~123.tmp~'), false)\n    lu.assertEquals(candidate('c:\\\\users\\\\someone\\\\somefile.docx~'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_125164_debugsquare", "language": "lua", "prompt": "-- Return x squared but also print a debug value of x.\nlocal function debugsquare(x)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_125164_debugsquare.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = debugsquare\n    lu.assertEquals(candidate(-2), 4)\n    lu.assertEquals(candidate(4), 16)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(5), 25)\n    lu.assertEquals(candidate(3), 9)\n    lu.assertEquals(candidate(2), 4)\n    lu.assertEquals(candidate(12), 144)\n    lu.assertEquals(candidate(10), 100)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_125500_cmds_to_bash", "language": "lua", "prompt": "-- Turn a list of cmds into a bash script.\nlocal function cmds_to_bash(cmds)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_125500_cmds_to_bash.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = cmds_to_bash\n    lu.assertEquals(candidate({'echo hello', 'echo world'}), '#!/bin/bash\\nset -vexubE -o pipefail\\necho hello\\necho world\\n')\n    lu.assertEquals(candidate({'echo hello world'}), '#!/bin/bash\\nset -vexubE -o pipefail\\necho hello world\\n')\n    lu.assertEquals(candidate({'set -ex', 'echo hello world'}), '#!/bin/bash\\nset -vexubE -o pipefail\\nset -ex\\necho hello world\\n')\n    lu.assertEquals(candidate({'a', 'b c'}), '#!/bin/bash\\nset -vexubE -o pipefail\\na\\nb c\\n')\n    lu.assertEquals(candidate({}), '#!/bin/bash\\nset -vexubE -o pipefail\\n\\n')\n    lu.assertEquals(candidate({'ls', 'non-existent', 'file'}), '#!/bin/bash\\nset -vexubE -o pipefail\\nls\\nnon-existent\\nfile\\n')\n    lu.assertEquals(candidate({'set -v', 'echo hello world'}), '#!/bin/bash\\nset -vexubE -o pipefail\\nset -v\\necho hello world\\n')\n    lu.assertEquals(candidate({'set -u', 'echo hello world'}), '#!/bin/bash\\nset -vexubE -o pipefail\\nset -u\\necho hello world\\n')\n    lu.assertEquals(candidate({'do a thing', 'do another thing'}), '#!/bin/bash\\nset -vexubE -o pipefail\\ndo a thing\\ndo another thing\\n')\n    lu.assertEquals(candidate({\"echo hello 'world'\", 'echo hello $var'}), \"#!/bin/bash\\nset -vexubE -o pipefail\\necho hello 'world'\\necho hello $var\\n\")\n    lu.assertEquals(candidate({'set -e', 'echo hello world'}), '#!/bin/bash\\nset -vexubE -o pipefail\\nset -e\\necho hello world\\n')\n    lu.assertEquals(candidate({'set -x', 'echo hello world'}), '#!/bin/bash\\nset -vexubE -o pipefail\\nset -x\\necho hello world\\n')\n    lu.assertEquals(candidate({'do a thing', 'do another thing'}), '#!/bin/bash\\nset -vexubE -o pipefail\\ndo a thing\\ndo another thing\\n')\n    lu.assertEquals(candidate({'a', 'b c | d'}), '#!/bin/bash\\nset -vexubE -o pipefail\\na\\nb c | d\\n')\n    lu.assertEquals(candidate({'echo \"hello\"', 'grep f', 'cat out.txt'}), '#!/bin/bash\\nset -vexubE -o pipefail\\necho \"hello\"\\ngrep f\\ncat out.txt\\n')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_125653_reverse_number", "language": "lua", "prompt": "--     Reverse a number.\nlocal function reverse_number(num)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_125653_reverse_number.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = reverse_number\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(123), 321)\n    lu.assertEquals(candidate(981), 189)\n    lu.assertEquals(candidate(1234), 4321)\n    lu.assertEquals(candidate(1000), 1)\n    lu.assertEquals(candidate(321), 123)\n    lu.assertEquals(candidate(12), 21)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(23), 32)\n    lu.assertEquals(candidate(100), 1)\n    lu.assertEquals(candidate(10), 1)\n    lu.assertEquals(candidate(999), 999)\n    lu.assertEquals(candidate(500), 5)\n    lu.assertEquals(candidate(123456789), 987654321)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_125811_compare_bits", "language": "lua", "prompt": "-- Subtract 2D list to determine changes to bit state.\nlocal function compare_bits(olds, news)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_125811_compare_bits.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = compare_bits\n    lu.assertEquals(candidate({{1, 1}, {1, 1}}, {{1, 1}, {1, 1}}), {{0, 0}, {0, 0}})\n    lu.assertEquals(candidate({{0, 0, 0}, {0, 0, 0}, {0, 0, 0}}, {{0, 0, 0}, {0, 0, 0}, {0, 0, 0}}), {{0, 0, 0}, {0, 0, 0}, {0, 0, 0}})\n    lu.assertEquals(candidate({{0, 0}, {0, 0}}, {{0, 0}, {0, 0}}), {{0, 0}, {0, 0}})\n    lu.assertEquals(candidate({{0, 0}, {0, 0}}, {{1, 1}, {1, 1}}), {{1, 1}, {1, 1}})\n    lu.assertEquals(candidate({{1, 1}, {1, 1}}, {{0, 0}, {0, 0}}), {{-1, -1}, {-1, -1}})\n    lu.assertEquals(candidate({{1, 1}, {0, 1}}, {{1, 1}, {1, 1}}), {{0, 0}, {1, 0}})\n    lu.assertEquals(candidate({{1, 0}, {1, 1}}, {{0, 1}, {0, 0}}), {{-1, 1}, {-1, -1}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_126107__compressed_name_to_c_string", "language": "lua", "prompt": "-- Convert a compressed name (with fragment references) to a string that\n-- the C++ compiler will accept. The primary reason for this function is\n-- because the hex escape sequence (\\xHH) in C/C++ has no length limit, so\n-- will happily run into the characters after the HH. So we have to break\n-- those references into separate strings. Example: converts (\"\u0001ab\")\n-- into (\"\u0001\" \"ab\").\nlocal function _compressed_name_to_c_string(compressed_name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_126107__compressed_name_to_c_string.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _compressed_name_to_c_string\n    lu.assertEquals(candidate('a\"b\"c\"d'), '\"a\"b\"c\"d\"')\n    lu.assertEquals(candidate('abc\\\\nabc'), '\"abc\\\\nabc\"')\n    lu.assertEquals(candidate('a\\x01\\x02b'), '\"a\" \"\\\\x01\" \"\\\\x02\" \"b\"')\n    lu.assertEquals(candidate('a\\\\x00b'), '\"a\\\\x00b\"')\n    lu.assertEquals(candidate('a\\x01b'), '\"a\" \"\\\\x01\" \"b\"')\n    lu.assertEquals(candidate('a'), '\"a\"')\n    lu.assertEquals(candidate('\\x01ab'), '\"\\\\x01\" \"ab\"')\n    lu.assertEquals(candidate('a\\x01\\x02\\x03\\x04b'), '\"a\" \"\\\\x01\" \"\\\\x02\" \"\\\\x03\" \"\\\\x04\" \"b\"')\n    lu.assertEquals(candidate('a\\x01\\x02\\x03b'), '\"a\" \"\\\\x01\" \"\\\\x02\" \"\\\\x03\" \"b\"')\n    lu.assertEquals(candidate('a\\x01\\x02\\x03\\x04\\x05b'), '\"a\" \"\\\\x01\" \"\\\\x02\" \"\\\\x03\" \"\\\\x04\" \"\\\\x05\" \"b\"')\n    lu.assertEquals(candidate('a\\\\b'), '\"a\\\\b\"')\n    lu.assertEquals(candidate('a\"b'), '\"a\"b\"')\n    lu.assertEquals(candidate('ab'), '\"ab\"')\n    lu.assertEquals(candidate('a\\\\b\\\\c'), '\"a\\\\b\\\\c\"')\n    lu.assertEquals(candidate('a\"b\"c'), '\"a\"b\"c\"')\n    lu.assertEquals(candidate('abc'), '\"abc\"')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_12626_mysql_quote", "language": "lua", "prompt": "-- Quote the string x using MySQL quoting rules. If x is the empty string,\n-- return \"NULL\". Probably not safe against maliciously formed strings, but\n-- our input is fixed and from a basically trustable source.\nlocal function mysql_quote(x)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_12626_mysql_quote.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = mysql_quote\n    lu.assertEquals(candidate('foo\\\\bar'), \"'foo\\\\\\\\bar'\")\n    lu.assertEquals(candidate('\\n'), \"'\\\\n'\")\n    lu.assertEquals(candidate(None), 'NULL')\n    lu.assertEquals(candidate('hello'), \"'hello'\")\n    lu.assertEquals(candidate(''), 'NULL')\n    lu.assertEquals(candidate('foo'), \"'foo'\")\n    lu.assertEquals(candidate('c\\\\'), \"'c\\\\\\\\'\")\n    lu.assertEquals(candidate('a'), \"'a'\")\n    lu.assertEquals(candidate(\"'\"), \"''''\")\n    lu.assertEquals(candidate('\\n\\n'), \"'\\\\n\\\\n'\")\n    lu.assertEquals(candidate('\\\\'), \"'\\\\\\\\'\")\n    lu.assertEquals(candidate(None), 'NULL')\n    lu.assertEquals(candidate('\\n\\n\\n'), \"'\\\\n\\\\n\\\\n'\")\n    lu.assertEquals(candidate('hello\\nworld'), \"'hello\\\\nworld'\")\n    lu.assertEquals(candidate('foo\\nbar'), \"'foo\\\\nbar'\")\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_126701__is_file_valid", "language": "lua", "prompt": "-- Decide if a file is valid.\nlocal function _is_file_valid(name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_126701__is_file_valid.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _is_file_valid\n    lu.assertEquals(candidate('.foo'), false)\n    lu.assertEquals(candidate('foo.txt'), true)\n    lu.assertEquals(candidate('.foo.bak'), false)\n    lu.assertEquals(candidate('.foo.txt'), false)\n    lu.assertEquals(candidate('.foo.txt.bak'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_12710_splitRPMFilename", "language": "lua", "prompt": "-- Pass in a standard style rpm fullname\n-- Return a name, version, release, epoch, arch, e.g.::\n--     foo-1.0-1.i386.rpm returns foo, 1.0, 1, i386\n--     1:bar-9-123a.ia64.rpm returns bar, 9, 123a, 1, ia64\nlocal function splitRPMFilename(filename)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_12710_splitRPMFilename.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = splitRPMFilename\n    lu.assertEquals(candidate('1:baz-999-1.i386.rpm'), {'baz', '999', '1', '1', 'i386'})\n    lu.assertEquals(candidate('foo-1.0-1.i386.rpm'), {'foo', '1.0', '1', '', 'i386'})\n    lu.assertEquals(candidate('1:foo-9-123a.ia64.rpm'), {'foo', '9', '123a', '1', 'ia64'})\n    lu.assertEquals(candidate('foo-1.0-1.i386.rpm'), {'foo', '1.0', '1', '', 'i386'})\n    lu.assertEquals(candidate('1:bar-9-123a.ia64.rpm'), {'bar', '9', '123a', '1', 'ia64'})\n    lu.assertEquals(candidate('bar-9-123a.ia64.rpm'), {'bar', '9', '123a', '', 'ia64'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_127284_matches", "language": "lua", "prompt": "-- Checks if the pattern is in the line currently being searched. Uses the flags to modify the patter and/or the\n-- line being searched through.\n-- `-i` Match line using a case-insensitive comparison.\n-- `-v` Invert the program -- collect all lines that fail to match the pattern.\n-- `-x` Only match entire lines, instead of lines that contain a match.\n-- :param line: the line to search through in the file or the string provided\n-- :param pattern: the pattern to use for the search\n-- :param flags: the flags to narrow down the search\n-- :return: Boolean value, returns True if the pattern is in the line\n-- :rtype: bool\nlocal function matches(line, pattern, flags)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_127284_matches.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = matches\n    lu.assertEquals(candidate('hello', 'hello', {'-x'}), true)\n    lu.assertEquals(candidate('test line', 'test line', {'-v'}), false)\n    lu.assertEquals(candidate('This line contains a python pattern.', 'python', {'-i', '-x'}), false)\n    lu.assertEquals(candidate('hello', 'Hello', {}), false)\n    lu.assertEquals(candidate('hello', 'hello', {'-x', '-v'}), false)\n    lu.assertEquals(candidate('This line contains a python pattern.', 'Python', {'-i', '-x', '-v'}), false)\n    lu.assertEquals(candidate('This line contains a python pattern.', 'python', {}), true)\n    lu.assertEquals(candidate('test line', 'test line', {'-x'}), true)\n    lu.assertEquals(candidate('hello', 'ell', {}), true)\n    lu.assertEquals(candidate('This line contains a python pattern.', 'python', {'-v'}), false)\n    lu.assertEquals(candidate('This line contains a python pattern.', 'PYTHON', {'-i'}), true)\n    lu.assertEquals(candidate('test line', 'TEST LINE', {'-x'}), false)\n    lu.assertEquals(candidate('hello', 'Hello', {'-i'}), true)\n    lu.assertEquals(candidate('This line contains a python pattern.', 'python', {'-x'}), false)\n    lu.assertEquals(candidate('hello', 'ell', {'-v'}), false)\n    lu.assertEquals(candidate('test line', 'TEST LINE', {'-i'}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_127444_parse_host_port", "language": "lua", "prompt": "-- Interpret a string as a host:port pair.\n-- An IPv6 address MUST be escaped if accompanied by a port,\n-- because otherwise ambiguity ensues: 2001:db8:85a3::8a2e:370:7334\n-- means both [2001:db8:85a3::8a2e:370:7334] and\n-- [2001:db8:85a3::8a2e:370]:7334.\n-- >>> parse_host_port('server01:80')\n-- ('server01', 80)\n-- >>> parse_host_port('server01')\n-- ('server01', None)\n-- >>> parse_host_port('server01', default_port=1234)\n-- ('server01', 1234)\n-- >>> parse_host_port('[::1]:80')\n-- ('::1', 80)\n-- >>> parse_host_port('[::1]')\n-- ('::1', None)\n-- >>> parse_host_port('[::1]', default_port=1234)\n-- ('::1', 1234)\n-- >>> parse_host_port('2001:db8:85a3::8a2e:370:7334', default_port=1234)\n-- ('2001:db8:85a3::8a2e:370:7334', 1234)\n-- >>> parse_host_port(None)\n-- (None, None)\nlocal function parse_host_port(address, default_port)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_127444_parse_host_port.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_host_port\n    lu.assertEquals(candidate('a:1234', None), {'a', 1234})\n    lu.assertEquals(candidate('server01:80'), {'server01', 80})\n    lu.assertEquals(candidate('a:1234', 123), {'a', 1234})\n    lu.assertEquals(candidate('foo'), {'foo', None})\n    lu.assertEquals(candidate('[::1]:80'), {'::1', 80})\n    lu.assertEquals(candidate('[::1]:1234', 123), {'::1', 1234})\n    lu.assertEquals(candidate(''), {None, None})\n    lu.assertEquals(candidate('server01'), {'server01', None})\n    lu.assertEquals(candidate('a'), {'a', None})\n    lu.assertEquals(candidate('foo:80'), {'foo', 80})\n    lu.assertEquals(candidate('[::1]:1234', None), {'::1', 1234})\n    lu.assertEquals(candidate(None), {None, None})\n    lu.assertEquals(candidate('[::1]'), {'::1', None})\n    lu.assertEquals(candidate('localhost:80'), {'localhost', 80})\n    lu.assertEquals(candidate('a:123'), {'a', 123})\n    lu.assertEquals(candidate('localhost'), {'localhost', None})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_127862_convert_to_cents", "language": "lua", "prompt": "-- Convert the price to cents, stripping the currency sign\n-- Parameters\n-- ----------\n-- price : str\n--     Price provided in string format\n-- Returns\n-- -------\n-- int\n--     Price converted to cents\nlocal function convert_to_cents(price)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_127862_convert_to_cents.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = convert_to_cents\n    lu.assertEquals(candidate('$0'), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_12854_get_metric", "language": "lua", "prompt": "-- Get metric value from output line\n-- :param line: console output line\n-- :param name: name of metric\n-- :param split: split character\n-- :return: metric value\nlocal function get_metric(line, name, split)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_12854_get_metric.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_metric\n    lu.assertEquals(candidate('MetricA', 'MetricA', ' '), '')\n    lu.assertEquals(candidate('MetricA : 0.1', 'MetricB', ' : '), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_128799_match_subroutine_call", "language": "lua", "prompt": "local function match_subroutine_call(names)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_128799_match_subroutine_call.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = match_subroutine_call\n    lu.assertEquals(candidate(list(' ')), '')\n    lu.assertEquals(candidate(list('')), '')\n    lu.assertEquals(candidate(list('SUB1 SUB2')), '')\n    lu.assertEquals(candidate({'FOO', 'CALL', 'BAR', 'BAZ'}), 'BAR')\n    lu.assertEquals(candidate(list()), '')\n    lu.assertEquals(candidate(list('SUB1 CALL SUB2')), '')\n    lu.assertEquals(candidate(list('CALL ')), '')\n    lu.assertEquals(candidate(list('SUB1 SUB2 SUB3 SUB4')), '')\n    lu.assertEquals(candidate({'FOO', 'BAR', 'BAZ'}), '')\n    lu.assertEquals(candidate(list('SUB1')), '')\n    lu.assertEquals(candidate(list('SUB1 SUB2 SUB3')), '')\n    lu.assertEquals(candidate(list('SUB1 SUB2 CALL')), '')\n    lu.assertEquals(candidate({'CALL', 'FOO'}), 'FOO')\n    lu.assertEquals(candidate(list('CALL')), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_129353_has_QRp", "language": "lua", "prompt": "-- Euler's criterion\n-- x**2 = a % p -> does x exist? \n-- not all a's in p have an x\nlocal function has_QRp(a, p)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_129353_has_QRp.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = has_QRp\n    lu.assertEquals(candidate(22, 31), false)\n    lu.assertEquals(candidate(7, 7), false)\n    lu.assertEquals(candidate(2, 91), false)\n    lu.assertEquals(candidate(1, 31), true)\n    lu.assertEquals(candidate(42, 43), false)\n    lu.assertEquals(candidate(19, 31), true)\n    lu.assertEquals(candidate(11, 20), false)\n    lu.assertEquals(candidate(4, 11), true)\n    lu.assertEquals(candidate(3, 11), true)\n    lu.assertEquals(candidate(8, 11), false)\n    lu.assertEquals(candidate(7, 31), true)\n    lu.assertEquals(candidate(15, 13), false)\n    lu.assertEquals(candidate(2, 5), false)\n    lu.assertEquals(candidate(7, 5), false)\n    lu.assertEquals(candidate(5, 31), true)\n    lu.assertEquals(candidate(12, 31), false)\n    lu.assertEquals(candidate(5, 11), true)\n    lu.assertEquals(candidate(6, 31), false)\n    lu.assertEquals(candidate(2, 7), true)\n    lu.assertEquals(candidate(5, 5), false)\n    lu.assertEquals(candidate(6, 5), true)\n    lu.assertEquals(candidate(24, 31), false)\n    lu.assertEquals(candidate(9, 31), true)\n    lu.assertEquals(candidate(0, 31), false)\n    lu.assertEquals(candidate(3, 5), false)\n    lu.assertEquals(candidate(8, 5), false)\n    lu.assertEquals(candidate(11, 13), false)\n    lu.assertEquals(candidate(25, 31), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_129399_hex_to_rgb", "language": "lua", "prompt": "-- Convert a hex value to RGB\n-- :param value: the hex color\n-- :type value: string\n-- :returns: rgb tuple\n-- :rtype: tuple\nlocal function hex_to_rgb(value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_129399_hex_to_rgb.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = hex_to_rgb\n    lu.assertEquals(candidate('#FFFFFF'), {255, 255, 255})\n    lu.assertEquals(candidate('000'), {0, 0, 0})\n    lu.assertEquals(candidate('#ff0000'), {255, 0, 0})\n    lu.assertEquals(candidate('999999'), {153, 153, 153})\n    lu.assertEquals(candidate('#000000'), {0, 0, 0})\n    lu.assertEquals(candidate('112233'), {17, 34, 51})\n    lu.assertEquals(candidate(None), None)\n    lu.assertEquals(candidate('#808080'), {128, 128, 128})\n    lu.assertEquals(candidate(''), None)\n    lu.assertEquals(candidate('FFFFFF'), {255, 255, 255})\n    lu.assertEquals(candidate('abcdef'), {171, 205, 239})\n    lu.assertEquals(candidate('ff0000'), {255, 0, 0})\n    lu.assertEquals(candidate('#000'), {0, 0, 0})\n    lu.assertEquals(candidate('#123456'), {18, 52, 86})\n    lu.assertEquals(candidate('F0F0F0'), {240, 240, 240})\n    lu.assertEquals(candidate('#999999'), {153, 153, 153})\n    lu.assertEquals(candidate('000000'), {0, 0, 0})\n    lu.assertEquals(candidate('#F0F0F0'), {240, 240, 240})\n    lu.assertEquals(candidate('FF0000'), {255, 0, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_129402_join_as_compacted_paragraphs", "language": "lua", "prompt": "-- :param paragraphs: List containing individual paragraphs; potentially with extraneous whitespace within\n-- :return: String with \n--  separated paragraphs and no extra whitespace\nlocal function join_as_compacted_paragraphs(paragraphs)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_129402_join_as_compacted_paragraphs.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = join_as_compacted_paragraphs\n    lu.assertEquals(candidate({'A paragraph with a \\n newline character, and a couple of\\t tabs'}), 'A paragraph with a newline character, and a couple of tabs')\n    lu.assertEquals(candidate({'I ate a\\n\\n\\n\\n\\n\\n\\n\\nball', 'I drank a\\n\\n\\n\\n\\n\\n\\n\\ncoffee'}), 'I ate a ball\\nI drank a coffee')\n    lu.assertEquals(candidate({'A paragraph with a\\nnewline character, and a couple of\\ttabs'}), 'A paragraph with a newline character, and a couple of tabs')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_129406_R10_yield", "language": "lua", "prompt": "--     R10 Determining the surface pressure Pmax\n-- (Sec 5.5.4)\n--     For the maximum surface pressure with yield\n--     or angle controlled tightening techniques.\nlocal function R10_yield(FMTab, Apmin, PG)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_129406_R10_yield.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = R10_yield\n    lu.assertEquals(candidate(0.1, 0.1, 1.0), 1.4)\n    lu.assertEquals(candidate(1.0, 1.0, 0.1), 1.4)\n    lu.assertEquals(candidate(2.0, 1.0, 2.0), 2.8)\n    lu.assertEquals(candidate(0.1, 0.1, 0.1), 1.4)\n    lu.assertEquals(candidate(1.0, 1.0, 2.0), 1.4)\n    lu.assertEquals(candidate(1.0, 1.0, 1.0), 1.4)\n    lu.assertEquals(candidate(1.0, 1.0, 1.0), 1.4)\n    lu.assertEquals(candidate(2.0, 1.0, 1.0), 2.8)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_129442_solution", "language": "lua", "prompt": "-- Complete the function such that:\n-- Given a list of digits LD, reverse all the digits in LD to a new list LR.\n-- Return the LR and largest element in LR in a tuple such that:\n--     - [123] -> ([321], 321)\n--     - [-789, 10] -> ([-987, 1], 1)\n--     - [11020, 3512] -> ([2011, 2153], 2153)\n-- Constraints:\n-- Eliminate leading zeros.\n-- Note the position of the negative operator after the reversal.\nlocal function solution(num_list)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_129442_solution.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = solution\n    lu.assertEquals(candidate({11020, 3512}), {{2011, 2153}, 2153})\n    lu.assertEquals(candidate({-789, 10}), {{-987, 1}, 1})\n    lu.assertEquals(candidate({123}), {{321}, 321})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_129631_levenshtein_distance", "language": "lua", "prompt": "-- Parameters:\n-- ----------\n--   w1: str\n--   w2: str\n-- Returns:\n-- --------\n--   int:\n--     Returns Levenshtein edit distance between the two strings \nlocal function levenshtein_distance(w1, w2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_129631_levenshtein_distance.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = levenshtein_distance\n    lu.assertEquals(candidate('aa', 'aa'), 0)\n    lu.assertEquals(candidate('hello', 'halo'), 2)\n    lu.assertEquals(candidate('kitten', 'kitt'), 2)\n    lu.assertEquals(candidate('a', ''), 1)\n    lu.assertEquals(candidate('', ''), 0)\n    lu.assertEquals(candidate('5678', '1234'), 4)\n    lu.assertEquals(candidate('b', 'a'), 1)\n    lu.assertEquals(candidate('1234', '5678'), 4)\n    lu.assertEquals(candidate('', 'a'), 1)\n    lu.assertEquals(candidate('kitten', 'sitting'), 3)\n    lu.assertEquals(candidate('kitten', 'sittin'), 2)\n    lu.assertEquals(candidate('cut', 'cat'), 1)\n    lu.assertEquals(candidate('a', 'b'), 1)\n    lu.assertEquals(candidate('kitten', 'kit'), 3)\n    lu.assertEquals(candidate('dog', 'cat'), 3)\n    lu.assertEquals(candidate('kitten', 'kittten'), 1)\n    lu.assertEquals(candidate('kitten', 'sitting'), 3)\n    lu.assertEquals(candidate('b', 'a'), 1)\n    lu.assertEquals(candidate('hello', 'hallo'), 1)\n    lu.assertEquals(candidate('k', ''), 1)\n    lu.assertEquals(candidate('sitting', 'kitten'), 3)\n    lu.assertEquals(candidate('kitten', 'kitte'), 1)\n    lu.assertEquals(candidate('cat', 'dog'), 3)\n    lu.assertEquals(candidate('a', 'b'), 1)\n    lu.assertEquals(candidate('cat', 'cut'), 1)\n    lu.assertEquals(candidate('', ''), 0)\n    lu.assertEquals(candidate('s', 's'), 0)\n    lu.assertEquals(candidate('kitten', 'k'), 5)\n    lu.assertEquals(candidate('', 'k'), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_130049_get_beta_skewness", "language": "lua", "prompt": "-- Compute skewness of beta distribution based on shape parameters `a` and `b`.\nlocal function get_beta_skewness(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_130049_get_beta_skewness.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_beta_skewness\n    lu.assertEquals(candidate(0.5, 0.5), 0.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_130400_sub", "language": "lua", "prompt": "--  Subtracts the two Polynomials, 'p1' and 'p2'\n-- The arguments can be a sequence of coefficients or an instance of the Polynomial class. \nlocal function sub(p1, p2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_130400_sub.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sub\n    lu.assertEquals(candidate({3, 4}, {1, 2}), {2, 2})\n    lu.assertEquals(candidate({0, 0, 0, 0, 0, 0, 0}, {1, 1, 1, 1, 1, 1, 1}), {-1, -1, -1, -1, -1, -1, -1})\n    lu.assertEquals(candidate({1, 2}, {3, 4}), {-2, -2})\n    lu.assertEquals(candidate({2}, {1}), {1})\n    lu.assertEquals(candidate({1}, {}), {1})\n    lu.assertEquals(candidate({}, {3, 2, 1}), {-3, -2, -1})\n    lu.assertEquals(candidate({1, 2, 3, 4}, {5, 6, 7, 8}), {-4, -4, -4, -4})\n    lu.assertEquals(candidate({1, 0}, {0, 1}), {1, -1})\n    lu.assertEquals(candidate({1, 2, 3}, {4, 5, 6}), {-3, -3, -3})\n    lu.assertEquals(candidate({0}, {0}), {0})\n    lu.assertEquals(candidate({5, 6, 7, 8}, {1, 2, 3, 4}), {4, 4, 4, 4})\n    lu.assertEquals(candidate({1}, {2}), {-1})\n    lu.assertEquals(candidate({4, 5, 6}, {1, 2, 3}), {3, 3, 3})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_130569_get_command_from_state", "language": "lua", "prompt": "-- This method gets appropriate command name for the state specified. It\n-- returns the command name for the specified state.\n-- :param state: The state for which the respective command name is required.\nlocal function get_command_from_state(state)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_130569_get_command_from_state.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_command_from_state\n    lu.assertEquals(candidate('present'), 'vrouter-create')\n    lu.assertEquals(candidate('update'), 'vrouter-modify')\n    lu.assertEquals(candidate('absent'), 'vrouter-delete')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_13090_get_urn_from_raw_update", "language": "lua", "prompt": "-- Return the URN of a raw group update\n-- Example: urn:li:fs_miniProfile:<id>\n-- Example: urn:li:fs_updateV2:(<urn>,GROUP_FEED,EMPTY,DEFAULT,false)\nlocal function get_urn_from_raw_update(raw_string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_13090_get_urn_from_raw_update.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_urn_from_raw_update\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:32423423432,MEMBER_COUNT_UPDATED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:32423423432')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:6161898594178132904,GROUP_FEED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:6161898594178132904')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:3243252353,GROUP_FEED,EMPTY,DEFAULT,false),EMPTY,EMPTY,EMPTY,false)'), 'urn:li:fs_miniProfile:3243252353')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:1,GROUP_FEED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:1')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:1,GROUP_FEED,EMPTY,DEFAULT,false),(urn:li:fs_miniProfile:2,GROUP_FEED,EMPTY,DEFAULT,false),(urn:li:fs_miniProfile:3,GROUP_FEED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:1')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:123456789,GROUP_JOIN_REQUEST_ACCEPTED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:123456789')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:32423423432,UPCOMING_EVENT_CREATED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:32423423432')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:921474837697135657,GROUP_FEED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:921474837697135657')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(<urn>,PROMOTED,EMPTY,DEFAULT,false)'), '<urn>')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:1234567890123456789,GROUP_FEED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:1234567890123456789')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:123456789,GROUP_FEED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:123456789')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:1159,GROUP_FEED,EMPTY,DEFAULT,false)garbage'), 'urn:li:fs_miniProfile:1159')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:32423423432,EVENT_ORGANIZER_CREATED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:32423423432')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:55555,GROUP_FEED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:55555')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:123456,MEMBERSHIP_UPDATED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:123456')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:123456,FEED_UPDATED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:123456')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:1,GROUP_FEED,EMPTY,DEFAULT,false),(urn:li:fs_updateV2:(urn:li:fs_miniProfile:2,GROUP_FEED,EMPTY,DEFAULT,false),GROUP_FEED,EMPTY,DEFAULT,false),(urn:li:fs_miniProfile:3,GROUP_FEED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:1')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:3243252353,GROUP_FEED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:3243252353')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(<urn>,GROUP_FEED,EMPTY,DEFAULT,false)'), '<urn>')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:1159,GROUP_FEED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:1159')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:32423423432,GROUP_FEED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:32423423432')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:5dc5e35e3e5e0340a5a1872e,GROUP_FEED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:5dc5e35e3e5e0340a5a1872e')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:123456789,OWNERSHIP_TRANSFER,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:123456789')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(<urn>,REMOVED,EMPTY,DEFAULT,false)'), '<urn>')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:55555,GROUP_FEED,EMPTY,DEFAULT,true)'), 'urn:li:fs_miniProfile:55555')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:123456,GROUP_FEED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:123456')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(<urn>,UPDATED,EMPTY,DEFAULT,false)'), '<urn>')\n    lu.assertEquals(candidate('urn:li:fs_miniProfile:(urn:li:fs_miniProfile:1234567890123456789,urn:li:organization:1234567890123456789)'), 'urn:li:fs_miniProfile:1234567890123456789')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(<urn>,GROUP_FEED,EMPTY,DEFAULT,false)'), '<urn>')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(<urn>,GROUP_FEED,EMPTY,DEFAULT,true)'), '<urn>')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:123456789,MEMBERSHIP_CHANGE,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:123456789')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(<urn>,UNSUBSCRIBED,EMPTY,DEFAULT,false)'), '<urn>')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:d52191c1-9b2c-45a9-a721-2a3317a8047c,GROUP_FEED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:d52191c1-9b2c-45a9-a721-2a3317a8047c')\n    lu.assertEquals(candidate('urn:li:fs_updateV2:(urn:li:fs_miniProfile:123456,POSTS_UPDATED,EMPTY,DEFAULT,false)'), 'urn:li:fs_miniProfile:123456')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_131292_GetEnvCall", "language": "lua", "prompt": "-- Maps the types availabe via env->Call__Method.\nlocal function GetEnvCall(is_constructor, is_static, return_type)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_131292_GetEnvCall.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = GetEnvCall\n    lu.assertEquals(candidate(false, false, 'void'), 'CallVoidMethod')\n    lu.assertEquals(candidate(false, false, 'Object'), 'CallObjectMethod')\n    lu.assertEquals(candidate(true, false, 'boolean'), 'NewObject')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_132314_get_full_policy_path", "language": "lua", "prompt": "-- Resource string will output strings like the following examples.\n-- Case 1:\n--   Input: arn:aws:iam::aws:policy/aws-service-role/AmazonGuardDutyServiceRolePolicy\n-- Output:\n--   aws-service-role/AmazonGuardDutyServiceRolePolicy\n-- Case 2:\n--   Input: arn:aws:iam::123456789012:role/ExampleRole\n--   Output: ExampleRole\n-- :param arn:\n-- :return:\nlocal function get_full_policy_path(arn)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_132314_get_full_policy_path.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_full_policy_path\n    lu.assertEquals(candidate('arn:aws:iam::aws:policy/aws-service-role/AmazonGuardDutyServiceRolePolicy'), 'aws-service-role/AmazonGuardDutyServiceRolePolicy')\n    lu.assertEquals(candidate('arn:aws:iam::aws:policy/aws-service-role/AmazonGuardDutyServiceRolePolicy'), 'aws-service-role/AmazonGuardDutyServiceRolePolicy')\n    lu.assertEquals(candidate('arn:aws:iam::123456789012:role/ExampleRole'), 'ExampleRole')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_132458_digitToInt", "language": "lua", "prompt": "-- digitToInt :: str -> int\n-- Convert a single digit Char to the corresponding Int. This function fails\n-- unless its argument satisfies isHexDigit, but recognises both upper and\n-- lower-case hexadecimal digits (i.e. '0'..'9', 'a'..'f', 'A'..'F').\nlocal function digitToInt(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_132458_digitToInt.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = digitToInt\n    lu.assertEquals(candidate('A'), 10)\n    lu.assertEquals(candidate('7'), 7)\n    lu.assertEquals(candidate('D'), 13)\n    lu.assertEquals(candidate('6'), 6)\n    lu.assertEquals(candidate('2'), 2)\n    lu.assertEquals(candidate('1'), 1)\n    lu.assertEquals(candidate('B'), 11)\n    lu.assertEquals(candidate('f'), 15)\n    lu.assertEquals(candidate('d'), 13)\n    lu.assertEquals(candidate('9'), 9)\n    lu.assertEquals(candidate('4'), 4)\n    lu.assertEquals(candidate('F'), 15)\n    lu.assertEquals(candidate('C'), 12)\n    lu.assertEquals(candidate('c'), 12)\n    lu.assertEquals(candidate('5'), 5)\n    lu.assertEquals(candidate('f'), 15)\n    lu.assertEquals(candidate('f'), 15)\n    lu.assertEquals(candidate('1'), 1)\n    lu.assertEquals(candidate('a'), 10)\n    lu.assertEquals(candidate('3'), 3)\n    lu.assertEquals(candidate('A'), 10)\n    lu.assertEquals(candidate('a'), 10)\n    lu.assertEquals(candidate('e'), 14)\n    lu.assertEquals(candidate('0'), 0)\n    lu.assertEquals(candidate('f'), int('f', 16))\n    lu.assertEquals(candidate('1'), 1)\n    lu.assertEquals(candidate('b'), 11)\n    lu.assertEquals(candidate('5'), 5)\n    lu.assertEquals(candidate('1'), int('1', 10))\n    lu.assertEquals(candidate('8'), 8)\n    lu.assertEquals(candidate('E'), 14)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_132637_drop_command", "language": "lua", "prompt": "--     Given a message text, drops the command prefix from the string.\nlocal function drop_command(message, command)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_132637_drop_command.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = drop_command\n    lu.assertEquals(candidate('!command parameter1 parameter2 parameter3', '!COMMAND'), 'parameter1 parameter2 parameter3')\n    lu.assertEquals(candidate('!command parameter1 parameter2 parameter3', '!command'), 'parameter1 parameter2 parameter3')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_132755_appartient_au_triangle", "language": "lua", "prompt": "-- verifie si le point P(x;y) appartient au triangle ABC\nlocal function appartient_au_triangle(X, Y, x, y)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_132755_appartient_au_triangle.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = appartient_au_triangle\n    lu.assertEquals(candidate({10, 10, 10}, {10, 10, 10}, 10, 10), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_133001_dequebecify", "language": "lua", "prompt": "--  Normalizes text to pure english\n-- From <http://stackoverflow.com/questions/517923>\n-- This function only transliterates French diacritics.\n-- If you need to separate Quebec from Canada, try:\n-- roc,qc = canada.sovereignty_referendum('quebec')\nlocal function dequebecify(input)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_133001_dequebecify.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = dequebecify\n    lu.assertEquals(candidate(\"C'est pas faux\"), \"C'est pas faux\")\n    lu.assertEquals(candidate('Je suis une phrase.'), 'Je suis une phrase.')\n    lu.assertEquals(candidate('\u00c9vang\u00e9liste fran\u00e7ais'), 'Evangeliste francais')\n    lu.assertEquals(candidate('test'), 'test')\n    lu.assertEquals(candidate('\u00c9quipe fran\u00e7aise'), 'Equipe francaise')\n    lu.assertEquals(candidate('Mais comment?'), 'Mais comment?')\n    lu.assertEquals(candidate('Deja vu'), 'Deja vu')\n    lu.assertEquals(candidate(\"L'\u00e9cole\"), \"L'ecole\")\n    lu.assertEquals(candidate('\u00c7a va?'), 'Ca va?')\n    lu.assertEquals(candidate('Et ca?'), 'Et ca?')\n    lu.assertEquals(candidate('Le \u00e9v\u00eaque'), 'Le eveque')\n    lu.assertEquals(candidate('R\u00e9sidence de la Madeleine'), 'Residence de la Madeleine')\n    lu.assertEquals(candidate('M\u00e8re de la Madeleine'), 'Mere de la Madeleine')\n    lu.assertEquals(candidate('Bonjour'), 'Bonjour')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_133468_filesafe", "language": "lua", "prompt": "-- Convert a string to something safe for filenames.\nlocal function filesafe(str_)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_133468_filesafe.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = filesafe\n    lu.assertEquals(candidate('This is a normal filename'), 'This is a normal filename')\n    lu.assertEquals(candidate('A very normal filename'), 'A very normal filename')\n    lu.assertEquals(candidate('True.0'), 'True.0')\n    lu.assertEquals(candidate('True'), 'True')\n    lu.assertEquals(candidate('.'), '.')\n    lu.assertEquals(candidate('..'), '..')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_135211_transform_basis_name", "language": "lua", "prompt": "-- Transforms the name of a basis set to an internal representation\n-- This makes comparison of basis set names easier by, for example,\n-- converting the name to all lower case.\nlocal function transform_basis_name(name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_135211_transform_basis_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = transform_basis_name\n    lu.assertEquals(candidate('foo_sl_bar'), 'foo_sl_bar')\n    lu.assertEquals(candidate('foo123'), 'foo123')\n    lu.assertEquals(candidate('foo/bar/baz'), 'foo_sl_bar_sl_baz')\n    lu.assertEquals(candidate('A'), 'a')\n    lu.assertEquals(candidate('foo*BAR'), 'foo_st_bar')\n    lu.assertEquals(candidate('foo*bar'), 'foo_st_bar')\n    lu.assertEquals(candidate('foo_st_bar'), 'foo_st_bar')\n    lu.assertEquals(candidate('a'), 'a')\n    lu.assertEquals(candidate('FOO'), 'foo')\n    lu.assertEquals(candidate('foo_sl_BAR'), 'foo_sl_bar')\n    lu.assertEquals(candidate('foo_st_BAR'), 'foo_st_bar')\n    lu.assertEquals(candidate('FOO123'), 'foo123')\n    lu.assertEquals(candidate('foo/BAR'), 'foo_sl_bar')\n    lu.assertEquals(candidate('foo*bar*baz'), 'foo_st_bar_st_baz')\n    lu.assertEquals(candidate('foo/bar'), 'foo_sl_bar')\n    lu.assertEquals(candidate('foo'), 'foo')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_135424_people_in_rec_area", "language": "lua", "prompt": "-- This function's job is to tell us how many people can fit in a rectangular area. We model people as equally sized circles, with the distance between the center of two circles being the \"social distance\" between them. Our function takes the lengths of the rectangle and the distance between the center of two adjacent circles as inputs.\n-- The circles are laid out in a rectangular grid within the rectangular area. This way, the lengths of the sides of the rectange can be given by L1=n*2r and L2 = m*2r where n and m are the number of circles and r is the radius of each circle. We also let social_d = 2r, the distane between the center of two circles.\nlocal function people_in_rec_area(length_1, length_2, social_d)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_135424_people_in_rec_area.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = people_in_rec_area\n    lu.assertEquals(candidate(1, 1, 1), 1)\n    lu.assertEquals(candidate(1, 4, 1), 4)\n    lu.assertEquals(candidate(20, 20, 20), 1)\n    lu.assertEquals(candidate(5, 10, 1), 50)\n    lu.assertEquals(candidate(1, 20, 1), 20)\n    lu.assertEquals(candidate(1, 2, 1), 2)\n    lu.assertEquals(candidate(1, 6, 1), 6)\n    lu.assertEquals(candidate(10, 10, 10), 1)\n    lu.assertEquals(candidate(5, 5, 1), 25)\n    lu.assertEquals(candidate(1, 1, 1), 1)\n    lu.assertEquals(candidate(1, 5, 1), 5)\n    lu.assertEquals(candidate(1, 3, 1), 3)\n    lu.assertEquals(candidate(5, 5, 3), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_13659__split_left", "language": "lua", "prompt": "-- Split a string by a delimiter which can be escaped by \\\nlocal function _split_left(val, sep)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_13659__split_left.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _split_left\n    lu.assertEquals(candidate('::foo:', ':'), {'', '', 'foo', ''})\n    lu.assertEquals(candidate('foo\\\\', ','), {'foo\\\\'})\n    lu.assertEquals(candidate('foo', ','), {'foo'})\n    lu.assertEquals(candidate('foo:bar', ':'), {'foo', 'bar'})\n    lu.assertEquals(candidate(':::foo:', ':'), {'', '', '', 'foo', ''})\n    lu.assertEquals(candidate(':foo:', ':'), {'', 'foo', ''})\n    lu.assertEquals(candidate('foo\\\\x', 'x\\\\y'), {'foo\\\\x'})\n    lu.assertEquals(candidate('foo\\\\x', '\\\\x\\\\y'), {'foo\\\\x'})\n    lu.assertEquals(candidate('a,b,c,', ','), {'a', 'b', 'c', ''})\n    lu.assertEquals(candidate('foo,bar', ',,'), {'foo,bar'})\n    lu.assertEquals(candidate('foo', 'x'), {'foo'})\n    lu.assertEquals(candidate('a,b,c', ','), {'a', 'b', 'c'})\n    lu.assertEquals(candidate('foo:', ':'), {'foo', ''})\n    lu.assertEquals(candidate('foo', ':'), {'foo'})\n    lu.assertEquals(candidate('foo', '\\\\x'), {'foo'})\n    lu.assertEquals(candidate('foo,bar', ','), {'foo', 'bar'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_136605_is_tissue_compatible", "language": "lua", "prompt": "-- Modeling actual  compatibility is complex, and depends on\n-- properties of different HLA markers and various other complications.\n-- Instead of dealing with the medical complexities, we use a simple \n-- model that produces a uniformly-distributed value that is dependent\n-- on the two inputs, and outputs a discretized probability.\n-- It's not important to understand the following code. But you should \n-- call this function with the receiver's PRA-type, receiver's ID, \n-- and the donor's  ID to check if their tissues are compatible or not.\n-- Example usage: is_tissue_compatible('Low', 4474, 3587)\nlocal function is_tissue_compatible(recv_pra, recv_id, don_id)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_136605_is_tissue_compatible.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_tissue_compatible\n    lu.assertEquals(candidate('High', 4474, 3587), false)\n    lu.assertEquals(candidate('Medium', 4474, 3587), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_136714_blasius", "language": "lua", "prompt": "-- Calculate friction coefficient according to Blasius.\n-- Parameters\n-- ----------\n-- re : float\n--     Reynolds number.\n-- Returns\n-- -------\n-- darcy_friction_factor : float\n--     Darcy friction factor.\nlocal function blasius(re)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_136714_blasius.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = blasius\n    lu.assertEquals(candidate(1.0), 0.3164)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_136879_clamp", "language": "lua", "prompt": "-- Clam n in [MIN, MAX[\nlocal function clamp(MIN, n, MAX)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_136879_clamp.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = clamp\n    lu.assertEquals(candidate(0, 5, 10), 5)\n    lu.assertEquals(candidate(0, 2, 2), 1)\n    lu.assertEquals(candidate(3, 3, 6), 3)\n    lu.assertEquals(candidate(3, 5, 6), 5)\n    lu.assertEquals(candidate(3, 4, 6), 4)\n    lu.assertEquals(candidate(0, -2, 2), 0)\n    lu.assertEquals(candidate(2, 3, 4), 3)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_137389_unit_form", "language": "lua", "prompt": "--     Return generated quadratic form with the given discriminant.\nlocal function unit_form(disc)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_137389_unit_form.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = unit_form\n    lu.assertEquals(candidate(0), {1, 0, 0})\n    lu.assertEquals(candidate(1), {1, 1, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_13746_rotation_cs", "language": "lua", "prompt": "-- For numpy arrays X and Y returns the numpy arrays of Xrot and Yrot\n-- for specified rotation angle cosine and sine values.\nlocal function rotation_cs(X, Y, c, s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_13746_rotation_cs.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rotation_cs\n    lu.assertEquals(candidate(0, 0, 1, 0), {0, 0})\n    lu.assertEquals(candidate(0, 0, 0, 1), {0, 0})\n    lu.assertEquals(candidate(0, 0, 0, 0), {0, 0})\n    lu.assertEquals(candidate(1, 0, 0, -1), {0, -1})\n    lu.assertEquals(candidate(1, 1, 0, 1), {-1, 1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_13749_get_parent_technique_id", "language": "lua", "prompt": "-- Given a sub-technique id, return parent\nlocal function get_parent_technique_id(sub_tid)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_13749_get_parent_technique_id.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_parent_technique_id\n    lu.assertEquals(candidate('T1001.001'), 'T1001')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_137905_parse_function_path", "language": "lua", "prompt": "-- Util to parse path to functions.\nlocal function parse_function_path(function_path)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_137905_parse_function_path.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_function_path\n    lu.assertEquals(candidate('a_module.a_function.another_function'), {'a_module.a_function', 'another_function'})\n    lu.assertEquals(candidate('a_module.a_function'), {'a_module', 'a_function'})\n    lu.assertEquals(candidate('test.func'), {'test', 'func'})\n    lu.assertEquals(candidate('test.func.func2'), {'test.func', 'func2'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_139038_prazen_kvadrat_n", "language": "lua", "prompt": "--  vrni string, ki bo narisal prazen kvadrat v velikost n_vrstic\nlocal function prazen_kvadrat_n(n_vrstic)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_139038_prazen_kvadrat_n.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = prazen_kvadrat_n\n    lu.assertEquals(candidate(0), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_140092_parse_addr", "language": "lua", "prompt": "-- Parse the --liveserver argument into a host/IP address and port range\nlocal function parse_addr(specified_address)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_140092_parse_addr.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_addr\n    lu.assertEquals(candidate('127.0.0.1:8000-8010'), {'127.0.0.1', {8000, 8001, 8002, 8003, 8004, 8005, 8006, 8007, 8008, 8009, 8010}})\n    lu.assertEquals(candidate('127.0.0.1:8000'), {'127.0.0.1', {8000}})\n    lu.assertEquals(candidate('127.0.0.1:8000-8010,8080'), {'127.0.0.1', {8000, 8001, 8002, 8003, 8004, 8005, 8006, 8007, 8008, 8009, 8010, 8080}})\n    lu.assertEquals(candidate('127.0.0.1:8000,8001'), {'127.0.0.1', {8000, 8001}})\n    lu.assertEquals(candidate('localhost:8000,8001,8003-8010'), {'localhost', {8000, 8001, 8003, 8004, 8005, 8006, 8007, 8008, 8009, 8010}})\n    lu.assertEquals(candidate('127.0.0.1:8000,8001,8002-8005'), {'127.0.0.1', {8000, 8001, 8002, 8003, 8004, 8005}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_140262_DNAtoRNA", "language": "lua", "prompt": "--  dna_to_rna == PEP8 (forced camelCase by CodeWars) \nlocal function DNAtoRNA(dna)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_140262_DNAtoRNA.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = DNAtoRNA\n    lu.assertEquals(candidate(candidate('ACGT')), 'ACGU')\n    lu.assertEquals(candidate('GCAT'), 'GCAU')\n    lu.assertEquals(candidate('TTTT'), 'UUUU')\n    lu.assertEquals(candidate('GATGGAACTTGACTACGTAAATT'), 'GAUGGAACUUGACUACGUAAAUU')\n    lu.assertEquals(candidate('GCAT'), 'GCAU')\n    lu.assertEquals(candidate('GCAT'), 'GCAU')\n    lu.assertEquals(candidate('GACCGCCGCC'), 'GACCGCCGCC')\n    lu.assertEquals(candidate('TTTT'), 'UUUU')\n    lu.assertEquals(candidate('GACCGCCGCC'), 'GACCGCCGCC')\n    lu.assertEquals(candidate('TTTT'), 'UUUU')\n    lu.assertEquals(candidate('ACGT'), 'ACGU')\n    lu.assertEquals(candidate('TTTT'), 'UUUU')\n    lu.assertEquals(candidate('GACCGCCGCC'), 'GACCGCCGCC')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_14050_box_sizing", "language": "lua", "prompt": "-- Validation for the ``box-sizing`` property from css3-ui\nlocal function box_sizing(keyword)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_14050_box_sizing.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = box_sizing\n    lu.assertEquals(candidate('content-box'), true)\n    lu.assertEquals(candidate('foo'), false)\n    lu.assertEquals(candidate('padding-box'), true)\n    lu.assertEquals(candidate('border-box'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_140877_parse_photo_link", "language": "lua", "prompt": "-- Extracts the base URL (URL without query parameters) and the photo name from a Onedrive photo URL\n-- :param photo_url: photo URL\n-- :return: base URL and photo name\nlocal function parse_photo_link(photo_url)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_140877_parse_photo_link.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_photo_link\n    lu.assertEquals(candidate('https://graph.microsoft.com/v1.0/me/drive/items/root/children/F22222222222222222222222222222222'), {'https://graph.microsoft.com/v1.0/me/drive/items/root/children/F22222222222222222222222222222222', 'F22222222222222222222222222222222'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_142183_is_parenthetical", "language": "lua", "prompt": "-- (str) -> bool\n-- Returns True if s starts with '(' and ends with ')'\nlocal function is_parenthetical(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_142183_is_parenthetical.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_parenthetical\n    lu.assertEquals(candidate('This string is not parenthetical (()())())'), false)\n    lu.assertEquals(candidate('(abc(def)(ghi)jkl)'), true)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate(')'), false)\n    lu.assertEquals(candidate('This string is not parenthetical ()()'), false)\n    lu.assertEquals(candidate('this is not a test('), false)\n    lu.assertEquals(candidate('(abc(def)ghi)'), true)\n    lu.assertEquals(candidate('(abc)'), true)\n    lu.assertEquals(candidate('This string is not parenthetical'), false)\n    lu.assertEquals(candidate('(this is a test)'), true)\n    lu.assertEquals(candidate('This string is not parenthetical (()'), false)\n    lu.assertEquals(candidate('this is not a test)'), false)\n    lu.assertEquals(candidate('This string is not parenthetical (()())('), false)\n    lu.assertEquals(candidate('('), false)\n    lu.assertEquals(candidate('((abc)def)ghi'), false)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('(abc)def(ghi)jkl'), false)\n    lu.assertEquals(candidate('()'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_142478_construct_vocab", "language": "lua", "prompt": "-- Combines words from two sentences into a single\n-- dictionary\n-- Input: words1 - List of strings\n--        words2 - List of strings\n-- Output: vocab - dictionary where key is word,\n--                     value is weight of word\nlocal function construct_vocab(words1, words2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_142478_construct_vocab.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = construct_vocab\n    lu.assertEquals(candidate({'orange', 'banana', 'apple'}, {'orange'}), {['orange'] = 1, ['banana'] = 1, ['apple'] = 1})\n    lu.assertEquals(candidate({'a', 'b', 'c'}, {'d', 'e', 'f'}), {['a'] = 1, ['b'] = 1, ['c'] = 1, ['d'] = 1, ['e'] = 1, ['f'] = 1})\n    lu.assertEquals(candidate({'orange', 'banana', 'apple'}, {}), {['orange'] = 1, ['banana'] = 1, ['apple'] = 1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_142835_has_divider_smaller_than", "language": "lua", "prompt": "-- Get True if n has a divided smaller than i\n-- :param n: number\n-- :param i: number\n-- :return: boolean\nlocal function has_divider_smaller_than(n, i)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_142835_has_divider_smaller_than.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = has_divider_smaller_than\n    lu.assertEquals(candidate(234, 22), true)\n    lu.assertEquals(candidate(7, 5), false)\n    lu.assertEquals(candidate(7, 3), false)\n    lu.assertEquals(candidate(10, 4), true)\n    lu.assertEquals(candidate(6, 5), true)\n    lu.assertEquals(candidate(234, 1000), true)\n    lu.assertEquals(candidate(6, 3), true)\n    lu.assertEquals(candidate(9, 5), true)\n    lu.assertEquals(candidate(1, 1), false)\n    lu.assertEquals(candidate(10, 5), true)\n    lu.assertEquals(candidate(-10, 5), true)\n    lu.assertEquals(candidate(3, 3), true)\n    lu.assertEquals(candidate(234, 12), true)\n    lu.assertEquals(candidate(1, 2), false)\n    lu.assertEquals(candidate(3, 1), false)\n    lu.assertEquals(candidate(2, 1), false)\n    lu.assertEquals(candidate(6, 2), true)\n    lu.assertEquals(candidate(5, 1), false)\n    lu.assertEquals(candidate(13, 2), false)\n    lu.assertEquals(candidate(-9, 5), true)\n    lu.assertEquals(candidate(7, 1), false)\n    lu.assertEquals(candidate(6, 4), true)\n    lu.assertEquals(candidate(-1, 5), false)\n    lu.assertEquals(candidate(6, 1), false)\n    lu.assertEquals(candidate(200, 5), true)\n    lu.assertEquals(candidate(4, 2), true)\n    lu.assertEquals(candidate(12, 2), true)\n    lu.assertEquals(candidate(1, 5), false)\n    lu.assertEquals(candidate(4, 1), false)\n    lu.assertEquals(candidate(-7, 5), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_143409_get_chunk_label", "language": "lua", "prompt": "-- Returns a readable elapsed time.\nlocal function get_chunk_label(tot_minutes)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_143409_get_chunk_label.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_chunk_label\n    lu.assertEquals(candidate(122), '02h:02m')\n    lu.assertEquals(candidate(12), '00h:12m')\n    lu.assertEquals(candidate(65), '01h:05m')\n    lu.assertEquals(candidate(135), '02h:15m')\n    lu.assertEquals(candidate(61), '01h:01m')\n    lu.assertEquals(candidate(98), '01h:38m')\n    lu.assertEquals(candidate(3599), '59h:59m')\n    lu.assertEquals(candidate(132), '02h:12m')\n    lu.assertEquals(candidate(1), '00h:01m')\n    lu.assertEquals(candidate(0), '00h:00m')\n    lu.assertEquals(candidate(60), '01h:00m')\n    lu.assertEquals(candidate(2), '00h:02m')\n    lu.assertEquals(candidate(1220), '20h:20m')\n    lu.assertEquals(candidate(20), '00h:20m')\n    lu.assertEquals(candidate(18), '00h:18m')\n    lu.assertEquals(candidate(120), '02h:00m')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_1437_check_host", "language": "lua", "prompt": "--  Helper function to get the hostname in desired format \nlocal function check_host(host)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_1437_check_host.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = check_host\n    lu.assertEquals(candidate(candidate('https://example.com')), 'https://example.com')\n    lu.assertEquals(candidate('example.com'), 'http://example.com')\n    lu.assertEquals(candidate('https://example.com/'), 'https://example.com')\n    lu.assertEquals(candidate('codecademy.com'), 'http://codecademy.com')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_144168_even", "language": "lua", "prompt": "-- returns true if even number, false if odd\nlocal function even(x)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_144168_even.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = even\n    lu.assertEquals(candidate(2), true)\n    lu.assertEquals(candidate(0), true)\n    lu.assertEquals(candidate(100), true)\n    lu.assertEquals(candidate(3), false)\n    lu.assertEquals(candidate(-2), true)\n    lu.assertEquals(candidate(42), true)\n    lu.assertEquals(candidate(15), false)\n    lu.assertEquals(candidate(2017), false)\n    lu.assertEquals(candidate(1), false)\n    lu.assertEquals(candidate(-1), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_144200_curate_list", "language": "lua", "prompt": "-- :param input_list:\n-- :type input_list:\n-- :param words_list:\n-- :type words_list:\n-- :return:\n-- :rtype:\nlocal function curate_list(input_list, words_list)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_144200_curate_list.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = curate_list\n    lu.assertEquals(candidate({}, {}), {})\n    lu.assertEquals(candidate({'a', 'b', 'c', 'd', 'e', 'f', 'g'}, {'a', 'b', 'c', 'd', 'e'}), {'a', 'b', 'c', 'd', 'e'})\n    lu.assertEquals(candidate({'a', 'b', 'c', 'd', 'e'}, {'a', 'b', 'c', 'd', 'e', 'f', 'g'}), {'a', 'b', 'c', 'd', 'e'})\n    lu.assertEquals(candidate({'a', 'b', 'c', 'd', 'e'}, {'a', 'b', 'c', 'd', 'e'}), {'a', 'b', 'c', 'd', 'e'})\n    lu.assertEquals(candidate({}, {'a', 'b', 'c'}), {})\n    lu.assertEquals(candidate({'a', 'b', 'c'}, {}), {})\n    lu.assertEquals(candidate({'a', 'b', 'c', 'd', 'e', 'f', 'g'}, {'h', 'i', 'j', 'k', 'l', 'm', 'n'}), {})\n    lu.assertEquals(candidate({'the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog'}, {'the', 'quick', 'brown', 'fox', 'jumped', 'the', 'lazy', 'dog'}), {'the', 'quick', 'brown', 'fox', 'jumped', 'the', 'lazy', 'dog'})\n    lu.assertEquals(candidate({'a', 'b', 'c', 'd', 'e', 'f', 'g'}, {}), {})\n    lu.assertEquals(candidate({'the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog'}, {'the', 'quick', 'brown', 'fox', 'over', 'the', 'lazy', 'dog'}), {'the', 'quick', 'brown', 'fox', 'over', 'the', 'lazy', 'dog'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_144223_line_id_2_txt", "language": "lua", "prompt": "-- Convert line id (integer) to string nnnn\n-- :return: line_id_txt -> <string> ID de la linia introduit en format text\nlocal function line_id_2_txt(line_id)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_144223_line_id_2_txt.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = line_id_2_txt\n    lu.assertEquals(candidate(3), '0003')\n    lu.assertEquals(candidate(19), '0019')\n    lu.assertEquals(candidate(999), '0999')\n    lu.assertEquals(candidate(24), '0024')\n    lu.assertEquals(candidate(9999), '9999')\n    lu.assertEquals(candidate(17), '0017')\n    lu.assertEquals(candidate(25), '0025')\n    lu.assertEquals(candidate(255), '0255')\n    lu.assertEquals(candidate(0), '0000')\n    lu.assertEquals(candidate(9), '0009')\n    lu.assertEquals(candidate(6), '0006')\n    lu.assertEquals(candidate(1), '0001')\n    lu.assertEquals(candidate(12), '0012')\n    lu.assertEquals(candidate(16), '0016')\n    lu.assertEquals(candidate(7), '0007')\n    lu.assertEquals(candidate(12), '0012')\n    lu.assertEquals(candidate(10), '0010')\n    lu.assertEquals(candidate(18), '0018')\n    lu.assertEquals(candidate(5000), '5000')\n    lu.assertEquals(candidate(15), '0015')\n    lu.assertEquals(candidate(2), '0002')\n    lu.assertEquals(candidate(8), '0008')\n    lu.assertEquals(candidate(1), '0001')\n    lu.assertEquals(candidate(99), '0099')\n    lu.assertEquals(candidate(1000), '1000')\n    lu.assertEquals(candidate(13), '0013')\n    lu.assertEquals(candidate(20), '0020')\n    lu.assertEquals(candidate(240), '0240')\n    lu.assertEquals(candidate(5), '0005')\n    lu.assertEquals(candidate(0), '0000')\n    lu.assertEquals(candidate(100), '0100')\n    lu.assertEquals(candidate(4), '0004')\n    lu.assertEquals(candidate(14), '0014')\n    lu.assertEquals(candidate(99999), '99999')\n    lu.assertEquals(candidate(12345), '12345')\n    lu.assertEquals(candidate(11), '0011')\n    lu.assertEquals(candidate(111), '0111')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_144251_keyword_filter", "language": "lua", "prompt": "-- return true if url contains all keywords,\n-- return false otherwise \nlocal function keyword_filter(url, keywords)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_144251_keyword_filter.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = keyword_filter\n    lu.assertEquals(candidate('http://foo.com/bar?a=1&b=2', {'a', 'b'}), true)\n    lu.assertEquals(candidate('http://foo.com/bar?a=1&b=2', {'b'}), true)\n    lu.assertEquals(candidate('http://foo.com/bar?a=1&b=2', {'a', 'b', 'c', 'd'}), false)\n    lu.assertEquals(candidate('http://foo.com/bar?a=1&b=2', {'a'}), true)\n    lu.assertEquals(candidate('http://foo.com/bar?a=1&b=2', {}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_144645__remove_prefix", "language": "lua", "prompt": "-- Removes prefixed from absolute etcd paths\nlocal function _remove_prefix(path)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_144645__remove_prefix.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _remove_prefix\n    lu.assertEquals(candidate('/a/b/c'), 'c')\n    lu.assertEquals(candidate('/a/b'), 'b')\n    lu.assertEquals(candidate('/a'), 'a')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('/foo/bar'), 'bar')\n    lu.assertEquals(candidate('/'), '')\n    lu.assertEquals(candidate('/foo'), 'foo')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_144790_iscsi_portal_with_port", "language": "lua", "prompt": "-- Add default port 3260 to iSCSI portal\n-- :param address: iSCSI portal without port\n-- :return: iSCSI portal with default port 3260\nlocal function iscsi_portal_with_port(address)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_144790_iscsi_portal_with_port.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = iscsi_portal_with_port\n    lu.assertEquals(candidate('10.1.2.3'), '10.1.2.3:3260')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_14508_betweenness_index", "language": "lua", "prompt": "--     find the index associated to a point in the static graph. See betweenness_centrality.\nlocal function betweenness_index(n_nodes, n_times, node_index, time_index, layer_index)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_14508_betweenness_index.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = betweenness_index\n    lu.assertEquals(candidate(1, 1, 0, 0, 0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_145532_middle_me", "language": "lua", "prompt": "--  This function takes a key of X and place it in the middle of Y repeated N times. \nlocal function middle_me(N, X, Y)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_145532_middle_me.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = middle_me\n    lu.assertEquals(candidate(1, 'abc', 'xyz'), 'abc')\n    lu.assertEquals(candidate(2, '', 'abc'), 'abcabc')\n    lu.assertEquals(candidate(2, 'abc', 'z'), 'zabcz')\n    lu.assertEquals(candidate(2, '', ''), '')\n    lu.assertEquals(candidate(2, '', 'def'), 'defdef')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_145712_valid_ip", "language": "lua", "prompt": "-- Check if an IP address is valid.\nlocal function valid_ip(query)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_145712_valid_ip.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = valid_ip\n    lu.assertEquals(candidate('127.0.0.1:8080'), false)\n    lu.assertEquals(candidate('127.0.0.1'), true)\n    lu.assertEquals(candidate('192.168.1.1.1.1'), false)\n    lu.assertEquals(candidate('192.168.1.1.1.1.1.1'), false)\n    lu.assertEquals(candidate('192.168.255.255'), true)\n    lu.assertEquals(candidate('0.0.0.0.0'), false)\n    lu.assertEquals(candidate('192.168.1.1'), true)\n    lu.assertEquals(candidate('255.255.255.255'), true)\n    lu.assertEquals(candidate('0.0.0.0'), true)\n    lu.assertEquals(candidate('255.255.255.255'), true)\n    lu.assertEquals(candidate('1.2.3.4'), true)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('192.168.3.11'), true)\n    lu.assertEquals(candidate('256.127.0.1'), false)\n    lu.assertEquals(candidate('abc'), false)\n    lu.assertEquals(candidate('127.0.0.256'), false)\n    lu.assertEquals(candidate('abc'), false)\n    lu.assertEquals(candidate('192.168.1.255'), true)\n    lu.assertEquals(candidate('127.0.256.1'), false)\n    lu.assertEquals(candidate('192.168.1.1.1.1.1'), false)\n    lu.assertEquals(candidate('127.0.0.300'), false)\n    lu.assertEquals(candidate('256.0.0.0'), false)\n    lu.assertEquals(candidate('192.168.1.1.1'), false)\n    lu.assertEquals(candidate('1.2.3.4.5'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_145929_containsExploit", "language": "lua", "prompt": "--  Returns whether or not the given str contains evidence that it is an open redirect exploit \nlocal function containsExploit(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_145929_containsExploit.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = containsExploit\n    lu.assertEquals(candidate('hi there! http://localhost/'), true)\n    lu.assertEquals(candidate('hi there! http://[::1]'), true)\n    lu.assertEquals(candidate('Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc euismod purus sit amet ante facilisis, quis rhoncus urna tempor. In hac habitasse platea dictumst. Aenean ullamcorper, diam in ornare posuere, eros odio tempus purus, vel vehicula sem dolor ut lorem. Vivamus a tincidunt turpis. Etiam eu dui vel odio commodo fringilla. Vestibulum ultrices, neque in facilisis pellentesque, nunc nibh interdum tortor, at venenatis risus nulla nec libero. Quisque viverra sapien vel lectus ultricies, quis mollis nisl fermentum. Morbi semper auctor mi, id hendrerit nunc. Mauris mattis eros non magna faucibus, id tincidunt diam interdum. Quisque congue lorem at arcu rhoncus, a gravida urna aliquet. Nunc vel diam lacinia, ullamcorper felis ut, convallis magna.'), false)\n    lu.assertEquals(candidate('hi there! https://[::1]/foo'), true)\n    lu.assertEquals(candidate('hi there! https://[::1]:8000/'), true)\n    lu.assertEquals(candidate('hello'), false)\n    lu.assertEquals(candidate('hi there! http://[::1]:8000/'), true)\n    lu.assertEquals(candidate('hi there! http://[::1]/foo'), true)\n    lu.assertEquals(candidate('hi there! http://example.com/test/123456?abc=1'), true)\n    lu.assertEquals(candidate('javascript:alert(1)'), true)\n    lu.assertEquals(candidate('Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer vel dolor ac diam bibendum placerat non non erat. Praesent non massa sit amet erat dapibus posuere. Sed quis orci et nisl dapibus iaculis.'), false)\n    lu.assertEquals(candidate('http://example.com'), true)\n    lu.assertEquals(candidate('https://example.com'), true)\n    lu.assertEquals(candidate('hi there! https://[::1]'), true)\n    lu.assertEquals(candidate('hi there! http://127.0.0.1/'), true)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('hi there! https://[::1]/'), true)\n    lu.assertEquals(candidate('hi there! http://example.com'), true)\n    lu.assertEquals(candidate('Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.'), false)\n    lu.assertEquals(candidate('hi there! javascript:alert(1)'), true)\n    lu.assertEquals(candidate('hi there! http://[::1]:8000'), true)\n    lu.assertEquals(candidate('hi there'), false)\n    lu.assertEquals(candidate('hi there! https://example.com/test/123456'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_146824_is_fq", "language": "lua", "prompt": "-- Return True if the supplied 'name' is fully-qualified, False otherwise.\n-- Usage examples:\n--     >>> is_fq('master')\n--     False\n--     >>> is_fq('refs/heads/master')\n--     True\n-- :name: string name of the ref to test\n-- :returns: bool\nlocal function is_fq(name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_146824_is_fq.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_fq\n    lu.assertEquals(candidate('master'), false)\n    lu.assertEquals(candidate('master'), false)\n    lu.assertEquals(candidate('refs/heads/master'), true)\n    lu.assertEquals(candidate('refs/heads/master'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_147099_style_to_dict", "language": "lua", "prompt": "-- Parses an HTML tag style attribute.\n-- :param style:\nlocal function style_to_dict(style)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_147099_style_to_dict.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = style_to_dict\n    lu.assertEquals(candidate('font-style: italic; font-style: normal'), {['font-style'] = 'normal'})\n    lu.assertEquals(candidate('font-weight: bold; font-style: italic'), {['font-weight'] = 'bold', ['font-style'] = 'italic'})\n    lu.assertEquals(candidate('color: rgb(255, 0, 0)'), {['color'] = 'rgb(255, 0, 0)'})\n    lu.assertEquals(candidate('display: block; display: inline-block; display: none'), {['display'] = 'none'})\n    lu.assertEquals(candidate('color: red; margin: 5px; font-size: 20px;'), {['color'] = 'red', ['margin'] = '5px', ['font-size'] = '20px'})\n    lu.assertEquals(candidate('foo'), {})\n    lu.assertEquals(candidate('color: red; margin: 5px;'), {['color'] = 'red', ['margin'] = '5px'})\n    lu.assertEquals(candidate('foo;'), {})\n    lu.assertEquals(candidate('margin:10px'), {['margin'] = '10px'})\n    lu.assertEquals(candidate('color: rgba(255, 0, 0, 0.5)'), {['color'] = 'rgba(255, 0, 0, 0.5)'})\n    lu.assertEquals(candidate(';;'), {})\n    lu.assertEquals(candidate('font-size: 123;'), {['font-size'] = '123'})\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('font-size: 14px'), {['font-size'] = '14px'})\n    lu.assertEquals(candidate('font-size: 123; color: #fff; color: #abc;'), {['font-size'] = '123', ['color'] = '#abc'})\n    lu.assertEquals(candidate('background-color:red;'), {['background-color'] = 'red'})\n    lu.assertEquals(candidate(' '), {})\n    lu.assertEquals(candidate('font-size: 13px; color: white; background-color: blue;'), {['font-size'] = '13px', ['color'] = 'white', ['background-color'] = 'blue'})\n    lu.assertEquals(candidate(';'), {})\n    lu.assertEquals(candidate('color: #f00'), {['color'] = '#f00'})\n    lu.assertEquals(candidate('margin-top:10px; margin-right:10px; margin-bottom:10px; margin-left:10px;'), {['margin-top'] = '10px', ['margin-right'] = '10px', ['margin-bottom'] = '10px', ['margin-left'] = '10px'})\n    lu.assertEquals(candidate('color: #ff0000'), {['color'] = '#ff0000'})\n    lu.assertEquals(candidate('color: red; margin: 5px; font-size: 20px;;'), {['color'] = 'red', ['margin'] = '5px', ['font-size'] = '20px'})\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('margin-top:10px; padding:20px'), {['margin-top'] = '10px', ['padding'] = '20px'})\n    lu.assertEquals(candidate('color: #ff0000;'), {['color'] = '#ff0000'})\n    lu.assertEquals(candidate('color: red;'), {['color'] = 'red'})\n    lu.assertEquals(candidate(' ; '), {})\n    lu.assertEquals(candidate('font-size: 123; color: #fff;'), {['font-size'] = '123', ['color'] = '#fff'})\n    lu.assertEquals(candidate(';'), {})\n    lu.assertEquals(candidate('font-size: 123; font-size: 456;'), {['font-size'] = '456'})\n    lu.assertEquals(candidate('foo;bar'), {})\n    lu.assertEquals(candidate('border:1px solid blue; font-size:18pt'), {['border'] = '1px solid blue', ['font-size'] = '18pt'})\n    lu.assertEquals(candidate('color: red; font-size: 12; display: block; display: inline-block'), {['color'] = 'red', ['font-size'] = '12', ['display'] = 'inline-block'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_14777_sqlite3_quote_name", "language": "lua", "prompt": "-- Quote `name` as a SQL identifier, e.g. a table or column name.\n-- Do NOT use this for strings, e.g. inserting data into a table.\n-- Use query parameters instead.\nlocal function sqlite3_quote_name(name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_14777_sqlite3_quote_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sqlite3_quote_name\n    lu.assertEquals(candidate('a\\rb\\nc'), '\"a\\rb\\nc\"')\n    lu.assertEquals(candidate('a.b.c'), '\"a.b.c\"')\n    lu.assertEquals(candidate(''), '\"\"')\n    lu.assertEquals(candidate('a1'), '\"a1\"')\n    lu.assertEquals(candidate('ABC'), '\"ABC\"')\n    lu.assertEquals(candidate('a'), '\"a\"')\n    lu.assertEquals(candidate('a\"b.c.d'), '\"a\"\"b.c.d\"')\n    lu.assertEquals(candidate('a.b.c\"d'), '\"a.b.c\"\"d\"')\n    lu.assertEquals(candidate('a.b\"c.d'), '\"a.b\"\"c.d\"')\n    lu.assertEquals(candidate('a.b.c.d'), '\"a.b.c.d\"')\n    lu.assertEquals(candidate('a.b'), '\"a.b\"')\n    lu.assertEquals(candidate('a b\"c d'), '\"a b\"\"c d\"')\n    lu.assertEquals(candidate('a.b.c.d\"'), '\"a.b.c.d\"\"\"')\n    lu.assertEquals(candidate('abc\"def'), '\"abc\"\"def\"')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_148003_Name_Validation", "language": "lua", "prompt": "--  Function to Validate a Name for Input: Allowing Spaces, - and '\nlocal function Name_Validation(Name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_148003_Name_Validation.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = Name_Validation\n    lu.assertEquals(candidate('Anne-Marie'), true)\n    lu.assertEquals(candidate('Sabrina'), true)\n    lu.assertEquals(candidate('<NAME>'), false)\n    lu.assertEquals(candidate('Anne Marie'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_148266_get_env", "language": "lua", "prompt": "--  If args contain `pypi-dev`, the package name will be `knackpy-dev`. Else the\n-- package name will be Knackpy.\nlocal function get_env(args)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_148266_get_env.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_env\n    lu.assertEquals(candidate({'pypi-dev'}), 'dev')\n    lu.assertEquals(candidate({}), 'prod')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_148854_toHex", "language": "lua", "prompt": "-- Converts the given value (0-255) into its hexadecimal representation\nlocal function toHex(val)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_148854_toHex.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = toHex\n    lu.assertEquals(candidate(128), '80')\n    lu.assertEquals(candidate(1), '01')\n    lu.assertEquals(candidate(47), '2f')\n    lu.assertEquals(candidate(167), 'a7')\n    lu.assertEquals(candidate(17), '11')\n    lu.assertEquals(candidate(5), '05')\n    lu.assertEquals(candidate(10), '0a')\n    lu.assertEquals(candidate(118), '76')\n    lu.assertEquals(candidate(20), '14')\n    lu.assertEquals(candidate(16), '10')\n    lu.assertEquals(candidate(23), '17')\n    lu.assertEquals(candidate(15), '0f')\n    lu.assertEquals(candidate(2), '02')\n    lu.assertEquals(candidate(12), '0c')\n    lu.assertEquals(candidate(254), 'fe')\n    lu.assertEquals(candidate(0), '00')\n    lu.assertEquals(candidate(255), 'ff')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_14894_copy_dict", "language": "lua", "prompt": "-- Returns a copy of source_dict, updated with the new key-value pairs in diffs.\nlocal function copy_dict(source_dict, diffs)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_14894_copy_dict.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = copy_dict\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2}, {['b'] = 2}), {['a'] = 1, ['b'] = 2})\n    lu.assertEquals(candidate({['x'] = 1, ['y'] = 2, ['z'] = 3}, {['x'] = 1, ['y'] = 2, ['z'] = 3}), {['x'] = 1, ['y'] = 2, ['z'] = 3})\n    lu.assertEquals(candidate(dict(), {}), {})\n    lu.assertEquals(candidate({}, {['a'] = 1, ['b'] = 2, ['c'] = 3}), {['a'] = 1, ['b'] = 2, ['c'] = 3})\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2}, {['a'] = 2, ['b'] = 2}), {['a'] = 2, ['b'] = 2})\n    lu.assertEquals(candidate({['x'] = 1, ['y'] = 2, ['z'] = 3}, {}), {['x'] = 1, ['y'] = 2, ['z'] = 3})\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2}, {['b'] = 2, ['c'] = 3, ['d'] = 4}), {['a'] = 1, ['b'] = 2, ['c'] = 3, ['d'] = 4})\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2}, {['a'] = 2, ['b'] = 2, ['c'] = 3, ['d'] = 4}), {['a'] = 2, ['b'] = 2, ['c'] = 3, ['d'] = 4})\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2}, {['b'] = 2, ['c'] = 3}), {['a'] = 1, ['b'] = 2, ['c'] = 3})\n    lu.assertEquals(candidate({['x'] = 1, ['y'] = 2, ['z'] = 3}, {['a'] = 1, ['b'] = 2, ['c'] = 3}), {['a'] = 1, ['b'] = 2, ['c'] = 3, ['x'] = 1, ['y'] = 2, ['z'] = 3})\n    lu.assertEquals(candidate({['x'] = 1, ['y'] = 2, ['z'] = 3}, {['w'] = 7, ['x'] = 8}), {['w'] = 7, ['x'] = 8, ['y'] = 2, ['z'] = 3})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_149266_ascii_replace", "language": "lua", "prompt": "-- replace quotes with their ASCII character representation\n-- Args:\n--     text (str): text to replace in\n-- Returns:\n--     str: replaced text\nlocal function ascii_replace(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_149266_ascii_replace.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = ascii_replace\n    lu.assertEquals(candidate('[This] [is a] [test].'), '[This] [is a] [test].')\n    lu.assertEquals(candidate('This is [a] test'), 'This is [a] test')\n    lu.assertEquals(candidate('This [is] a test.'), 'This [is] a test.')\n    lu.assertEquals(candidate(\"Bob's favorite language is [&#39;]Python\"), \"Bob&#39;s favorite language is [']Python\")\n    lu.assertEquals(candidate('I love to ride my bike.'), 'I love to ride my bike.')\n    lu.assertEquals(candidate('This is [a] [test]'), 'This is [a] [test]')\n    lu.assertEquals(candidate('[This] is [a] [test].'), '[This] is [a] [test].')\n    lu.assertEquals(candidate('This is a test]'), 'This is a test]')\n    lu.assertEquals(candidate(\"''\"), '&#39;&#39;')\n    lu.assertEquals(candidate('This is a test.'), 'This is a test.')\n    lu.assertEquals(candidate('&#39;'), '&#39;')\n    lu.assertEquals(candidate('[This is a test].'), '[This is a test].')\n    lu.assertEquals(candidate(\"There's no place like home, home is where the heart is.\"), 'There&#39;s no place like home, home is where the heart is.')\n    lu.assertEquals(candidate('[This] is a test.'), '[This] is a test.')\n    lu.assertEquals(candidate(\"Hi, my name is 'Bob'\"), 'Hi, my name is &#39;Bob&#39;')\n    lu.assertEquals(candidate('This is [a test'), 'This is [a test')\n    lu.assertEquals(candidate('This is a [test]'), 'This is a [test]')\n    lu.assertEquals(candidate('I&#39;m a programmer'), candidate(\"I'm a programmer\"))\n    lu.assertEquals(candidate(\"this should be a simple quote: '&#39;\"), 'this should be a simple quote: &#39;&#39;')\n    lu.assertEquals(candidate(\"this should be a simple quote: '\"), 'this should be a simple quote: &#39;')\n    lu.assertEquals(candidate('This is [a] test.'), 'This is [a] test.')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_149402_obtenerBinario", "language": "lua", "prompt": "-- bin(numero) obtiene el valor binario de numero\n-- [2:] obtiene los elementos de del binario anterior excepto los primeros 2, por ejemplo 11000000[2:] regresa 000000\n-- zfill(8) rellena con ceros a la izquiera el valor anterior hasta que este tenga longitud 8, por ejemplo 111111 regresa 00111111\nlocal function obtenerBinario(numero)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_149402_obtenerBinario.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = obtenerBinario\n    lu.assertEquals(candidate(12), '00001100')\n    lu.assertEquals(candidate(0), '00000000')\n    lu.assertEquals(candidate(2), '00000010')\n    lu.assertEquals(candidate(128), '10000000')\n    lu.assertEquals(candidate(2048), '100000000000')\n    lu.assertEquals(candidate(21), '00010101')\n    lu.assertEquals(candidate(64), '01000000')\n    lu.assertEquals(candidate(19), '00010011')\n    lu.assertEquals(candidate(15), '00001111')\n    lu.assertEquals(candidate(8), '00001000')\n    lu.assertEquals(candidate(7), '00000111')\n    lu.assertEquals(candidate(19), '00010011')\n    lu.assertEquals(candidate(128), '10000000')\n    lu.assertEquals(candidate(6), '00000110')\n    lu.assertEquals(candidate(0), '00000000')\n    lu.assertEquals(candidate(9), '00001001')\n    lu.assertEquals(candidate(18), '00010010')\n    lu.assertEquals(candidate(9), '00001001')\n    lu.assertEquals(candidate(187), '10111011')\n    lu.assertEquals(candidate(3), '00000011')\n    lu.assertEquals(candidate(1024), '10000000000')\n    lu.assertEquals(candidate(14), '00001110')\n    lu.assertEquals(candidate(2), '00000010')\n    lu.assertEquals(candidate(12), '00001100')\n    lu.assertEquals(candidate(13), '00001101')\n    lu.assertEquals(candidate(1), '00000001')\n    lu.assertEquals(candidate(0), '00000000')\n    lu.assertEquals(candidate(17), '00010001')\n    lu.assertEquals(candidate(6), '00000110')\n    lu.assertEquals(candidate(7), '00000111')\n    lu.assertEquals(candidate(17), '00010001')\n    lu.assertEquals(candidate(18), '00010010')\n    lu.assertEquals(candidate(16), '00010000')\n    lu.assertEquals(candidate(64), '01000000')\n    lu.assertEquals(candidate(5), '00000101')\n    lu.assertEquals(candidate(10), '00001010')\n    lu.assertEquals(candidate(2), '00000010')\n    lu.assertEquals(candidate(16), '00010000')\n    lu.assertEquals(candidate(15), '00001111')\n    lu.assertEquals(candidate(4), '00000100')\n    lu.assertEquals(candidate(4), '00000100')\n    lu.assertEquals(candidate(14), '00001110')\n    lu.assertEquals(candidate(1), '00000001')\n    lu.assertEquals(candidate(32), '00100000')\n    lu.assertEquals(candidate(4), '00000100')\n    lu.assertEquals(candidate(5), '00000101')\n    lu.assertEquals(candidate(8), '00001000')\n    lu.assertEquals(candidate(128), '10000000')\n    lu.assertEquals(candidate(3), '00000011')\n    lu.assertEquals(candidate(1), '00000001')\n    lu.assertEquals(candidate(10), '00001010')\n    lu.assertEquals(candidate(20), '00010100')\n    lu.assertEquals(candidate(170), '10101010')\n    lu.assertEquals(candidate(8), '00001000')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_149428_squared_loss", "language": "lua", "prompt": "-- Returns the squared difference between two numbers\nlocal function squared_loss(x1, x2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_149428_squared_loss.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = squared_loss\n    lu.assertEquals(candidate(0, 0), 0)\n    lu.assertEquals(candidate(-1, -2), 1)\n    lu.assertEquals(candidate(3, 3), 0)\n    lu.assertEquals(candidate(5, 2), 9)\n    lu.assertEquals(candidate(5, 5), 0)\n    lu.assertEquals(candidate(1, 1), 0)\n    lu.assertEquals(candidate(1, 2), 1)\n    lu.assertEquals(candidate(5, 3), 4)\n    lu.assertEquals(candidate(4, 3), 1)\n    lu.assertEquals(candidate(10, 5), 25)\n    lu.assertEquals(candidate(9, 0), 81)\n    lu.assertEquals(candidate(3, 5), 4)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_149915_next_enum_variation", "language": "lua", "prompt": "-- Loop through indices from [0, 0, ...] to [L0-1, L1-1, ...]\n-- where Li is len(enums[i]).  The list can be thought of as a number with many\n-- digits, where each digit is in [0, Li), and this function effectively implements\n-- the increment operation, with the least-significant digit being the first item.\nlocal function next_enum_variation(enums, enum_indices)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_149915_next_enum_variation.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = next_enum_variation\n    lu.assertEquals(candidate({{'a', {'a', 'b', 'c'}}, {'b', {'x', 'y', 'z'}}}, {0, 0}), true)\n    lu.assertEquals(candidate({{'a', {'a', 'b', 'c'}}, {'b', {'x', 'y', 'z'}}}, {2, 1}), true)\n    lu.assertEquals(candidate({{'a', {'a', 'b', 'c'}}, {'b', {'x', 'y', 'z'}}}, {2, 0}), true)\n    lu.assertEquals(candidate({{'A', {'a', 'b'}}, {'B', {'c', 'd'}}}, {1, 0}), true)\n    lu.assertEquals(candidate({{'A', {'a', 'b'}}, {'B', {'c'}}}, {0, 0}), true)\n    lu.assertEquals(candidate({{'a', {'a', 'b', 'c'}}, {'b', {'x', 'y', 'z'}}}, {1, 1}), true)\n    lu.assertEquals(candidate({{'a', {'b', 'c'}}, {'d', {'e', 'f'}}}, {1, 2}), false)\n    lu.assertEquals(candidate({{'a', {'b', 'c'}}, {'d', {'e', 'f'}}}, {0, 0}), true)\n    lu.assertEquals(candidate({{'A', {'a', 'b'}}, {'B', {'c'}}}, {1, 0}), false)\n    lu.assertEquals(candidate({{'a', {'a', 'b', 'c'}}, {'b', {'x', 'y', 'z'}}}, {0, 1}), true)\n    lu.assertEquals(candidate({{'a', {'b', 'c'}}, {'d', {'e', 'f'}}}, {1, 0}), true)\n    lu.assertEquals(candidate({{'a', {'a', 'b', 'c'}}, {'b', {'x', 'y', 'z'}}}, {1, 0}), true)\n    lu.assertEquals(candidate({{'a', {'b', 'c'}}, {'d', {'e', 'f'}}}, {2, 1}), false)\n    lu.assertEquals(candidate({{'a', {'b', 'c'}}, {'d', {'e', 'f'}}}, {0, 1}), true)\n    lu.assertEquals(candidate({{'A', {'a', 'b'}}, {'B', {'c', 'd'}}}, {0, 0}), true)\n    lu.assertEquals(candidate({{'a', {'b', 'c'}}, {'d', {'e', 'f'}}}, {1, 1}), false)\n    lu.assertEquals(candidate({{'A', {'a', 'b'}}, {'B', {'c', 'd'}}, {'C', {'e', 'f'}}}, {0, 0, 0}), true)\n    lu.assertEquals(candidate({{'A', {'a', 'b'}}, {'B', {'c', 'd'}}, {'C', {'e', 'f'}}}, {1, 0, 0}), true)\n    lu.assertEquals(candidate({{'a', {'b', 'c'}}, {'d', {'e', 'f'}}}, {2, 2}), false)\n    lu.assertEquals(candidate({{'a', {'a', 'b', 'c'}}, {'b', {'x', 'y', 'z'}}}, {1, 2}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_149954_to_lutron_level", "language": "lua", "prompt": "-- Convert the given Home Assistant light level (0-255) to Lutron (0-100).\nlocal function to_lutron_level(level)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_149954_to_lutron_level.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = to_lutron_level\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(254), 99)\n    lu.assertEquals(candidate(255), 100)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_150881_position", "language": "lua", "prompt": "-- Return a heuristic value based on the position of the largest value on the board.\nlocal function position(b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_150881_position.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = position\n    lu.assertEquals(candidate({{0, 0, 0, 0, 0}, {0, 0, 0, 0, 0}, {0, 0, 0, 0, 0}, {0, 0, 0, 0, 0}, {0, 0, 0, 0, 0}}), 0)\n    lu.assertEquals(candidate({{3, 5, 7}, {3, 5, 7}}), 0)\n    lu.assertEquals(candidate({{1, 0, 3}, {4, 5, 6}, {7, 8, 9}}), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_152130_parse_list", "language": "lua", "prompt": "--  Parse a list of input strings \nlocal function parse_list(val)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_152130_parse_list.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_list\n    lu.assertEquals(candidate(' 1, 2, 3'), '[1, 2, 3]')\n    lu.assertEquals(candidate('  1, 2, 3  '), '[1, 2, 3]')\n    lu.assertEquals(candidate(''), '[]')\n    lu.assertEquals(candidate('    '), '[]')\n    lu.assertEquals(candidate('1, 2, 3'), '[1, 2, 3]')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_154389_roman_to_int", "language": "lua", "prompt": "--  Convert a Roman numeral to an integer.\n-- Adopted from https://www.oreilly.com/library/view/python-cookbook/0596001673/ch03s24.html\nlocal function roman_to_int(expr)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_154389_roman_to_int.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = roman_to_int\n    lu.assertEquals(candidate('MMXXIV'), 2024)\n    lu.assertEquals(candidate('L'), 50)\n    lu.assertEquals(candidate('MCMXCIV'), 1994)\n    lu.assertEquals(candidate('MCMLXXXIX'), 1989)\n    lu.assertEquals(candidate('IIII'), 4)\n    lu.assertEquals(candidate('IX'), 9)\n    lu.assertEquals(candidate('MCMLXXXIV'), 1984)\n    lu.assertEquals(candidate('V'), 5)\n    lu.assertEquals(candidate('I'), 1)\n    lu.assertEquals(candidate('XXXV'), 35)\n    lu.assertEquals(candidate('C'), 100)\n    lu.assertEquals(candidate('X'), 10)\n    lu.assertEquals(candidate('MMMM'), 4000)\n    lu.assertEquals(candidate('LVIII'), 58)\n    lu.assertEquals(candidate('D'), 500)\n    lu.assertEquals(candidate('II'), 2)\n    lu.assertEquals(candidate('CLXVI'), 166)\n    lu.assertEquals(candidate('M'), 1000)\n    lu.assertEquals(candidate('IV'), 4)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_154778__clamp_transpose", "language": "lua", "prompt": "-- Clamps the specified transpose amount to keep a ns in the desired bounds.\n-- Args:\n--   transpose_amount: Number of steps to transpose up or down.\n--   ns_min_pitch: The lowest pitch in the target note sequence.\n--   ns_max_pitch: The highest pitch in the target note sequence.\n--   min_allowed_pitch: The lowest pitch that should be allowed in the transposed\n--     note sequence.\n--   max_allowed_pitch: The highest pitch that should be allowed in the\n--     transposed note sequence.\n-- Returns:\n--   A new transpose amount that, if applied to the target note sequence, will\n--   keep all notes within the range [MIN_PITCH, MAX_PITCH]\nlocal function _clamp_transpose(transpose_amount, ns_min_pitch, ns_max_pitch, min_allowed_pitch, max_allowed_pitch)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_154778__clamp_transpose.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _clamp_transpose\n    lu.assertEquals(candidate(1, 24, 25, 24, 26), 1)\n    lu.assertEquals(candidate(1, 24, 25, 21, 26), 1)\n    lu.assertEquals(candidate(1, 24, 25, 23, 26), 1)\n    lu.assertEquals(candidate(0, 21, 108, 0, 127), 0)\n    lu.assertEquals(candidate(0, 21, 108, 0, 108), 0)\n    lu.assertEquals(candidate(1, 24, 25, 22, 26), 1)\n    lu.assertEquals(candidate(1, 24, 25, 20, 26), 1)\n    lu.assertEquals(candidate(1, 24, 25, 25, 26), 1)\n    lu.assertEquals(candidate(1, 24, 25, 20, 24), -1)\n    lu.assertEquals(candidate(1, 24, 25, 25, 24), -1)\n    lu.assertEquals(candidate(1, 21, 108, 0, 127), 1)\n    lu.assertEquals(candidate(1, 24, 25, 21, 24), -1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_155131_align_up", "language": "lua", "prompt": "-- Align the input variable with unit of sizes. The aligned data will always\n-- be larger than the inputs.\n-- Args:\n--     v: the variable to be aligned.\n--     unit_size: the block size of the aligned data.\n-- Return:\n--     aligned variable.\nlocal function align_up(v, unit_size)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_155131_align_up.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = align_up\n    lu.assertEquals(candidate(5, 4), 8)\n    lu.assertEquals(candidate(8, 8), 8)\n    lu.assertEquals(candidate(1024), 1024)\n    lu.assertEquals(candidate(1, 4), 4)\n    lu.assertEquals(candidate(3), 4)\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(1, 2), 2)\n    lu.assertEquals(candidate(1023), 1024)\n    lu.assertEquals(candidate(2, 3), 3)\n    lu.assertEquals(candidate(8), 8)\n    lu.assertEquals(candidate(7, 4), 8)\n    lu.assertEquals(candidate(3, 8), 8)\n    lu.assertEquals(candidate(1023, 512), 1024)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(2, 2), 2)\n    lu.assertEquals(candidate(3, 4), 4)\n    lu.assertEquals(candidate(-1, 512), 0)\n    lu.assertEquals(candidate(1024, 512), 1024)\n    lu.assertEquals(candidate(6), 6)\n    lu.assertEquals(candidate(-1), 0)\n    lu.assertEquals(candidate(1), 2)\n    lu.assertEquals(candidate(4, 4), 4)\n    lu.assertEquals(candidate(5, 16), 16)\n    lu.assertEquals(candidate(7), 8)\n    lu.assertEquals(candidate(11), 12)\n    lu.assertEquals(candidate(0, 512), 0)\n    lu.assertEquals(candidate(6, 4), 8)\n    lu.assertEquals(candidate(8, 16), 16)\n    lu.assertEquals(candidate(5), 6)\n    lu.assertEquals(candidate(4), 4)\n    lu.assertEquals(candidate(7, 128), 128)\n    lu.assertEquals(candidate(9), 10)\n    lu.assertEquals(candidate(10), 10)\n    lu.assertEquals(candidate(1, 3), 3)\n    lu.assertEquals(candidate(3, 2), 4)\n    lu.assertEquals(candidate(2, 4), 4)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_155421_get_bandwidth", "language": "lua", "prompt": "--  Module to determine the bandwidth for a segment\n-- download\nlocal function get_bandwidth(data, duration)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_155421_get_bandwidth.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_bandwidth\n    lu.assertEquals(candidate(0, 1), 0)\n    lu.assertEquals(candidate(0, 2), 0)\n    lu.assertEquals(candidate(0, 3), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_155975_get_false_positive", "language": "lua", "prompt": "--     Returns True, False for false positive as per DefectDojo standards.\n-- :param false_p:\n-- :return:\nlocal function get_false_positive(false_p)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_155975_get_false_positive.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_false_positive\n    lu.assertEquals(candidate(true), true)\n    lu.assertEquals(candidate(false), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_15619_is_anagram_0", "language": "lua", "prompt": "--     This is my first solution, and it's incorrect because this method checks palindrome, not anagram.\nlocal function is_anagram_0(s1, s2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_15619_is_anagram_0.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_anagram_0\n    lu.assertEquals(candidate('dog', 'dog'), false)\n    lu.assertEquals(candidate('', ' '), false)\n    lu.assertEquals(candidate(' ', ''), false)\n    lu.assertEquals(candidate('ab', 'ba'), true)\n    lu.assertEquals(candidate('a', 'ab'), false)\n    lu.assertEquals(candidate('aba', 'aba'), true)\n    lu.assertEquals(candidate('listen', 'silent'), false)\n    lu.assertEquals(candidate('abc', ''), false)\n    lu.assertEquals(candidate('a', None), false)\n    lu.assertEquals(candidate('abcd', 'badc'), false)\n    lu.assertEquals(candidate('a', 'a'), true)\n    lu.assertEquals(candidate(None, None), false)\n    lu.assertEquals(candidate('ab', None), false)\n    lu.assertEquals(candidate('ab', 'a'), false)\n    lu.assertEquals(candidate('', 'a'), false)\n    lu.assertEquals(candidate('abc', 'def'), false)\n    lu.assertEquals(candidate('abcd', 'dbac'), false)\n    lu.assertEquals(candidate('ab', 'ac'), false)\n    lu.assertEquals(candidate('  d', 'd  '), true)\n    lu.assertEquals(candidate(None, 'ab'), false)\n    lu.assertEquals(candidate('dog', 'god'), true)\n    lu.assertEquals(candidate('aabbcc', 'bbcca'), false)\n    lu.assertEquals(candidate('dog', ''), false)\n    lu.assertEquals(candidate('ab', 'bb'), false)\n    lu.assertEquals(candidate('a', ''), false)\n    lu.assertEquals(candidate('aabb', 'bbaa'), true)\n    lu.assertEquals(candidate('a b', 'b a'), true)\n    lu.assertEquals(candidate('a', 'b'), false)\n    lu.assertEquals(candidate(None, 'a'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_156273__extract_param", "language": "lua", "prompt": "-- Extract a parameter in the style of \"key=value\".\n-- Return `''` if the `arg == name`,\n--        :obj:`None` if the key does not match name,\n--        value otherwise (might be `''`).\nlocal function _extract_param(arg, name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_156273__extract_param.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _extract_param\n    lu.assertEquals(candidate('notkey=value', 'key'), None)\n    lu.assertEquals(candidate('key=value', 'notkey'), None)\n    lu.assertEquals(candidate('', 'a'), None)\n    lu.assertEquals(candidate('a=', 'a'), '')\n    lu.assertEquals(candidate('someother=', 'someother'), '')\n    lu.assertEquals(candidate('a=b', 'a=c'), None)\n    lu.assertEquals(candidate('a=b', 'c='), None)\n    lu.assertEquals(candidate('some=value', 'some'), 'value')\n    lu.assertEquals(candidate('key=value', 'key'), 'value')\n    lu.assertEquals(candidate('a=b', ''), None)\n    lu.assertEquals(candidate('=a', 'a'), None)\n    lu.assertEquals(candidate('a', ''), None)\n    lu.assertEquals(candidate('key=value=more', 'key'), 'value=more')\n    lu.assertEquals(candidate('key', 'key'), '')\n    lu.assertEquals(candidate('a=b', 'c'), None)\n    lu.assertEquals(candidate('=a', '=a'), '')\n    lu.assertEquals(candidate('a=b', 'a'), 'b')\n    lu.assertEquals(candidate('a=b', 'a='), None)\n    lu.assertEquals(candidate('a=', 'a='), '')\n    lu.assertEquals(candidate('', 'key'), None)\n    lu.assertEquals(candidate('some=', 'some'), '')\n    lu.assertEquals(candidate('key=', 'key'), '')\n    lu.assertEquals(candidate('someother=value', 'someother'), 'value')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_156491_numbits", "language": "lua", "prompt": "-- Gets the minimum number of bits required to encode given number of different values.\n-- This method implements zserio built-in operator numBits.\n-- :param num_values: The number of different values from which to calculate number of bits.\n-- :returns: Number of bits required to encode num_values different values.\nlocal function numbits(num_values)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_156491_numbits.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = numbits\n    lu.assertEquals(candidate(26), 5)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(12), 4)\n    lu.assertEquals(candidate(25), 5)\n    lu.assertEquals(candidate(23), 5)\n    lu.assertEquals(candidate(33), 6)\n    lu.assertEquals(candidate(9), 4)\n    lu.assertEquals(candidate(31), 5)\n    lu.assertEquals(candidate(14), 4)\n    lu.assertEquals(candidate(10), 4)\n    lu.assertEquals(candidate(7), 3)\n    lu.assertEquals(candidate(15), 4)\n    lu.assertEquals(candidate(35), 6)\n    lu.assertEquals(candidate(19), 5)\n    lu.assertEquals(candidate(21), 5)\n    lu.assertEquals(candidate(8), 3)\n    lu.assertEquals(candidate(3), 2)\n    lu.assertEquals(candidate(24), 5)\n    lu.assertEquals(candidate(22), 5)\n    lu.assertEquals(candidate(11), 4)\n    lu.assertEquals(candidate(30), 5)\n    lu.assertEquals(candidate(34), 6)\n    lu.assertEquals(candidate(20), 5)\n    lu.assertEquals(candidate(36), 6)\n    lu.assertEquals(candidate(4), 2)\n    lu.assertEquals(candidate(18), 5)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(27), 5)\n    lu.assertEquals(candidate(2), 1)\n    lu.assertEquals(candidate(28), 5)\n    lu.assertEquals(candidate(29), 5)\n    lu.assertEquals(candidate(6), 3)\n    lu.assertEquals(candidate(17), 5)\n    lu.assertEquals(candidate(5), 3)\n    lu.assertEquals(candidate(13), 4)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_157050_takemod", "language": "lua", "prompt": "-- Determine if the input is odd or even values and \n-- return a of 0 and 1 depending on the truth value\n-- Parameters\n-- ----------\n-- nvols : int\n-- Returns\n-- -------\n-- decisions : int\nlocal function takemod(nvols)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_157050_takemod.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = takemod\n    lu.assertEquals(candidate(1), 0)\n    lu.assertEquals(candidate(2), 1)\n    lu.assertEquals(candidate(3), 0)\n    lu.assertEquals(candidate(5), 0)\n    lu.assertEquals(candidate(8), 1)\n    lu.assertEquals(candidate(6), 1)\n    lu.assertEquals(candidate(4), 1)\n    lu.assertEquals(candidate(7), 0)\n    lu.assertEquals(candidate(200), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_157096_unquote", "language": "lua", "prompt": "-- Remove namespace from prefixed tag.\n-- See: [Python issue 18304](https://bugs.python.org/issue18304)\n-- Arguments:\n--     tag {str} -- (possibly-)namespaced tag\n-- Returns:\n--     str -- tag name without namespace\nlocal function unquote(tag)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_157096_unquote.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = unquote\n    lu.assertEquals(candidate('{http://www.w3.org/1999/02/22-rdf-syntax-ns#}Description'), 'Description')\n    lu.assertEquals(candidate('{http://www.w3.org/1999/xhtml}html'), 'html')\n    lu.assertEquals(candidate('{http://www.w3.org/2000/01/rdf-schema#}subClassOf'), 'subClassOf')\n    lu.assertEquals(candidate('{http://www.w3.org/2000/01/rdf-schema#}domain'), 'domain')\n    lu.assertEquals(candidate('{http://www.w3.org/1999/02/22-rdf-syntax-ns#}li'), 'li')\n    lu.assertEquals(candidate('{http://purl.org/dc/elements/1.1/}rights'), 'rights')\n    lu.assertEquals(candidate('bar'), 'bar')\n    lu.assertEquals(candidate('html'), 'html')\n    lu.assertEquals(candidate('{http://www.w3.org/2000/01/rdf-schema#}label'), 'label')\n    lu.assertEquals(candidate('{http://www.example.com}bar'), 'bar')\n    lu.assertEquals(candidate('{http://www.w3.org/1999/xhtml}p'), 'p')\n    lu.assertEquals(candidate('{http://www.w3.org/1999/02/22-rdf-syntax-ns#}Bag'), 'Bag')\n    lu.assertEquals(candidate('{http://www.w3.org/2000/01/rdf-schema#}subPropertyOf'), 'subPropertyOf')\n    lu.assertEquals(candidate('p'), 'p')\n    lu.assertEquals(candidate('{http://schemas.opengis.net/kml/2.2}MultiGeometry'), 'MultiGeometry')\n    lu.assertEquals(candidate('{http://www.w3.org/XML/1998/namespace}lang'), 'lang')\n    lu.assertEquals(candidate('{http://www.w3.org/1999/02/22-rdf-syntax-ns#}RDF'), 'RDF')\n    lu.assertEquals(candidate('foo bar'), 'foo bar')\n    lu.assertEquals(candidate('{http://www.w3.org/2000/01/rdf-schema#}seeAlso'), 'seeAlso')\n    lu.assertEquals(candidate('{http://www.w3.org/2000/01/rdf-schema#}isDefinedBy'), 'isDefinedBy')\n    lu.assertEquals(candidate('{http://www.w3.org/2000/01/rdf-schema#}range'), 'range')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_157569_queen_constraint", "language": "lua", "prompt": "-- Constraint is satisfied (true) if A, B are really the same variable,\n-- or if they are not in the same row, down diagonal, or up diagonal.\nlocal function queen_constraint(A, a, B, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_157569_queen_constraint.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = queen_constraint\n    lu.assertEquals(candidate(1, 1, 3, 1), false)\n    lu.assertEquals(candidate(1, 1, 2, 2), false)\n    lu.assertEquals(candidate(1, 2, 2, 3), false)\n    lu.assertEquals(candidate(0, 3, 1, 3), false)\n    lu.assertEquals(candidate(1, 3, 2, 2), false)\n    lu.assertEquals(candidate(0, 1, 1, 3), true)\n    lu.assertEquals(candidate(1, 2, 4, 2), false)\n    lu.assertEquals(candidate(1, 2, 2, 1), false)\n    lu.assertEquals(candidate(4, 4, 2, 4), false)\n    lu.assertEquals(candidate(1, 3, 3, 1), false)\n    lu.assertEquals(candidate(0, 1, 2, 3), false)\n    lu.assertEquals(candidate(1, 2, 2, 2), false)\n    lu.assertEquals(candidate(1, 1, 1, 1), true)\n    lu.assertEquals(candidate(1, 3, 3, 3), false)\n    lu.assertEquals(candidate(0, 1, 2, 1), false)\n    lu.assertEquals(candidate(1, 1, 2, 1), false)\n    lu.assertEquals(candidate(1, 3, 2, 3), false)\n    lu.assertEquals(candidate(1, 2, 3, 2), false)\n    lu.assertEquals(candidate(1, 3, 3, 2), true)\n    lu.assertEquals(candidate(1, 2, 1, 2), true)\n    lu.assertEquals(candidate(1, 2, 3, 3), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_158362_fix_typo", "language": "lua", "prompt": "-- Helper function. Fix typo in one of the tags\nlocal function fix_typo(name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_158362_fix_typo.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fix_typo\n    lu.assertEquals(candidate('jednostkaAdmnistracyjna'), 'jednostkaAdministracyjna')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_158852_frames", "language": "lua", "prompt": "-- Find the number of frames shown.\nlocal function frames(minutes, fps)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_158852_frames.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = frames\n    lu.assertEquals(candidate(1, 1), 60)\n    lu.assertEquals(candidate(1, 30), 1800)\n    lu.assertEquals(candidate(1, 5), 300)\n    lu.assertEquals(candidate(0, 60), 0)\n    lu.assertEquals(candidate(1, 60), 3600)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_158961_parse_custom_data", "language": "lua", "prompt": "-- Parse SCOUT_CUSTOM info field\n-- Input: \"key1|val1,key2|val2\"\n-- Output: [ [\"key1\",\"val1\"], [\"key2\", \"val2\"] ]\nlocal function parse_custom_data(custom_str)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_158961_parse_custom_data.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_custom_data\n    lu.assertEquals(candidate('key1|val1,key2|val2'), {{'key1', 'val1'}, {'key2', 'val2'}})\n    lu.assertEquals(candidate('key1|val1,key2|val2'), {{'key1', 'val1'}, {'key2', 'val2'}})\n    lu.assertEquals(candidate('key1|val1,key2|val2'), {{'key1', 'val1'}, {'key2', 'val2'}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_159043_rational_to_cfrac", "language": "lua", "prompt": "--     Terms of the simple continued fraction representation of n/d\nlocal function rational_to_cfrac(n, d)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_159043_rational_to_cfrac.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rational_to_cfrac\n    lu.assertEquals(candidate(6, 4), {1, 2})\n    lu.assertEquals(candidate(2, 1), {2})\n    lu.assertEquals(candidate(0, 3), {0})\n    lu.assertEquals(candidate(1234567890, 1), {1234567890})\n    lu.assertEquals(candidate(3, 1), {3})\n    lu.assertEquals(candidate(1, 1), {1})\n    lu.assertEquals(candidate(2, 4), {0, 2})\n    lu.assertEquals(candidate(0, 1), {0})\n    lu.assertEquals(candidate(6, 2), {3})\n    lu.assertEquals(candidate(5, 5), {1})\n    lu.assertEquals(candidate(0, 1), {0})\n    lu.assertEquals(candidate(4, 4), {1})\n    lu.assertEquals(candidate(4, 3), {1, 3})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_159200_linear", "language": "lua", "prompt": "-- linear\n-- Parameters\n-- ----------\n-- x : int\n-- a : float\n-- b : float\n-- Returns\n-- -------\n-- float\n--     a*x + b\nlocal function linear(x, a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_159200_linear.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = linear\n    lu.assertEquals(candidate(3, 2, 1), 7)\n    lu.assertEquals(candidate(5, 3, 1), 16)\n    lu.assertEquals(candidate(1, 1, 0), 1)\n    lu.assertEquals(candidate(0, 1, 1), 1)\n    lu.assertEquals(candidate(0, 0, -1), -1)\n    lu.assertEquals(candidate(6, 1, 0), 6)\n    lu.assertEquals(candidate(0, 1, -1), -1)\n    lu.assertEquals(candidate(0, 1, 0), 0)\n    lu.assertEquals(candidate(4, 3, 1), 13)\n    lu.assertEquals(candidate(0, 0, 0), 0)\n    lu.assertEquals(candidate(3, 3, 1), 10)\n    lu.assertEquals(candidate(1, 2, 3), 5)\n    lu.assertEquals(candidate(1, 3, 1), 4)\n    lu.assertEquals(candidate(3, 1, 0), 3)\n    lu.assertEquals(candidate(6, 3, 1), 19)\n    lu.assertEquals(candidate(3, 5, 6), 21)\n    lu.assertEquals(candidate(0, 2, 2), 2)\n    lu.assertEquals(candidate(5, 1, 0), 5)\n    lu.assertEquals(candidate(10, 0, 0), 0)\n    lu.assertEquals(candidate(2, 1, 0), 2)\n    lu.assertEquals(candidate(4, 1, 0), 4)\n    lu.assertEquals(candidate(0, 0, 1), 1)\n    lu.assertEquals(candidate(2, 3, 1), 7)\n    lu.assertEquals(candidate(1, 0, 0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_159279__kamb_radius", "language": "lua", "prompt": "-- Radius of kernel for Kamb-style smoothing.\nlocal function _kamb_radius(n, sigma)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_159279__kamb_radius.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _kamb_radius\n    lu.assertEquals(candidate(10, 0), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_159762_contains_sublist", "language": "lua", "prompt": "-- Check if one list contains the items from another list (in the same order).\n-- :param lst: The main list.\n-- :param sublist: The sublist to check for.\n-- :returns: :data:`True` if the main list contains the items from the\n--           sublist in the same order, :data:`False` otherwise.\n-- Based on `this StackOverflow answer <http://stackoverflow.com/a/3314913>`_.\nlocal function contains_sublist(lst, sublst)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_159762_contains_sublist.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = contains_sublist\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6}, {2, 3}), true)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 5, 6}), true)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6}, {4, 5, 6}), true)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6}, {5, 6}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_159828_make_key", "language": "lua", "prompt": "-- Make a single string, combining multiple fields.\nlocal function make_key(dir, cmdline)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_159828_make_key.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = make_key\n    lu.assertEquals(candidate('/home/user/src/project1', 'command line argument 2'), '/home/user/src/project1|command line argument 2')\n    lu.assertEquals(candidate('foo|bar', 'ls | grep'), 'foo|bar|ls | grep')\n    lu.assertEquals(candidate('dir', 'other_cmdline'), 'dir|other_cmdline')\n    lu.assertEquals(candidate('foo|bar', 'ls | grep && touch'), 'foo|bar|ls | grep && touch')\n    lu.assertEquals(candidate('foo|bar', 'ls | grep && touch'), 'foo|bar|ls | grep && touch')\n    lu.assertEquals(candidate('foobar', 'echo'), 'foobar|echo')\n    lu.assertEquals(candidate('/home/user/src/project2', 'command line argument 2'), '/home/user/src/project2|command line argument 2')\n    lu.assertEquals(candidate('foobar', 'ls'), 'foobar|ls')\n    lu.assertEquals(candidate('/home/user/src/project2', 'command line argument 1'), '/home/user/src/project2|command line argument 1')\n    lu.assertEquals(candidate('dir', 'cmdline'), 'dir|cmdline')\n    lu.assertEquals(candidate('foo bar', 'ls'), 'foo bar|ls')\n    lu.assertEquals(candidate('/usr', '-h'), '/usr|-h')\n    lu.assertEquals(candidate('foo|bar', 'ls'), 'foo|bar|ls')\n    lu.assertEquals(candidate('/home/user/src/project1', 'command line argument 1'), '/home/user/src/project1|command line argument 1')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_160355_life_counter", "language": "lua", "prompt": "--     returns quanity of living squares\nlocal function life_counter(field)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_160355_life_counter.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = life_counter\n    lu.assertEquals(candidate({{None, None, None, None, None, None, None, None, None, None}, {None, None, None, None, None, None, None, None, None, None}, {None, None, None, None, None, None, None, None, None, None}, {None, None, None, None, None, None, None, None, None, None}, {None, None, None, None, None, None, None, None, None, None}, {None, None, None, None, None, None, None, None, None, None}, {None, None, None, None, None, None, None, None, None, None}, {None, None, None, None, None, None, None, None, None, None}, {None, None, None, None, None, None, None, None, None, None}, {None, None, None, None, None, None, None, None, None, None}}), 0)\n    lu.assertEquals(candidate({{'o', 'o', 'o', 'o', 'o'}, {'o', 'o', 'x', 'o', 'o'}, {'o', 'o', 'o', 'o', 'o'}, {'o', 'o', 'o', 'o', 'o'}, {'o', 'o', 'o', 'o', 'o'}}), 24)\n    lu.assertEquals(candidate({{'o', 'o', 'o', 'o', 'o'}, {'o', 'o', 'o', 'o', 'o'}, {'o', 'o', 'o', 'o', 'o'}, {'o', 'o', 'o', 'o', 'o'}, {'o', 'o', 'o', 'o', 'o'}}), 25)\n    lu.assertEquals(candidate({{'.', '.', '.'}, {'o', 'o', 'o'}, {'o', 'o', 'o'}}), 6)\n    lu.assertEquals(candidate({{'.', '.', '.', '.', '.', '.'}, {'.', 'o', '.', '.', '.', '.'}, {'.', '.', '.', '.', '.', '.'}, {'.', '.', '.', '.', '.', '.'}, {'.', '.', '.', '.', '.', '.'}, {'.', '.', '.', '.', '.', '.'}}), 1)\n    lu.assertEquals(candidate({{'o', 'o', 'o', 'o', 'o'}, {'o', 'o', 'o', 'o', 'o'}, {'o', 'o', 'o', 'o', 'o'}, {'o', 'o', 'o', 'o', 'o'}, {'o', 'o', 'o', 'o', 'o'}}), 25)\n    lu.assertEquals(candidate({{'o', 'o', 'o', 'o'}, {'o', 'o', 'o', 'o'}, {'o', 'o', 'o', 'o'}, {'o', 'o', 'o', 'o'}}), 16)\n    lu.assertEquals(candidate({{'.', '.', '.'}, {'.', '.', '.'}, {'.', '.', '.'}}), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_161014_compute_returns", "language": "lua", "prompt": "--     Compute returns for each time step, given the rewards\n-- @param rewards: list of floats, where rewards[t] is the reward\n--                 obtained at time step t\n-- @param gamma: the discount factor\n-- @returns list of floats representing the episode's returns\n--     G_t = r_t + \\gamma r_{t+1} + \\gamma^2 r_{t+2} + ... \n--     >>> compute_returns([0,0,0,1], 1.0)\n--     [1.0, 1.0, 1.0, 1.0]\n--     >>> compute_returns([0,0,0,1], 0.9)\n--     [0.7290000000000001, 0.81, 0.9, 1.0]\n--     >>> compute_returns([0,-0.5,5,0.5,-10], 0.9)\n--     [-2.5965000000000003, -2.8850000000000002, -2.6500000000000004, -8.5, -10.0]\nlocal function compute_returns(rewards, gamma)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_161014_compute_returns.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = compute_returns\n    lu.assertEquals(candidate({0, 0, 0, 1}, 1.0), {1.0, 1.0, 1.0, 1.0})\n    lu.assertEquals(candidate({0, 0, 0, 1}, 0.9), {0.7290000000000001, 0.81, 0.9, 1.0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_161910_get_F1score", "language": "lua", "prompt": "-- correct like [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n-- predict like [0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n-- :return: F1\nlocal function get_F1score(correct, predict)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_161910_get_F1score.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_F1score\n    lu.assertEquals(candidate({1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}, {1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_162923_tricks_to_result", "language": "lua", "prompt": "-- Convert tricks made to a result, e.g. 8 tricks\n-- in a 4-level contract becomes -2\nlocal function tricks_to_result(tricks, level)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_162923_tricks_to_result.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = tricks_to_result\n    lu.assertEquals(candidate(8, 4), -2)\n    lu.assertEquals(candidate(3, 1), -4)\n    lu.assertEquals(candidate(1, 1), -6)\n    lu.assertEquals(candidate(5, 1), -2)\n    lu.assertEquals(candidate(9, 1), 2)\n    lu.assertEquals(candidate(6, 1), -1)\n    lu.assertEquals(candidate(8, 1), 1)\n    lu.assertEquals(candidate(7, 1), 0)\n    lu.assertEquals(candidate(2, 1), -5)\n    lu.assertEquals(candidate(4, 1), -3)\n    lu.assertEquals(candidate(10, 1), 3)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_164096_denoise", "language": "lua", "prompt": "--  Set or get denoise \nlocal function denoise(val)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_164096_denoise.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = denoise\n    lu.assertEquals(candidate(true), true)\n    lu.assertEquals(candidate(false), false)\n    lu.assertEquals(candidate(true), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_164767_get_competitive_tier_mi18n", "language": "lua", "prompt": "-- Turn the tier returned by the API into the respective tier name displayed in-game.\nlocal function get_competitive_tier_mi18n(tier)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_164767_get_competitive_tier_mi18n.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_competitive_tier_mi18n\n    lu.assertEquals(candidate(1), 'bbs/area1')\n    lu.assertEquals(candidate(3), 'bbs/area3')\n    lu.assertEquals(candidate(2), 'bbs/area2')\n    lu.assertEquals(candidate(4), 'bbs/area4')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_16478_batting_average", "language": "lua", "prompt": "-- Calculates the batting average to 3 decimal places using number of at bats and hits\nlocal function batting_average(at_bats, hits)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_16478_batting_average.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = batting_average\n    lu.assertEquals(candidate(1, 1), 1.0)\n    lu.assertEquals(candidate(10, 0), 0.0)\n    lu.assertEquals(candidate(1, 0), 0)\n    lu.assertEquals(candidate(20, 10), 0.5)\n    lu.assertEquals(candidate(20, 20), 1.0)\n    lu.assertEquals(candidate(100, 0), 0.0)\n    lu.assertEquals(candidate(100, 30), 0.3)\n    lu.assertEquals(candidate(100, 20), 0.2)\n    lu.assertEquals(candidate(3, 2), 0.667)\n    lu.assertEquals(candidate(5, 2), 0.4)\n    lu.assertEquals(candidate(2, 2), 1)\n    lu.assertEquals(candidate(10, 10), 1.0)\n    lu.assertEquals(candidate(10, 5), 0.5)\n    lu.assertEquals(candidate(100, 10), 0.1)\n    lu.assertEquals(candidate(4, 2), 0.5)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_165045__test", "language": "lua", "prompt": "-- Miller-Rabin strong pseudoprime test for one base.\n-- Return False if n is definitely composite, True if n is\n-- probably prime, with a probability greater than 3/4.\nlocal function _test(n, base, s, t)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_165045__test.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _test\n    lu.assertEquals(candidate(33, 7, 1, 1), false)\n    lu.assertEquals(candidate(341, 5, 10, 3), false)\n    lu.assertEquals(candidate(15, 2, 1, 1), false)\n    lu.assertEquals(candidate(1341, 3, 2, 3), false)\n    lu.assertEquals(candidate(2, 3, 1, 1), true)\n    lu.assertEquals(candidate(41, 2, 1, 4), false)\n    lu.assertEquals(candidate(341, 3, 2, 4), false)\n    lu.assertEquals(candidate(65, 2, 1, 1), false)\n    lu.assertEquals(candidate(41, 2, 5, 3), false)\n    lu.assertEquals(candidate(341, 3, 2, 3), false)\n    lu.assertEquals(candidate(130, 2, 1, 1), false)\n    lu.assertEquals(candidate(3, 19, 1, 2), true)\n    lu.assertEquals(candidate(3, 11, 1, 2), true)\n    lu.assertEquals(candidate(64, 2, 1, 1), false)\n    lu.assertEquals(candidate(5, 3, 1, 3), false)\n    lu.assertEquals(candidate(6, 3, 1, 3), false)\n    lu.assertEquals(candidate(341, 3, 10, 3), false)\n    lu.assertEquals(candidate(129, 2, 1, 1), false)\n    lu.assertEquals(candidate(15, 7, 1, 1), false)\n    lu.assertEquals(candidate(5, 2, 1, 1), false)\n    lu.assertEquals(candidate(9, 7, 1, 1), false)\n    lu.assertEquals(candidate(1341, 5, 10, 3), false)\n    lu.assertEquals(candidate(33, 2, 1, 1), false)\n    lu.assertEquals(candidate(341, 2, 10, 3), false)\n    lu.assertEquals(candidate(1341, 2, 10, 3), false)\n    lu.assertEquals(candidate(128, 2, 1, 1), false)\n    lu.assertEquals(candidate(11, 2, 1, 1), false)\n    lu.assertEquals(candidate(2, 2, 1, 1), false)\n    lu.assertEquals(candidate(7, 3, 1, 3), true)\n    lu.assertEquals(candidate(102, 2, 1, 1), false)\n    lu.assertEquals(candidate(1341, 3, 10, 3), false)\n    lu.assertEquals(candidate(6, 2, 1, 1), false)\n    lu.assertEquals(candidate(41, 2, 1, 3), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_165051__convert_from_F", "language": "lua", "prompt": "-- Convert F temp to C\n-- param temp: temp in F to convert\n-- return: float\nlocal function _convert_from_F(temp)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_165051__convert_from_F.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _convert_from_F\n    lu.assertEquals(candidate(90.0), 32.2)\n    lu.assertEquals(candidate(212), 100.0)\n    lu.assertEquals(candidate(32), 0.0)\n    lu.assertEquals(candidate(212), 100)\n    lu.assertEquals(candidate(70), 21.1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_165396_rgb_to_hex", "language": "lua", "prompt": "--  [255,255,255] -> \"#FFFFFF\" \nlocal function rgb_to_hex(rgb)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_165396_rgb_to_hex.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rgb_to_hex\n    lu.assertEquals(candidate({0, 0, 0}), '#000000')\n    lu.assertEquals(candidate({1, 2, 3}), '#010203')\n    lu.assertEquals(candidate({0, 0, 0}), '#000000')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_165487_get_uce_name", "language": "lua", "prompt": "-- use own function vs. import from match_contigs_to_probes - we don't want lowercase\nlocal function get_uce_name(header)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_165487_get_uce_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_uce_name\n    lu.assertEquals(candidate('>uce-1_1202_10807_10836_2401_2430_0_0_0'), 'uce-1')\n    lu.assertEquals(candidate('>uce-1 1202 10807 10836 2401 2430 0 0 0.000000 0.000000'), 'uce-1')\n    lu.assertEquals(candidate('>uce-1 1202 10807 10836 2401 2430 0 0 0'), 'uce-1')\n    lu.assertEquals(candidate('>uce-1_1202_10807_10836_2401_2430_0_0_0 1213 1389'), 'uce-1')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_16588_rst_heading", "language": "lua", "prompt": "-- Provides an underline for restructured text heading.\n-- Syntax::\n--     {{ value|rst_heading:\"=\" }}\n-- Results in:\n-- ``value``\n-- ``=====``\nlocal function rst_heading(value, arg)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_16588_rst_heading.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rst_heading\n    lu.assertEquals(candidate('value', '='), candidate('value', '='))\n    lu.assertEquals(candidate('value', '='), 'value\\n=====')\n    lu.assertEquals(candidate('foo bar', '*'), 'foo bar\\n*******')\n    lu.assertEquals(candidate('value', '='), candidate('value', '='))\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_16590_format_time", "language": "lua", "prompt": "-- Defines how to format time in FunctionEvent\nlocal function format_time(time_us)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_16590_format_time.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = format_time\n    lu.assertEquals(candidate(0), '0.000us')\n    lu.assertEquals(candidate(10), '10.000us')\n    lu.assertEquals(candidate(1), '1.000us')\n    lu.assertEquals(candidate(100), '100.000us')\n    lu.assertEquals(candidate(123456), '123.456ms')\n    lu.assertEquals(candidate(123), '123.000us')\n    lu.assertEquals(candidate(123456789), '123.457s')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_167250_det_matriz", "language": "lua", "prompt": "-- Calcula a determinante de uma matriz\nlocal function det_matriz(matriz)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_167250_det_matriz.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = det_matriz\n    lu.assertEquals(candidate({{1, 2, 3, 4}, {5, 6, 7, 8}, {9, 10, 11, 12}, {13, 14, 15, 16}}), 0)\n    lu.assertEquals(candidate({{0, 2, 3}, {0, 4, 5}, {0, 0, 6}}), 0)\n    lu.assertEquals(candidate({{1, 2}, {3, 4}}), -2)\n    lu.assertEquals(candidate({{1, 2, 3, 4}, {3, 4, 5, 6}, {5, 6, 7, 8}, {7, 8, 9, 10}}), 0)\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}), 0)\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}), 0)\n    lu.assertEquals(candidate({{2, 2, 2, 2}, {2, 2, 2, 2}, {2, 2, 2, 2}, {2, 2, 2, 2}}), 0)\n    lu.assertEquals(candidate({{1, 2, 3, 4}, {5, 6, 7, 8}, {9, 10, 11, 12}, {13, 14, 15, 16}}), 0)\n    lu.assertEquals(candidate({{1, 2, 3}, {1, 2, 3}, {1, 2, 3}}), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_167319_build_years_list", "language": "lua", "prompt": "-- create a list of 10 years counting backward from the start year\nlocal function build_years_list(start)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_167319_build_years_list.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = build_years_list\n    lu.assertEquals(candidate(2017), {2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008})\n    lu.assertEquals(candidate(2012), {2012, 2011, 2010, 2009, 2008, 2007, 2006, 2005, 2004, 2003})\n    lu.assertEquals(candidate(1995), {1995, 1994, 1993, 1992, 1991, 1990, 1989, 1988, 1987, 1986})\n    lu.assertEquals(candidate(2021), {2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_167707_validate_ticket_name", "language": "lua", "prompt": "-- validate that the ticket name is valid\n-- :param name: the name of the ticket\n-- :return: an error message (if any) or nothing if the ticket name is in the correct format\nlocal function validate_ticket_name(name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_167707_validate_ticket_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = validate_ticket_name\n    lu.assertEquals(candidate(' '), {'Ticket name cannot begin/end with a space'})\n    lu.assertEquals(candidate('hello@world'), {'Ticket name must be alphanumeric only'})\n    lu.assertEquals(candidate('Hello '), {'Ticket name cannot begin/end with a space'})\n    lu.assertEquals(candidate('Hello World'), {})\n    lu.assertEquals(candidate('hello world'), {})\n    lu.assertEquals(candidate('0123456789012345678901234567890123456789012345678901234567890'), {'Ticket name exceeds character limit (60)'})\n    lu.assertEquals(candidate(''), {'Ticket name must contain at least (1) character'})\n    lu.assertEquals(candidate('012345678901234567890123456789012345678901234567890123456789'), {})\n    lu.assertEquals(candidate(' Hello'), {'Ticket name cannot begin/end with a space'})\n    lu.assertEquals(candidate('Ticket$100'), {'Ticket name must be alphanumeric only'})\n    lu.assertEquals(candidate(''), {'Ticket name must contain at least (1) character'})\n    lu.assertEquals(candidate(''), {'Ticket name must contain at least (1) character'})\n    lu.assertEquals(candidate('123456789012345678901234567890'), {})\n    lu.assertEquals(candidate('Hello, World'), {'Ticket name must be alphanumeric only'})\n    lu.assertEquals(candidate('Hello World!'), {'Ticket name must be alphanumeric only'})\n    lu.assertEquals(candidate('hello world '), {'Ticket name cannot begin/end with a space'})\n    lu.assertEquals(candidate('hello+world'), {'Ticket name must be alphanumeric only'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_168621_create_new_id", "language": "lua", "prompt": "-- Create a new unique id for the record to be added.\nlocal function create_new_id(region, last_id_number)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_168621_create_new_id.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = create_new_id\n    lu.assertEquals(candidate('North Carolina', 2499), 'North Carolina2500')\n    lu.assertEquals(candidate('New York', 5999), 'New York6000')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_169552_is_group", "language": "lua", "prompt": "-- Return ``True`` if passed object is Group and ``False`` otherwise.\nlocal function is_group(group)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_169552_is_group.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_group\n    lu.assertEquals(candidate(10), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_169608_address_fixup", "language": "lua", "prompt": "--  Some Kern Co. addresses have typos. \nlocal function address_fixup(a)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_169608_address_fixup.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = address_fixup\n    lu.assertEquals(candidate(candidate('3225 PANAMA LANE, BAKERSFIELD, CA 93313')), '3225 PANAMA LANE, BAKERSFIELD, CA 93313')\n    lu.assertEquals(candidate(candidate('3500 Stine Rd, Bakersfield, CA 93309')), '3500 Stine Rd, Bakersfield, CA 93309')\n    lu.assertEquals(candidate('2901 Silent Ave Suite 201, Bakersfield, CA 93308'), '2901 Sillect Ave Suite 201, Bakersfield, CA 93308')\n    lu.assertEquals(candidate(candidate('2901 Sillect Ave Suite 201, Bakersfield, CA 93308')), '2901 Sillect Ave Suite 201, Bakersfield, CA 93308')\n    lu.assertEquals(candidate(candidate('3300 Buena Vista Rd Bldg A, Bakersfield, CA 93311')), '3300 Buena Vista Rd Bldg A, Bakersfield, CA 93311')\n    lu.assertEquals(candidate('3500 Stine Rd Bakersfield, Bakersfield, CA 93309'), '3500 Stine Rd, Bakersfield, CA 93309')\n    lu.assertEquals(candidate('3300 BUENA VISTA RD A, Bakersfield, CA 93311'), '3300 Buena Vista Rd Bldg A, Bakersfield, CA 93311')\n    lu.assertEquals(candidate(candidate('8000 WHITE LANE, BAKERSFIELD, CA 93309')), '8000 WHITE LANE, BAKERSFIELD, CA 93309')\n    lu.assertEquals(candidate('8000 WHITE LANE, Bakersfield, CA 93301'), '8000 WHITE LANE, BAKERSFIELD, CA 93309')\n    lu.assertEquals(candidate('3500 Stine Rd Bakersfield, Bakersfield, CA 93309'), '3500 Stine Rd, Bakersfield, CA 93309')\n    lu.assertEquals(candidate('Rite Aid Store 06303, Bakersfield, CA 93313'), '3225 PANAMA LANE, BAKERSFIELD, CA 93313')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_170197_mask_to_cidr", "language": "lua", "prompt": "-- Convert netmask in dot-notation to decimal CIDR notation\nlocal function mask_to_cidr(netmask)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_170197_mask_to_cidr.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = mask_to_cidr\n    lu.assertEquals(candidate('255.255.248.128'), 22)\n    lu.assertEquals(candidate('255.255.255.0'), 24)\n    lu.assertEquals(candidate('255.255.192.128'), 19)\n    lu.assertEquals(candidate('255.255.255.252'), 30)\n    lu.assertEquals(candidate('255.255.240.128'), 21)\n    lu.assertEquals(candidate('255.255.0.0'), 16)\n    lu.assertEquals(candidate('255.255.240.0'), 20)\n    lu.assertEquals(candidate('255.255.252.128'), 23)\n    lu.assertEquals(candidate('255.255.192.0'), 18)\n    lu.assertEquals(candidate('255.255.248.0'), 21)\n    lu.assertEquals(candidate('255.255.252.0'), 22)\n    lu.assertEquals(candidate('255.255.255.0'), 24)\n    lu.assertEquals(candidate('255.255.255.255'), 32)\n    lu.assertEquals(candidate('255.255.255.128'), 25)\n    lu.assertEquals(candidate('255.0.0.0'), 8)\n    lu.assertEquals(candidate('255.255.254.128'), 24)\n    lu.assertEquals(candidate('255.255.254.0'), 23)\n    lu.assertEquals(candidate('255.255.224.0'), 19)\n    lu.assertEquals(candidate('255.255.224.128'), 20)\n    lu.assertEquals(candidate('255.255.255.0'), 24)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_170431_prelogin_url", "language": "lua", "prompt": "--     Fetches the correct dimagi.com url for a \"prelogin\" view.\nlocal function prelogin_url(urlname)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_170431_prelogin_url.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = prelogin_url\n    lu.assertEquals(candidate('public_pricing'), 'https://dimagi.com/commcare/pricing/')\n    lu.assertEquals(candidate('go_to_pricing'), 'https://dimagi.com/commcare/pricing/')\n    lu.assertEquals(candidate('https://dimagi.com/commcare/'), 'https://dimagi.com/commcare/')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_170606_gcd_modulus", "language": "lua", "prompt": "-- finds the GCD of a and b\n-- Args:\n--  a, b: non-negative integers\n-- Returns:\n--  int: the GCD of a and b\nlocal function gcd_modulus(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_170606_gcd_modulus.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = gcd_modulus\n    lu.assertEquals(candidate(1, 1), 1)\n    lu.assertEquals(candidate(92, 14), 2)\n    lu.assertEquals(candidate(69, 19), 1)\n    lu.assertEquals(candidate(0, 0), 0)\n    lu.assertEquals(candidate(3, 2), 1)\n    lu.assertEquals(candidate(2, 9), 1)\n    lu.assertEquals(candidate(1, 0), 1)\n    lu.assertEquals(candidate(1000, 10), 10)\n    lu.assertEquals(candidate(29, 51), 1)\n    lu.assertEquals(candidate(4, 19), 1)\n    lu.assertEquals(candidate(3, 7), 1)\n    lu.assertEquals(candidate(89, 46), 1)\n    lu.assertEquals(candidate(3, 4), 1)\n    lu.assertEquals(candidate(12, 10), 2)\n    lu.assertEquals(candidate(0, 10), 10)\n    lu.assertEquals(candidate(1000, 0), 1000)\n    lu.assertEquals(candidate(37, 53), 1)\n    lu.assertEquals(candidate(1000000000, 1000000001), 1)\n    lu.assertEquals(candidate(5, 81), 1)\n    lu.assertEquals(candidate(82, 90), 2)\n    lu.assertEquals(candidate(2, 1), 1)\n    lu.assertEquals(candidate(89, 77), 1)\n    lu.assertEquals(candidate(70, 97), 1)\n    lu.assertEquals(candidate(12, 6), 6)\n    lu.assertEquals(candidate(42, 56), 14)\n    lu.assertEquals(candidate(42, 6), 6)\n    lu.assertEquals(candidate(93, 22), 1)\n    lu.assertEquals(candidate(2, 8), 2)\n    lu.assertEquals(candidate(48, 18), 6)\n    lu.assertEquals(candidate(10, 5), 5)\n    lu.assertEquals(candidate(10, 100), 10)\n    lu.assertEquals(candidate(4, 2), 2)\n    lu.assertEquals(candidate(96, 22), 2)\n    lu.assertEquals(candidate(2, 4), 2)\n    lu.assertEquals(candidate(2, 6), 2)\n    lu.assertEquals(candidate(6, 24), 6)\n    lu.assertEquals(candidate(100, 5), 5)\n    lu.assertEquals(candidate(38, 17), 1)\n    lu.assertEquals(candidate(2, 2), 2)\n    lu.assertEquals(candidate(1, 2), 1)\n    lu.assertEquals(candidate(29, 90), 1)\n    lu.assertEquals(candidate(73, 88), 1)\n    lu.assertEquals(candidate(5, 6), 1)\n    lu.assertEquals(candidate(4, 3), 1)\n    lu.assertEquals(candidate(1000000000, 1000000000), 1000000000)\n    lu.assertEquals(candidate(11, 49), 1)\n    lu.assertEquals(candidate(0, 1), 1)\n    lu.assertEquals(candidate(15, 20), 5)\n    lu.assertEquals(candidate(1000000001, 1000000000), 1)\n    lu.assertEquals(candidate(4, 8), 4)\n    lu.assertEquals(candidate(5, 2), 1)\n    lu.assertEquals(candidate(10, 0), 10)\n    lu.assertEquals(candidate(10, 1000), 10)\n    lu.assertEquals(candidate(100, 10), 10)\n    lu.assertEquals(candidate(4, 9), 1)\n    lu.assertEquals(candidate(12, 18), 6)\n    lu.assertEquals(candidate(2, 5), 1)\n    lu.assertEquals(candidate(3, 6), 3)\n    lu.assertEquals(candidate(3, 9), 3)\n    lu.assertEquals(candidate(3, 8), 1)\n    lu.assertEquals(candidate(4, 5), 1)\n    lu.assertEquals(candidate(5, 4), 1)\n    lu.assertEquals(candidate(4, 6), 2)\n    lu.assertEquals(candidate(2, 3), 1)\n    lu.assertEquals(candidate(20, 12), 4)\n    lu.assertEquals(candidate(41, 69), 1)\n    lu.assertEquals(candidate(5, 10), 5)\n    lu.assertEquals(candidate(12, 30), 6)\n    lu.assertEquals(candidate(2, 7), 1)\n    lu.assertEquals(candidate(100, 12), 4)\n    lu.assertEquals(candidate(4, 7), 1)\n    lu.assertEquals(candidate(8, 4), 4)\n    lu.assertEquals(candidate(97, 7), 1)\n    lu.assertEquals(candidate(0, 1000), 1000)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_171423_greatest_common_divisor", "language": "lua", "prompt": "-- Function to calculate the greatest common divisor\nlocal function greatest_common_divisor(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_171423_greatest_common_divisor.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = greatest_common_divisor\n    lu.assertEquals(candidate(30, 10), 10)\n    lu.assertEquals(candidate(54, 24), 6)\n    lu.assertEquals(candidate(2, 6), 2)\n    lu.assertEquals(candidate(1, 10), 1)\n    lu.assertEquals(candidate(10, 15), 5)\n    lu.assertEquals(candidate(20, 10), 10)\n    lu.assertEquals(candidate(123, 45), 3)\n    lu.assertEquals(candidate(100, 10), 10)\n    lu.assertEquals(candidate(1000000, 4000000000), 1000000)\n    lu.assertEquals(candidate(10, 1), 1)\n    lu.assertEquals(candidate(5, 10), 5)\n    lu.assertEquals(candidate(3, 15), 3)\n    lu.assertEquals(candidate(20, 30), 10)\n    lu.assertEquals(candidate(100, 100), 100)\n    lu.assertEquals(candidate(100, 25), 25)\n    lu.assertEquals(candidate(6, 15), 3)\n    lu.assertEquals(candidate(15, 5), 5)\n    lu.assertEquals(candidate(2, 3), 1)\n    lu.assertEquals(candidate(25, 100), 25)\n    lu.assertEquals(candidate(2, 4), 2)\n    lu.assertEquals(candidate(7, 3), 1)\n    lu.assertEquals(candidate(25, 25), 25)\n    lu.assertEquals(candidate(5, 2), 1)\n    lu.assertEquals(candidate(4000000000, 1000000), 1000000)\n    lu.assertEquals(candidate(4, 6), 2)\n    lu.assertEquals(candidate(30, 20), 10)\n    lu.assertEquals(candidate(10, 30), 10)\n    lu.assertEquals(candidate(234567, 89), 1)\n    lu.assertEquals(candidate(3, 5), 1)\n    lu.assertEquals(candidate(10, 5), 5)\n    lu.assertEquals(candidate(1, 1), 1)\n    lu.assertEquals(candidate(15, 20), 5)\n    lu.assertEquals(candidate(20, 15), 5)\n    lu.assertEquals(candidate(10, 100), 10)\n    lu.assertEquals(candidate(2, 1), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_171452_normalize", "language": "lua", "prompt": "-- Normalizes whitespace in a specified string of text.\nlocal function normalize(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_171452_normalize.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = normalize\n    lu.assertEquals(candidate('I   \\t\\t\\n love\\n\\n\\nthis course!'), 'I love this course!')\n    lu.assertEquals(candidate('This is a test!'), 'This is a test!')\n    lu.assertEquals(candidate('I love this        course!'), 'I love this course!')\n    lu.assertEquals(candidate('The  quick   brown      fox    jumps over the lazy dog.'), 'The quick brown fox jumps over the lazy dog.')\n    lu.assertEquals(candidate('I love\\n\\n\\n\\n        this\\n\\n\\n\\n\\n        course!'), 'I love this course!')\n    lu.assertEquals(candidate('I love this\\n        course!'), 'I love this course!')\n    lu.assertEquals(candidate('I love this course!'), 'I love this course!')\n    lu.assertEquals(candidate('I   \\t\\t\\n love this course!'), 'I love this course!')\n    lu.assertEquals(candidate('This is a test?'), 'This is a test?')\n    lu.assertEquals(candidate('This is a test.'), 'This is a test.')\n    lu.assertEquals(candidate('  I love this course!  '), 'I love this course!')\n    lu.assertEquals(candidate(' I love this course!'), 'I love this course!')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_171829_obter_pos_c", "language": "lua", "prompt": "-- obter_pos_c: posicao -> str\n-- Esta funcao devolve a componente coluna da posicao.\nlocal function obter_pos_c(pos)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_171829_obter_pos_c.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = obter_pos_c\n    lu.assertEquals(candidate({3, 3}), 'c')\n    lu.assertEquals(candidate({9, 9}), 'c')\n    lu.assertEquals(candidate({2, 2}), 'b')\n    lu.assertEquals(candidate({6, 6}), 'c')\n    lu.assertEquals(candidate({1, 1}), 'a')\n    lu.assertEquals(candidate({5, 5}), 'b')\n    lu.assertEquals(candidate({7, 7}), 'a')\n    lu.assertEquals(candidate({4, 4}), 'a')\n    lu.assertEquals(candidate({8, 8}), 'b')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_1724_map", "language": "lua", "prompt": "--     Map a value from one range to another\n-- :param in_min: minimum of input range\n-- :param in_max: maximum of input range\n-- :param out_min: minimum of output range\n-- :param out_max: maximum of output range\n-- :return: The value scaled to the new range\n-- :rtype: int\nlocal function map(x, in_min, in_max, out_min, out_max)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_1724_map.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = map\n    lu.assertEquals(candidate(100, 100, 0, 1, 10), 1)\n    lu.assertEquals(candidate(100, 0, 100, 0, 100), 100)\n    lu.assertEquals(candidate(-100, -100, 100, 0, 100), 0)\n    lu.assertEquals(candidate(0, 0, 100, 0, 100), 0)\n    lu.assertEquals(candidate(99, 0, 99, 0, 100), 100)\n    lu.assertEquals(candidate(10, 0, 10, 0, 10), 10)\n    lu.assertEquals(candidate(1, 0, 10, 1, 10), 1)\n    lu.assertEquals(candidate(8, 0, 10, 0, 10), 8)\n    lu.assertEquals(candidate(50, 0, 100, -100, 100), 0)\n    lu.assertEquals(candidate(50, 0, 100, 0, 200), 100)\n    lu.assertEquals(candidate(9, 0, 10, 0, 10), 9)\n    lu.assertEquals(candidate(3, 0, 10, 0, 10), 3)\n    lu.assertEquals(candidate(1, 0, 10, 0, 10), 1)\n    lu.assertEquals(candidate(-100, -100, 100, 0, 200), 0)\n    lu.assertEquals(candidate(1, 0, 10, 1, 20), 2)\n    lu.assertEquals(candidate(2, 0, 10, 0, 10), 2)\n    lu.assertEquals(candidate(0, 0, 10, 0, 10), 0)\n    lu.assertEquals(candidate(1, 0, 10, 10, 0), 9)\n    lu.assertEquals(candidate(3, 0, 10, 1, 20), 6)\n    lu.assertEquals(candidate(4, 0, 10, 1, 20), 8)\n    lu.assertEquals(candidate(2, 0, 10, 1, 20), 4)\n    lu.assertEquals(candidate(10, 10, 0, 1, 10), 1)\n    lu.assertEquals(candidate(42, 0, 100, 0, 100), 42)\n    lu.assertEquals(candidate(50, 0, 100, 0, 100), 50)\n    lu.assertEquals(candidate(4, 0, 10, 0, 10), 4)\n    lu.assertEquals(candidate(5, 0, 10, 1, 20), 10)\n    lu.assertEquals(candidate(1, 0, 1, 0, 100), 100)\n    lu.assertEquals(candidate(100, 0, 100, 1, 10), 10)\n    lu.assertEquals(candidate(5, 0, 10, 0, 10), 5)\n    lu.assertEquals(candidate(6, 0, 10, 0, 10), 6)\n    lu.assertEquals(candidate(7, 0, 10, 0, 10), 7)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_172573_replace_word_choice", "language": "lua", "prompt": "-- Replace a word in the provided sentence with a new one.\n-- :param sentence: str - a sentence to replace words in.\n-- :param old_word: str - word to replace.\n-- :param new_word: str - replacement word.\n-- :return: str - input sentence with new words in place of old words.\nlocal function replace_word_choice(sentence, old_word, new_word)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_172573_replace_word_choice.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = replace_word_choice\n    lu.assertEquals(candidate('The rain in Spain falls mainly on the plain.', 'plain', 'lake'), 'The rain in Spain falls mainly on the lake.')\n    lu.assertEquals(candidate('There was a girl with a telescope', 'robot', 'girl'), 'There was a girl with a telescope')\n    lu.assertEquals(candidate(\"I'm so happy to have you here.\", 'happy', 'excited'), \"I'm so excited to have you here.\")\n    lu.assertEquals(candidate('I am so happy', 'happy', 'glad'), 'I am so glad')\n    lu.assertEquals(candidate('There was a girl with a telescope', 'girl', 'robot'), 'There was a robot with a telescope')\n    lu.assertEquals(candidate('There was a girl with a telescope', 'telescope', 'robot'), 'There was a girl with a robot')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_172804_to_rtl", "language": "lua", "prompt": "-- Modifies a path to look like the RTL net/register names\nlocal function to_rtl(path)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_172804_to_rtl.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = to_rtl\n    lu.assertEquals(candidate('net_a.field_b.field_c'), 'net_a_field_b_field_c')\n    lu.assertEquals(candidate('net_a.field_b.field_c.field_d.field_e.field_f'), 'net_a_field_b_field_c_field_d_field_e_field_f')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_172880_get_key", "language": "lua", "prompt": "--  Return the first key in the dictionary \"dict\" that contains the\n-- received value \"value\".\n-- Parameters\n-- ==========\n-- dict: Dict[Any, Any]\n--     Dictionary to be used.\n-- value: Any\n--     Value to be found in the dictionary.\nlocal function get_key(dict, value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_172880_get_key.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_key\n    lu.assertEquals(candidate({['a'] = 0, ['b'] = 1, ['c'] = 2}, 2), 'c')\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 0, ['c'] = 0}, 0), 'b')\n    lu.assertEquals(candidate({['a'] = 0, ['b'] = 1, ['c'] = 0}, 0), 'a')\n    lu.assertEquals(candidate({['1'] = 1}, 1), '1')\n    lu.assertEquals(candidate({['1'] = 1, ['2'] = 2}, 1), '1')\n    lu.assertEquals(candidate({['a'] = 0, ['b'] = 0, ['c'] = 1}, 1), 'c')\n    lu.assertEquals(candidate({['1'] = 1, ['2'] = 2}, 2), '2')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_173041__get_authority_url", "language": "lua", "prompt": "-- Convert authority endpoint (active_directory) to MSAL authority:\n-- - AAD: https://login.microsoftonline.com/your_tenant\n-- - ADFS: https://adfs.redmond.azurestack.corp.microsoft.com/adfs\n--     For ADFS, tenant is discarded.\nlocal function _get_authority_url(authority_endpoint, tenant)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_173041__get_authority_url.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _get_authority_url\n    lu.assertEquals(candidate('https://login.microsoftonline.com', None), {'https://login.microsoftonline.com/organizations', false})\n    lu.assertEquals(candidate('https://login.microsoftonline.com/', None), {'https://login.microsoftonline.com/organizations', false})\n    lu.assertEquals(candidate('https://login.microsoftonline.com/', 'common'), {'https://login.microsoftonline.com/common', false})\n    lu.assertEquals(candidate('https://login.microsoftonline.com', 'common'), {'https://login.microsoftonline.com/common', false})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_173554_part_one", "language": "lua", "prompt": "-- Part one\nlocal function part_one(data)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_173554_part_one.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = part_one\n    lu.assertEquals(candidate('1122'), 3)\n    lu.assertEquals(candidate('91212129'), 9)\n    lu.assertEquals(candidate('1234'), 0)\n    lu.assertEquals(candidate('1111'), 4)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_17433_get_max", "language": "lua", "prompt": "-- compare two input numbers, and return bigger one.\n-- :param current_max: int, the current max score.\n-- :param input_score: int, the score just input.\n-- :return: int, compare two numbers and return bigger one.\nlocal function get_max(current_max, input_score)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_17433_get_max.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_max\n    lu.assertEquals(candidate(10, 1), 10)\n    lu.assertEquals(candidate(1, 2), 2)\n    lu.assertEquals(candidate(15, 15), 15)\n    lu.assertEquals(candidate(0, 1), 1)\n    lu.assertEquals(candidate(10, 0), 10)\n    lu.assertEquals(candidate(0, 0), 0)\n    lu.assertEquals(candidate(10, 15), 15)\n    lu.assertEquals(candidate(10, 10), 10)\n    lu.assertEquals(candidate(1, 1), 1)\n    lu.assertEquals(candidate(3, 5), 5)\n    lu.assertEquals(candidate(-1, 2), 2)\n    lu.assertEquals(candidate(2, -1), 2)\n    lu.assertEquals(candidate(15, 10), 15)\n    lu.assertEquals(candidate(1, 0), 1)\n    lu.assertEquals(candidate(2, 1), 2)\n    lu.assertEquals(candidate(0, 10), 10)\n    lu.assertEquals(candidate(5, 10), 10)\n    lu.assertEquals(candidate(1, 10), 10)\n    lu.assertEquals(candidate(10, 5), 10)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_174589_ngrams", "language": "lua", "prompt": "--     Return min_n to max_n n-grams of elements from a given sequence.\nlocal function ngrams(seq, min_n, max_n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_174589_ngrams.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = ngrams\n    lu.assertEquals(candidate('Hello', 6, 6), {})\n    lu.assertEquals(candidate('abcde', 1, 1), {'a', 'b', 'c', 'd', 'e'})\n    lu.assertEquals(candidate('abcd', 1, 1), {'a', 'b', 'c', 'd'})\n    lu.assertEquals(candidate('abcd', 1, 2), {'a', 'b', 'c', 'd', 'ab', 'bc', 'cd'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_175069__link_environment", "language": "lua", "prompt": "-- Generate the environment variables used for defining a docker link.\n-- Docker containers expect an enviroment variable\n-- `<alias>_PORT_<local_port>_TCP`` which contains the URL of the remote end\n-- of a link, as well as parsed variants ``_ADDR``, ``_PORT``, ``_PROTO``.\n-- :param unicode protocol: The protocol used for the link.\n-- :param unicode alias: The name of the link.\n-- :param int local_port: The port the local application expects to access.\n-- :param unicode hostname: The remote hostname to connect to.\n-- :param int remote_port: The remote port to connect to.\nlocal function _link_environment(protocol, alias, local_port, hostname, remote_port)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_175069__link_environment.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _link_environment\n    lu.assertEquals(candidate('udp', 'ALIAS', 123, 'HOST', 456), {['ALIAS_PORT_123_UDP'] = 'udp://HOST:456', ['ALIAS_PORT_123_UDP_ADDR'] = 'HOST', ['ALIAS_PORT_123_UDP_PORT'] = '456', ['ALIAS_PORT_123_UDP_PROTO'] = 'udp'})\n    lu.assertEquals(candidate('tcp', 'ALIAS', 123, '10.0.0.1', 456), {['ALIAS_PORT_123_TCP'] = 'tcp://10.0.0.1:456', ['ALIAS_PORT_123_TCP_ADDR'] = '10.0.0.1', ['ALIAS_PORT_123_TCP_PORT'] = '456', ['ALIAS_PORT_123_TCP_PROTO'] = 'tcp'})\n    lu.assertEquals(candidate('tcp', 'ALIAS', 123, 'HOST', 456), {['ALIAS_PORT_123_TCP'] = 'tcp://HOST:456', ['ALIAS_PORT_123_TCP_ADDR'] = 'HOST', ['ALIAS_PORT_123_TCP_PORT'] = '456', ['ALIAS_PORT_123_TCP_PROTO'] = 'tcp'})\n    lu.assertEquals(candidate('tcp', 'bar', 8080, 'foo', 5000), {['BAR_PORT_8080_TCP'] = 'tcp://foo:5000', ['BAR_PORT_8080_TCP_ADDR'] = 'foo', ['BAR_PORT_8080_TCP_PORT'] = '5000', ['BAR_PORT_8080_TCP_PROTO'] = 'tcp'})\n    lu.assertEquals(candidate('tcp', 'name', 5000, 'hostname', 5001), {['NAME_PORT_5000_TCP'] = 'tcp://hostname:5001', ['NAME_PORT_5000_TCP_ADDR'] = 'hostname', ['NAME_PORT_5000_TCP_PORT'] = '5001', ['NAME_PORT_5000_TCP_PROTO'] = 'tcp'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_176136_array_reverse_order_transform_next_index_to_current_index", "language": "lua", "prompt": "-- Transforms the position depending on the move.\n-- Works with the array_swap move type.\n-- This function transforms the position so that it can be used as the indice\n-- in the unaltered array, yet return the value it would have had if the move\n-- was actually performed and the position was used as indice.\n-- Parameters\n-- ----------\n-- position : int\n--     The index that one wants to use in the array if the move was performed.\n-- move : tuple of int\n--     A tuple with that represents a single, unique move.\n-- Returns\n-- -------\n-- int\n--     The index in the unaltered array that has the same value as the\n--     location in an array where the move was performed.\n-- Examples\n-- --------\n-- Some simple examples, the move remains the same, but the position changes:\n-- .. doctest::\n--     >>> from lclpy.evaluation.deltaeval.delta_qap \\\n--     ...     import array_reverse_order_transform_next_index_to_current_index \\\n--     ...         as transform_next_index_to_current_index\n--     ... # tests\n--     >>> transform_next_index_to_current_index(0, (1, 4))\n--     0\n--     >>> transform_next_index_to_current_index(1, (1, 4))\n--     4\n--     >>> transform_next_index_to_current_index(2, (1, 4))\n--     3\n--     >>> transform_next_index_to_current_index(3, (1, 4))\n--     2\n--     >>> transform_next_index_to_current_index(4, (1, 4))\n--     1\n--     >>> transform_next_index_to_current_index(5, (1, 4))\n--     5\nlocal function array_reverse_order_transform_next_index_to_current_index(position, move)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_176136_array_reverse_order_transform_next_index_to_current_index.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = array_reverse_order_transform_next_index_to_current_index\n    lu.assertEquals(candidate(5, {1, 4}), 5)\n    lu.assertEquals(candidate(2, {1, 4}), 3)\n    lu.assertEquals(candidate(0, {1, 4}), 0)\n    lu.assertEquals(candidate(4, {1, 4}), 1)\n    lu.assertEquals(candidate(1, {1, 4}), 4)\n    lu.assertEquals(candidate(3, {1, 4}), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_176194_other_classes", "language": "lua", "prompt": "-- Returns a list of class indices excluding the class indexed by class_ind\n-- :param nb_classes: number of classes in the task\n-- :param class_ind: the class index to be omitted\n-- :return: list of class indices excluding the class indexed by class_ind\nlocal function other_classes(nb_classes, class_ind)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_176194_other_classes.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = other_classes\n    lu.assertEquals(candidate(10, 3), {0, 1, 2, 4, 5, 6, 7, 8, 9})\n    lu.assertEquals(candidate(5, 2), {0, 1, 3, 4})\n    lu.assertEquals(candidate(6, 2), {0, 1, 3, 4, 5})\n    lu.assertEquals(candidate(5, 1), {0, 2, 3, 4})\n    lu.assertEquals(candidate(5, 4), {0, 1, 2, 3})\n    lu.assertEquals(candidate(3, 2), {0, 1})\n    lu.assertEquals(candidate(2, 1), {0})\n    lu.assertEquals(candidate(3, 0), {1, 2})\n    lu.assertEquals(candidate(2, 0), {1})\n    lu.assertEquals(candidate(5, 3), {0, 1, 2, 4})\n    lu.assertEquals(candidate(8, 4), {0, 1, 2, 3, 5, 6, 7})\n    lu.assertEquals(candidate(4, 1), {0, 2, 3})\n    lu.assertEquals(candidate(3, 1), {0, 2})\n    lu.assertEquals(candidate(5, 0), {1, 2, 3, 4})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_17889_clean_query_string", "language": "lua", "prompt": "--  Cleans string of ' 's and 's \nlocal function clean_query_string(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_17889_clean_query_string.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = clean_query_string\n    lu.assertEquals(candidate('Hello%20World'), 'Hello%20World')\n    lu.assertEquals(candidate('Hello%2C+World'), 'Hello%2C+World')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_179175_partition_2", "language": "lua", "prompt": "-- partition array a[l..r]\n-- Pivot: Use the last element of the array. Swap with the first element.\nlocal function partition_2(a, l, r)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_179175_partition_2.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = partition_2\n    lu.assertEquals(candidate({1, 2, 3, 4, 5}, 0, 4), 4)\n    lu.assertEquals(candidate({3, 1, 2, 5, 4, 6}, 0, 3), 3)\n    lu.assertEquals(candidate({1, 4, 2, 3}, 0, 3), 2)\n    lu.assertEquals(candidate({3, 1, 2, 5, 4, 6}, 0, 4), 3)\n    lu.assertEquals(candidate(list(range(20)), 0, 19), 19)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5}, 0, 3), 3)\n    lu.assertEquals(candidate({4, 3, 2, 1}, 0, 3), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_180440_dir_filter", "language": "lua", "prompt": "-- Accept each item which doesn't start with _\n-- :type item: str\n-- :param item: a string item to filter\n-- :return: true if item doesn't start with _\nlocal function dir_filter(item)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_180440_dir_filter.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = dir_filter\n    lu.assertEquals(candidate('1'), true)\n    lu.assertEquals(candidate('foo/_bar.py'), true)\n    lu.assertEquals(candidate('___'), false)\n    lu.assertEquals(candidate('_____'), false)\n    lu.assertEquals(candidate('_foo.py'), false)\n    lu.assertEquals(candidate('a'), true)\n    lu.assertEquals(candidate('____'), false)\n    lu.assertEquals(candidate('a_1'), true)\n    lu.assertEquals(candidate('foo.py'), true)\n    lu.assertEquals(candidate('_'), false)\n    lu.assertEquals(candidate('a1'), true)\n    lu.assertEquals(candidate('_foo/_bar.py'), false)\n    lu.assertEquals(candidate('_1'), false)\n    lu.assertEquals(candidate('________'), false)\n    lu.assertEquals(candidate('__'), false)\n    lu.assertEquals(candidate('_______'), false)\n    lu.assertEquals(candidate('not_underscore'), true)\n    lu.assertEquals(candidate('_'), false)\n    lu.assertEquals(candidate('__init__.py'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_180566_factorial", "language": "lua", "prompt": "-- Return factorial of number.\nlocal function factorial(number)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_180566_factorial.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = factorial\n    lu.assertEquals(candidate(8), 40320)\n    lu.assertEquals(candidate(5), 120)\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(16), 20922789888000)\n    lu.assertEquals(candidate(17), 355687428096000)\n    lu.assertEquals(candidate(20), 2432902008176640000)\n    lu.assertEquals(candidate(4), 24)\n    lu.assertEquals(candidate(11), 39916800)\n    lu.assertEquals(candidate(0), 1)\n    lu.assertEquals(candidate(12), 479001600)\n    lu.assertEquals(candidate(10), 3628800)\n    lu.assertEquals(candidate(19), 121645100408832000)\n    lu.assertEquals(candidate(15), 1307674368000)\n    lu.assertEquals(candidate(13), 6227020800)\n    lu.assertEquals(candidate(9), 362880)\n    lu.assertEquals(candidate(18), 6402373705728000)\n    lu.assertEquals(candidate(3), 6)\n    lu.assertEquals(candidate(6), 720)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(14), 87178291200)\n    lu.assertEquals(candidate(7), 5040)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_180620_compute_iou", "language": "lua", "prompt": "-- Compute IoU between two boxes.\n-- box1: [b1_y1, b1_x1, b1_y2, b1_x2]\n-- box2: [b2_y1, b2_x1, b2_y2, b2_x2]\n-- return: float\nlocal function compute_iou(box1, box2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_180620_compute_iou.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = compute_iou\n    lu.assertEquals(candidate({0, 0, 1, 1}, {0, 0, 0, 1}), 0)\n    lu.assertEquals(candidate({0, 0, 1, 1}, {0, 0, 1, 1}), 1)\n    lu.assertEquals(candidate({0, 0, 1, 1}, {0, 1, 1, 1}), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_180956__fabric_network_ipam_name", "language": "lua", "prompt": "-- :param fabric_name: string\n-- :param network_type: string (One of the constants defined in NetworkType)\n-- :return: string\nlocal function _fabric_network_ipam_name(fabric_name, network_type)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_180956__fabric_network_ipam_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _fabric_network_ipam_name\n    lu.assertEquals(candidate('fab9', 'management'), 'fab9-management-network-ipam')\n    lu.assertEquals(candidate('foo', 'bar'), 'foo-bar-network-ipam')\n    lu.assertEquals(candidate('fab10', 'management'), 'fab10-management-network-ipam')\n    lu.assertEquals(candidate('my-fabric-name', 'management'), 'my-fabric-name-management-network-ipam')\n    lu.assertEquals(candidate('foo-bar', 'vlan'), 'foo-bar-vlan-network-ipam')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_181012_get_msg", "language": "lua", "prompt": "-- Create a message telling the user what kind of model we're training.\n-- Args:\n--   feat (bool): whether this model is being trained with external features\n--   mpnn (bool): whether this model is being trained with an mpnn (vs. just with\n--     external features)\n--   train_folder (str): path to the training folder\n-- Returns:\n--   msg (str): the message\nlocal function get_msg(feat, mpnn, train_folder)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_181012_get_msg.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_msg\n    lu.assertEquals(candidate(false, true, 'test'), 'Training a ChemProp model with an MPNN in folder test\\n')\n    lu.assertEquals(candidate(true, true, 'folder1'), 'Training a ChemProp model with set features and an MPNN in folder folder1\\n')\n    lu.assertEquals(candidate(false, true, 'folder1'), 'Training a ChemProp model with an MPNN in folder folder1\\n')\n    lu.assertEquals(candidate(true, false, 'folder1'), 'Training a ChemProp model with set features in folder folder1\\n')\n    lu.assertEquals(candidate(true, true, 'test'), 'Training a ChemProp model with set features and an MPNN in folder test\\n')\n    lu.assertEquals(candidate(true, false, 'test'), 'Training a ChemProp model with set features in folder test\\n')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_181215_b_add", "language": "lua", "prompt": "-- add two bitstrings encoded as strings of '0's and '1's.\nlocal function b_add(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_181215_b_add.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = b_add\n    lu.assertEquals(candidate('0000', '0001'), '0001')\n    lu.assertEquals(candidate('0010', '0000'), '0010')\n    lu.assertEquals(candidate('0000', '0000'), '0000')\n    lu.assertEquals(candidate('0001', '0010'), '0011')\n    lu.assertEquals(candidate('0001', '0000'), '0001')\n    lu.assertEquals(candidate('0011', '0000'), '0011')\n    lu.assertEquals(candidate('0010', '0001'), '0011')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_181976_get_entity_name", "language": "lua", "prompt": "-- Returns the entity name after stripping off namespace and/or version information\n-- Args:\n--     entity: The full entity name\nlocal function get_entity_name(entity)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_181976_get_entity_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_entity_name\n    lu.assertEquals(candidate('entity_name'), 'entity_name')\n    lu.assertEquals(candidate('org.sagebionetworks.repo.model.FileEntity'), 'FileEntity')\n    lu.assertEquals(candidate('org.sagebionetworks.repo.model.Folder'), 'Folder')\n    lu.assertEquals(candidate('my_namespace.my_entity'), 'my_entity')\n    lu.assertEquals(candidate('my_entity'), 'my_entity')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_182034_strip_url", "language": "lua", "prompt": "-- receive a URL Field and remove leading http:// or https://\n-- optionally remove www.\n-- :param url: eg. http://www.medyear.com\n-- :param www remove the prefix passed = \"www.\"\n-- :return:\nlocal function strip_url(domain, www)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_182034_strip_url.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = strip_url\n    lu.assertEquals(candidate('www.medyear.com', 'www'), 'medyear.com')\n    lu.assertEquals(candidate('http://www.medyear.com'), 'www.medyear.com')\n    lu.assertEquals(candidate('www.medyear.com', 'www'), 'medyear.com')\n    lu.assertEquals(candidate('https://www.medyear.com', 'www'), 'medyear.com')\n    lu.assertEquals(candidate('www.medyear.com'), 'www.medyear.com')\n    lu.assertEquals(candidate('https://www.medyear.com'), 'www.medyear.com')\n    lu.assertEquals(candidate('http://www.medyear.com', 'www'), 'medyear.com')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_182677_pddl_to_tarski_type", "language": "lua", "prompt": "--  Translate a few PDDL types into their corresponding Tarski names\n-- (e.g. the FSTRIPS type \"int\" corresponds to the Tarski type \"Integer\").\nlocal function pddl_to_tarski_type(typename)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_182677_pddl_to_tarski_type.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = pddl_to_tarski_type\n    lu.assertEquals(candidate('int'), 'Integer')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_184499_get_bucket_key", "language": "lua", "prompt": "-- Return bucket name and key from given S3 URI\nlocal function get_bucket_key(uri)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_184499_get_bucket_key.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_bucket_key\n    lu.assertEquals(candidate('s3://mybucket/foo/bar.json'), {'mybucket', 'foo/bar.json'})\n    lu.assertEquals(candidate('s3://mybucket'), {'mybucket', ''})\n    lu.assertEquals(candidate('s3://mybucket/foo/bar/'), {'mybucket', 'foo/bar/'})\n    lu.assertEquals(candidate('s3://foo/bar/baz'), {'foo', 'bar/baz'})\n    lu.assertEquals(candidate('s3://mybucket/'), {'mybucket', ''})\n    lu.assertEquals(candidate('s3://foo/bar'), {'foo', 'bar'})\n    lu.assertEquals(candidate('s3://mybucket/foo/bar.json'), {'mybucket', 'foo/bar.json'})\n    lu.assertEquals(candidate('s3://mybucket'), {'mybucket', ''})\n    lu.assertEquals(candidate('s3://mybucket/'), {'mybucket', ''})\n    lu.assertEquals(candidate('s3://mybucket/foo/bar/'), {'mybucket', 'foo/bar/'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_18473_find_sum_of_arithmetic_sequence", "language": "lua", "prompt": "-- Finds the sum of an arithmetic sequence\n-- :param requested_terms:\n-- :param first_term:\n-- :param common_difference:\n-- :return: the sum of an arithmetic sequence\nlocal function find_sum_of_arithmetic_sequence(requested_terms, first_term, common_difference)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_18473_find_sum_of_arithmetic_sequence.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = find_sum_of_arithmetic_sequence\n    lu.assertEquals(candidate(10, 1, 1), 55)\n    lu.assertEquals(candidate(1, 1, 2), 1)\n    lu.assertEquals(candidate(1, 5, 1), 5)\n    lu.assertEquals(candidate(5, 1, 1), 15)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_185648_IRAF_image_type", "language": "lua", "prompt": "-- Convert MaximDL default image type names to IRAF\n-- Parameters\n-- ----------\n-- image_type : str\n--     Value of the FITS header keyword IMAGETYP; acceptable values are\n--     below in Notes.\n-- Returns\n-- -------\n-- str\n--     IRAF image type (one of 'BIAS', 'DARK', 'FLAT' or 'LIGHT')\n-- Notes\n-- -----\n-- The MaximDL default is, e.g. 'Bias Frame', which IRAF calls\n-- 'BIAS'. Can safely be called with an IRAF-style image_type.\nlocal function IRAF_image_type(image_type)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_185648_IRAF_image_type.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = IRAF_image_type\n    lu.assertEquals(candidate(candidate('FLAT')), 'FLAT')\n    lu.assertEquals(candidate('Flat Frame'), 'FLAT')\n    lu.assertEquals(candidate(candidate('BIAS')), 'BIAS')\n    lu.assertEquals(candidate('Bias Frame'), 'BIAS')\n    lu.assertEquals(candidate(candidate('DARK')), 'DARK')\n    lu.assertEquals(candidate('Light Frame'), 'LIGHT')\n    lu.assertEquals(candidate(candidate('LIGHT')), 'LIGHT')\n    lu.assertEquals(candidate('Dark Frame'), 'DARK')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_185855_length_range_for_entropy", "language": "lua", "prompt": "-- Returns length range to sample from for given entropy.\nlocal function length_range_for_entropy(entropy)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_185855_length_range_for_entropy.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = length_range_for_entropy\n    lu.assertEquals(candidate(2), {3, 4})\n    lu.assertEquals(candidate(5), {3, 5})\n    lu.assertEquals(candidate(0), {3, 3})\n    lu.assertEquals(candidate(1234), candidate(1234))\n    lu.assertEquals(candidate(4), {3, 5})\n    lu.assertEquals(candidate(3), {3, 4})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_186735_string_to_list", "language": "lua", "prompt": "--  converts string to list of ints \nlocal function string_to_list(the_string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_186735_string_to_list.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = string_to_list\n    lu.assertEquals(candidate('1,'), {{1}})\n    lu.assertEquals(candidate('3, 4, 5,'), {{3}, {4}, {5}})\n    lu.assertEquals(candidate('3,'), {{3}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_186984__module_descriptor_file", "language": "lua", "prompt": "-- Returns the name of the file containing descriptor for the 'module_dir'.\nlocal function _module_descriptor_file(module_dir)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_186984__module_descriptor_file.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _module_descriptor_file\n    lu.assertEquals(candidate('foo/bar'), 'foo/bar.descriptor.txt')\n    lu.assertEquals(candidate('foo'), 'foo.descriptor.txt')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_188499_bond_energy", "language": "lua", "prompt": "-- Calculate the bond energy using the harmonic potential.\n-- Args:\n--   r (float):  distance between atoms [angstrom]\n--   fc (float):  force constant [kcal/mol]\n--   r0 (float):  equilibrium distance [angstrom]\n-- Returns:\n--   e_bond (float):  energy of bond [kcal/mol]\nlocal function bond_energy(r, fc, r0)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_188499_bond_energy.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = bond_energy\n    lu.assertEquals(candidate(0.0, 0.0, 0.0), 0.0)\n    lu.assertEquals(candidate(1.0, 1.0, 0.0), 0.5)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_189051_is_return", "language": "lua", "prompt": "-- Determine if a parameter is named as a (internal) return.\n-- :param param_name: String with a parameter name\n-- :returns: True iff the name has the form of an internal return name\nlocal function is_return(param_name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_189051_is_return.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_return\n    lu.assertEquals(candidate(' _return_ '), false)\n    lu.assertEquals(candidate('$return'), true)\n    lu.assertEquals(candidate('$return_8'), true)\n    lu.assertEquals(candidate('return.'), false)\n    lu.assertEquals(candidate('$return_values[0][1]'), true)\n    lu.assertEquals(candidate('$return_17'), true)\n    lu.assertEquals(candidate('$return_26'), true)\n    lu.assertEquals(candidate('$return_7'), true)\n    lu.assertEquals(candidate('$return_18'), true)\n    lu.assertEquals(candidate('$return_0'), true)\n    lu.assertEquals(candidate('return_'), false)\n    lu.assertEquals(candidate('$return_values[0][1][2][3]'), true)\n    lu.assertEquals(candidate('$return_28'), true)\n    lu.assertEquals(candidate('$return_25'), true)\n    lu.assertEquals(candidate('$return_values[0][1][2]'), true)\n    lu.assertEquals(candidate('$return_values'), true)\n    lu.assertEquals(candidate('$return_values[0][1][2][3][4]'), true)\n    lu.assertEquals(candidate('$return_9'), true)\n    lu.assertEquals(candidate('_return_'), false)\n    lu.assertEquals(candidate('$return_23'), true)\n    lu.assertEquals(candidate('$return_14'), true)\n    lu.assertEquals(candidate('$return_29'), true)\n    lu.assertEquals(candidate('_return '), false)\n    lu.assertEquals(candidate('$return_16'), true)\n    lu.assertEquals(candidate(' return'), false)\n    lu.assertEquals(candidate('$return_19'), true)\n    lu.assertEquals(candidate('return'), false)\n    lu.assertEquals(candidate('$return_21'), true)\n    lu.assertEquals(candidate('$return_20'), true)\n    lu.assertEquals(candidate('.return.'), false)\n    lu.assertEquals(candidate('$return'), true)\n    lu.assertEquals(candidate(' return_'), false)\n    lu.assertEquals(candidate('.return'), false)\n    lu.assertEquals(candidate('$return_15'), true)\n    lu.assertEquals(candidate('return '), false)\n    lu.assertEquals(candidate('$return_27'), true)\n    lu.assertEquals(candidate('$return_value'), true)\n    lu.assertEquals(candidate('$return_values[0]'), true)\n    lu.assertEquals(candidate('$return_24'), true)\n    lu.assertEquals(candidate('not_a_return'), false)\n    lu.assertEquals(candidate('$return_22'), true)\n    lu.assertEquals(candidate('$return_values[0][1][2][3][4][5]'), true)\n    lu.assertEquals(candidate('$return_12'), true)\n    lu.assertEquals(candidate('$return_6'), true)\n    lu.assertEquals(candidate('$return_13'), true)\n    lu.assertEquals(candidate('$return_11'), true)\n    lu.assertEquals(candidate('$return_10'), true)\n    lu.assertEquals(candidate('$return_5'), true)\n    lu.assertEquals(candidate('_return'), false)\n    lu.assertEquals(candidate(' return '), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_189531_composite_colors", "language": "lua", "prompt": "--  Composite two colors together using their given alpha.\n-- The first color will be composited on top of the second color.\n-- Parameters\n-- ----------\n-- first : tuple\n--     The rgba tuple of the first color. All values are floats in\n--     the range 0.0 - 1.0.\n-- second : tuple\n--     The rgba tuple of the second color. The format of this tuple\n--     is the same as the first color.\n-- Returns\n-- -------\n-- result : tuple\n--     The composited rgba color tuple.\nlocal function composite_colors(first, second)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_189531_composite_colors.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = composite_colors\n    lu.assertEquals(candidate({1.0, 1.0, 1.0, 1.0}, {0.0, 0.0, 0.0, 1.0}), {1.0, 1.0, 1.0, 1.0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_189571_infer_emg_channels", "language": "lua", "prompt": "-- This function receives a list of channel names and will return\n-- one frontal, one central and one occipital channel.    \nlocal function infer_emg_channels(ch_names)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_189571_infer_emg_channels.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = infer_emg_channels\n    lu.assertEquals(candidate({'EMG Chin'}), {'EMG Chin'})\n    lu.assertEquals(candidate({'EMG Chin'}), {'EMG Chin'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_189989_constrain", "language": "lua", "prompt": "-- constrain a position (pos) in the area defined by size\nlocal function constrain(pos, size)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_189989_constrain.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = constrain\n    lu.assertEquals(candidate({99, 199}, {100, 200}), {99, 199})\n    lu.assertEquals(candidate({-1, -1}, {100, 200}), {0, 0})\n    lu.assertEquals(candidate({101, 201}, {100, 200}), {99, 199})\n    lu.assertEquals(candidate({100, 200}, {100, 200}), {99, 199})\n    lu.assertEquals(candidate({9, 19}, {100, 200}), {9, 19})\n    lu.assertEquals(candidate({0, 0}, {0, 0}), {0, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_19021_diff_possible", "language": "lua", "prompt": "-- Given a list of sorted integers and a non negative\n-- integer k, find if there exists 2 indicies i and j\n-- such that A[i] - A[j] = k, i != j\nlocal function diff_possible(numbers, k)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_19021_diff_possible.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = diff_possible\n    lu.assertEquals(candidate(list(range(1000)), 1000), false)\n    lu.assertEquals(candidate({1, 2, 3, 5, 6, 10}, 5), true)\n    lu.assertEquals(candidate({1, 2, 3, 5, 6, 10}, 3), true)\n    lu.assertEquals(candidate(list(range(10)), 7), true)\n    lu.assertEquals(candidate(list(range(10)), 8), true)\n    lu.assertEquals(candidate(list(range(20)), 4), true)\n    lu.assertEquals(candidate(list(range(10)), 3), true)\n    lu.assertEquals(candidate(list(range(10)), 2), true)\n    lu.assertEquals(candidate(list(range(20)), 9), true)\n    lu.assertEquals(candidate(list(range(10)), 4), true)\n    lu.assertEquals(candidate(list(range(1000)), 999), true)\n    lu.assertEquals(candidate(list(range(10)), 10), false)\n    lu.assertEquals(candidate({1, 2, 3, 5, 6, 10}, 9), true)\n    lu.assertEquals(candidate(list(range(10)), 9), true)\n    lu.assertEquals(candidate({1, 2, 3, 5, 6, 10}, 6), false)\n    lu.assertEquals(candidate({1, 2, 3, 5, 6, 10}, 1), true)\n    lu.assertEquals(candidate(list(range(5)), 3), true)\n    lu.assertEquals(candidate(list(range(100)), 1000), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_190761_seg_text2listxy", "language": "lua", "prompt": "-- Purpose: parse x, y coordinates from text of seg (segmentation) annotation in xml\n-- Args: \n--     text: text of seg (segmentation) annotation in xml, \"[x0,y0, x1,y1, x2,y2, x3,y3, ...]\"\n-- Returns:  lists of storing x y coordinates, \n--     x: [x0, x1, x2, x3, ...]\n--     y: [y0, y1, y2, y3, ...]\nlocal function seg_text2listxy(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_190761_seg_text2listxy.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = seg_text2listxy\n    lu.assertEquals(candidate('[1, 2, 3, 4, 5, 6]'), {{1, 3, 5}, {2, 4, 6}})\n    lu.assertEquals(candidate('[1, 2, 3, 4]'), {{1, 3}, {2, 4}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_190870___get_list_str", "language": "lua", "prompt": "-- Get value of the categorical variable, and put 3 value in one line\n-- :param x: str\n-- :return: list\nlocal function __get_list_str(x)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_190870___get_list_str.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = __get_list_str\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('1,2,3'), '1,2,3')\n    lu.assertEquals(candidate('a'), 'a')\n    lu.assertEquals(candidate('a,b,c'), 'a,b,c')\n    lu.assertEquals(candidate('1\\x012\\x013'), '1,2,3')\n    lu.assertEquals(candidate('1'), '1')\n    lu.assertEquals(candidate('1,2,3'), '1,2,3')\n    lu.assertEquals(candidate('a\\x01b\\x01c'), 'a,b,c')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_191156_caesar", "language": "lua", "prompt": "-- :type c: str\n-- :type x: int\n-- :rtype: str\nlocal function caesar(c, x)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_191156_caesar.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = caesar\n    lu.assertEquals(candidate('Z', 1), 'A')\n    lu.assertEquals(candidate('N', 1), 'O')\n    lu.assertEquals(candidate('a', 3), 'd')\n    lu.assertEquals(candidate('n', 0), 'n')\n    lu.assertEquals(candidate('Z', 2), 'B')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_191557_calc_permutation", "language": "lua", "prompt": "--     Evaluates the permutation expression\nlocal function calc_permutation(m, mm, _accuracy)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_191557_calc_permutation.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = calc_permutation\n    lu.assertEquals(candidate(1, 1, 0.9), 1)\n    lu.assertEquals(candidate(5, 5, 0.9), 1)\n    lu.assertEquals(candidate(10, 10, 0.9), 1)\n    lu.assertEquals(candidate(9, 9, 0.9), 1)\n    lu.assertEquals(candidate(6, 6, 0.9), 1)\n    lu.assertEquals(candidate(2, 2, 0.9), 1)\n    lu.assertEquals(candidate(3, 3, 0.9), 1)\n    lu.assertEquals(candidate(4, 4, 0.9), 1)\n    lu.assertEquals(candidate(7, 7, 0.9), 1)\n    lu.assertEquals(candidate(8, 8, 0.9), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_192692_tordist", "language": "lua", "prompt": "-- Calculate the toroidial distance between two scalars\n-- Args:\n--     x1(float) : first datapoint\n--     x2(float) : second datapoint\n--     wrap_dist(float) : wrapping distance (highest value), values higher than this will wrap around to zero\n-- Returns:\n--     distance(float) : toroidial distance between x1 and x2, wrapping around wrap_dist\nlocal function tordist(x1, x2, wrap_dist)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_192692_tordist.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = tordist\n    lu.assertEquals(candidate(0.75, 1, 2), 0.25)\n    lu.assertEquals(candidate(100, 100, 10), 0)\n    lu.assertEquals(candidate(0.75, 1.25, 2), 0.5)\n    lu.assertEquals(candidate(9, 10, 10), 1)\n    lu.assertEquals(candidate(0, 1, 10), 1)\n    lu.assertEquals(candidate(0, 9, 10), 1)\n    lu.assertEquals(candidate(1.25, 0.75, 2), 0.5)\n    lu.assertEquals(candidate(1, 0.5, 1), 0.5)\n    lu.assertEquals(candidate(0.5, 1, 1), 0.5)\n    lu.assertEquals(candidate(1, 0.75, 2), 0.25)\n    lu.assertEquals(candidate(2, 11, 10), 1)\n    lu.assertEquals(candidate(1, 2, 3), 1)\n    lu.assertEquals(candidate(1, 1, 1), 0)\n    lu.assertEquals(candidate(0, 0, 10), 0)\n    lu.assertEquals(candidate(0.5, 0.75, 1), 0.25)\n    lu.assertEquals(candidate(5, 0, 10), 5)\n    lu.assertEquals(candidate(0.75, 0.5, 1), 0.25)\n    lu.assertEquals(candidate(0, 5, 10), 5)\n    lu.assertEquals(candidate(2, 1, 10), 1)\n    lu.assertEquals(candidate(0, -1, 10), 1)\n    lu.assertEquals(candidate(0, 10, 10), 0)\n    lu.assertEquals(candidate(2, 1, 2), 1)\n    lu.assertEquals(candidate(0, -9, 10), 1)\n    lu.assertEquals(candidate(0, -10, 10), 0)\n    lu.assertEquals(candidate(0, 0, 10), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_193452_g_iter", "language": "lua", "prompt": "-- Return the value of G(n), computed iteratively.\n-- >>> g_iter(1)\n-- 1\n-- >>> g_iter(2)\n-- 2\n-- >>> g_iter(3)\n-- 3\n-- >>> g_iter(4)\n-- 10\n-- >>> g_iter(5)\n-- 22\n-- >>> from construct_check import check\n-- >>> # ban recursion\n-- >>> check(HW_SOURCE_FILE, 'g_iter', ['Recursion'])\n-- True\nlocal function g_iter(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_193452_g_iter.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = g_iter\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(5), 22)\n    lu.assertEquals(candidate(3), 3)\n    lu.assertEquals(candidate(4), 10)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_193505_decoupParagraphEnPhrases", "language": "lua", "prompt": "-- returns the paragraph splited in phrases ignoring specifics titles. To be completed\nlocal function decoupParagraphEnPhrases(paragraph)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_193505_decoupParagraphEnPhrases.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = decoupParagraphEnPhrases\n    lu.assertEquals(candidate('Bonjour, comment vous allez?'), {'Bonjour, comment vous allez?'})\n    lu.assertEquals(candidate('Ceci est une phrase. Ceci est une autre. Ceci est une derni\u00e8re. Ceci est un quatri\u00e8me.'), {'Ceci est une phrase.', 'Ceci est une autre.', 'Ceci est une derni\u00e8re.', 'Ceci est un quatri\u00e8me.'})\n    lu.assertEquals(candidate('Bonjour, comment allez vous?'), {'Bonjour, comment allez vous?'})\n    lu.assertEquals(candidate('Bonjour, comment allez-vous?'), {'Bonjour, comment allez-vous?'})\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('Ceci est une phrase. Ceci est une autre.'), {'Ceci est une phrase.', 'Ceci est une autre.'})\n    lu.assertEquals(candidate('Ceci est une phrase.'), {'Ceci est une phrase.'})\n    lu.assertEquals(candidate('Hello world!'), {'Hello world!'})\n    lu.assertEquals(candidate('Ceci est une phrase. Ceci est une autre. Ceci est une derni\u00e8re.'), {'Ceci est une phrase.', 'Ceci est une autre.', 'Ceci est une derni\u00e8re.'})\n    lu.assertEquals(candidate('Bonjour, comment allez vous?'), {'Bonjour, comment allez vous?'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_193898_to_devport", "language": "lua", "prompt": "-- Convert a (pipe, port) combination into a 9-bit (devport) number\n-- NOTE: For now this is a Tofino-specific method\nlocal function to_devport(pipe, port)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_193898_to_devport.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = to_devport\n    lu.assertEquals(candidate(0, 129), 129)\n    lu.assertEquals(candidate(1, 5), 133)\n    lu.assertEquals(candidate(1, 12), 140)\n    lu.assertEquals(candidate(2, 5), 261)\n    lu.assertEquals(candidate(0, 15), 15)\n    lu.assertEquals(candidate(0, 63), 63)\n    lu.assertEquals(candidate(2, 6), 262)\n    lu.assertEquals(candidate(1, 4), 132)\n    lu.assertEquals(candidate(1, 14), 142)\n    lu.assertEquals(candidate(1, 4), 132)\n    lu.assertEquals(candidate(1, 0), 128)\n    lu.assertEquals(candidate(1, 1), 129)\n    lu.assertEquals(candidate(2, 3), 259)\n    lu.assertEquals(candidate(0, 128), 128)\n    lu.assertEquals(candidate(1, 8), 136)\n    lu.assertEquals(candidate(1, 10), 138)\n    lu.assertEquals(candidate(1, 6), 134)\n    lu.assertEquals(candidate(1, 0), 128)\n    lu.assertEquals(candidate(2, 7), 263)\n    lu.assertEquals(candidate(1, 5), 133)\n    lu.assertEquals(candidate(1, 6), 134)\n    lu.assertEquals(candidate(2, 0), 256)\n    lu.assertEquals(candidate(2, 128), 384)\n    lu.assertEquals(candidate(1, 1), 129)\n    lu.assertEquals(candidate(0, 2), 2)\n    lu.assertEquals(candidate(0, 6), 6)\n    lu.assertEquals(candidate(1, 11), 139)\n    lu.assertEquals(candidate(2, 4), 260)\n    lu.assertEquals(candidate(0, 305419896), 305419896)\n    lu.assertEquals(candidate(0, 1311768467463790320), 1311768467463790320)\n    lu.assertEquals(candidate(0, 3), 3)\n    lu.assertEquals(candidate(1, 9), 137)\n    lu.assertEquals(candidate(0, 159), 159)\n    lu.assertEquals(candidate(0, 1), 1)\n    lu.assertEquals(candidate(0, 7), 7)\n    lu.assertEquals(candidate(1, 2), 130)\n    lu.assertEquals(candidate(0, 8), 8)\n    lu.assertEquals(candidate(0, 0), 0)\n    lu.assertEquals(candidate(2, 1), 257)\n    lu.assertEquals(candidate(0, 5), 5)\n    lu.assertEquals(candidate(0, 4), 4)\n    lu.assertEquals(candidate(1, 15), 143)\n    lu.assertEquals(candidate(1, 7), 135)\n    lu.assertEquals(candidate(1, 3), 131)\n    lu.assertEquals(candidate(2, 2), 258)\n    lu.assertEquals(candidate(1, 3), 131)\n    lu.assertEquals(candidate(1, 2), 130)\n    lu.assertEquals(candidate(0, 255), 255)\n    lu.assertEquals(candidate(0, 127), 127)\n    lu.assertEquals(candidate(1, 13), 141)\n    lu.assertEquals(candidate(1, 7), 135)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_193960__is_mgmt_url", "language": "lua", "prompt": "--     small helper to test if URL is for management API.\nlocal function _is_mgmt_url(path)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_193960__is_mgmt_url.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _is_mgmt_url\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('/mgmt/foo'), true)\n    lu.assertEquals(candidate('/mgmt/'), true)\n    lu.assertEquals(candidate('/'), false)\n    lu.assertEquals(candidate('/mgmt/not-mgmt'), true)\n    lu.assertEquals(candidate('not-mgmt'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_194153__fix_endpoint", "language": "lua", "prompt": "-- Remove all text before \"http\".\n-- Workaround because the endpoint is automatically prefixed with the data folder. However this does not make sense for\n-- a sparql endpoint.\n-- :param endpoint:\n-- :return:\nlocal function _fix_endpoint(endpoint)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_194153__fix_endpoint.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _fix_endpoint\n    lu.assertEquals(candidate('https://dbpedia.org/sparql'), 'https://dbpedia.org/sparql')\n    lu.assertEquals(candidate('http://dbpedia.org/sparql'), 'http://dbpedia.org/sparql')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_194405_factorial", "language": "lua", "prompt": "--  To Find Factorial Of n \nlocal function factorial(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_194405_factorial.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = factorial\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(4), 24)\n    lu.assertEquals(candidate(9), 362880)\n    lu.assertEquals(candidate(7), 5040)\n    lu.assertEquals(candidate(5), 120)\n    lu.assertEquals(candidate(6), 720)\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(3), 6)\n    lu.assertEquals(candidate(8), 40320)\n    lu.assertEquals(candidate(10), 3628800)\n    lu.assertEquals(candidate(0), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_196090_max_subarray", "language": "lua", "prompt": "--  Maximum subarray - optimized version \nlocal function max_subarray(sequence)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_196090_max_subarray.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = max_subarray\n    lu.assertEquals(candidate({1}), 1)\n    lu.assertEquals(candidate(list()), 0)\n    lu.assertEquals(candidate(list({10})), 10)\n    lu.assertEquals(candidate(list({10, 20})), 30)\n    lu.assertEquals(candidate({-1, 1, 2, -2, 3}), 4)\n    lu.assertEquals(candidate(list({10, 20, 30, 40, 50, 60})), 210)\n    lu.assertEquals(candidate(list({10, -20})), 10)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5}), 15)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_196910_is_event", "language": "lua", "prompt": "--     Test if a method is an event.\nlocal function is_event(attribute)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_196910_is_event.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_event\n    lu.assertEquals(candidate('on_anything'), true)\n    lu.assertEquals(candidate('on_event123'), true)\n    lu.assertEquals(candidate('_on_event'), false)\n    lu.assertEquals(candidate('on_Event123'), true)\n    lu.assertEquals(candidate('on_event1'), true)\n    lu.assertEquals(candidate('on'), false)\n    lu.assertEquals(candidate('on_event3'), true)\n    lu.assertEquals(candidate('on_my_button_2'), true)\n    lu.assertEquals(candidate('on_event5'), true)\n    lu.assertEquals(candidate('on_123'), true)\n    lu.assertEquals(candidate('On_event'), false)\n    lu.assertEquals(candidate('on_Event'), true)\n    lu.assertEquals(candidate('on_event4'), true)\n    lu.assertEquals(candidate('on_Event_with_dashes'), true)\n    lu.assertEquals(candidate('on_Event'), true)\n    lu.assertEquals(candidate('on_event'), true)\n    lu.assertEquals(candidate('on_event_with_dashes'), true)\n    lu.assertEquals(candidate('on_event2'), true)\n    lu.assertEquals(candidate('abc'), false)\n    lu.assertEquals(candidate('on_my_button'), true)\n    lu.assertEquals(candidate('1'), false)\n    lu.assertEquals(candidate('foo'), false)\n    lu.assertEquals(candidate('on_my_button_3'), true)\n    lu.assertEquals(candidate('On'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_197145_calc_average_ig", "language": "lua", "prompt": "-- Helper function for SHSEL filter algorithm. It returns the average\n-- Infomation gain value of one existing path in pruning function.\n-- Args:\n--     path_nodes (list): Node in path whose node_availability is True.\n--     node_values (dict): Dictionary about every node in the directed graph\n--         and its information gain value.\n-- Returns:\n--     float: The average InfoGain value of one existing path.\nlocal function calc_average_ig(path_nodes, node_values)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_197145_calc_average_ig.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = calc_average_ig\n    lu.assertEquals(candidate({0, 1, 2}, {[0] = 1, [1] = 2, [2] = 3}), 2.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_197672_get_search_threshs", "language": "lua", "prompt": "-- Clips the thresholds for binary search based on current word counts.\n-- The upper threshold parameter typically has a large default value that can\n-- result in many iterations of unnecessary search. Thus we clip the upper and\n-- lower bounds of search to the maximum and the minimum wordcount values.\n-- Args:\n--   word_counts: list of (string, int) tuples\n--   upper_thresh: int, upper threshold for binary search\n--   lower_thresh: int, lower threshold for binary search\n-- Returns:\n--   upper_search: int, clipped upper threshold for binary search\n--   lower_search: int, clipped lower threshold for binary search\nlocal function get_search_threshs(word_counts, upper_thresh, lower_thresh)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_197672_get_search_threshs.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_search_threshs\n    lu.assertEquals(candidate({{'a', 2}, {'b', 3}, {'c', 4}, {'d', 5}, {'e', 6}, {'f', 7}, {'g', 8}}, None, 7), {8, 7})\n    lu.assertEquals(candidate({{'cat', 3}, {'dog', 5}, {'bird', 7}, {'fish', 9}, {'dog', 11}}, 11, 9), {11, 9})\n    lu.assertEquals(candidate({{'a', 1}, {'b', 2}, {'c', 3}}, None, 5), {3, 5})\n    lu.assertEquals(candidate({{'cat', 3}, {'dog', 5}, {'bird', 7}, {'fish', 9}, {'dog', 11}}, 11, 11), {11, 11})\n    lu.assertEquals(candidate({{'a', 10}, {'b', 20}, {'c', 30}}, 20, 30), {20, 30})\n    lu.assertEquals(candidate({{'a', 2}, {'b', 3}, {'c', 4}, {'d', 5}, {'e', 6}, {'f', 7}, {'g', 8}}, None, 6), {8, 6})\n    lu.assertEquals(candidate({{'a', 2}, {'b', 3}, {'c', 4}, {'d', 5}, {'e', 6}, {'f', 7}, {'g', 8}}, None, 3), {8, 3})\n    lu.assertEquals(candidate({{'a', 10}, {'b', 20}, {'c', 30}}, 10, 15), {10, 15})\n    lu.assertEquals(candidate({{'a', 10}, {'b', 20}, {'c', 30}}, 25, 25), {25, 25})\n    lu.assertEquals(candidate({{'cat', 3}, {'dog', 5}, {'bird', 7}, {'fish', 9}, {'dog', 11}}, 8, 8), {8, 8})\n    lu.assertEquals(candidate({{'a', 10}, {'b', 20}, {'c', 30}}, None, None), {30, 10})\n    lu.assertEquals(candidate({{'cat', 3}, {'dog', 5}, {'bird', 7}, {'fish', 9}, {'dog', 11}}, 8, 6), {8, 6})\n    lu.assertEquals(candidate({{'a', 10}, {'b', 20}, {'c', 30}}, None, 30), {30, 30})\n    lu.assertEquals(candidate(list(zip({'a', 'b', 'c'}, {5, 2, 1})), None, None), {5, 1})\n    lu.assertEquals(candidate({{'a', 1}, {'b', 1}, {'c', 1}}, None, 2), {1, 2})\n    lu.assertEquals(candidate(list(zip({'a', 'b', 'c'}, {5, 2, 1})), 100, 0), {5, 1})\n    lu.assertEquals(candidate({{'a', 2}, {'b', 3}, {'c', 4}, {'d', 5}, {'e', 6}, {'f', 7}, {'g', 8}}, None, 5), {8, 5})\n    lu.assertEquals(candidate({{'a', 10}, {'b', 20}, {'c', 30}}, 20, None), {20, 10})\n    lu.assertEquals(candidate({{'a', 10}, {'b', 20}, {'c', 30}}, 25, 15), {25, 15})\n    lu.assertEquals(candidate({{'a', 10}, {'b', 20}, {'c', 30}}, 10, 25), {10, 25})\n    lu.assertEquals(candidate({{'a', 2}, {'b', 3}, {'c', 4}, {'d', 5}, {'e', 6}, {'f', 7}, {'g', 8}}, None, 4), {8, 4})\n    lu.assertEquals(candidate({{'a', 10}, {'b', 3}, {'c', 5}, {'d', 8}, {'e', 20}, {'f', 25}}, None, 3), {25, 3})\n    lu.assertEquals(candidate({{'a', 2}, {'b', 3}, {'c', 4}, {'d', 5}, {'e', 6}, {'f', 7}, {'g', 8}}, None, 2), {8, 2})\n    lu.assertEquals(candidate({{'a', 10}, {'b', 20}, {'c', 30}}, None, None), {30, 10})\n    lu.assertEquals(candidate({{'cat', 3}, {'dog', 5}, {'bird', 7}, {'fish', 9}, {'dog', 11}}, 8, None), {8, 3})\n    lu.assertEquals(candidate({{'a', 10}, {'b', 20}, {'c', 30}}, None, 15), {30, 15})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_197814_contar_letras", "language": "lua", "prompt": "-- Cuenta la cantidad de letras especificas en la cadena\n-- Argumentos:\n--     cadena (str) -- cadena sobre la que contar\n--     letra (str) -- letra que quiero contar\nlocal function contar_letras(cadena, letras)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_197814_contar_letras.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = contar_letras\n    lu.assertEquals(candidate('hola a todos', 'e'), 0)\n    lu.assertEquals(candidate('hola a todos', 't'), 1)\n    lu.assertEquals(candidate('hola a todos', 'a'), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_198063__get_docstring_default_value", "language": "lua", "prompt": "-- Get the description of argument's default value from docstring.\n-- Parameters\n-- ----------\n-- var_doc : str\n--     Docstring's part of argument.\n-- Returns\n-- -------\n-- default_val : str\n--     Description of the defautl value.\nlocal function _get_docstring_default_value(var_doc)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_198063__get_docstring_default_value.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _get_docstring_default_value\n    lu.assertEquals(candidate('name : str, default None\\n   A name for the user.'), 'None')\n    lu.assertEquals(candidate('name : str, optional\\n   A name for the user.'), '')\n    lu.assertEquals(candidate('name : str, default\\n   A name for the user.'), '')\n    lu.assertEquals(candidate('name: str, optional\\n   A name for the user.'), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_198911_is_quantity_range", "language": "lua", "prompt": "-- Checks if [] are present in val.\nlocal function is_quantity_range(val)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_198911_is_quantity_range.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_quantity_range\n    lu.assertEquals(candidate('4[]m]'), true)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('   '), false)\n    lu.assertEquals(candidate('6[m]'), true)\n    lu.assertEquals(candidate('1[m]'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_199908_ats_url", "language": "lua", "prompt": "--     Return the URL for the ESGF SAML AttributeService\nlocal function ats_url(base_url)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_199908_ats_url.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = ats_url\n    lu.assertEquals(candidate('http://esgf.org'), 'http://esgf.org/esgf-idp/saml/soap/secure/attributeService.htm')\n    lu.assertEquals(candidate('https://esgf-node.llnl.gov/idp/shibboleth'), 'https://esgf-node.llnl.gov/idp/shibboleth/esgf-idp/saml/soap/secure/attributeService.htm')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_200188_RPL_ENDOFWHOIS", "language": "lua", "prompt": "--  Reply Code 318 \nlocal function RPL_ENDOFWHOIS(sender, receipient, message)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_200188_RPL_ENDOFWHOIS.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = RPL_ENDOFWHOIS\n    lu.assertEquals(candidate('foo', 'bar', 'baz'), '<foo>: baz')\n    lu.assertEquals(candidate('TestSender', 'TestReceipient', 'TestMessage'), '<TestSender>: TestMessage')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_200932_get_position_from_periods", "language": "lua", "prompt": "-- Get the position from a period list.\n-- It will return the index of the right-closest number in the period list.\n-- For example, the cumulative_period = [100, 200, 300, 400],\n-- if iteration == 50, return 0;\n-- if iteration == 210, return 2;\n-- if iteration == 300, return 2.\n-- Args:\n--     iteration (int): Current iteration.\n--     cumulative_period (list[int]): Cumulative period list.\n-- Returns:\n--     int: The position of the right-closest number in the period list.\nlocal function get_position_from_periods(iteration, cumulative_period)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_200932_get_position_from_periods.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_position_from_periods\n    lu.assertEquals(candidate(10, {10, 20}), 0)\n    lu.assertEquals(candidate(210, {100, 200, 300, 400}), 2)\n    lu.assertEquals(candidate(201, {100, 200, 300}), 2)\n    lu.assertEquals(candidate(2, {100, 200, 300}), 0)\n    lu.assertEquals(candidate(99, {100, 200}), 0)\n    lu.assertEquals(candidate(299, {100, 200, 300}), 2)\n    lu.assertEquals(candidate(1, {100, 200, 300, 400}), 0)\n    lu.assertEquals(candidate(99, {100, 200, 300}), 0)\n    lu.assertEquals(candidate(0, {100}), 0)\n    lu.assertEquals(candidate(99, {100}), 0)\n    lu.assertEquals(candidate(101, {100, 200, 300}), 1)\n    lu.assertEquals(candidate(199, {100, 200, 300}), 1)\n    lu.assertEquals(candidate(199, {100, 200}), 1)\n    lu.assertEquals(candidate(300, {100, 200, 300, 400}), 2)\n    lu.assertEquals(candidate(50, {100, 200, 300, 400}), 0)\n    lu.assertEquals(candidate(100, {100}), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_202385_removeallspaces", "language": "lua", "prompt": "-- Remove all spaces.\nlocal function removeallspaces(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_202385_removeallspaces.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = removeallspaces\n    lu.assertEquals(candidate(' this   is a     mess of   spaces   '), 'thisisamessofspaces')\n    lu.assertEquals(candidate('Hello   World  '), 'HelloWorld')\n    lu.assertEquals(candidate('Hello   World'), 'HelloWorld')\n    lu.assertEquals(candidate('     a b c     '), 'abc')\n    lu.assertEquals(candidate(' Hello   World  '), 'HelloWorld')\n    lu.assertEquals(candidate('abc'), 'abc')\n    lu.assertEquals(candidate('     This is a mess of spaces'), 'Thisisamessofspaces')\n    lu.assertEquals(candidate('This is a mess of spaces'), 'Thisisamessofspaces')\n    lu.assertEquals(candidate('     '), '')\n    lu.assertEquals(candidate('      '), '')\n    lu.assertEquals(candidate('Hello World '), 'HelloWorld')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('This is a mess of spaces     '), 'Thisisamessofspaces')\n    lu.assertEquals(candidate('      a b c      '), 'abc')\n    lu.assertEquals(candidate('Hello World  '), 'HelloWorld')\n    lu.assertEquals(candidate('  This is a mess of spaces  '), 'Thisisamessofspaces')\n    lu.assertEquals(candidate(' Hello World  '), 'HelloWorld')\n    lu.assertEquals(candidate('Hello World'), 'HelloWorld')\n    lu.assertEquals(candidate('     This is a mess of spaces     '), 'Thisisamessofspaces')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_203080_format", "language": "lua", "prompt": "-- Format a FastQ entry.\n-- :param name: the read name\n-- :param sequence: the read sequence\n-- :param quality: the read quality\n-- :return: a formatted fastq entry\nlocal function format(name, sequence, quality)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_203080_format.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = format\n    lu.assertEquals(candidate('name', 'ACGT', '####'), '@name\\nACGT\\n+\\n####\\n')\n    lu.assertEquals(candidate('name', 'ACGT', '####'), '@name\\nACGT\\n+\\n####\\n')\n    lu.assertEquals(candidate('foo', 'bar', 'baz'), '@foo\\nbar\\n+\\nbaz\\n')\n    lu.assertEquals(candidate('name', 'ATCGATCG', '#####'), '@name\\nATCGATCG\\n+\\n#####\\n')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_204072_make_subtype", "language": "lua", "prompt": "-- Make subtype from type and biotype.\nlocal function make_subtype(type_, biotype)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_204072_make_subtype.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = make_subtype\n    lu.assertEquals(candidate('gene', 'macro_lncRNA antisense'), 'gene macro_lncRNA antisense')\n    lu.assertEquals(candidate(None, None), None)\n    lu.assertEquals(candidate('gene', 'sense_overlapping'), 'gene sense_overlapping')\n    lu.assertEquals(candidate('TF_binding', None), 'TF_binding')\n    lu.assertEquals(candidate('gene', 'antisense lincRNA'), 'gene antisense lincRNA')\n    lu.assertEquals(candidate('TF_binding', 'protein_coding'), 'TF_binding protein_coding')\n    lu.assertEquals(candidate('gene', 'tRNA'), 'gene tRNA')\n    lu.assertEquals(candidate('TF_binding', 'protein_coding TF_binding'), 'TF_binding protein_coding TF_binding')\n    lu.assertEquals(candidate('gene', 'snRNA'), 'gene snRNA')\n    lu.assertEquals(candidate('gene', 'tRNA-pseudogene'), 'gene tRNA-pseudogene')\n    lu.assertEquals(candidate('gene', 'antisense'), 'gene antisense')\n    lu.assertEquals(candidate('gene', 'snoRNA'), 'gene snoRNA')\n    lu.assertEquals(candidate('gene', 'miRNA'), 'gene miRNA')\n    lu.assertEquals(candidate('gene', 'lincRNA'), 'gene lincRNA')\n    lu.assertEquals(candidate('gene', 'macro_lncRNA'), 'gene macro_lncRNA')\n    lu.assertEquals(candidate('gene', 'rRNA'), 'gene rRNA')\n    lu.assertEquals(candidate('TF_binding', 'protein_coding TF_binding TF_binding'), 'TF_binding protein_coding TF_binding TF_binding')\n    lu.assertEquals(candidate('gene', None), 'gene')\n    lu.assertEquals(candidate('gene', 'pseudogene'), 'gene pseudogene')\n    lu.assertEquals(candidate('gene', 'sense_intronic'), 'gene sense_intronic')\n    lu.assertEquals(candidate('gene', 'protein_coding'), 'gene protein_coding')\n    lu.assertEquals(candidate('gene', 'rRNA-pseudogene'), 'gene rRNA-pseudogene')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_20424_bbox_to_pixel_offsets", "language": "lua", "prompt": "-- Helper function for zonal_stats(). Modified from:\n-- https://gist.github.com/perrygeo/5667173\n-- Original code copyright 2013 Matthew Perry\nlocal function bbox_to_pixel_offsets(gt, bbox)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_20424_bbox_to_pixel_offsets.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = bbox_to_pixel_offsets\n    lu.assertEquals(candidate({0, 1, 2, 3, 4, 5}, {-0.1, 0.1, 0.3, 0.4}), {0, 0, 1, 1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_204699_prepare_summary_line", "language": "lua", "prompt": "-- Prepares a summary line by formatting it.\n-- Args:\n--     cost: The cost of the summary line item.\n--     currency: The currency to append to the summary line item.\n-- Returns:\n--     The formatted summary line.\nlocal function prepare_summary_line(cost, currency)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_204699_prepare_summary_line.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = prepare_summary_line\n    lu.assertEquals(candidate(20000.12, 'JPY'), '20000.12 JPY')\n    lu.assertEquals(candidate(20.14, 'USD'), '20.14 USD')\n    lu.assertEquals(candidate(456, 'EUR'), '456 EUR')\n    lu.assertEquals(candidate(789, 'GBP'), '789 GBP')\n    lu.assertEquals(candidate(10.55, 'JPY'), '10.55 JPY')\n    lu.assertEquals(candidate(123, 'USD'), '123 USD')\n    lu.assertEquals(candidate(0.05, 'CAD'), '0.05 CAD')\n    lu.assertEquals(candidate(200.1, 'EUR'), '200.1 EUR')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_205474_get_chain_length", "language": "lua", "prompt": "-- Get length of the chain with index \"chain_idx\", starting from (and including)\n-- generation \"start_gen_idx\" to end of chain, or until first\n-- empty bin (while excluding empty bin).\nlocal function get_chain_length(chains, chain_idx, start_gen_idx)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_205474_get_chain_length.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_chain_length\n    lu.assertEquals(candidate({{{0, 0}, {0, 0}, {0, 0}}, {{0, 0}, {0, 0}, {0, 0}}, {{0, 0}, {0, 0}, {0, 0}}}, 1, 0), 3)\n    lu.assertEquals(candidate({{{0, 0}, {0, 0}}, {{0, 0}, {0, 0}}, {{0, 0}, {0, 0}}, {{0, 0}, {0, 0}}}, 1, 0), 4)\n    lu.assertEquals(candidate({{{0, 0}, {0, 0}, {0, 0}}, {{0, 0}, {0, 0}}, {{0, 0}, {0, 0}, {0, 0}}}, 1, 0), 3)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_206622_iso_date2", "language": "lua", "prompt": "-- Returns int tuple (yyyy,mm,dd) if adate is in form of 'yyyy-dd-mm' else (0,0,0)\nlocal function iso_date2(adate)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_206622_iso_date2.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = iso_date2\n    lu.assertEquals(candidate(''), {0, 0, 0})\n    lu.assertEquals(candidate('201-1-00'), {0, 0, 0})\n    lu.assertEquals(candidate('201-1-1'), {0, 0, 0})\n    lu.assertEquals(candidate('2018-1-1'), {0, 0, 0})\n    lu.assertEquals(candidate('20-1-01'), {0, 0, 0})\n    lu.assertEquals(candidate(None), {0, 0, 0})\n    lu.assertEquals(candidate('201-01-1'), {0, 0, 0})\n    lu.assertEquals(candidate('201-00-1'), {0, 0, 0})\n    lu.assertEquals(candidate('2022-1-3'), {0, 0, 0})\n    lu.assertEquals(candidate('20-01-01'), {0, 0, 0})\n    lu.assertEquals(candidate('1987-02-03'), {1987, 2, 3})\n    lu.assertEquals(candidate('2022-11-1'), {0, 0, 0})\n    lu.assertEquals(candidate('2022-1-32'), {0, 0, 0})\n    lu.assertEquals(candidate('201-1-01'), {0, 0, 0})\n    lu.assertEquals(candidate('2018-01-1'), {0, 0, 0})\n    lu.assertEquals(candidate('1987-02-100'), {0, 0, 0})\n    lu.assertEquals(candidate('2018-00-1'), {0, 0, 0})\n    lu.assertEquals(candidate('2018-01-21'), {2018, 1, 21})\n    lu.assertEquals(candidate('2020-01-02'), {2020, 1, 2})\n    lu.assertEquals(candidate('2018-01-01'), {2018, 1, 1})\n    lu.assertEquals(candidate('1987-3-03'), {0, 0, 0})\n    lu.assertEquals(candidate('20-1-1'), {0, 0, 0})\n    lu.assertEquals(candidate('20-01-1'), {0, 0, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_207245_get_binary_category", "language": "lua", "prompt": "-- Get an integer binary classification label from a score between 0 and 1.\nlocal function get_binary_category(score)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_207245_get_binary_category.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_binary_category\n    lu.assertEquals(candidate(0.75), 1)\n    lu.assertEquals(candidate(0.99), 1)\n    lu.assertEquals(candidate(0.01), 0)\n    lu.assertEquals(candidate(0.25), 0)\n    lu.assertEquals(candidate(0.6), 1)\n    lu.assertEquals(candidate(0.2), 0)\n    lu.assertEquals(candidate(0.9), 1)\n    lu.assertEquals(candidate(0.4), 0)\n    lu.assertEquals(candidate(0.8), 1)\n    lu.assertEquals(candidate(1.0), 1)\n    lu.assertEquals(candidate(0.0), 0)\n    lu.assertEquals(candidate(0.3), 0)\n    lu.assertEquals(candidate(0.9999), 1)\n    lu.assertEquals(candidate(0.0001), 0)\n    lu.assertEquals(candidate(0.1), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_207726_get_stride_sequence", "language": "lua", "prompt": "-- Return the sequence of the secondary structure.\n-- Parameters\n-- ----------\n-- stride_desc : list of (str, str, float, float, float)\n--     The Stride description.\n-- Returns\n-- -------\n-- sequence : list of str\n--     The secondary structure sequence.\nlocal function get_stride_sequence(stride_desc)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_207726_get_stride_sequence.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_stride_sequence\n    lu.assertEquals(candidate({{'H', 'H', 1, 2, 1}, {'E', 'E', 3, 4, 3}, {'L', 'L', 5, 6, 5}, {'H', 'H', 7, 8, 7}, {'E', 'E', 9, 10, 9}}), {'H', 'E', 'L', 'H', 'E'})\n    lu.assertEquals(candidate({{'H', 'H', 1, 2, 1}, {'E', 'E', 3, 4, 3}, {'L', 'L', 5, 6, 5}, {'H', 'H', 7, 8, 7}, {'E', 'E', 9, 10, 9}, {'L', 'L', 11, 12, 11}}), {'H', 'E', 'L', 'H', 'E', 'L'})\n    lu.assertEquals(candidate({{'H', 'H', 1, 2, 1}, {'E', 'E', 3, 4, 3}, {'L', 'L', 5, 6, 5}, {'H', 'H', 7, 8, 7}}), {'H', 'E', 'L', 'H'})\n    lu.assertEquals(candidate({{'H', 'H', 1, 2, 1}, {'E', 'E', 3, 4, 3}, {'L', 'L', 5, 6, 5}}), {'H', 'E', 'L'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_209252_parse_size", "language": "lua", "prompt": "--         Parses a size specification. Valid specifications are:\n-- 123: bytes\n-- 123k: kilobytes\n-- 123m: megabytes\n-- 123g: gigabytes\nlocal function parse_size(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_209252_parse_size.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_size\n    lu.assertEquals(candidate('1k'), 1024)\n    lu.assertEquals(candidate('1'), 1)\n    lu.assertEquals(candidate('123'), 123)\n    lu.assertEquals(candidate('1000'), 1000)\n    lu.assertEquals(candidate(None), None)\n    lu.assertEquals(candidate(''), None)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_209453_contrasting_text_color", "language": "lua", "prompt": "-- Get a contrasting foreground text color for specified background hex color\n-- :param hext_str: A hex string color ('#XXXXXX') for which to determine a black-or-white\n--     foreground color.\n-- :return: '#FFF' or '#000'.\nlocal function contrasting_text_color(hex_str)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_209453_contrasting_text_color.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = contrasting_text_color\n    lu.assertEquals(candidate('#FFFFFF'), '#000')\n    lu.assertEquals(candidate('#012345'), '#FFF')\n    lu.assertEquals(candidate('#000000'), '#FFF')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_209455_is_glob_mask", "language": "lua", "prompt": "--     Checks whether text contains mathing symbols usable with glob.glob()\nlocal function is_glob_mask(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_209455_is_glob_mask.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_glob_mask\n    lu.assertEquals(candidate('a/b/c/**.py'), true)\n    lu.assertEquals(candidate('foo\\\\?'), true)\n    lu.assertEquals(candidate('*'), true)\n    lu.assertEquals(candidate('foo*'), true)\n    lu.assertEquals(candidate('a/b/*.py'), true)\n    lu.assertEquals(candidate('foo?'), true)\n    lu.assertEquals(candidate('a/b/**/*.py'), true)\n    lu.assertEquals(candidate('foo\\\\*'), true)\n    lu.assertEquals(candidate('a/b/c'), false)\n    lu.assertEquals(candidate('a/b/**.py'), true)\n    lu.assertEquals(candidate('foo'), false)\n    lu.assertEquals(candidate('*.py'), true)\n    lu.assertEquals(candidate('some_text'), false)\n    lu.assertEquals(candidate('a/b/c/**/*.py'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_209668_to_yx", "language": "lua", "prompt": "-- transform a scalar from [0;4095] to a (y,x) coordinate in [0:63,0:63]\nlocal function to_yx(point)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_209668_to_yx.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = to_yx\n    lu.assertEquals(candidate(4095), {63, 63})\n    lu.assertEquals(candidate(1), {1, 0})\n    lu.assertEquals(candidate(0), {0, 0})\n    lu.assertEquals(candidate(65), {1, 1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_210558_is_matched", "language": "lua", "prompt": "-- Finds out how balanced an expression is.\n-- With a string containing only brackets.\n-- >>> is_matched('[]()()(((([])))')\n-- False\n-- >>> is_matched('[](){{{[]}}}')\n-- True\nlocal function is_matched(expression)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_210558_is_matched.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_matched\n    lu.assertEquals(candidate('[](){{{[]}}}'), true)\n    lu.assertEquals(candidate('[]()()()'), true)\n    lu.assertEquals(candidate('[]()()()(((([])))'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_211884_simple_atmo_opstring", "language": "lua", "prompt": "-- Make a simple atmospheric correction formula.\nlocal function simple_atmo_opstring(haze, contrast, bias)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_211884_simple_atmo_opstring.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = simple_atmo_opstring\n    lu.assertEquals(candidate(0.0, 1.0, 0.0), 'gamma g 1.0, gamma b 1.0, sigmoidal rgb 1.0 0.0')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_212029_fix_url_path", "language": "lua", "prompt": "-- Add \"/\" to end of URL, if URL has path and doesn't end with \"/\"\n-- the path will be removed by urljoin.\nlocal function fix_url_path(url)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_212029_fix_url_path.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fix_url_path\n    lu.assertEquals(candidate('https://www.example.com'), 'https://www.example.com/')\n    lu.assertEquals(candidate('https://www.example.com/'), 'https://www.example.com/')\n    lu.assertEquals(candidate('https://www.example.com/test'), 'https://www.example.com/test/')\n    lu.assertEquals(candidate('https://www.example.com/test/'), 'https://www.example.com/test/')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_212643_binary_to_integer", "language": "lua", "prompt": "-- Convert R or G or B pixel values from binary to integer.\n-- INPUT: A string tuple (e.g. (\"00101010\"))\n-- OUTPUT: Return an int tuple (e.g. (220))\nlocal function binary_to_integer(binary)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_212643_binary_to_integer.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = binary_to_integer\n    lu.assertEquals(candidate('011011101'), 221)\n    lu.assertEquals(candidate('10101010'), 170)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_212796_is_abs", "language": "lua", "prompt": "-- Check if field is absolute value.\n-- Parameters\n-- ----------\n-- field : str\n--     Field name.\n-- Returns\n-- -------\n-- (bool, str)\n--     Whether the field is absolute or not along with the basic field itself.\nlocal function is_abs(field)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_212796_is_abs.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_abs\n    lu.assertEquals(candidate('hello'), {'hello', false})\n    lu.assertEquals(candidate('hello)world'), {'hello)world', false})\n    lu.assertEquals(candidate('ABS(ABS(hello))'), {'ABS(hello)', true})\n    lu.assertEquals(candidate('ABS(hello)'), {'hello', true})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_212940_path2ParentPath", "language": "lua", "prompt": "-- >>> path2ParentPath('/xxx/yyy/zzz/')\n-- '/xxx/yyy/zzz'\n-- >>> path2ParentPath('/xxx/yyy/zzz')\n-- '/xxx/yyy'\n-- >>> path2ParentPath('/xxx/yyy/zzz.gif')\n-- '/xxx/yyy'\nlocal function path2ParentPath(path)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_212940_path2ParentPath.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = path2ParentPath\n    lu.assertEquals(candidate('/xxx/yyy/zzz'), '/xxx/yyy')\n    lu.assertEquals(candidate('/xxx/yyy/zzz/'), '/xxx/yyy/zzz')\n    lu.assertEquals(candidate('/xxx/yyy/zzz.gif'), '/xxx/yyy')\n    lu.assertEquals(candidate('/xxx/yyy/zzz'), '/xxx/yyy')\n    lu.assertEquals(candidate('/xxx/yyy/zzz/'), '/xxx/yyy/zzz')\n    lu.assertEquals(candidate('/xxx/yyy/zzz.gif'), '/xxx/yyy')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_213348__mask_to_shift", "language": "lua", "prompt": "--  Return the index of the least significant bit in the mask \nlocal function _mask_to_shift(mask)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_213348__mask_to_shift.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _mask_to_shift\n    lu.assertEquals(candidate(1), 0)\n    lu.assertEquals(candidate(15), 0)\n    lu.assertEquals(candidate(64), 6)\n    lu.assertEquals(candidate(2), 1)\n    lu.assertEquals(candidate(251658240), 24)\n    lu.assertEquals(candidate(1), 0)\n    lu.assertEquals(candidate(128), 7)\n    lu.assertEquals(candidate(8), 3)\n    lu.assertEquals(candidate(65536), 16)\n    lu.assertEquals(candidate(3), 0)\n    lu.assertEquals(candidate(12), 2)\n    lu.assertEquals(candidate(2), 1)\n    lu.assertEquals(candidate(2), 1)\n    lu.assertEquals(candidate(4), 2)\n    lu.assertEquals(candidate(1), 0)\n    lu.assertEquals(candidate(32), 5)\n    lu.assertEquals(candidate(4), 2)\n    lu.assertEquals(candidate(16), 4)\n    lu.assertEquals(candidate(8), 3)\n    lu.assertEquals(candidate(8), 3)\n    lu.assertEquals(candidate(4), 2)\n    lu.assertEquals(candidate(6), 1)\n    lu.assertEquals(candidate(14), 1)\n    lu.assertEquals(candidate(256), 8)\n    lu.assertEquals(candidate(7), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_21334_azimu_half", "language": "lua", "prompt": "-- Transform azimuth from 180-360 range to range 0-180.\n-- :param degrees: Degrees in range 0 - 360\n-- :return: Degrees in range 0 - 180\nlocal function azimu_half(degrees)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_21334_azimu_half.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = azimu_half\n    lu.assertEquals(candidate(360), 180)\n    lu.assertEquals(candidate(180), 0)\n    lu.assertEquals(candidate(210), 30)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(60), 60)\n    lu.assertEquals(candidate(135), 135)\n    lu.assertEquals(candidate(350), 170)\n    lu.assertEquals(candidate(270), 90)\n    lu.assertEquals(candidate(90), 90)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_213491_calculate_a", "language": "lua", "prompt": "--  Private function \nlocal function calculate_a(cl_i, int_, n_term)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_213491_calculate_a.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = calculate_a\n    lu.assertEquals(candidate(0, 0.08, 10), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_213836_decodeModifiers", "language": "lua", "prompt": "-- {:032b}\n-- 0 0 0 0 0 0 0 0 0 0 0 1   1   1   1   1   0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1\n-- 0                     11  12  13  14  15                                31\n-- cmd  00000000000100000000000100001000 b11\n-- alt  00000000000010000000000100100000 b12\n-- ctrl 00000000000001000000000100000001 b13\n-- shft 00000000000000100000000100000010 b14\n-- caps 00000000000000010000000100000000 b15\nlocal function decodeModifiers(modifier)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_213836_decodeModifiers.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = decodeModifiers\n    lu.assertEquals(candidate(65536), 'Caps')\n    lu.assertEquals(candidate(0), '')\n    lu.assertEquals(candidate(1), '')\n    lu.assertEquals(candidate(0), '')\n    lu.assertEquals(candidate(0), '')\n    lu.assertEquals(candidate(0), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_213973_choice_verification", "language": "lua", "prompt": "-- Check choice and return True according.\nlocal function choice_verification(choice)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_213973_choice_verification.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = choice_verification\n    lu.assertEquals(candidate('O'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_214021_joinargs", "language": "lua", "prompt": "-- Joins given args (if valid) using join_str.\n-- The result is stored in a context variable.\n-- Example usage: {% join '/' str1 str2 str3 ... as var %}\nlocal function joinargs(join_str)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_214021_joinargs.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = joinargs\n    lu.assertEquals(candidate('/', None, None, None, None, None), '')\n    lu.assertEquals(candidate('/', None, None, None), '')\n    lu.assertEquals(candidate('/', 'hello'), 'hello')\n    lu.assertEquals(candidate('/', None, None), '')\n    lu.assertEquals(candidate('/', 'foo', '', 'bar'), 'foo/bar')\n    lu.assertEquals(candidate('/', 'hello', 'world', '!', ''), 'hello/world/!')\n    lu.assertEquals(candidate('/', 1, 2, 3, 4, 5), '1/2/3/4/5')\n    lu.assertEquals(candidate('', None, None, None, None, None), '')\n    lu.assertEquals(candidate('/', None, None, None, None), '')\n    lu.assertEquals(candidate('', None, None, None, None), '')\n    lu.assertEquals(candidate('', None, None, None), '')\n    lu.assertEquals(candidate('/'), '')\n    lu.assertEquals(candidate('/', 'foo', 'bar'), 'foo/bar')\n    lu.assertEquals(candidate('/', 1, None, 2, None, 3, None, 4, None, 5), '1/2/3/4/5')\n    lu.assertEquals(candidate('/', 'foo'), 'foo')\n    lu.assertEquals(candidate('/', 'hello', 'world'), 'hello/world')\n    lu.assertEquals(candidate('/', 1), '1')\n    lu.assertEquals(candidate('', None, None), '')\n    lu.assertEquals(candidate('/', 'hello', 'world', '!', '', ''), 'hello/world/!')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_214624_metacyc_url", "language": "lua", "prompt": "--  Return the url for the pathway on the MetaCyc website \n-- Args:\n--     pathway (string): The MetaCyc pathway\n-- Returns\n--    (string): The url to the website for the pathway\nlocal function metacyc_url(pathway)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_214624_metacyc_url.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = metacyc_url\n    lu.assertEquals(candidate('PFK'), 'http://metacyc.org/META/NEW-IMAGE?type=NIL&object=PFK')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_215353_sum_2_dictionaries", "language": "lua", "prompt": "-- Given two dictionaries of totals, where each total refers to a key\n-- in the dictionary, add the totals.\n-- E.g.:  dicta = { 'a' : 3, 'b' : 1 }\n--        dictb = { 'a' : 1, 'c' : 5 }\n--        dicta + dictb = { 'a' : 4, 'b' : 1, 'c' : 5 }\n-- @param dicta: (dictionary)\n-- @param dictb: (dictionary)\n-- @return: (dictionary) - the sum of the 2 dictionaries\nlocal function sum_2_dictionaries(dicta, dictb)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_215353_sum_2_dictionaries.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sum_2_dictionaries\n    lu.assertEquals(candidate({['a'] = 1}, {}), {['a'] = 1})\n    lu.assertEquals(candidate({['a'] = 0, ['b'] = 0}, {['a'] = 0, ['b'] = 0}), {['a'] = 0, ['b'] = 0})\n    lu.assertEquals(candidate({['a'] = 0}, {['a'] = 0}), {['a'] = 0})\n    lu.assertEquals(candidate({['a'] = 0, ['b'] = 0}, {['a'] = 0, ['b'] = 0}), {['a'] = 0, ['b'] = 0})\n    lu.assertEquals(candidate({}, {['a'] = 3, ['b'] = 1, ['c'] = 5}), {['a'] = 3, ['b'] = 1, ['c'] = 5})\n    lu.assertEquals(candidate({}, {}), {})\n    lu.assertEquals(candidate({['a'] = 3}, {['b'] = 1, ['c'] = 5}), {['a'] = 3, ['b'] = 1, ['c'] = 5})\n    lu.assertEquals(candidate({['a'] = 3, ['b'] = 1, ['c'] = 5}, {}), {['a'] = 3, ['b'] = 1, ['c'] = 5})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_215837_verify", "language": "lua", "prompt": "-- To check whether `url` belongs to YouTube, if yes returns True\n-- else False\nlocal function verify(url)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_215837_verify.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = verify\n    lu.assertEquals(candidate('https://www.youtube.com/watch?v=vZ19cI4k-oI&index=12'), true)\n    lu.assertEquals(candidate('https://www.youtube.com'), true)\n    lu.assertEquals(candidate('https://www.youttube.com'), false)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('https://youtu.be/dQw4w9WgXcQ'), true)\n    lu.assertEquals(candidate('https://www.youtube.com/watch?v=vZ19cI4k-oI'), true)\n    lu.assertEquals(candidate('https://www.youtube.com/watch?v=vZ19cI4k-oI&list=PLhTjy8cBISEqY-J1w0J6iC613vudN2Y4B'), true)\n    lu.assertEquals(candidate('https://www.youtube.com/watch?v=vZ19cI4k-oI&list=PLhTjy8cBISEqY-J1w0J6iC613vudN2Y4B&index=12&t=454s'), true)\n    lu.assertEquals(candidate('https://www.youtube.com/watch?v=dQw4w9WgXcQ'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_215878_is_duplicate", "language": "lua", "prompt": "-- Return True if the string 'Possible Duplicate is in string s or False, otherwise.'\n-- :param s:\n-- :return:\nlocal function is_duplicate(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_215878_is_duplicate.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_duplicate\n    lu.assertEquals(candidate(str(16)), false)\n    lu.assertEquals(candidate('Possible Duplicate: 6221711006451504961, 6221711006451504962, 6221711006451504963, 6221711006451504964, 6221711006451504965'), true)\n    lu.assertEquals(candidate('Possible Duplicate: 13.24 13.24 13.24 13.24'), true)\n    lu.assertEquals(candidate('4'), false)\n    lu.assertEquals(candidate('0'), false)\n    lu.assertEquals(candidate('Possible Duplicate: 13.24 13.24 13.24 13.24 13.24'), true)\n    lu.assertEquals(candidate(str(4)), false)\n    lu.assertEquals(candidate(str(8)), false)\n    lu.assertEquals(candidate('Possible Duplicate: 0.00014341297035841606 0.00014341297035841606'), true)\n    lu.assertEquals(candidate('Possible Duplicate: 13.24'), true)\n    lu.assertEquals(candidate('12'), false)\n    lu.assertEquals(candidate('\\nPossible Duplicate:\\nFirst name: John\\nLast name: Doe\\nEmail: <EMAIL>\\nFirst name: John\\nLast name: Doe\\nEmail: <EMAIL>\\n'), true)\n    lu.assertEquals(candidate(str(0)), false)\n    lu.assertEquals(candidate(str(2)), false)\n    lu.assertEquals(candidate(str(6)), false)\n    lu.assertEquals(candidate('8'), false)\n    lu.assertEquals(candidate('Possible Duplicate: 13.24 '), true)\n    lu.assertEquals(candidate('Possible Duplicate: 6221711006451504961, 6221711006451504962, 6221711006451504963, 6221711006451504964'), true)\n    lu.assertEquals(candidate(str(10)), false)\n    lu.assertEquals(candidate('10'), false)\n    lu.assertEquals(candidate(str(14)), false)\n    lu.assertEquals(candidate('2'), false)\n    lu.assertEquals(candidate(str(12)), false)\n    lu.assertEquals(candidate('6'), false)\n    lu.assertEquals(candidate(str(18)), false)\n    lu.assertEquals(candidate('\\nPossible Duplicate:\\nFirst name: John\\nLast name: Doe\\nEmail: <EMAIL>\\nFirst name: John\\nLast name: Doe\\nEmail: <EMAIL>\\n\\nPossible Duplicate:\\nFirst name: John\\nLast name: Doe\\nEmail: <EMAIL>\\nFirst name: Mary\\nLast name: Smith\\nEmail: <EMAIL>\\n'), true)\n    lu.assertEquals(candidate('14'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_216479_find_common_left", "language": "lua", "prompt": "-- :param list[str] strings: list of strings we want to find a common left part in\n-- :rtype: str\nlocal function find_common_left(strings)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_216479_find_common_left.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = find_common_left\n    lu.assertEquals(candidate({'a', 'b'}), '')\n    lu.assertEquals(candidate({'abc', 'def'}), '')\n    lu.assertEquals(candidate({'aa', 'ab', 'a'}), 'a')\n    lu.assertEquals(candidate({'aba', 'cdc', 'eae'}), '')\n    lu.assertEquals(candidate({'ab', 'a', 'ac'}), 'a')\n    lu.assertEquals(candidate({'abcd', 'abab', 'ababd', 'abcdx'}), 'ab')\n    lu.assertEquals(candidate({'abc', 'a', 'acb'}), 'a')\n    lu.assertEquals(candidate({'aaa', 'aab', 'abb', 'bbb', 'ccc'}), '')\n    lu.assertEquals(candidate({'abc', 'd', 'cba'}), '')\n    lu.assertEquals(candidate({'', 'c', 'c'}), '')\n    lu.assertEquals(candidate({'a', 'b', 'c', 'd'}), '')\n    lu.assertEquals(candidate({'', 'T', 'a', 't', 'a', 'a', 'T', 'T', ''}), '')\n    lu.assertEquals(candidate({'aa', 'a'}), 'a')\n    lu.assertEquals(candidate({'', ''}), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_216526_center_position", "language": "lua", "prompt": "-- Center bounds within available space.\n-- :param low_bound: current lower bound\n-- :param high_bound: current upper bound\n-- :param low_limit: minimum allowed bound\n-- :param high_limit: maximum allowed bound\n-- :param space: available space\n-- :return: centered low bound, centered high bound\nlocal function center_position(low_bound, high_bound, low_limit, high_limit, space)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_216526_center_position.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = center_position\n    lu.assertEquals(candidate(0, 0, 0, 0, 10), {0, 0})\n    lu.assertEquals(candidate(1, 3, 0, 4, 4), {1, 3})\n    lu.assertEquals(candidate(0, 3, 0, 4, 2), {0, 3})\n    lu.assertEquals(candidate(0, 5, 0, 0, 10), {0, 5})\n    lu.assertEquals(candidate(0, 1, 0, 2, 2), {0, 1})\n    lu.assertEquals(candidate(0, 10, 0, 0, 10), {0, 10})\n    lu.assertEquals(candidate(0, 1, 0, 0, 10), {0, 1})\n    lu.assertEquals(candidate(0, 2, 0, 4, 2), {0, 2})\n    lu.assertEquals(candidate(0, 4, 0, 6, 10), {0, 4})\n    lu.assertEquals(candidate(0, 4, 0, 8, 10), {0, 4})\n    lu.assertEquals(candidate(0, 1, 1, 2, 2), {0, 1})\n    lu.assertEquals(candidate(0, 2, 0, 3, 2), {0, 2})\n    lu.assertEquals(candidate(1, 3, 0, 4, 2), {0, 2})\n    lu.assertEquals(candidate(0, 2, 0, 4, 4), {0, 2})\n    lu.assertEquals(candidate(0, 1, 1, 2, 3), {1, 2})\n    lu.assertEquals(candidate(0, 4, 0, 0, 10), {0, 4})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_217312_and_is_true", "language": "lua", "prompt": "-- Function:  and_is_true\n-- Description:  Uses a truth table to do an AND check between two values of\n--     {Yes (True) / No (False)}.\n-- Arguments:\n--     (input) itemx -> Yes or No value.\n--     (input) itemy -> Yes or No value.\n--     (output) Return True | False based on AND comparsion.\nlocal function and_is_true(itemx, itemy)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_217312_and_is_true.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = and_is_true\n    lu.assertEquals(candidate('No', 'Yes'), false)\n    lu.assertEquals(candidate('Yes', 'No'), false)\n    lu.assertEquals(candidate('No', 'No'), false)\n    lu.assertEquals(candidate('Yes', 'Yes'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_217479__number_channels", "language": "lua", "prompt": "-- Determines the number of channels corresponding to a RGB flag.\nlocal function _number_channels(rgb)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_217479__number_channels.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _number_channels\n    lu.assertEquals(candidate(true), 3)\n    lu.assertEquals(candidate(false), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_217549_is_valid_git_sha1", "language": "lua", "prompt": "-- check if a string is a valid git sha1 string\n-- Input:\n-- hash: string to validate\n-- Output:\n-- True if the string has 40 characters and is an hexadecimal number, False\n-- otherwise.\nlocal function is_valid_git_sha1(hash)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_217549_is_valid_git_sha1.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_valid_git_sha1\n    lu.assertEquals(candidate('0123456789012345678901234567890123456789x'), false)\n    lu.assertEquals(candidate('012345678901234567890123456789012345678x'), false)\n    lu.assertEquals(candidate('a'), false)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('01234567890'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_217944_upsample", "language": "lua", "prompt": "-- Stretch bits worth of data to fill the byte.\n-- This is done by duplicating the MSB to fill the remaining space.\nlocal function upsample(bits, data)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_217944_upsample.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = upsample\n    lu.assertEquals(candidate(9, 0), 0)\n    lu.assertEquals(candidate(0, 0), 0)\n    lu.assertEquals(candidate(0, 1), 1)\n    lu.assertEquals(candidate(1, 0), 0)\n    lu.assertEquals(candidate(8, 0), 0)\n    lu.assertEquals(candidate(0, 255), 255)\n    lu.assertEquals(candidate(3, 0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_218685_capitalized", "language": "lua", "prompt": "-- Return a string with its first character capitalized.\nlocal function capitalized(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_218685_capitalized.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = capitalized\n    lu.assertEquals(candidate('Word'), 'Word')\n    lu.assertEquals(candidate('sentence'), 'Sentence')\n    lu.assertEquals(candidate('abc'), 'Abc')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('a'), 'A')\n    lu.assertEquals(candidate(None), None)\n    lu.assertEquals(candidate('A'), 'A')\n    lu.assertEquals(candidate('word'), 'Word')\n    lu.assertEquals(candidate('Sentence'), 'Sentence')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_218914_problem_26", "language": "lua", "prompt": "--  longest recurring cycle in decimal fractions\nlocal function problem_26(lim)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_218914_problem_26.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = problem_26\n    lu.assertEquals(candidate(1000), 983)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_220758_arabic_to_roman", "language": "lua", "prompt": "-- Return roman version of the specified arabic number.\nlocal function arabic_to_roman(number)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_220758_arabic_to_roman.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = arabic_to_roman\n    lu.assertEquals(candidate(891), 'DCCCXCI')\n    lu.assertEquals(candidate(25), 'XXV')\n    lu.assertEquals(candidate(16), 'XVI')\n    lu.assertEquals(candidate(80), 'LXXX')\n    lu.assertEquals(candidate(501), 'DI')\n    lu.assertEquals(candidate(990), 'CMXC')\n    lu.assertEquals(candidate(14), 'XIV')\n    lu.assertEquals(candidate(15), 'XV')\n    lu.assertEquals(candidate(6), 'VI')\n    lu.assertEquals(candidate(649), 'DCXLIX')\n    lu.assertEquals(candidate(93), 'XCIII')\n    lu.assertEquals(candidate(500), 'D')\n    lu.assertEquals(candidate(88), 'LXXXVIII')\n    lu.assertEquals(candidate(9), 'IX')\n    lu.assertEquals(candidate(99), 'XCIX')\n    lu.assertEquals(candidate(12), 'XII')\n    lu.assertEquals(candidate(10), 'X')\n    lu.assertEquals(candidate(1), 'I')\n    lu.assertEquals(candidate(7), 'VII')\n    lu.assertEquals(candidate(8), 'VIII')\n    lu.assertEquals(candidate(19), 'XIX')\n    lu.assertEquals(candidate(3), 'III')\n    lu.assertEquals(candidate(2), 'II')\n    lu.assertEquals(candidate(600), 'DC')\n    lu.assertEquals(candidate(17), 'XVII')\n    lu.assertEquals(candidate(400), 'CD')\n    lu.assertEquals(candidate(23), 'XXIII')\n    lu.assertEquals(candidate(27), 'XXVII')\n    lu.assertEquals(candidate(20), 'XX')\n    lu.assertEquals(candidate(100), 'C')\n    lu.assertEquals(candidate(40), 'XL')\n    lu.assertEquals(candidate(21), 'XXI')\n    lu.assertEquals(candidate(0), '')\n    lu.assertEquals(candidate(30), 'XXX')\n    lu.assertEquals(candidate(798), 'DCCXCVIII')\n    lu.assertEquals(candidate(22), 'XXII')\n    lu.assertEquals(candidate(300), 'CCC')\n    lu.assertEquals(candidate(13), 'XIII')\n    lu.assertEquals(candidate(70), 'LXX')\n    lu.assertEquals(candidate(200), 'CC')\n    lu.assertEquals(candidate(11), 'XI')\n    lu.assertEquals(candidate(24), 'XXIV')\n    lu.assertEquals(candidate(5), 'V')\n    lu.assertEquals(candidate(60), 'LX')\n    lu.assertEquals(candidate(90), 'XC')\n    lu.assertEquals(candidate(18), 'XVIII')\n    lu.assertEquals(candidate(50), 'L')\n    lu.assertEquals(candidate(4), 'IV')\n    lu.assertEquals(candidate(700), 'DCC')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_221003_create_nonlocal_service_cluster_name", "language": "lua", "prompt": "-- Create the cluster name for the non-local namespace, service, color.\nlocal function create_nonlocal_service_cluster_name(namespace, service, color, index)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_221003_create_nonlocal_service_cluster_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = create_nonlocal_service_cluster_name\n    lu.assertEquals(candidate('default', 'test-service', 'blue', 1), 'remote-default-test-service-blue-1')\n    lu.assertEquals(candidate('default', 'test-service', 'blue', 2), 'remote-default-test-service-blue-2')\n    lu.assertEquals(candidate('default', 'test-service', 'blue', 2), 'remote-default-test-service-blue-2')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_221888_FindMaximumSubarray", "language": "lua", "prompt": "-- Encuentra la mayor subsecuencia dentro de la lista A.\n-- Si se recibe una lista vacia se lanza una excepcion de tipo IndexError.\n-- Retorna:\n-- max_left -- El indice izquierdo del subarreglo\n-- max_right -- El indice derecho del subarreglo\n-- suma -- La suma total del subarreglo\nlocal function FindMaximumSubarray(A)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_221888_FindMaximumSubarray.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = FindMaximumSubarray\n    lu.assertEquals(candidate({1, 2, 3}), {0, 2, 6})\n    lu.assertEquals(candidate({-1, -2, -3, -4}), {0, 0, -1})\n    lu.assertEquals(candidate({1}), {0, 0, 1})\n    lu.assertEquals(candidate({-1, -2, 0, 1}), {2, 3, 1})\n    lu.assertEquals(candidate({1, 2, 3}), {0, 2, 6})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_22246_get_chunk_slices", "language": "lua", "prompt": "-- Create list of chunk slices [(s_i, e_i), ...]\n-- Parameters\n-- ----------\n-- ds_len : 'int'\n--     Length of dataset axis to chunk\n-- chunk_size : 'int'\n--     Size of chunks\n-- Returns\n-- -------\n-- chunks : 'list'\n--     List of chunk start and end positions\n--     [(s_i, e_i), (s_i+1, e_i+1), ...]\nlocal function get_chunk_slices(ds_dim, chunk_size)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_22246_get_chunk_slices.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_chunk_slices\n    lu.assertEquals(candidate(10, 15), {{0, 10}})\n    lu.assertEquals(candidate(2, 1), {{0, 1}, {1, 2}})\n    lu.assertEquals(candidate(6, 6), {{0, 6}})\n    lu.assertEquals(candidate(10, 13), {{0, 10}})\n    lu.assertEquals(candidate(10, 14), {{0, 10}})\n    lu.assertEquals(candidate(10, 12), {{0, 10}})\n    lu.assertEquals(candidate(9, 5), {{0, 5}, {5, 9}})\n    lu.assertEquals(candidate(10, 10), {{0, 10}})\n    lu.assertEquals(candidate(3, 2), {{0, 2}, {2, 3}})\n    lu.assertEquals(candidate(6, 2), {{0, 2}, {2, 4}, {4, 6}})\n    lu.assertEquals(candidate(10, 17), {{0, 10}})\n    lu.assertEquals(candidate(6, 1), {{0, 1}, {1, 2}, {2, 3}, {3, 4}, {4, 5}, {5, 6}})\n    lu.assertEquals(candidate(1, 1), {{0, 1}})\n    lu.assertEquals(candidate(2, 2), {{0, 2}})\n    lu.assertEquals(candidate(6, 4), {{0, 4}, {4, 6}})\n    lu.assertEquals(candidate(7, 2), {{0, 2}, {2, 4}, {4, 6}, {6, 7}})\n    lu.assertEquals(candidate(5, 1), {{0, 1}, {1, 2}, {2, 3}, {3, 4}, {4, 5}})\n    lu.assertEquals(candidate(3, 1), {{0, 1}, {1, 2}, {2, 3}})\n    lu.assertEquals(candidate(10, 5), {{0, 5}, {5, 10}})\n    lu.assertEquals(candidate(10, 16), {{0, 10}})\n    lu.assertEquals(candidate(6, 7), {{0, 6}})\n    lu.assertEquals(candidate(10, 18), {{0, 10}})\n    lu.assertEquals(candidate(5, 2), {{0, 2}, {2, 4}, {4, 5}})\n    lu.assertEquals(candidate(8, 4), {{0, 4}, {4, 8}})\n    lu.assertEquals(candidate(9, 2), {{0, 2}, {2, 4}, {4, 6}, {6, 8}, {8, 9}})\n    lu.assertEquals(candidate(7, 4), {{0, 4}, {4, 7}})\n    lu.assertEquals(candidate(4, 1), {{0, 1}, {1, 2}, {2, 3}, {3, 4}})\n    lu.assertEquals(candidate(4, 2), {{0, 2}, {2, 4}})\n    lu.assertEquals(candidate(5, 3), {{0, 3}, {3, 5}})\n    lu.assertEquals(candidate(5, 5), {{0, 5}})\n    lu.assertEquals(candidate(5, 6), {{0, 5}})\n    lu.assertEquals(candidate(6, 3), {{0, 3}, {3, 6}})\n    lu.assertEquals(candidate(10, 11), {{0, 10}})\n    lu.assertEquals(candidate(8, 2), {{0, 2}, {2, 4}, {4, 6}, {6, 8}})\n    lu.assertEquals(candidate(6, 5), {{0, 5}, {5, 6}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_222628_indent", "language": "lua", "prompt": "-- Indent each row of the given string block with ``n*2`` spaces.\nlocal function indent(block)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_222628_indent.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = indent\n    lu.assertEquals(candidate('foo\\nbar'), '  foo\\n  bar')\n    lu.assertEquals(candidate('hello\\n  world'), '  hello\\n    world')\n    lu.assertEquals(candidate('hello\\nworld'), '  hello\\n  world')\n    lu.assertEquals(candidate('hello'), '  hello')\n    lu.assertEquals(candidate('foo'), '  foo')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_223007_get_unlabled_last_index", "language": "lua", "prompt": "-- For example, for CIFAR100 we have len_dataset 10000 for test data.\n-- The number of samples per class is 1000.\n-- If we want 9000 unlabeled samples then the ratio_unlabeled is 9/10.\n-- The number of samples per class for the unlabeled dataset is 9/10*100=90.\n-- If the number of samples for the final test is 1000 samples and we have 100\n-- classes, then the number of samples per class will be 10 (only).\n-- :param num_unlabeled_samples: number of unlabeled samples from the test set\n-- :param len_dataset: the total number of samples in the intial test set\n-- :param len_class: the number of samples for a given class\n-- :return: for the array of sample indices for the class, the last index for\n-- the unlabeled part\n-- >>> num_unlabeled_samples = 9000\n-- >>> len_dataset = 10000\n-- >>> len_class = 100\n-- >>> result = get_unlabled_last_index(num_unlabeled_samples=num_unlabeled_samples, len_dataset=len_dataset, len_class=len_class)\n-- >>> assert result == 90\n-- >>> # print('result: ', result)\nlocal function get_unlabled_last_index(num_unlabeled_samples, len_dataset, len_class)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_223007_get_unlabled_last_index.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_unlabled_last_index\n    lu.assertEquals(candidate(9000, 10000, 10000), 9000)\n    lu.assertEquals(candidate(2000, 1000, 100), 200)\n    lu.assertEquals(candidate(1000, 1000, 100), 100)\n    lu.assertEquals(candidate(10, 100, 100), 10)\n    lu.assertEquals(candidate(1, 100, 100), 1)\n    lu.assertEquals(candidate(9000, 10000, 100), 90)\n    lu.assertEquals(candidate(100, 1000, 100), 10)\n    lu.assertEquals(candidate(0, 100, 100), 0)\n    lu.assertEquals(candidate(100, 100, 30), 30)\n    lu.assertEquals(candidate(100, 100, 50), 50)\n    lu.assertEquals(candidate(10000, 1000, 100), 1000)\n    lu.assertEquals(candidate(200, 100, 10), 20)\n    lu.assertEquals(candidate(100, 100, 10), 10)\n    lu.assertEquals(candidate(9000, 10000, 1000), 900)\n    lu.assertEquals(candidate(50, 100, 10), 5)\n    lu.assertEquals(candidate(100, 100, 1), 1)\n    lu.assertEquals(candidate(9000, 10000, 500), 450)\n    lu.assertEquals(candidate(9000, 10000, 150), 135)\n    lu.assertEquals(candidate(9000, 10000, 200), 180)\n    lu.assertEquals(candidate(100, 100, 40), 40)\n    lu.assertEquals(candidate(100, 100, 60), 60)\n    lu.assertEquals(candidate(100, 100, 20), 20)\n    lu.assertEquals(candidate(900, 1000, 100), 90)\n    lu.assertEquals(candidate(9000, 10000, 100), 90)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_223709_one_to_three", "language": "lua", "prompt": "--  Take a score -1, 0, or 1, and return the three vector of labels \nlocal function one_to_three(one)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_223709_one_to_three.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = one_to_three\n    lu.assertEquals(candidate(0), {0, 1, 0})\n    lu.assertEquals(candidate(1), {0, 0, 1})\n    lu.assertEquals(candidate(-1), {1, 0, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_224204_glue_template_and_params", "language": "lua", "prompt": "-- Return wiki text of template glued from params.\n-- You can use items from extract_templates_and_params here to get\n-- an equivalent template wiki text (it may happen that the order\n-- of the params changes).\nlocal function glue_template_and_params(template_and_params)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_224204_glue_template_and_params.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = glue_template_and_params\n    lu.assertEquals(candidate({'Template', {['param1'] = 'value1', ['param2'] = 'value2', ['param3'] = 'value3', ['param4'] = 'value4'}}), '{{Template\\n|param1=value1\\n|param2=value2\\n|param3=value3\\n|param4=value4\\n}}')\n    lu.assertEquals(candidate({'Template', {['param1'] = 'value1', ['param2'] = 'value2', ['param3'] = 'value3', ['param4'] = 'value4', ['param5'] = 'value5'}}), '{{Template\\n|param1=value1\\n|param2=value2\\n|param3=value3\\n|param4=value4\\n|param5=value5\\n}}')\n    lu.assertEquals(candidate({'Template', {['param1'] = 'value1', ['param2'] = 'value2', ['param3'] = 'value3'}}), '{{Template\\n|param1=value1\\n|param2=value2\\n|param3=value3\\n}}')\n    lu.assertEquals(candidate({'Template', {['param1'] = 'value1', ['param2'] = 'value2'}}), '{{Template\\n|param1=value1\\n|param2=value2\\n}}')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_224251_export_shard_uuid", "language": "lua", "prompt": "-- Sharding of the UUID for the import/export\n-- :param uuid: UUID to be sharded (v4)\n-- :type uuid: str\n-- :return: Sharded UUID as a subfolder path\n-- :rtype: str\nlocal function export_shard_uuid(uuid)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_224251_export_shard_uuid.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = export_shard_uuid\n    lu.assertEquals(candidate('412c7920-220e-45d8-b1a1-8704b04144b7'), '41/2c/7920-220e-45d8-b1a1-8704b04144b7')\n    lu.assertEquals(candidate('a83f28ec-9b98-4036-923a-84b758b43790'), 'a8/3f/28ec-9b98-4036-923a-84b758b43790')\n    lu.assertEquals(candidate('9d241b76-b780-4a0f-98e1-400088a41f92'), '9d/24/1b76-b780-4a0f-98e1-400088a41f92')\n    lu.assertEquals(candidate('61516d6c-3190-4434-998f-4e9179a86b61'), '61/51/6d6c-3190-4434-998f-4e9179a86b61')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_224338_check_header", "language": "lua", "prompt": "--  Check whether a line is header, if it is, change it into html format\n-- :param line: str, a line in markdown file\n-- :return: boolean, whether a line is header\n--          str, the line in html format\nlocal function check_header(line)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_224338_check_header.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = check_header\n    lu.assertEquals(candidate('This is not a header.'), {false, ''})\n    lu.assertEquals(candidate('#Heading 1'), {false, ''})\n    lu.assertEquals(candidate('##### Heading 5'), {true, '<h5 id=\"Heading-5\">Heading 5</h5>'})\n    lu.assertEquals(candidate('##Heading 2'), {false, ''})\n    lu.assertEquals(candidate('# foo'), {true, '<h1 id=\"foo\">foo</h1>'})\n    lu.assertEquals(candidate('This is not a header'), {false, ''})\n    lu.assertEquals(candidate('##### test'), {true, '<h5 id=\"test\">test</h5>'})\n    lu.assertEquals(candidate('###'), {false, ''})\n    lu.assertEquals(candidate('#####Heading 5'), {false, ''})\n    lu.assertEquals(candidate('test'), {false, ''})\n    lu.assertEquals(candidate('foo'), {false, ''})\n    lu.assertEquals(candidate('A Header'), {false, ''})\n    lu.assertEquals(candidate('##### foo'), {true, '<h5 id=\"foo\">foo</h5>'})\n    lu.assertEquals(candidate('###### Heading 6'), {true, '<h6 id=\"Heading-6\">Heading 6</h6>'})\n    lu.assertEquals(candidate('# Heading 1'), {true, '<h1 id=\"Heading-1\">Heading 1</h1>'})\n    lu.assertEquals(candidate('#### Heading 4'), {true, '<h4 id=\"Heading-4\">Heading 4</h4>'})\n    lu.assertEquals(candidate('### foo'), {true, '<h3 id=\"foo\">foo</h3>'})\n    lu.assertEquals(candidate('## foo'), {true, '<h2 id=\"foo\">foo</h2>'})\n    lu.assertEquals(candidate('####### An Un-Countable Level Header'), {false, ''})\n    lu.assertEquals(candidate('###### test'), {true, '<h6 id=\"test\">test</h6>'})\n    lu.assertEquals(candidate('# test'), {true, '<h1 id=\"test\">test</h1>'})\n    lu.assertEquals(candidate('### test'), {true, '<h3 id=\"test\">test</h3>'})\n    lu.assertEquals(candidate('#### test'), {true, '<h4 id=\"test\">test</h4>'})\n    lu.assertEquals(candidate('###### foo'), {true, '<h6 id=\"foo\">foo</h6>'})\n    lu.assertEquals(candidate('## Heading 2'), {true, '<h2 id=\"Heading-2\">Heading 2</h2>'})\n    lu.assertEquals(candidate('####Heading 4'), {false, ''})\n    lu.assertEquals(candidate('#### foo'), {true, '<h4 id=\"foo\">foo</h4>'})\n    lu.assertEquals(candidate('##'), {false, ''})\n    lu.assertEquals(candidate('######Heading 6'), {false, ''})\n    lu.assertEquals(candidate('This is not a header\\n\\n'), {false, ''})\n    lu.assertEquals(candidate('### Heading 3'), {true, '<h3 id=\"Heading-3\">Heading 3</h3>'})\n    lu.assertEquals(candidate('## test'), {true, '<h2 id=\"test\">test</h2>'})\n    lu.assertEquals(candidate('###Heading 3'), {false, ''})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_225363_minify_html", "language": "lua", "prompt": "-- Perform a template-specific, rudimentary HTML minification for displaCy.\n-- Disclaimer: NOT a general-purpose solution, only removes indentation and\n-- newlines.\n-- html (unicode): Markup to minify.\n-- RETURNS (unicode): \"Minified\" HTML.\nlocal function minify_html(html)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_225363_minify_html.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = minify_html\n    lu.assertEquals(candidate(' \\n  <p> Hello, world! </p> \\n '), '<p> Hello, world! </p>')\n    lu.assertEquals(candidate('\\n    <h1>Hello, World!</h1>\\n    <p>This is a paragraph.</p>\\n    '), '<h1>Hello, World!</h1><p>This is a paragraph.</p>')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('\\n    <h1>Hello, World!</h1>\\n    '), '<h1>Hello, World!</h1>')\n    lu.assertEquals(candidate('\\n    <h1>Hello, World!</h1>\\n\\n    <p>This is a paragraph.</p>\\n\\n    <p>This is another paragraph.</p>\\n    '), '<h1>Hello, World!</h1><p>This is a paragraph.</p><p>This is another paragraph.</p>')\n    lu.assertEquals(candidate('   '), '')\n    lu.assertEquals(candidate('\\n'), '')\n    lu.assertEquals(candidate('        <p>Hello, world.</p>        '), '<p>Hello, world.</p>')\n    lu.assertEquals(candidate('   <p>Hello, world!</p> \\n \\n\\n '), '<p>Hello, world!</p>')\n    lu.assertEquals(candidate('    <p>Hello, world.</p>    '), '<p>Hello, world.</p>')\n    lu.assertEquals(candidate('\\n        <p>Hello, world.</p>        \\n'), '<p>Hello, world.</p>')\n    lu.assertEquals(candidate('    <p>A paragraph.</p>'), '<p>A paragraph.</p>')\n    lu.assertEquals(candidate('<html><head><title>Test</title></head><body><p>A paragraph.</p></body></html>'), '<html><head><title>Test</title></head><body><p>A paragraph.</p></body></html>')\n    lu.assertEquals(candidate('\\n    <h1>Hello, World!</h1>\\n    <p>This is a paragraph.</p>\\n    <p>This is another paragraph.</p>\\n    '), '<h1>Hello, World!</h1><p>This is a paragraph.</p><p>This is another paragraph.</p>')\n    lu.assertEquals(candidate('\\n    <h1>Hello, World!</h1>\\n\\n    <p>This is a paragraph.</p>\\n    '), '<h1>Hello, World!</h1><p>This is a paragraph.</p>')\n    lu.assertEquals(candidate('<p>A paragraph.</p>'), '<p>A paragraph.</p>')\n    lu.assertEquals(candidate('<p>Hello, world.</p>'), '<p>Hello, world.</p>')\n    lu.assertEquals(candidate('\\n    <p>Hello, world.</p>    \\n'), '<p>Hello, world.</p>')\n    lu.assertEquals(candidate(' \\n\\n\\n\\n  \\n'), '')\n    lu.assertEquals(candidate('Hello, world!'), 'Hello, world!')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_226063_conjugatePartition", "language": "lua", "prompt": "-- Find the conjugate of a partition.\n-- E.g. len(p) = max(conjugate(p)) and vice versa.\n-- D. Eppstein, August 2005.\nlocal function conjugatePartition(p)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_226063_conjugatePartition.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = conjugatePartition\n    lu.assertEquals(candidate({1, 1, 1}), {3})\n    lu.assertEquals(candidate({3, 3, 3}), {3, 3, 3})\n    lu.assertEquals(candidate({1}), {1})\n    lu.assertEquals(candidate({1, 2, 3}), {3, 2, 1})\n    lu.assertEquals(candidate({1}), {1})\n    lu.assertEquals(candidate(candidate({2, 2, 2, 2})), {2, 2, 2, 2})\n    lu.assertEquals(candidate({1, 1, 1, 1, 1, 1, 1, 1}), {8})\n    lu.assertEquals(candidate(candidate({10, 5, 3, 2, 1})), {10, 5, 3, 2, 1})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate(candidate({2})), {2})\n    lu.assertEquals(candidate({1, 1}), {2})\n    lu.assertEquals(candidate(candidate({2, 2, 2, 2, 2, 2, 1})), {2, 2, 2, 2, 2, 2, 1})\n    lu.assertEquals(candidate(candidate({2, 2, 2, 2, 2, 2})), {2, 2, 2, 2, 2, 2})\n    lu.assertEquals(candidate({1, 2, 1}), {3, 1})\n    lu.assertEquals(candidate(candidate({2, 1, 1})), {2, 1, 1})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate(candidate({})), {})\n    lu.assertEquals(candidate({1, 2}), {2, 1})\n    lu.assertEquals(candidate(candidate({2, 2, 2, 2, 2})), {2, 2, 2, 2, 2})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6, 7, 8}), {8, 7, 6, 5, 4, 3, 2, 1})\n    lu.assertEquals(candidate(candidate({2, 2})), {2, 2})\n    lu.assertEquals(candidate(candidate({5, 4, 3, 2, 1})), {5, 4, 3, 2, 1})\n    lu.assertEquals(candidate({1, 1, 1, 1}), {4})\n    lu.assertEquals(candidate({2, 1}), {2, 1})\n    lu.assertEquals(candidate({1, 1, 1, 1, 1, 1, 1}), {7})\n    lu.assertEquals(candidate(candidate({2, 2, 2})), {2, 2, 2})\n    lu.assertEquals(candidate({1, 1}), {2})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_22607_float_str", "language": "lua", "prompt": "--     Convert float to string, for use in command line arguments.\nlocal function float_str(a)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_22607_float_str.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = float_str\n    lu.assertEquals(candidate(1e-100), '1e-100')\n    lu.assertEquals(candidate(1e-08), '1e-08')\n    lu.assertEquals(candidate(float('inf')), 'inf')\n    lu.assertEquals(candidate(1.0), '1.0')\n    lu.assertEquals(candidate(10000000000.0), '10000000000.0')\n    lu.assertEquals(candidate(1000.0), '1000.0')\n    lu.assertEquals(candidate(1e-10), '1e-10')\n    lu.assertEquals(candidate(0.0), '0.0')\n    lu.assertEquals(candidate(float('-inf')), '-inf')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_226474_get_version_substitute", "language": "lua", "prompt": "-- Transform provider version str to universal version type.\nlocal function get_version_substitute(version_str)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_226474_get_version_substitute.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_version_substitute\n    lu.assertEquals(candidate('The 2009 video mix'), 'video version')\n    lu.assertEquals(candidate('the 2009 spanglish version'), 'spanish version')\n    lu.assertEquals(candidate('The 2009 radio mix'), 'radio version')\n    lu.assertEquals(candidate('the remaster'), 'remaster')\n    lu.assertEquals(candidate('some other stuff'), 'some other stuff')\n    lu.assertEquals(candidate('The 2009 spanglish version'), 'spanish version')\n    lu.assertEquals(candidate('the 2009 spanish version'), 'spanish version')\n    lu.assertEquals(candidate('The 2009 spanish version'), 'spanish version')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_226709__LJ_ab_to_ab", "language": "lua", "prompt": "--     Convert AB representation to AB representation of the LJ potential\nlocal function _LJ_ab_to_ab(coeffs)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_226709__LJ_ab_to_ab.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _LJ_ab_to_ab\n    lu.assertEquals(candidate({['A'] = 2, ['B'] = 3}), {['A'] = 2, ['B'] = 3})\n    lu.assertEquals(candidate({['A'] = 1, ['B'] = 2}), {['A'] = 1, ['B'] = 2})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_22682_remove_quotes", "language": "lua", "prompt": "-- This function is used here to remove quotes from\n-- paths used in this script.\n-- :param string: Path with quotes.\n-- :return: Path without quotes.\nlocal function remove_quotes(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_22682_remove_quotes.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_quotes\n    lu.assertEquals(candidate('C:\\\\Users\\\\Test User\\\\AppData\\\\Local\\\\Programs'), 'C:\\\\Users\\\\Test User\\\\AppData\\\\Local\\\\Programs')\n    lu.assertEquals(candidate('\"C:\\\\\\\\Users\\\\\\\\Markus\\\\\\\\Desktop\"'), 'C:\\\\\\\\Users\\\\\\\\Markus\\\\\\\\Desktop')\n    lu.assertEquals(candidate('\"C:\\\\Users\\\\Markus\\\\Desktop\"'), 'C:\\\\Users\\\\Markus\\\\Desktop')\n    lu.assertEquals(candidate('C:\\\\Users\\\\Batman\\\\Desktop\\\\not_so_important_file.txt'), 'C:\\\\Users\\\\Batman\\\\Desktop\\\\not_so_important_file.txt')\n    lu.assertEquals(candidate('\"C:\\\\Users\\\\Batman\\\\Desktop\\\\super_important_file.txt\"'), 'C:\\\\Users\\\\Batman\\\\Desktop\\\\super_important_file.txt')\n    lu.assertEquals(candidate('\"C:\\\\Users\\\\Batman\\\\Desktop\\\\not_so_important_file.txt\"'), 'C:\\\\Users\\\\Batman\\\\Desktop\\\\not_so_important_file.txt')\n    lu.assertEquals(candidate('\"/path/with/quotes/in/it.txt\"'), '/path/with/quotes/in/it.txt')\n    lu.assertEquals(candidate('C:\\\\Users\\\\Batman\\\\Desktop\\\\super_important_file.txt'), 'C:\\\\Users\\\\Batman\\\\Desktop\\\\super_important_file.txt')\n    lu.assertEquals(candidate('\"C:\\\\my path\\\\file.txt\"'), 'C:\\\\my path\\\\file.txt')\n    lu.assertEquals(candidate('C:\\\\Users\\\\Test User\\\\AppData\\\\Local\\\\Programs'), 'C:\\\\Users\\\\Test User\\\\AppData\\\\Local\\\\Programs')\n    lu.assertEquals(candidate('\"C:\\\\Users\\\\Markus\"'), 'C:\\\\Users\\\\Markus')\n    lu.assertEquals(candidate('\"/path/with/quotes/in/it.txt\"'), '/path/with/quotes/in/it.txt')\n    lu.assertEquals(candidate('\"C:\\\\Users\\\\Test User\\\\AppData\\\\Local\\\\Programs\"'), 'C:\\\\Users\\\\Test User\\\\AppData\\\\Local\\\\Programs')\n    lu.assertEquals(candidate('C:\\\\Users\\\\Batman\\\\Desktop\\\\super_important_file.txt'), 'C:\\\\Users\\\\Batman\\\\Desktop\\\\super_important_file.txt')\n    lu.assertEquals(candidate('C:\\\\Users\\\\Test User\\\\AppData\\\\Local\\\\Programs'), 'C:\\\\Users\\\\Test User\\\\AppData\\\\Local\\\\Programs')\n    lu.assertEquals(candidate('C:\\\\Users\\\\Batman\\\\Desktop\\\\not_so_important_file.txt'), 'C:\\\\Users\\\\Batman\\\\Desktop\\\\not_so_important_file.txt')\n    lu.assertEquals(candidate('\"C:\\\\Users\\\\Batman\\\\Desktop\\\\super_important_file.txt\"'), 'C:\\\\Users\\\\Batman\\\\Desktop\\\\super_important_file.txt')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_227166_partition", "language": "lua", "prompt": "-- Partitions a given array using the first element as the pivot.\nlocal function partition(v)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_227166_partition.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = partition\n    lu.assertEquals(candidate(list(range(10))), {0, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}})\n    lu.assertEquals(candidate({1}), {0, {1}})\n    lu.assertEquals(candidate({0, 2, 4, 6, 8}), {0, {0, 2, 4, 6, 8}})\n    lu.assertEquals(candidate({0, 1, 2, 3, 4, 5, 6, 7, 8, 9}), {0, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_227167_parse_reg_02h_byte", "language": "lua", "prompt": "-- Net ID\nlocal function parse_reg_02h_byte(byte_val)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_227167_parse_reg_02h_byte.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_reg_02h_byte\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(127), 127)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(255), 255)\n    lu.assertEquals(candidate(255), 255)\n    lu.assertEquals(candidate(0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_227348__find_minmax_indices", "language": "lua", "prompt": "-- Finds the indices corresponding to the minimum and maximum values\n-- in an integer vector.\n-- :args invec: The input integer array.\nlocal function _find_minmax_indices(invec)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_227348__find_minmax_indices.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _find_minmax_indices\n    lu.assertEquals(candidate({1, 2, 3}), {0, 2})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_22782_extract_instance_name", "language": "lua", "prompt": "-- Given instance URL returns instance name.\nlocal function extract_instance_name(url)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_22782_extract_instance_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = extract_instance_name\n    lu.assertEquals(candidate('http://localhost:8000/instances/project_id:region:instance_id'), 'project_id:region:instance_id')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_229260_get_status_code_value", "language": "lua", "prompt": "-- function to return appropriate status code value from the dictionary\nlocal function get_status_code_value(status_code)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_229260_get_status_code_value.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_status_code_value\n    lu.assertEquals(candidate('203'), 'Non-authoritative Information')\n    lu.assertEquals(candidate('415'), 'Unsupported Media Type')\n    lu.assertEquals(candidate('204'), 'No Content')\n    lu.assertEquals(candidate('302'), 'Found')\n    lu.assertEquals(candidate('303'), 'See Other')\n    lu.assertEquals(candidate('403'), 'Forbidden')\n    lu.assertEquals(candidate('304'), 'Not Modified')\n    lu.assertEquals(candidate('501'), 'Not Implemented')\n    lu.assertEquals(candidate('201'), 'Created')\n    lu.assertEquals(candidate('206'), 'Partial Content')\n    lu.assertEquals(candidate('400'), 'Bad Request')\n    lu.assertEquals(candidate('100'), 'Continue')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_229673_u16leListToByteList", "language": "lua", "prompt": "-- Convert a halfword array into a byte array\nlocal function u16leListToByteList(data)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_229673_u16leListToByteList.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = u16leListToByteList\n    lu.assertEquals(candidate({4660, 22136}), {52, 18, 120, 86})\n    lu.assertEquals(candidate(list()), list())\n    lu.assertEquals(candidate({0}), {0, 0})\n    lu.assertEquals(candidate({4660, 22136}), {52, 18, 120, 86})\n    lu.assertEquals(candidate({65535}), {255, 255})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({1, 2, 3, 4}), {1, 0, 2, 0, 3, 0, 4, 0})\n    lu.assertEquals(candidate({4660, 22136, 39612, 57087}), {52, 18, 120, 86, 188, 154, 255, 222})\n    lu.assertEquals(candidate({4660, 22136, 39612}), {52, 18, 120, 86, 188, 154})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_229855_parse_youtube_title", "language": "lua", "prompt": "-- Parse song tags from youtube title.\n-- Current logic is to assumme the youtube title is always in format 'author-song title'.\n-- If there exists dashes in the title, up to the first dash is the author and the rest is the song title.\n-- If there are no dashes, return original title as song title.\n-- There will never be more than one dash because of the way we clean youtube titles.\n-- Return tuple (author_title, song_title)\nlocal function parse_youtube_title(full_title)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_229855_parse_youtube_title.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_youtube_title\n    lu.assertEquals(candidate('author-song title'), {'author', 'song title'})\n    lu.assertEquals(candidate('author - song title'), {'author', 'song title'})\n    lu.assertEquals(candidate(\"The Beatles - Sgt. Pepper's Lonely Hearts Club Band\"), {'The Beatles', \"Sgt. Pepper's Lonely Hearts Club Band\"})\n    lu.assertEquals(candidate(\"Sgt. Pepper's Lonely Hearts Club Band\"), {None, \"Sgt. Pepper's Lonely Hearts Club Band\"})\n    lu.assertEquals(candidate('Someone-awesome song title'), {'Someone', 'awesome song title'})\n    lu.assertEquals(candidate('Sgt. Pepper Lonely Hearts Club Band'), {None, 'Sgt. Pepper Lonely Hearts Club Band'})\n    lu.assertEquals(candidate('Someone-awesome song title'), {'Someone', 'awesome song title'})\n    lu.assertEquals(candidate('The Beatles - Sgt. Pepper Lonely Hearts Club Band'), {'The Beatles', 'Sgt. Pepper Lonely Hearts Club Band'})\n    lu.assertEquals(candidate('awesome song title'), {None, 'awesome song title'})\n    lu.assertEquals(candidate('awesome song title'), {None, 'awesome song title'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_23033_is_basic_type", "language": "lua", "prompt": "-- Returns True if the signature is a basic type\n-- 'a', '(', '{', and 'v' are not considered basic types because they usually\n-- cannot be handled the same as other types.\nlocal function is_basic_type(signature)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_23033_is_basic_type.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_basic_type\n    lu.assertEquals(candidate('q'), true)\n    lu.assertEquals(candidate('d'), true)\n    lu.assertEquals(candidate('y'), true)\n    lu.assertEquals(candidate('g'), true)\n    lu.assertEquals(candidate('i'), true)\n    lu.assertEquals(candidate('s'), true)\n    lu.assertEquals(candidate('x'), true)\n    lu.assertEquals(candidate('('), false)\n    lu.assertEquals(candidate('b'), true)\n    lu.assertEquals(candidate('n'), true)\n    lu.assertEquals(candidate('t'), true)\n    lu.assertEquals(candidate('v'), false)\n    lu.assertEquals(candidate('a'), false)\n    lu.assertEquals(candidate('{'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_230829_echo", "language": "lua", "prompt": "--     Very simple endpoint that just echos your message back to you\n-- :param message:  str of the message to echo\n-- :return:         str of the message echoed\nlocal function echo(message)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_230829_echo.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = echo\n    lu.assertEquals(candidate('world'), 'ECHO: world')\n    lu.assertEquals(candidate('hello'), 'ECHO: hello')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_231491_truncate", "language": "lua", "prompt": "-- Return text truncated to the max_length character if needed.\nlocal function truncate(text, max_length)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_231491_truncate.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = truncate\n    lu.assertEquals(candidate('This is a long string.', 10), 'This is...')\n    lu.assertEquals(candidate('Hello World', 1000), 'Hello World')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_231656_get_unique_tokens", "language": "lua", "prompt": "-- Delimit the input `geneset_name` by \"; \", and return a new string\n-- that includes only unique tokens delimited by \"; \".\nlocal function get_unique_tokens(geneset_name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_231656_get_unique_tokens.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_unique_tokens\n    lu.assertEquals(candidate('A; A; B; C'), 'A; B; C')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_232067_truncpad", "language": "lua", "prompt": "-- Return srcline truncated and padded to length, aligned as requested.\nlocal function truncpad(srcline, length, align, ellipsis)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_232067_truncpad.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = truncpad\n    lu.assertEquals(candidate('1234', 3, 'l', false), '123')\n    lu.assertEquals(candidate('1234', 6, 'r'), '  1234')\n    lu.assertEquals(candidate('this is a test', 4), 'this')\n    lu.assertEquals(candidate('1234', 5, 'r'), ' 1234')\n    lu.assertEquals(candidate('1234', 3, 'c', false), '123')\n    lu.assertEquals(candidate('12345', 5), '12345')\n    lu.assertEquals(candidate('hello', 6, 'r'), ' hello')\n    lu.assertEquals(candidate('1234', 6, 'l'), '1234  ')\n    lu.assertEquals(candidate('this is a test', 4, 'r', false), 'this')\n    lu.assertEquals(candidate('1234', 5, 'c'), ' 1234')\n    lu.assertEquals(candidate('hello', 6, 'l'), 'hello ')\n    lu.assertEquals(candidate('1234567', 10), '1234567   ')\n    lu.assertEquals(candidate('hello', 4), 'hell')\n    lu.assertEquals(candidate('hello', 6), 'hello ')\n    lu.assertEquals(candidate('1234', 3, 'r', false), '123')\n    lu.assertEquals(candidate('hello', 4, 'l'), 'hell')\n    lu.assertEquals(candidate('1234', 3, 'l'), '123')\n    lu.assertEquals(candidate('hello', 5), 'hello')\n    lu.assertEquals(candidate('1234', 5, 'l'), '1234 ')\n    lu.assertEquals(candidate('1234', 3, 'r'), '123')\n    lu.assertEquals(candidate('12345', 10), '12345     ')\n    lu.assertEquals(candidate('123456', 10), '123456    ')\n    lu.assertEquals(candidate('1234', 3, 'c'), '123')\n    lu.assertEquals(candidate('hello', 4, 'c'), 'hell')\n    lu.assertEquals(candidate('hello', 4, 'r'), 'hell')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_232208_linearize", "language": "lua", "prompt": "-- Generates linearization constraints for the product y = ab.\n-- Parameters\n-- ----------\n-- a : str\n--     First factor.\n-- b : str\n--     Second factor.\n-- y : Product.\n-- Returns\n-- -------\n-- List[str]\n--     A list holding the three linearization constraints.\nlocal function linearize(a, b, y)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_232208_linearize.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = linearize\n    lu.assertEquals(candidate('a1', 'b1', 'y1'), {'- y1 + a1 >= 0', '- y1 + b1 >= 0', '- y1 + a1 + b1 <= 1'})\n    lu.assertEquals(candidate('a', 'b', 'y1'), {'- y1 + a >= 0', '- y1 + b >= 0', '- y1 + a + b <= 1'})\n    lu.assertEquals(candidate('1', '2', '3'), {'- 3 + 1 >= 0', '- 3 + 2 >= 0', '- 3 + 1 + 2 <= 1'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_232442_padding", "language": "lua", "prompt": "-- use '0' to padding the sentence\nlocal function padding(sample, seq_max_len)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_232442_padding.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = padding\n    lu.assertEquals(candidate({{1, 2}, {3, 4}, {5}}, 4), {{1, 2, 0, 0}, {3, 4, 0, 0}, {5, 0, 0, 0}})\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}, 5), {{1, 2, 3, 0, 0}, {4, 5, 6, 0, 0}, {7, 8, 9, 0, 0}})\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5}, {6, 7, 8, 9}}, 5), {{1, 2, 3, 0, 0}, {4, 5, 0, 0, 0}, {6, 7, 8, 9, 0}})\n    lu.assertEquals(candidate({{1, 2, 3}, {2, 3}}, 5), {{1, 2, 3, 0, 0}, {2, 3, 0, 0, 0}})\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6, 7}}, 4), {{1, 2, 3, 0}, {4, 5, 6, 7}})\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}}, 5), {{1, 2, 3, 0, 0}, {4, 5, 6, 0, 0}})\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}, {7}}, 5), {{1, 2, 3, 0, 0}, {4, 5, 6, 0, 0}, {7, 0, 0, 0, 0}})\n    lu.assertEquals(candidate({{1, 2}, {3, 4}, {5}}, 5), {{1, 2, 0, 0, 0}, {3, 4, 0, 0, 0}, {5, 0, 0, 0, 0}})\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}}, 4), {{1, 2, 3, 0}, {4, 5, 6, 0}})\n    lu.assertEquals(candidate({{1}, {2, 3}}, 3), {{1, 0, 0}, {2, 3, 0}})\n    lu.assertEquals(candidate({{1, 2, 3}, {2, 3}}, 4), {{1, 2, 3, 0}, {2, 3, 0, 0}})\n    lu.assertEquals(candidate({}, 3), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_233100_coding_problem_22", "language": "lua", "prompt": "-- Given a dictionary of words and a string made up of those words (no spaces), return the original sentence in a\n-- list. If there is more than one possible reconstruction, return any of them. If there is no possible\n-- reconstruction, then return null.\n-- Examples:\n-- >>> coding_problem_22(['Riccardo', 'Brigittie', 'and', 'lollipop'], 'RiccardoandBrigittie')\n-- ['Riccardo', 'and', 'Brigittie']\n-- >>> coding_problem_22(['quick', 'brown', 'the', 'fox'], 'thequickbrownfox')\n-- ['the', 'quick', 'brown', 'fox']\n-- >>> coding_problem_22(['bed', 'bath', 'bedbath', 'and', 'beyond'], 'bedbathandbeyond')\n-- ['bed', 'bath', 'and', 'beyond']\nlocal function coding_problem_22(dictionary, the_string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_233100_coding_problem_22.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = coding_problem_22\n    lu.assertEquals(candidate({'bed', 'bath', 'bedbath', 'and', 'beyond'}, 'bedbathandbeyond'), {'bed', 'bath', 'and', 'beyond'})\n    lu.assertEquals(candidate({'quick', 'brown', 'the', 'fox'}, 'thequickbrownfox'), {'the', 'quick', 'brown', 'fox'})\n    lu.assertEquals(candidate({'Riccardo', 'Brigittie', 'and', 'lollipop'}, 'RiccardoandBrigittie'), {'Riccardo', 'and', 'Brigittie'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_234706_is_valid", "language": "lua", "prompt": "--  Returns True if the number is a sum of two discrete numbers in \n-- the preceding sequence.\nlocal function is_valid(sequence, number)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_234706_is_valid.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_valid\n    lu.assertEquals(candidate(list(range(100)), 200), false)\n    lu.assertEquals(candidate({1}, 1), false)\n    lu.assertEquals(candidate(list(range(10)), 16), true)\n    lu.assertEquals(candidate({}, 10), false)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5}, 6), true)\n    lu.assertEquals(candidate(list(range(10)), 1), true)\n    lu.assertEquals(candidate(list(range(10)), 15), true)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, 12), true)\n    lu.assertEquals(candidate(list(range(10)), 19), false)\n    lu.assertEquals(candidate(list(range(100)), 201), false)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, 16), true)\n    lu.assertEquals(candidate(list(range(10)), 6), true)\n    lu.assertEquals(candidate(list(range(10)), 9), true)\n    lu.assertEquals(candidate(list(range(10)), 4), true)\n    lu.assertEquals(candidate(list(range(100)), 10), true)\n    lu.assertEquals(candidate({1, 2, 3, 4, 5}, 7), true)\n    lu.assertEquals(candidate(list(range(10)), 18), true)\n    lu.assertEquals(candidate(list(range(10)), 21), false)\n    lu.assertEquals(candidate(list(range(10)), 2), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_23499_get_years", "language": "lua", "prompt": "-- Get years contained in a time period.\n-- Returns the list of years contained in between the provided\n-- start time and the stop time.\n-- :param start_time: Start time to determine list of years\n-- :type start_time: str\n-- :param stop_time: Stop time to determine list of years\n-- :type stop_time: str\n-- :return: Creation date\n-- :rtype: list of str\nlocal function get_years(start_time, stop_time)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_23499_get_years.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_years\n    lu.assertEquals(candidate('1968-06-19T13:46:29.000Z', '2007-04-26T20:36:19.000Z'), {'1968', '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977', '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007'})\n    lu.assertEquals(candidate('2017-05-05', '2017-05-15'), {'2017'})\n    lu.assertEquals(candidate('2017-05-05', '2017-05-05'), {'2017'})\n    lu.assertEquals(candidate('2010-09-16T04:04:36.000Z', '2012-04-26T20:36:19.000Z'), {'2010', '2011', '2012'})\n    lu.assertEquals(candidate('2017-05-05', '2016-05-05'), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_235080_gen_color", "language": "lua", "prompt": "-- Generates a red color in 'dot' format, which tone is based in the number of elements of a cluster (more elements, more intense).\n-- @param num_elems: \n-- @param max_elems: \n-- @return: \nlocal function gen_color(num_elems, max_elems)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_235080_gen_color.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = gen_color\n    lu.assertEquals(candidate(3, 5), '0.000 0.600 1.000')\n    lu.assertEquals(candidate(5, 5), '0.000 1.000 1.000')\n    lu.assertEquals(candidate(200, 200), '0.000 1.000 1.000')\n    lu.assertEquals(candidate(0, 100), '0.000 0.000 1.000')\n    lu.assertEquals(candidate(50, 100), '0.000 0.500 1.000')\n    lu.assertEquals(candidate(50, 50), '0.000 1.000 1.000')\n    lu.assertEquals(candidate(1, 10), '0.000 0.100 1.000')\n    lu.assertEquals(candidate(0, 100), '0.000 0.000 1.000')\n    lu.assertEquals(candidate(1, 1), '0.000 1.000 1.000')\n    lu.assertEquals(candidate(0, 10), '0.000 0.000 1.000')\n    lu.assertEquals(candidate(100, 100), '0.000 1.000 1.000')\n    lu.assertEquals(candidate(3, 3), '0.000 1.000 1.000')\n    lu.assertEquals(candidate(0, 5), '0.000 0.000 1.000')\n    lu.assertEquals(candidate(5, 5), '0.000 1.000 1.000')\n    lu.assertEquals(candidate(1, 1), '0.000 1.000 1.000')\n    lu.assertEquals(candidate(0, 1), '0.000 0.000 1.000')\n    lu.assertEquals(candidate(10, 20), '0.000 0.500 1.000')\n    lu.assertEquals(candidate(10, 30), '0.000 0.333 1.000')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_236346__is_compliant_with_reference_json", "language": "lua", "prompt": "-- Validates if a json file contains the same metadata as provided in arguments.\nlocal function _is_compliant_with_reference_json(reference_problem_name, reference_graph_type, reference_p, json)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_236346__is_compliant_with_reference_json.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _is_compliant_with_reference_json\n    lu.assertEquals(candidate('reference_problem_name', 'reference_graph_type', 2, {['problem_name'] = 'reference_problem_name', ['graph_type'] = 'reference_graph_type', ['p'] = 2}), false)\n    lu.assertEquals(candidate('reference_problem_name', 'reference_graph_type', 2, {['problem_name'] = 'reference_problem_name', ['graph_type'] = 'reference_graph_type', ['p'] = 2, ['foo'] = 'bar'}), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_236919_egcd", "language": "lua", "prompt": "-- SRC: https://en.wikibooks.org/wiki/Algorithm_Implementation/Mathematics/Extended_Euclidean_algorithm\n-- return (g, x, y) such that a*x + b*y = g = gcd(a, b)\nlocal function egcd(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_236919_egcd.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = egcd\n    lu.assertEquals(candidate(1, 0), {1, 1, 0})\n    lu.assertEquals(candidate(0, 20), {20, 0, 1})\n    lu.assertEquals(candidate(4, 5), {1, -1, 1})\n    lu.assertEquals(candidate(10, 0), {10, 1, 0})\n    lu.assertEquals(candidate(0, 1), {1, 0, 1})\n    lu.assertEquals(candidate(0, 0), {0, 0, 1})\n    lu.assertEquals(candidate(30, 30), {30, 1, 0})\n    lu.assertEquals(candidate(5, 4), {1, 1, -1})\n    lu.assertEquals(candidate(200, 200), {200, 1, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_237220_setbit", "language": "lua", "prompt": "-- set n-th bit (i.e. set to 1) in an integer or array of integers\n-- Args:\n--     x: integer or :class:`numpy.ndarray` of integers\n--     nth_bit: position of bit to be set (0, 1, 2, ..)\n-- Returns:\n--     integer or array of integers where n-th bit is set while all other bits are kept as in input x\n-- Examples:\n--     >>> setbit(0, 1)\n--         2\n--     >>> setbit(3, 2)\n--         7\nlocal function setbit(x, nth_bit)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_237220_setbit.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = setbit\n    lu.assertEquals(candidate(0, 6), 64)\n    lu.assertEquals(candidate(2, 1), 2)\n    lu.assertEquals(candidate(1, 4), 17)\n    lu.assertEquals(candidate(7, 0), 7)\n    lu.assertEquals(candidate(3, 2), 7)\n    lu.assertEquals(candidate(0, 5), 32)\n    lu.assertEquals(candidate(0, 2), 4)\n    lu.assertEquals(candidate(0, 1), 2)\n    lu.assertEquals(candidate(0, 3), 8)\n    lu.assertEquals(candidate(0, 0), 1)\n    lu.assertEquals(candidate(0, 4), 16)\n    lu.assertEquals(candidate(0, 8), 256)\n    lu.assertEquals(candidate(0, 7), 128)\n    lu.assertEquals(candidate(1, 0), 1)\n    lu.assertEquals(candidate(1, 2), 5)\n    lu.assertEquals(candidate(1, 1), 3)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_237237_fix_indentation", "language": "lua", "prompt": "-- Replace tabs by spaces\nlocal function fix_indentation(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_237237_fix_indentation.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fix_indentation\n    lu.assertEquals(candidate(\"if True:\\n    print('The indentation is wrong!')\"), \"if True:\\n    print('The indentation is wrong!')\")\n    lu.assertEquals(candidate('\\nif x:\\n    return 0\\nelse:\\n    return 1\\n'), '\\nif x:\\n    return 0\\nelse:\\n    return 1\\n')\n    lu.assertEquals(candidate('\\ndef func():\\n    if x:\\n        return 0\\n    else:\\n        return 1\\n'), '\\ndef func():\\n    if x:\\n        return 0\\n    else:\\n        return 1\\n')\n    lu.assertEquals(candidate('\\nif x:\\n    return 0\\nelif y:\\n    return 1\\nelse:\\n    return 2\\n'), '\\nif x:\\n    return 0\\nelif y:\\n    return 1\\nelse:\\n    return 2\\n')\n    lu.assertEquals(candidate('\\ndef func():\\n    if x:\\n        return 0\\n    elif y:\\n        return 1\\n    elif z:\\n        return 2\\n    else:\\n        return 3\\n'), '\\ndef func():\\n    if x:\\n        return 0\\n    elif y:\\n        return 1\\n    elif z:\\n        return 2\\n    else:\\n        return 3\\n')\n    lu.assertEquals(candidate('    I am indented by four spaces, or four tabs.'), '    I am indented by four spaces, or four tabs.')\n    lu.assertEquals(candidate(\"if True:\\n\\tprint('The indentation is wrong!')\"), \"if True:\\n    print('The indentation is wrong!')\")\n    lu.assertEquals(candidate('\\ndef func():\\n    if x:\\n        return 0\\n    elif y:\\n        return 1\\n    else:\\n        return 2\\n'), '\\ndef func():\\n    if x:\\n        return 0\\n    elif y:\\n        return 1\\n    else:\\n        return 2\\n')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_237242_normalize_archive_entry_name", "language": "lua", "prompt": "-- Get the normalized name of an archive file entry.\n-- Args:\n--     name (str): Name of the archive file entry.\n-- Returns:\n--     str: The normalized name.\nlocal function normalize_archive_entry_name(name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_237242_normalize_archive_entry_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = normalize_archive_entry_name\n    lu.assertEquals(candidate('foo/bar/'), 'foo/bar/')\n    lu.assertEquals(candidate('foo\\\\bar'), 'foo/bar')\n    lu.assertEquals(candidate('..'), '..')\n    lu.assertEquals(candidate('a/b'), 'a/b')\n    lu.assertEquals(candidate('../'), '../')\n    lu.assertEquals(candidate('.'), '.')\n    lu.assertEquals(candidate('a'), 'a')\n    lu.assertEquals(candidate('foo/bar'), 'foo/bar')\n    lu.assertEquals(candidate('foo\\\\bar\\\\baz'), 'foo/bar/baz')\n    lu.assertEquals(candidate('/'), '/')\n    lu.assertEquals(candidate('a/b/'), 'a/b/')\n    lu.assertEquals(candidate('./'), './')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('a/'), 'a/')\n    lu.assertEquals(candidate('foo'), 'foo')\n    lu.assertEquals(candidate('/a/'), '/a/')\n    lu.assertEquals(candidate('/a'), '/a')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_237520_extended_gcd", "language": "lua", "prompt": "-- Returns a tuple (r, i, j) such that r = gcd(a, b) = ia + jb\nlocal function extended_gcd(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_237520_extended_gcd.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = extended_gcd\n    lu.assertEquals(candidate(12, 12), {12, 0, 1})\n    lu.assertEquals(candidate(1, 12), {1, 1, 0})\n    lu.assertEquals(candidate(100, 100), {100, 0, 1})\n    lu.assertEquals(candidate(12, 1), {1, 0, 1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_238527_get_cluster", "language": "lua", "prompt": "-- get the real starting cluster\nlocal function get_cluster(startclust, offset)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_238527_get_cluster.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_cluster\n    lu.assertEquals(candidate(0, 2), 0)\n    lu.assertEquals(candidate(181, 1), 2)\n    lu.assertEquals(candidate(180, 1), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_238578_get_library_name", "language": "lua", "prompt": "--     Utility to split between the library name and version number when needed\nlocal function get_library_name(library_name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_238578_get_library_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_library_name\n    lu.assertEquals(candidate('django == 2.2.2'), 'django')\n    lu.assertEquals(candidate('Django >= 1.11'), 'Django')\n    lu.assertEquals(candidate('django'), 'django')\n    lu.assertEquals(candidate('os!=1.0'), 'os')\n    lu.assertEquals(candidate('os'), 'os')\n    lu.assertEquals(candidate('django ==1.11.6,>=1.8,>=1.4,<1.9'), 'django')\n    lu.assertEquals(candidate('django.utils'), 'django.utils')\n    lu.assertEquals(candidate('django ~=1.11,!=1.11.6,>=1.8,>=1.4,<1.9'), 'django')\n    lu.assertEquals(candidate('django'), 'django')\n    lu.assertEquals(candidate('django!=1.11,!=1.11.6'), 'django')\n    lu.assertEquals(candidate('django ==1.11.6,==1.11'), 'django')\n    lu.assertEquals(candidate('Django == 1.2.3,!=1.3.4.5, >=2.3.4'), 'Django')\n    lu.assertEquals(candidate('os==1.0!=1.0'), 'os')\n    lu.assertEquals(candidate('django.utils.log'), 'django.utils.log')\n    lu.assertEquals(candidate('django.utils.log.AdminEmailHandler'), 'django.utils.log.AdminEmailHandler')\n    lu.assertEquals(candidate('Django >= 1.11, == 2.3.4'), 'Django')\n    lu.assertEquals(candidate('Django == 2.2.2'), 'Django')\n    lu.assertEquals(candidate('os==1.0'), 'os')\n    lu.assertEquals(candidate('django!=1.11,!=1.11.6,>=1.8,>=1.4,<1.9'), 'django')\n    lu.assertEquals(candidate('os==1.0!=1.0>0.0'), 'os')\n    lu.assertEquals(candidate('os~=1.0'), 'os')\n    lu.assertEquals(candidate('django ==1.11.6'), 'django')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_239032_remove_path_segments", "language": "lua", "prompt": "-- Removes the path segments of <remove> from the end of the path\n-- segments <segments>.\n-- Examples:\n--   # ('/a/b/c', 'b/c') -> '/a/'\n--   remove_path_segments(['','a','b','c'], ['b','c']) == ['','a','']\n--   # ('/a/b/c', '/b/c') -> '/a'\n--   remove_path_segments(['','a','b','c'], ['','b','c']) == ['','a']\n-- Returns: The list of all remaining path segments after the segments\n-- in <remove> have been removed from the end of <segments>. If no\n-- segments from <remove> were removed from <segments>, <segments> is\n-- returned unmodified.\nlocal function remove_path_segments(segments, remove)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_239032_remove_path_segments.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_path_segments\n    lu.assertEquals(candidate({'', 'a'}, {'', 'a', 'b'}), {'', 'a'})\n    lu.assertEquals(candidate({'', 'a'}, {'', 'a'}), {})\n    lu.assertEquals(candidate({'', 'a'}, {'', 'b', 'c', 'd', 'e'}), {'', 'a'})\n    lu.assertEquals(candidate({'', 'a', 'b', 'c'}, {'', 'b', 'c'}), {'', 'a'})\n    lu.assertEquals(candidate({'', 'a'}, {'', 'b', 'a', 'c'}), {'', 'a'})\n    lu.assertEquals(candidate({'', 'a'}, {'', 'b', 'c'}), {'', 'a'})\n    lu.assertEquals(candidate({''}, {''}), {})\n    lu.assertEquals(candidate({'', 'a', 'b', 'c'}, {'a', 'b', 'd'}), {'', 'a', 'b', 'c'})\n    lu.assertEquals(candidate({'', 'a', 'b', 'c', 'd'}, {'', 'b', 'c', 'd'}), {'', 'a'})\n    lu.assertEquals(candidate({'', 'a'}, {'', 'b', 'c', 'a'}), {'', 'a'})\n    lu.assertEquals(candidate({'', 'a', 'b', 'c'}, {'b', 'c'}), {'', 'a', ''})\n    lu.assertEquals(candidate({'', 'a', 'b', 'c'}, {'', 'b', 'c'}), {'', 'a'})\n    lu.assertEquals(candidate({'', 'a'}, {'', 'b', 'a'}), {'', 'a'})\n    lu.assertEquals(candidate({'', 'a'}, {}), {'', 'a'})\n    lu.assertEquals(candidate({'', 'a', 'b', 'c'}, {'c', 'd'}), {'', 'a', 'b', 'c'})\n    lu.assertEquals(candidate({'', 'a', 'b', 'c'}, {'b', 'd'}), {'', 'a', 'b', 'c'})\n    lu.assertEquals(candidate({'', 'a'}, {'', 'b', 'c', 'd'}), {'', 'a'})\n    lu.assertEquals(candidate({'', 'a', 'b', 'c'}, {'b', 'c'}), {'', 'a', ''})\n    lu.assertEquals(candidate({'', 'a'}, {''}), {'', 'a'})\n    lu.assertEquals(candidate({'', 'a'}, {'', 'b'}), {'', 'a'})\n    lu.assertEquals(candidate({'', 'a'}, {'', 'a', 'b', 'c'}), {'', 'a'})\n    lu.assertEquals(candidate({'', 'a', 'b', 'c'}, {'d'}), {'', 'a', 'b', 'c'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_23945_pre_text", "language": "lua", "prompt": "--     Encapsulate a string inside a Markdown <pre> container\nlocal function pre_text(string, lang)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_23945_pre_text.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = pre_text\n    lu.assertEquals(candidate('test\\ntest', 'cpp'), '```cpp\\ntest\\ntest```')\n    lu.assertEquals(candidate('test', 'java'), '```java\\ntest```')\n    lu.assertEquals(candidate('test', 'cpp'), '```cpp\\ntest```')\n    lu.assertEquals(candidate('test'), '```test```')\n    lu.assertEquals(candidate('test\\ntest'), '```test\\ntest```')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_239754__extract_language", "language": "lua", "prompt": "-- Extracts language from locale string.\n-- :param locale_string: Something like language_COUNTRY.encoding\n-- :return: language\nlocal function _extract_language(locale_string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_239754__extract_language.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _extract_language\n    lu.assertEquals(candidate('en_GB'), 'en')\n    lu.assertEquals(candidate('sr_RS@latin'), 'sr')\n    lu.assertEquals(candidate('sr_RS@cyrillic'), 'sr')\n    lu.assertEquals(candidate('sr_ME'), 'sr')\n    lu.assertEquals(candidate('fr_FR'), 'fr')\n    lu.assertEquals(candidate('sr_RS'), 'sr')\n    lu.assertEquals(candidate('fr_CA'), 'fr')\n    lu.assertEquals(candidate('en_US'), 'en')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_23979_hash_to_dir", "language": "lua", "prompt": "-- Transforms a given hash to a relative path and filename\n-- ex: '002badb952000339cdcf1b61a3205b221766bf49' ->\n--     '00/2badb952000339cdcf1b61a3205b221766bf49'\n-- :param hash: the hash to split\n-- :rtype: string\nlocal function hash_to_dir(hash)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_23979_hash_to_dir.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = hash_to_dir\n    lu.assertEquals(candidate('00'), '00/')\n    lu.assertEquals(candidate('006061c77988c862085fc6c29c5357e3810822d3'), '00/6061c77988c862085fc6c29c5357e3810822d3')\n    lu.assertEquals(candidate('007a90c0e00899f0596419a627d76f4256705188'), '00/7a90c0e00899f0596419a627d76f4256705188')\n    lu.assertEquals(candidate('002badb952000339cdcf1b61a3205b221766bf49'), '00/2badb952000339cdcf1b61a3205b221766bf49')\n    lu.assertEquals(candidate('0'), '0/')\n    lu.assertEquals(candidate('002badb952000339cdcf1b61a3205b221766bf49'), '00/2badb952000339cdcf1b61a3205b221766bf49')\n    lu.assertEquals(candidate('001426260e00059b5e5a401954d6071f19c74031'), '00/1426260e00059b5e5a401954d6071f19c74031')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_239937_convert2relative", "language": "lua", "prompt": "--     YOLO format use relative coordinates for annotation\nlocal function convert2relative(bbox, darknet_height, darknet_width)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_239937_convert2relative.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = convert2relative\n    lu.assertEquals(candidate({0, 0, 10, 10}, 10, 10), {0, 0, 1, 1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_240045_caterpillar_sub_sequence", "language": "lua", "prompt": "-- Generate the steps for a given frame.\nlocal function caterpillar_sub_sequence(frame, new, cat_length)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_240045_caterpillar_sub_sequence.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = caterpillar_sub_sequence\n    lu.assertEquals(candidate({0, 0, 0, 0, 0, 0, 0}, 0, 5), {{0, 0, 0, 0, 0, 0, 0}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_240081_compose_username", "language": "lua", "prompt": "-- @brief Compose the username\n-- The username policy via openid is as follow:\n-- * Try to use the nick name\n-- * If not available fall back to email\n-- * Append the the openid provider as domain. Delimiter is % in order to \n--   diferentiate from @ (if email is used)\n-- @param nick The nick name or None\n-- @param email The email or None\n-- @param provider the Authentication provider\n-- @return Non in case no user name was derived, otherwise the username\nlocal function compose_username(nick, email, provider)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_240081_compose_username.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = compose_username\n    lu.assertEquals(candidate(), '<EMAIL>%provider')\n    lu.assertEquals(candidate(None, '<EMAIL>', 'google'), '<EMAIL>%google')\n    lu.assertEquals(candidate('Peter', None, 'yahoo'), 'Peter%yahoo')\n    lu.assertEquals(candidate(), 'Nick%provider')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_241238_concatixnames", "language": "lua", "prompt": "--     Args:\n-- ixname (str): 'ix'\n-- source_suffix (str): 'left'\n-- target_suffix (str): 'right'\n--     Returns:\n-- str, str, list(): 'ix_source', 'ix_target', ['ix_source', 'ix_target']\nlocal function concatixnames(ixname, source_suffix, target_suffix)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_241238_concatixnames.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = concatixnames\n    lu.assertEquals(candidate('ix', 'source', 'target'), {'ix_source', 'ix_target', {'ix_source', 'ix_target'}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_24135_temp_commentary", "language": "lua", "prompt": "-- Gives temperature advice to the end user.\nlocal function temp_commentary(current_temp)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_24135_temp_commentary.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = temp_commentary\n    lu.assertEquals(candidate(5), \"It's Freezing Cold. Staying inside and a cup of Hot chocolate would be nice!\")\n    lu.assertEquals(candidate(55), \"It's cold right now. Make sure you keep yourself warm!\")\n    lu.assertEquals(candidate(40), \"It's cold right now. Make sure you keep yourself warm!\")\n    lu.assertEquals(candidate(85), \"It's hot and sunny right now. Don't forget that sunscreen!\")\n    lu.assertEquals(candidate(69), \"It's nice and warm right now. Time to flex those flip-flops!\")\n    lu.assertEquals(candidate(25), \"Brrrrrrr!!! Remember to wear your protective gear so you don't freeze!\")\n    lu.assertEquals(candidate(75), \"It's nice and warm right now. Time to flex those flip-flops!\")\n    lu.assertEquals(candidate(59), \"It's nice and cool right now. Go play outside in this great weather!\")\n    lu.assertEquals(candidate(95), \"It's scorching hot right now. Stay inside and be cool!\")\n    lu.assertEquals(candidate(100), \"It's scorching hot right now. Stay inside and be cool!\")\n    lu.assertEquals(candidate(-15), \"It's Freezing Cold. Staying inside and a cup of Hot chocolate would be nice!\")\n    lu.assertEquals(candidate(65), \"It's nice and cool right now. Go play outside in this great weather!\")\n    lu.assertEquals(candidate(6), \"It's Freezing Cold. Staying inside and a cup of Hot chocolate would be nice!\")\n    lu.assertEquals(candidate(80), \"It's hot and sunny right now. Don't forget that sunscreen!\")\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_241380_sum_digits", "language": "lua", "prompt": "-- Sum all the digits of n.\n-- >>> sum_digits(10) # 1 + 0 = 1\n-- 1\n-- >>> sum_digits(4224) # 4 + 2 + 2 + 4 = 12\n-- 12\n-- >>> sum_digits(1234567890)\n-- 45\n-- >>> x = sum_digits(123) # make sure that you are using return rather than print\n-- >>> x\n-- 6\nlocal function sum_digits(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_241380_sum_digits.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sum_digits\n    lu.assertEquals(candidate(4224), 12)\n    lu.assertEquals(candidate(42), 6)\n    lu.assertEquals(candidate(123), 6)\n    lu.assertEquals(candidate(10), 1)\n    lu.assertEquals(candidate(1234567890), 45)\n    lu.assertEquals(candidate(1000), 1)\n    lu.assertEquals(candidate(10000), 1)\n    lu.assertEquals(candidate(10000000), 1)\n    lu.assertEquals(candidate(123456789), 45)\n    lu.assertEquals(candidate(0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_241518_str_tags_to_list", "language": "lua", "prompt": "-- Convert string of comma separated tags to list, stripped of empty tags and whitespace.\nlocal function str_tags_to_list(tags)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_241518_str_tags_to_list.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = str_tags_to_list\n    lu.assertEquals(candidate('  hello ,   world   '), {'hello', 'world'})\n    lu.assertEquals(candidate('hello, world'), {'hello', 'world'})\n    lu.assertEquals(candidate(',hello,,, world'), {'hello', 'world'})\n    lu.assertEquals(candidate('hello'), {'hello'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_241903_datenum", "language": "lua", "prompt": "-- Return a date category with format\nlocal function datenum(name, format)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_241903_datenum.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = datenum\n    lu.assertEquals(candidate('date', \"'%Y-%m-%d'\"), \"candidate(date,'%Y-%m-%d')\")\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_242285_str_width", "language": "lua", "prompt": "-- calc string width, support cjk characters.\nlocal function str_width(unicode_text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_242285_str_width.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = str_width\n    lu.assertEquals(candidate('      '), 6)\n    lu.assertEquals(candidate('abc     '), 8)\n    lu.assertEquals(candidate('abc    '), 7)\n    lu.assertEquals(candidate('A\\u2000B'), 3)\n    lu.assertEquals(candidate('1234567890'), 10)\n    lu.assertEquals(candidate('abc  '), 5)\n    lu.assertEquals(candidate('hello\\nworld'), 11)\n    lu.assertEquals(candidate('       '), 7)\n    lu.assertEquals(candidate('abc '), 4)\n    lu.assertEquals(candidate('ABC'), 3)\n    lu.assertEquals(candidate('   '), 3)\n    lu.assertEquals(candidate('abcdef'), 6)\n    lu.assertEquals(candidate('A\u0301B'), 3)\n    lu.assertEquals(candidate('abc'), 3)\n    lu.assertEquals(candidate('  '), 2)\n    lu.assertEquals(candidate('\uff41\uff42\uff43'), 6)\n    lu.assertEquals(candidate('hello world'), 11)\n    lu.assertEquals(candidate('\uff21\uff22\uff23'), 6)\n    lu.assertEquals(candidate('abc       '), 10)\n    lu.assertEquals(candidate('abcdefg'), 7)\n    lu.assertEquals(candidate(' '), 1)\n    lu.assertEquals(candidate('abc   '), 6)\n    lu.assertEquals(candidate('hello\\tworld'), 11)\n    lu.assertEquals(candidate('\uff71\uff71\uff71\uff71'), 4)\n    lu.assertEquals(candidate('abc      '), 9)\n    lu.assertEquals(candidate('abcde'), 5)\n    lu.assertEquals(candidate('\uff71\uff71'), 2)\n    lu.assertEquals(candidate('\uff71\uff71\uff71'), 3)\n    lu.assertEquals(candidate('        '), 8)\n    lu.assertEquals(candidate('     '), 5)\n    lu.assertEquals(candidate('    '), 4)\n    lu.assertEquals(candidate('abc        '), 11)\n    lu.assertEquals(candidate('A'), 1)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('\uff71'), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_242482_get_interval_unit", "language": "lua", "prompt": "-- Get interval unit.\n-- :param interval:\n-- :return:\nlocal function get_interval_unit(interval)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_242482_get_interval_unit.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_interval_unit\n    lu.assertEquals(candidate(1000), 'seconds')\n    lu.assertEquals(candidate(-1.5), 'seconds')\n    lu.assertEquals(candidate(10), 'seconds')\n    lu.assertEquals(candidate(59), 'seconds')\n    lu.assertEquals(candidate(0.5), 'seconds')\n    lu.assertEquals(candidate(3), 'seconds')\n    lu.assertEquals(candidate(1), 'seconds')\n    lu.assertEquals(candidate(-0.5), 'seconds')\n    lu.assertEquals(candidate(61), 'seconds')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_242504_LJ", "language": "lua", "prompt": "--  Lennard-Jones potential \nlocal function LJ(v, epsilon, sigma)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_242504_LJ.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = LJ\n    lu.assertEquals(candidate(20, 0, 2), 0)\n    lu.assertEquals(candidate(20, 0, 1), 0)\n    lu.assertEquals(candidate(20, 0, 0), 0)\n    lu.assertEquals(candidate(1, 1, 1), 0)\n    lu.assertEquals(candidate(20, 1, 0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_243078_check_origin", "language": "lua", "prompt": "--  Sorting function for origin \nlocal function check_origin(origin)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_243078_check_origin.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = check_origin\n    lu.assertEquals(candidate({'XY', 'Y'}), None)\n    lu.assertEquals(candidate({'X', 'X'}), 'X')\n    lu.assertEquals(candidate({'X', 'X'}), 'X')\n    lu.assertEquals(candidate({'XY', ''}), None)\n    lu.assertEquals(candidate({'Y', 'XY'}), None)\n    lu.assertEquals(candidate({'', 'XX'}), None)\n    lu.assertEquals(candidate({'XY', 'XY'}), None)\n    lu.assertEquals(candidate({'XX', ''}), None)\n    lu.assertEquals(candidate({'Y', 'Y'}), 'Y')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_243138_prepend_slash", "language": "lua", "prompt": "-- Prepend a slash to a URL fragment, checking if it already has one.\nlocal function prepend_slash(url, prepend)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_243138_prepend_slash.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = prepend_slash\n    lu.assertEquals(candidate('https://example.com', false), 'https://example.com')\n    lu.assertEquals(candidate('https://example.com', true), '/https://example.com')\n    lu.assertEquals(candidate('/https://example.com/', true), '/https://example.com/')\n    lu.assertEquals(candidate('https://example.com/', true), '/https://example.com/')\n    lu.assertEquals(candidate('https://example.com/', false), 'https://example.com/')\n    lu.assertEquals(candidate('/https://example.com', true), '/https://example.com')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_243650__nf", "language": "lua", "prompt": "-- None Filter\nlocal function _nf(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_243650__nf.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _nf\n    lu.assertEquals(candidate('foo'), 'foo')\n    lu.assertEquals(candidate('Hello World!'), 'Hello World!')\n    lu.assertEquals(candidate('test'), 'test')\n    lu.assertEquals(candidate('None'), None)\n    lu.assertEquals(candidate(None), None)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_24406_rearange_base_link_list", "language": "lua", "prompt": "-- Rarange base link to beginning of table\nlocal function rearange_base_link_list(table, base_link_index)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_24406_rearange_base_link_list.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rearange_base_link_list\n    lu.assertEquals(candidate({1}, 0), {1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_244262_get_shard_range", "language": "lua", "prompt": "-- In case dataset_size is not evenly divided by world_size, we need to pad\n-- one extra example in each shard\n-- shard_len = dataset_size // world_size + 1\n-- Case 1 rank < remainder: each shard start position is rank * shard_len\n-- Case 2 rank >= remainder: without padding, each shard start position is\n-- rank * (shard_len - 1) + remainder = rank * shard_len - (rank - remainder)\n-- But to make sure all shard have same size, we need to pad one extra example\n-- when rank >= remainder, so start_position = start_position - 1\n-- For example, dataset_size = 21, world_size = 8\n-- rank 0 to 4: [0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]\n-- rank 5 to 7: [14, 15, 16], [16, 17, 18], [18, 19, 20]\nlocal function get_shard_range(dataset_size, rank, world_size)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_244262_get_shard_range.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_shard_range\n    lu.assertEquals(candidate(10, 0, 3), {0, 3})\n    lu.assertEquals(candidate(11, 1, 3), {4, 7})\n    lu.assertEquals(candidate(3, 0, 2), {0, 1})\n    lu.assertEquals(candidate(3, 1, 2), {1, 2})\n    lu.assertEquals(candidate(11, 0, 4), {0, 2})\n    lu.assertEquals(candidate(11, 2, 3), {7, 10})\n    lu.assertEquals(candidate(4, 1, 2), {2, 3})\n    lu.assertEquals(candidate(10, 0, 1), {0, 9})\n    lu.assertEquals(candidate(7, 0, 3), {0, 2})\n    lu.assertEquals(candidate(10, 0, 4), {0, 2})\n    lu.assertEquals(candidate(3, 0, 1), {0, 2})\n    lu.assertEquals(candidate(4, 0, 1), {0, 3})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_244748_get_3x3_translation", "language": "lua", "prompt": "-- return a matrix 3x3 for translation\nlocal function get_3x3_translation(x, y, z)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_244748_get_3x3_translation.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_3x3_translation\n    lu.assertEquals(candidate(2, 3, 4), {{2, 0, 0}, {0, 3, 0}, {0, 0, 4}})\n    lu.assertEquals(candidate(1, 2, 3), {{1, 0, 0}, {0, 2, 0}, {0, 0, 3}})\n    lu.assertEquals(candidate(1, 1, 1), {{1, 0, 0}, {0, 1, 0}, {0, 0, 1}})\n    lu.assertEquals(candidate(1, 2, 3), candidate(1, 2, 3))\n    lu.assertEquals(candidate(3, 1, 2), {{3, 0, 0}, {0, 1, 0}, {0, 0, 2}})\n    lu.assertEquals(candidate(1, 2, 3), {{1, 0, 0}, {0, 2, 0}, {0, 0, 3}})\n    lu.assertEquals(candidate(0, 0, 0), {{0, 0, 0}, {0, 0, 0}, {0, 0, 0}})\n    lu.assertEquals(candidate(4, 4, 4), {{4, 0, 0}, {0, 4, 0}, {0, 0, 4}})\n    lu.assertEquals(candidate(-3, -2, -1), {{-3, 0, 0}, {0, -2, 0}, {0, 0, -1}})\n    lu.assertEquals(candidate(-3, -6, -9), {{-3, 0, 0}, {0, -6, 0}, {0, 0, -9}})\n    lu.assertEquals(candidate(1, 2, 3), {{1, 0, 0}, {0, 2, 0}, {0, 0, 3}})\n    lu.assertEquals(candidate(0, 0, 0), {{0, 0, 0}, {0, 0, 0}, {0, 0, 0}})\n    lu.assertEquals(candidate(3, 2, 1), {{3, 0, 0}, {0, 2, 0}, {0, 0, 1}})\n    lu.assertEquals(candidate(-1, 3, 1), {{-1, 0, 0}, {0, 3, 0}, {0, 0, 1}})\n    lu.assertEquals(candidate(5, 10, 15), {{5, 0, 0}, {0, 10, 0}, {0, 0, 15}})\n    lu.assertEquals(candidate(3, -1, 2), {{3, 0, 0}, {0, -1, 0}, {0, 0, 2}})\n    lu.assertEquals(candidate(-2, -3, -4), {{-2, 0, 0}, {0, -3, 0}, {0, 0, -4}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_245061_decode_bert", "language": "lua", "prompt": "-- Decodes text that uses https://github.com/google/sentencepiece encoding.\n-- Assumes that pieces are separated by a space\nlocal function decode_bert(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_245061_decode_bert.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = decode_bert\n    lu.assertEquals(candidate('A long time ago in a galaxy far, far away'), 'A long time ago in a galaxy far, far away')\n    lu.assertEquals(candidate('I like cats and ## dogs '), 'I like cats and dogs')\n    lu.assertEquals(candidate('I like to go to the mall'), 'I like to go to the mall')\n    lu.assertEquals(candidate('long time ago in a galaxy far, far away'), 'long time ago in a galaxy far, far away')\n    lu.assertEquals(candidate('this is a test'), 'this is a test')\n    lu.assertEquals(candidate('I like to go to the m all'), 'I like to go to the m all')\n    lu.assertEquals(candidate('I like cats and dogs '), 'I like cats and dogs')\n    lu.assertEquals(candidate('I like cats and ## dogs'), 'I like cats and dogs')\n    lu.assertEquals(candidate('long time ago in a galaxy far ##, far away'), 'long time ago in a galaxy far, far away')\n    lu.assertEquals(candidate('I like cats and dogs  '), 'I like cats and dogs')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_245144_get_dist_sq", "language": "lua", "prompt": "-- returns the distance squared between two points. Faster than the true euclidean dist\nlocal function get_dist_sq(point_a, point_b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_245144_get_dist_sq.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_dist_sq\n    lu.assertEquals(candidate({0, 0}, {0, 0}), 0)\n    lu.assertEquals(candidate({0, 0}, {3, 4}), 25)\n    lu.assertEquals(candidate({1, 1}, {1, 1}), 0)\n    lu.assertEquals(candidate(), 1)\n    lu.assertEquals(candidate({0, 0}, {0, 0}), 0)\n    lu.assertEquals(candidate({-3, -4}, {-3, -4}), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_246231_parse_env", "language": "lua", "prompt": "-- Convert list of strings into dict object.\n-- Docker Inspect ENV is a list of strings. Env strings are\n-- in the form of KEY=VALUE. Split strings into key=value pairs\n-- and return dict object. Only return keys with \"good_stuff\".\nlocal function parse_env(Env)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_246231_parse_env.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_env\n    lu.assertEquals(candidate({'USER=db_user', 'PASS=<PASSWORD>', 'EXTRA=1'}), {['USER'] = 'db_user', ['PASS'] = '<PASSWORD>'})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({'USER=db_user', 'PASS=<PASSWORD>', '_DB=db_name', 'EXTRA=1'}), {['USER'] = 'db_user', ['PASS'] = '<PASSWORD>', ['_DB'] = 'db_name'})\n    lu.assertEquals(candidate({'_DB=foo', 'USER=bar'}), {['_DB'] = 'foo', ['USER'] = 'bar'})\n    lu.assertEquals(candidate({'USER=foo', '_DB=bar'}), {['USER'] = 'foo', ['_DB'] = 'bar'})\n    lu.assertEquals(candidate({'USER=foo', 'PASS=<PASSWORD>', 'BAD_THING=bar'}), {['USER'] = 'foo', ['PASS'] = '<PASSWORD>'})\n    lu.assertEquals(candidate({'USER=foo', 'USER=bar'}), {['USER'] = 'bar'})\n    lu.assertEquals(candidate({'USER=db_user', 'PASS=<PASSWORD>', '_DB=db_name'}), {['USER'] = 'db_user', ['PASS'] = '<PASSWORD>', ['_DB'] = 'db_name'})\n    lu.assertEquals(candidate({'USER=foo', 'PASS=<PASSWORD>', '_DB=bar'}), {['USER'] = 'foo', ['PASS'] = '<PASSWORD>', ['_DB'] = 'bar'})\n    lu.assertEquals(candidate({'USER=foo', 'PASS=bar', '_DB=baz', 'USER=foo', 'PASS=bar', '_DB=baz'}), {['USER'] = 'foo', ['PASS'] = 'bar', ['_DB'] = 'baz'})\n    lu.assertEquals(candidate({'USER=foo', 'PASS=<PASSWORD>'}), {['USER'] = 'foo', ['PASS'] = '<PASSWORD>'})\n    lu.assertEquals(candidate({'USER=foo', 'PASS=bar', '_DB=baz'}), {['USER'] = 'foo', ['PASS'] = 'bar', ['_DB'] = 'baz'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_246717_version_get", "language": "lua", "prompt": "-- Check if version v1 is great or equal then version v2.\nlocal function version_get(v1, v2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_246717_version_get.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = version_get\n    lu.assertEquals(candidate('1.2.3.3', '1.2.3.4'), false)\n    lu.assertEquals(candidate('1.2.3a', '1.2.3'), false)\n    lu.assertEquals(candidate('1.1.0', '1.1.1'), false)\n    lu.assertEquals(candidate('1.1.3', '1.2'), false)\n    lu.assertEquals(candidate('1.2.3a', '1.2.3b'), false)\n    lu.assertEquals(candidate('1.2', '1.2.4'), false)\n    lu.assertEquals(candidate('1', '1.2'), false)\n    lu.assertEquals(candidate('1', '1.1.0'), false)\n    lu.assertEquals(candidate('1.2.4', '1.2.3'), true)\n    lu.assertEquals(candidate('1.1.1', '1.1.2'), false)\n    lu.assertEquals(candidate('1.1.1.0', '1.1.1.1'), false)\n    lu.assertEquals(candidate('1.2.3', '1.3.0'), false)\n    lu.assertEquals(candidate('1.2.3', '1.2.4'), false)\n    lu.assertEquals(candidate('1.1', '1.2'), false)\n    lu.assertEquals(candidate('1.2.2', '1.2'), true)\n    lu.assertEquals(candidate('1', '1.1.1'), false)\n    lu.assertEquals(candidate('1.1.1', '1.2.1'), false)\n    lu.assertEquals(candidate('1', '1.1'), false)\n    lu.assertEquals(candidate('1.1.0', '1.2.0'), false)\n    lu.assertEquals(candidate('1.2.3', '1.2'), true)\n    lu.assertEquals(candidate('1', '2.1.0'), false)\n    lu.assertEquals(candidate('1.1.1', '1.1.0'), true)\n    lu.assertEquals(candidate('1.2.3', '1.2.4'), false)\n    lu.assertEquals(candidate('1.3.0', '1.2.4'), true)\n    lu.assertEquals(candidate('1.2.3b', '1.2.3a'), false)\n    lu.assertEquals(candidate('1', '1.0'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_247246_is_prefix", "language": "lua", "prompt": "-- Return True if pre_path is a path-prefix of path.\nlocal function is_prefix(pre_path, path)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_247246_is_prefix.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_prefix\n    lu.assertEquals(candidate('', ''), true)\n    lu.assertEquals(candidate('', 'foo'), true)\n    lu.assertEquals(candidate('foo', ''), false)\n    lu.assertEquals(candidate('a.b.c', 'a.b.c.d.e'), true)\n    lu.assertEquals(candidate('foo.bar', 'foo'), false)\n    lu.assertEquals(candidate('', 'foo.bar'), true)\n    lu.assertEquals(candidate('a.b.c.d', 'a.b.c.d.e'), true)\n    lu.assertEquals(candidate('', 'a.b.c.d.e'), true)\n    lu.assertEquals(candidate('a', 'a.b.c.d.e'), true)\n    lu.assertEquals(candidate('foo.bar', 'baz.foo.bar'), false)\n    lu.assertEquals(candidate('foo.bar', ''), false)\n    lu.assertEquals(candidate('foo.bar', 'foo.bar.baz'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_247808_get_next_coin", "language": "lua", "prompt": "-- Return the next coin. \n-- >>> get_next_coin(1)\n-- 5\n-- >>> get_next_coin(5)\n-- 10\n-- >>> get_next_coin(10)\n-- 25\n-- >>> get_next_coin(2) # Other values return None\nlocal function get_next_coin(coin)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_247808_get_next_coin.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_next_coin\n    lu.assertEquals(candidate(17), None)\n    lu.assertEquals(candidate(3), None)\n    lu.assertEquals(candidate(10), 25)\n    lu.assertEquals(candidate(1), 5)\n    lu.assertEquals(candidate(117), None)\n    lu.assertEquals(candidate(2), None)\n    lu.assertEquals(candidate(5), 10)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_247936__full_license", "language": "lua", "prompt": "-- Get the full license from the image info\n-- :param image_info: the information about a particular image\n-- :return: the full license text for the image\nlocal function _full_license(image_info)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_247936__full_license.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _full_license\n    lu.assertEquals(candidate({['license'] = 'CC0', ['license_version'] = '1.0'}), 'CC0 1.0')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_24798_p_a2", "language": "lua", "prompt": "-- Probability of selecting one input given ninputs and npsyns attempts. This\n-- uses a binomial distribution.\n-- @param npsyns: The number of proximal synapses.\n-- @param ninputs: The number of inputs.\n-- @return: The computed probability.\nlocal function p_a2(npsyns, ninputs)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_24798_p_a2.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = p_a2\n    lu.assertEquals(candidate(1, 1), 1.0)\n    lu.assertEquals(candidate(1, 4), 0.25)\n    lu.assertEquals(candidate(1, 2), 0.5)\n    lu.assertEquals(candidate(1, 1), 1.0)\n    lu.assertEquals(candidate(1, 3), 0.3333333333333333)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_248015_irshift", "language": "lua", "prompt": "-- Same as a >>= b.\nlocal function irshift(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_248015_irshift.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = irshift\n    lu.assertEquals(candidate(1, 3), 0)\n    lu.assertEquals(candidate(-1, 8), -1)\n    lu.assertEquals(candidate(2, 8), 0)\n    lu.assertEquals(candidate(0, 2), 0)\n    lu.assertEquals(candidate(10, 5), 0)\n    lu.assertEquals(candidate(3, 3), 0)\n    lu.assertEquals(candidate(-1, 1), -1)\n    lu.assertEquals(candidate(-1, 9), -1)\n    lu.assertEquals(candidate(2, 0), 2)\n    lu.assertEquals(candidate(10, 7), 0)\n    lu.assertEquals(candidate(0, 1), 0)\n    lu.assertEquals(candidate(1, 5), 0)\n    lu.assertEquals(candidate(2, 3), 0)\n    lu.assertEquals(candidate(-1, 23), -1)\n    lu.assertEquals(candidate(-2, 1), -1)\n    lu.assertEquals(candidate(-1, 24), -1)\n    lu.assertEquals(candidate(2, 4), 0)\n    lu.assertEquals(candidate(-1, 17), -1)\n    lu.assertEquals(candidate(-1, 3), -1)\n    lu.assertEquals(candidate(-1, 14), -1)\n    lu.assertEquals(candidate(-1, 18), -1)\n    lu.assertEquals(candidate(3, 2), 0)\n    lu.assertEquals(candidate(-1, 22), -1)\n    lu.assertEquals(candidate(-1, 21), -1)\n    lu.assertEquals(candidate(1, 1), 0)\n    lu.assertEquals(candidate(-1, 4), -1)\n    lu.assertEquals(candidate(1, 6), 0)\n    lu.assertEquals(candidate(-1, 25), -1)\n    lu.assertEquals(candidate(1, 2), 0)\n    lu.assertEquals(candidate(-1, 10), -1)\n    lu.assertEquals(candidate(-1, 16), -1)\n    lu.assertEquals(candidate(0, 10), 0)\n    lu.assertEquals(candidate(1, 0), 1)\n    lu.assertEquals(candidate(1, 8), 0)\n    lu.assertEquals(candidate(-1, 5), -1)\n    lu.assertEquals(candidate(-1, 6), -1)\n    lu.assertEquals(candidate(10, 4), 0)\n    lu.assertEquals(candidate(2, 6), 0)\n    lu.assertEquals(candidate(2, 7), 0)\n    lu.assertEquals(candidate(1, 4), 0)\n    lu.assertEquals(candidate(10, 6), 0)\n    lu.assertEquals(candidate(-1, 2), -1)\n    lu.assertEquals(candidate(10, 3), 1)\n    lu.assertEquals(candidate(-1, 12), -1)\n    lu.assertEquals(candidate(-1, 15), -1)\n    lu.assertEquals(candidate(10, 2), 2)\n    lu.assertEquals(candidate(-1, 7), -1)\n    lu.assertEquals(candidate(-1, 20), -1)\n    lu.assertEquals(candidate(1, 7), 0)\n    lu.assertEquals(candidate(-1, 13), -1)\n    lu.assertEquals(candidate(10, 0), 10)\n    lu.assertEquals(candidate(2, 5), 0)\n    lu.assertEquals(candidate(0, 0), 0)\n    lu.assertEquals(candidate(10, 1), 5)\n    lu.assertEquals(candidate(2, 1), 1)\n    lu.assertEquals(candidate(-1, 11), -1)\n    lu.assertEquals(candidate(-1, 19), -1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_248555_is_text_all_capital", "language": "lua", "prompt": "-- Returns true of the entire text is written with capitals. False otherwise.\nlocal function is_text_all_capital(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_248555_is_text_all_capital.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_text_all_capital\n    lu.assertEquals(candidate('abc'), false)\n    lu.assertEquals(candidate(''), true)\n    lu.assertEquals(candidate('ABC'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_249778_dist_modulus_to_distance", "language": "lua", "prompt": "--  Convert distance modulus -> distance (pc)\n-- : dm : distance modulus\nlocal function dist_modulus_to_distance(dm)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_249778_dist_modulus_to_distance.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = dist_modulus_to_distance\n    lu.assertEquals(candidate(-10), 0.1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_25003_stringquote", "language": "lua", "prompt": "-- escapes quotes as neccessary and returns a string representing\n-- the text\nlocal function stringquote(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_25003_stringquote.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = stringquote\n    lu.assertEquals(candidate('\"one\"'), '\\'\"one\"\\'')\n    lu.assertEquals(candidate(\"ab'c\"), '\"ab\\'c\"')\n    lu.assertEquals(candidate(\"'a\\\\nb\"), '\"\\'a\\\\nb\"')\n    lu.assertEquals(candidate(\"'\"), '\"\\'\"')\n    lu.assertEquals(candidate(\"a'b\"), '\"a\\'b\"')\n    lu.assertEquals(candidate(\"'one'\"), '\"\\'one\\'\"')\n    lu.assertEquals(candidate('ab\"c\\''), '\"ab\"\"c\\'\"')\n    lu.assertEquals(candidate(\"a\\\\nb'c\"), '\"a\\\\nb\\'c\"')\n    lu.assertEquals(candidate('one'), \"'one'\")\n    lu.assertEquals(candidate(\"a\\\\\\\\'b\"), '\"a\\\\\\\\\\'b\"')\n    lu.assertEquals(candidate(''), \"''\")\n    lu.assertEquals(candidate('abc'), \"'abc'\")\n    lu.assertEquals(candidate('one'), \"'one'\")\n    lu.assertEquals(candidate('ab\"c\\'d'), '\"ab\"\"c\\'d\"')\n    lu.assertEquals(candidate(\"one' \"), '\"one\\' \"')\n    lu.assertEquals(candidate('a'), \"'a'\")\n    lu.assertEquals(candidate(\"a\\\\'b\"), '\"a\\\\\\'b\"')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_250429_BitGet", "language": "lua", "prompt": "-- Gets bit value at position pos from the left of the length-N bit-representation of n\nlocal function BitGet(n, N, pos)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_250429_BitGet.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = BitGet\n    lu.assertEquals(candidate(0, 2, 0), 0)\n    lu.assertEquals(candidate(170, 8, 7), 0)\n    lu.assertEquals(candidate(0, 1, 0), 0)\n    lu.assertEquals(candidate(7, 2, 0), 1)\n    lu.assertEquals(candidate(2, 16, 1), 0)\n    lu.assertEquals(candidate(31, 8, 1), 0)\n    lu.assertEquals(candidate(170, 8, 3), 0)\n    lu.assertEquals(candidate(7, 5, 2), 1)\n    lu.assertEquals(candidate(170, 8, 6), 1)\n    lu.assertEquals(candidate(170, 8, 1), 0)\n    lu.assertEquals(candidate(4, 2, 1), 0)\n    lu.assertEquals(candidate(3, 2, 0), 1)\n    lu.assertEquals(candidate(31, 8, 2), 0)\n    lu.assertEquals(candidate(682, 8, 0), 1)\n    lu.assertEquals(candidate(15, 8, 6), 1)\n    lu.assertEquals(candidate(682, 8, 1), 0)\n    lu.assertEquals(candidate(2, 2, 1), 0)\n    lu.assertEquals(candidate(8, 8, 3), 0)\n    lu.assertEquals(candidate(2, 8, 1), 0)\n    lu.assertEquals(candidate(2147483648, 32, 0), 1)\n    lu.assertEquals(candidate(64, 16, 6), 0)\n    lu.assertEquals(candidate(15, 8, 5), 1)\n    lu.assertEquals(candidate(170, 8, 5), 0)\n    lu.assertEquals(candidate(8, 16, 3), 0)\n    lu.assertEquals(candidate(128, 16, 7), 0)\n    lu.assertEquals(candidate(682, 8, 2), 1)\n    lu.assertEquals(candidate(3, 2, 1), 1)\n    lu.assertEquals(candidate(0, 2, 1), 0)\n    lu.assertEquals(candidate(31, 8, 3), 1)\n    lu.assertEquals(candidate(15, 8, 7), 1)\n    lu.assertEquals(candidate(4, 2, 0), 0)\n    lu.assertEquals(candidate(170, 8, 4), 1)\n    lu.assertEquals(candidate(31, 8, 0), 0)\n    lu.assertEquals(candidate(7, 5, 0), 0)\n    lu.assertEquals(candidate(0, 3, 0), 0)\n    lu.assertEquals(candidate(1, 2, 0), 0)\n    lu.assertEquals(candidate(170, 8, 2), 1)\n    lu.assertEquals(candidate(4, 16, 2), 0)\n    lu.assertEquals(candidate(682, 8, 3), 0)\n    lu.assertEquals(candidate(15, 8, 4), 1)\n    lu.assertEquals(candidate(170, 8, 0), 1)\n    lu.assertEquals(candidate(32, 16, 5), 0)\n    lu.assertEquals(candidate(7, 2, 1), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_250588_excel_col_name2int", "language": "lua", "prompt": "-- >>> excel_col_name2int('A')\n-- 1\n-- >>> excel_col_name2int('AA')\n-- 27\n-- >>> excel_col_name2int('AB')\n-- 28\nlocal function excel_col_name2int(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_250588_excel_col_name2int.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = excel_col_name2int\n    lu.assertEquals(candidate('A'), 1)\n    lu.assertEquals(candidate('AA'), 27)\n    lu.assertEquals(candidate('B'), 2)\n    lu.assertEquals(candidate('J'), 10)\n    lu.assertEquals(candidate('H'), 8)\n    lu.assertEquals(candidate('Q'), 17)\n    lu.assertEquals(candidate('W'), 23)\n    lu.assertEquals(candidate('K'), 11)\n    lu.assertEquals(candidate('M'), 13)\n    lu.assertEquals(candidate('A'), 1)\n    lu.assertEquals(candidate('G'), 7)\n    lu.assertEquals(candidate('O'), 15)\n    lu.assertEquals(candidate('R'), 18)\n    lu.assertEquals(candidate('F'), 6)\n    lu.assertEquals(candidate('AA'), 27)\n    lu.assertEquals(candidate('T'), 20)\n    lu.assertEquals(candidate('X'), 24)\n    lu.assertEquals(candidate('I'), 9)\n    lu.assertEquals(candidate('C'), 3)\n    lu.assertEquals(candidate('S'), 19)\n    lu.assertEquals(candidate('V'), 22)\n    lu.assertEquals(candidate('E'), 5)\n    lu.assertEquals(candidate('P'), 16)\n    lu.assertEquals(candidate('N'), 14)\n    lu.assertEquals(candidate('L'), 12)\n    lu.assertEquals(candidate('D'), 4)\n    lu.assertEquals(candidate('U'), 21)\n    lu.assertEquals(candidate('AB'), 28)\n    lu.assertEquals(candidate('AB'), 28)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_251103_hamming_with_n", "language": "lua", "prompt": "-- Hamming Distance without counting wildcard smbols.\n-- Args:\n--     s1: the first sequence for comparison.\n--     s2: the second sequence for comparison.\n-- Returns:\n--     the distance without accounting unrestricted sites.\nlocal function hamming_with_n(s1, s2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_251103_hamming_with_n.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = hamming_with_n\n    lu.assertEquals(candidate('AGT', 'CCC'), 3)\n    lu.assertEquals(candidate('AGT', 'AGC'), 1)\n    lu.assertEquals(candidate('AA', 'AAA'), 0)\n    lu.assertEquals(candidate('AAA', 'AA'), 0)\n    lu.assertEquals(candidate('AGT', 'CCT'), 2)\n    lu.assertEquals(candidate('AGT', 'AGT'), 0)\n    lu.assertEquals(candidate('AA', 'AA'), 0)\n    lu.assertEquals(candidate('AGT', 'AGG'), 1)\n    lu.assertEquals(candidate('A', 'A'), 0)\n    lu.assertEquals(candidate('AGT', 'GAT'), 2)\n    lu.assertEquals(candidate('', ''), 0)\n    lu.assertEquals(candidate('AGT', 'GTT'), 2)\n    lu.assertEquals(candidate('AAA', 'AAA'), 0)\n    lu.assertEquals(candidate('AGT', 'TGG'), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_251439_prefix_dict", "language": "lua", "prompt": "-- Add prefix_s to every key in dict\n-- :param di_:\n-- :param prefix_s:\n-- :return:\nlocal function prefix_dict(di_, prefix_s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_251439_prefix_dict.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = prefix_dict\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2}, 'some_prefix_'), {['some_prefix_a'] = 1, ['some_prefix_b'] = 2})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_251602_match_link", "language": "lua", "prompt": "--  Diagnoses in app have substrings of how diagnosis named in desease list \nlocal function match_link(links, name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_251602_match_link.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = match_link\n    lu.assertEquals(candidate({['pain'] = 'Pain'}, 'pain in the joints'), 'Pain')\n    lu.assertEquals(candidate({['pain'] = 'Pain'}, 'pain in the hands and joints'), 'Pain')\n    lu.assertEquals(candidate({['pain'] = 'Pain'}, 'pain is located at the knee'), 'Pain')\n    lu.assertEquals(candidate({['pain'] = 'Pain'}, 'pain in the right shoulder'), 'Pain')\n    lu.assertEquals(candidate({['pain'] = 'Pain'}, 'pain in the right hip'), 'Pain')\n    lu.assertEquals(candidate({['pain'] = 'Pain'}, 'pain in the left knee'), 'Pain')\n    lu.assertEquals(candidate({['pain'] = 'Pain'}, 'pain in the hips'), 'Pain')\n    lu.assertEquals(candidate({['pain'] = 'Pain'}, 'pain in the leg'), 'Pain')\n    lu.assertEquals(candidate({['pain'] = 'Pain'}, 'pain in the shins'), 'Pain')\n    lu.assertEquals(candidate({['pain'] = 'Pain'}, 'pain in the legs'), 'Pain')\n    lu.assertEquals(candidate({['pain'] = 'Pain'}, 'pain in the right knee'), 'Pain')\n    lu.assertEquals(candidate({['pain'] = 'Pain'}, 'pain in the left hip'), 'Pain')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_252412_is_up", "language": "lua", "prompt": "-- Returns True if the interface is up, False if it's down, and None if there\n-- is not enuough information present to determine whether it's up or down\nlocal function is_up(line)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_252412_is_up.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_up\n    lu.assertEquals(candidate('    eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500'), true)\n    lu.assertEquals(candidate('UP'), true)\n    lu.assertEquals(candidate('state UP group default qlen 1000'), true)\n    lu.assertEquals(candidate('     UP    inet6 2001:db8::1/64  scope global  '), true)\n    lu.assertEquals(candidate('    lo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536'), true)\n    lu.assertEquals(candidate('    UP      inet 172.16.0.1/16  brd 172.16.0.255  mtu 1500'), true)\n    lu.assertEquals(candidate('state UP    group default qlen   1000'), true)\n    lu.assertEquals(candidate('state UNKNOWN group default qlen 1000'), None)\n    lu.assertEquals(candidate('state DOWN  group default qlen 1000'), false)\n    lu.assertEquals(candidate('    UP      inet 172.16.0.1/16  brd 172.16.0.255  mtu 1500'), true)\n    lu.assertEquals(candidate('eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500'), true)\n    lu.assertEquals(candidate('state DOWN group default qlen 1000'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_252535_last_blank", "language": "lua", "prompt": "-- Determine if the input source ends in a blank.\n-- A blank is either a newline or a line consisting of whitespace.\n-- Parameters\n-- ----------\n-- src : string\n--   A single or multiline string.\nlocal function last_blank(src)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_252535_last_blank.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = last_blank\n    lu.assertEquals(candidate('  \\\\n  '), false)\n    lu.assertEquals(candidate(' '), true)\n    lu.assertEquals(candidate(' \\n'), true)\n    lu.assertEquals(candidate('a\\\\nb'), false)\n    lu.assertEquals(candidate('   \\n   foo\\nbar\\n   '), true)\n    lu.assertEquals(candidate('a\\\\n b\\\\nc'), false)\n    lu.assertEquals(candidate(None), false)\n    lu.assertEquals(candidate(' \\n '), true)\n    lu.assertEquals(candidate('foo'), false)\n    lu.assertEquals(candidate('  \\\\n  \\\\n  '), false)\n    lu.assertEquals(candidate('\\n'), true)\n    lu.assertEquals(candidate('a\\\\n b'), false)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('a\\n'), false)\n    lu.assertEquals(candidate('   foo   '), false)\n    lu.assertEquals(candidate('   foo'), false)\n    lu.assertEquals(candidate('a'), false)\n    lu.assertEquals(candidate(' a\\n b'), false)\n    lu.assertEquals(candidate(' a\\n'), false)\n    lu.assertEquals(candidate(' a\\n b\\n '), true)\n    lu.assertEquals(candidate('foo\\nbar\\n   '), true)\n    lu.assertEquals(candidate('foo   '), false)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('\\n'), true)\n    lu.assertEquals(candidate('   \\n'), true)\n    lu.assertEquals(candidate('a'), false)\n    lu.assertEquals(candidate('a\\n\\n'), true)\n    lu.assertEquals(candidate('foo\\nbar'), false)\n    lu.assertEquals(candidate(''), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_253299_replace_slash", "language": "lua", "prompt": "-- Replaces slash with division slash symbol for CheckStyle Jenkins plugin\nlocal function replace_slash(name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_253299_replace_slash.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = replace_slash\n    lu.assertEquals(candidate('x'), 'x')\n    lu.assertEquals(candidate('/foo/bar/'), '\u2215foo\u2215bar\u2215')\n    lu.assertEquals(candidate('1'), '1')\n    lu.assertEquals(candidate('hello/world'), 'hello\u2215world')\n    lu.assertEquals(candidate('hello/world/12345'), 'hello\u2215world\u221512345')\n    lu.assertEquals(candidate('/'), '\u2215')\n    lu.assertEquals(candidate('123'), '123')\n    lu.assertEquals(candidate('//hello'), '\u2215\u2215hello')\n    lu.assertEquals(candidate('foo/bar//'), 'foo\u2215bar\u2215\u2215')\n    lu.assertEquals(candidate('foo//bar/baz'), 'foo\u2215\u2215bar\u2215baz')\n    lu.assertEquals(candidate('A/B'), 'A\u2215B')\n    lu.assertEquals(candidate('abc123'), 'abc123')\n    lu.assertEquals(candidate('//foo'), '\u2215\u2215foo')\n    lu.assertEquals(candidate('hello'), 'hello')\n    lu.assertEquals(candidate('foo/bar/baz'), 'foo\u2215bar\u2215baz')\n    lu.assertEquals(candidate('A/B/C'), 'A\u2215B\u2215C')\n    lu.assertEquals(candidate('/A/B/C/'), '\u2215A\u2215B\u2215C\u2215')\n    lu.assertEquals(candidate('//'), '\u2215\u2215')\n    lu.assertEquals(candidate('foo//bar'), 'foo\u2215\u2215bar')\n    lu.assertEquals(candidate('bar'), 'bar')\n    lu.assertEquals(candidate('hello/world/12345/54321'), 'hello\u2215world\u221512345\u221554321')\n    lu.assertEquals(candidate('/A/B/'), '\u2215A\u2215B\u2215')\n    lu.assertEquals(candidate('/A/B/C/D/'), '\u2215A\u2215B\u2215C\u2215D\u2215')\n    lu.assertEquals(candidate('abc'), 'abc')\n    lu.assertEquals(candidate('foo/bar'), 'foo\u2215bar')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('A/B/C/D'), 'A\u2215B\u2215C\u2215D')\n    lu.assertEquals(candidate('foo'), 'foo')\n    lu.assertEquals(candidate(None), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_253524_remove_block_hashtags", "language": "lua", "prompt": "-- attempt to remove hidden hashtags at the bottom of captions\nlocal function remove_block_hashtags(caption)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_253524_remove_block_hashtags.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_block_hashtags\n    lu.assertEquals(candidate('a #simple #caption\\n\\n\u2022 #a hidden hashtag\\n\\n\u2022 another hidden hashtag\\n\\n\u2022 a third hidden hashtag'), 'a #simple #caption')\n    lu.assertEquals(candidate('Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.'), 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.')\n    lu.assertEquals(candidate('Hey check out this #python #code\\n\u2022 #programming #code #python #fun'), 'Hey check out this #python #code')\n    lu.assertEquals(candidate('#dogcatdog'), '#dogcatdog')\n    lu.assertEquals(candidate('Hey check out this #python #code\\n\u2022 #programming #code #python #fun\\n\u2022 #python #coding #fun\\n\u2022 #python #fun #code\\n\u2022 #python #fun #code\\n\u2022 #python #fun #code'), 'Hey check out this #python #code')\n    lu.assertEquals(candidate('Hey check out this #python #code\\n\u2022 #programming #code #python #fun\\n\u2022 #python #coding #fun\\n\u2022 #python #fun #code'), 'Hey check out this #python #code')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('a #simple #caption\\n\\n\u2022 #a hidden hashtag\\n\\n\u2022 #another hidden hashtag'), 'a #simple #caption')\n    lu.assertEquals(candidate('This is a caption with hashtags.\\n\\n###test ###hashtag ###hashtag'), 'This is a caption with hashtags.')\n    lu.assertEquals(candidate(\"Hello, Twitter! This is <NAME>, and today we're excited to introduce a brand new way to discover and share on Twitter. With the new Discover tab, you can find the content you love and follow people who love it!\"), \"Hello, Twitter! This is <NAME>, and today we're excited to introduce a brand new way to discover and share on Twitter. With the new Discover tab, you can find the content you love and follow people who love it!\")\n    lu.assertEquals(candidate('This is a caption with hashtags.\\n\\n#hello\\n\\n###test ###hashtag ###hashtag\\n\\n'), 'This is a caption with hashtags.')\n    lu.assertEquals(candidate('Hey check out this #python #code\\n\u2022 #programming #code #python #fun\\n\u2022 #python #coding #fun'), 'Hey check out this #python #code')\n    lu.assertEquals(candidate('A few days ago I had a very good feeling about the project because of how the community was and how active we were. I was also happy to see that the project was gaining momentum!'), 'A few days ago I had a very good feeling about the project because of how the community was and how active we were. I was also happy to see that the project was gaining momentum!')\n    lu.assertEquals(candidate(\"Today we're announcing a major new feature, which allows you to view who has liked your photos! You can now filter the photo grid by your liked photos to see who has liked your photos!\"), \"Today we're announcing a major new feature, which allows you to view who has liked your photos! You can now filter the photo grid by your liked photos to see who has liked your photos!\")\n    lu.assertEquals(candidate('a #simple #caption\\n\\n\u2022 #a hidden hashtag\\n\\n\u2022 another hidden hashtag\\n\\n\u2022 a third hidden hashtag\\n\\n\u2022 a fourth hidden hashtag'), 'a #simple #caption')\n    lu.assertEquals(candidate('a #simple #caption\\n\\n\u2022 #a hidden hashtag'), 'a #simple #caption')\n    lu.assertEquals(candidate('dogcatdogcatdogcat'), 'dogcatdogcatdogcat')\n    lu.assertEquals(candidate('hello world'), 'hello world')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_253671__gen_bia_img_url", "language": "lua", "prompt": "-- Genarate BIA Image URL\nlocal function _gen_bia_img_url(imgname)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_253671__gen_bia_img_url.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _gen_bia_img_url\n    lu.assertEquals(candidate('4011225839_82f37d3a43_b.jpg'), 'http://www.istartedsomething.com/bingimages/cache/4011225839_82f37d3a43_b.jpg')\n    lu.assertEquals(candidate('4096.jpg'), 'http://www.istartedsomething.com/bingimages/cache/4096.jpg')\n    lu.assertEquals(candidate('1844c585d7706905996f70d34e6e88f4.jpg'), 'http://www.istartedsomething.com/bingimages/cache/1844c585d7706905996f70d34e6e88f4.jpg')\n    lu.assertEquals(candidate('16526562929_4a36810594_b.jpg'), 'http://www.istartedsomething.com/bingimages/cache/16526562929_4a36810594_b.jpg')\n    lu.assertEquals(candidate('test.jpg'), 'http://www.istartedsomething.com/bingimages/cache/test.jpg')\n    lu.assertEquals(candidate(), 'http://www.istartedsomething.com/bingimages/cache/mybiaimage.jpg')\n    lu.assertEquals(candidate('13190.jpg'), 'http://www.istartedsomething.com/bingimages/cache/13190.jpg')\n    lu.assertEquals(candidate('542048039_d5e364672a_b.jpg'), 'http://www.istartedsomething.com/bingimages/cache/542048039_d5e364672a_b.jpg')\n    lu.assertEquals(candidate('12299423875_7e6178659f_b.jpg'), 'http://www.istartedsomething.com/bingimages/cache/12299423875_7e6178659f_b.jpg')\n    lu.assertEquals(candidate('25805.jpg'), 'http://www.istartedsomething.com/bingimages/cache/25805.jpg')\n    lu.assertEquals(candidate('test'), 'http://www.istartedsomething.com/bingimages/cache/test')\n    lu.assertEquals(candidate('foo.png'), 'http://www.istartedsomething.com/bingimages/cache/foo.png')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_254264_sorted_items", "language": "lua", "prompt": "-- Return an iterator of the dict's items sorted by its keys.\nlocal function sorted_items(params)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_254264_sorted_items.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sorted_items\n    lu.assertEquals(candidate({['a'] = 1, ['c'] = 3, ['b'] = 2}), {{'a', 1}, {'b', 2}, {'c', 3}})\n    lu.assertEquals(candidate(dict()), {})\n    lu.assertEquals(candidate({['a'] = 1, ['c'] = 3, ['b'] = 2, ['d'] = 4}), {{'a', 1}, {'b', 2}, {'c', 3}, {'d', 4}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_254385_parse_seat_to_binary", "language": "lua", "prompt": "-- Take a seat identifier BFFFBBFRRR and determine it's binary\n-- number\nlocal function parse_seat_to_binary(seat)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_254385_parse_seat_to_binary.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_seat_to_binary\n    lu.assertEquals(candidate(''), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_254436__get_int_type_index", "language": "lua", "prompt": "--     Returns the index into the types array corresponding to this int\nlocal function _get_int_type_index(i)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_254436__get_int_type_index.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _get_int_type_index\n    lu.assertEquals(candidate(12345), 3)\n    lu.assertEquals(candidate(4294967295), 2)\n    lu.assertEquals(candidate(2147483646), 3)\n    lu.assertEquals(candidate(2147483648), 2)\n    lu.assertEquals(candidate(10), 3)\n    lu.assertEquals(candidate(1024), 3)\n    lu.assertEquals(candidate(4), 3)\n    lu.assertEquals(candidate(-2147483648), 3)\n    lu.assertEquals(candidate(1), 3)\n    lu.assertEquals(candidate(-1), 3)\n    lu.assertEquals(candidate(-42), 3)\n    lu.assertEquals(candidate(42), 3)\n    lu.assertEquals(candidate(2147483647), 3)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_254770_key_int_to_str", "language": "lua", "prompt": "-- Convert spotify's 'pitch class notation' to\n-- and actual key value\nlocal function key_int_to_str(key)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_254770_key_int_to_str.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = key_int_to_str\n    lu.assertEquals(candidate(8), 'G#')\n    lu.assertEquals(candidate('13'), 'No key')\n    lu.assertEquals(candidate(9), 'A')\n    lu.assertEquals(candidate(5), 'F')\n    lu.assertEquals(candidate(-5), 'No key')\n    lu.assertEquals(candidate(-8), 'No key')\n    lu.assertEquals(candidate(15), 'No key')\n    lu.assertEquals(candidate(3), 'D#')\n    lu.assertEquals(candidate(1), 'C#')\n    lu.assertEquals(candidate(4), 'E')\n    lu.assertEquals(candidate(-1), 'No key')\n    lu.assertEquals(candidate(10), 'A#')\n    lu.assertEquals(candidate(13), 'No key')\n    lu.assertEquals(candidate(-3), 'No key')\n    lu.assertEquals(candidate('12'), 'No key')\n    lu.assertEquals(candidate(-2), 'No key')\n    lu.assertEquals(candidate(11), 'B')\n    lu.assertEquals(candidate(-4), 'No key')\n    lu.assertEquals(candidate(14), 'No key')\n    lu.assertEquals(candidate(2), 'D')\n    lu.assertEquals(candidate(7), 'G')\n    lu.assertEquals(candidate(12), 'No key')\n    lu.assertEquals(candidate(0), 'C')\n    lu.assertEquals(candidate(-6), 'No key')\n    lu.assertEquals(candidate(24), 'No key')\n    lu.assertEquals(candidate(-7), 'No key')\n    lu.assertEquals(candidate(6), 'F#')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_255070_average_best_three", "language": "lua", "prompt": "-- from input of four numbers average biggest three\n-- average_best_three(1, 10, 20, 30)\n-- 20\nlocal function average_best_three(grade1, grade2, grade3, grade4)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_255070_average_best_three.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = average_best_three\n    lu.assertEquals(candidate(3, 3, 3, 3), 3)\n    lu.assertEquals(candidate(10, 10, 10, 10), 10)\n    lu.assertEquals(candidate(1, 10, 20, 30), 20)\n    lu.assertEquals(candidate(10, 1, 30, 20), 20)\n    lu.assertEquals(candidate(-5, -4, -3, -2), -3)\n    lu.assertEquals(candidate(10, 20, 10, 30), 20)\n    lu.assertEquals(candidate(-1, -2, -3, -4), -2)\n    lu.assertEquals(candidate(10, 1, 20, 30), 20)\n    lu.assertEquals(candidate(1, 1, 1, 1), 1)\n    lu.assertEquals(candidate(5, 5, 5, 5), 5)\n    lu.assertEquals(candidate(100, 100, 100, 100), 100)\n    lu.assertEquals(candidate(0, 0, 0, 0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_255382_phex", "language": "lua", "prompt": "-- convert int to 2 characters hex string\n-- which not contain '0x' in begin or 'L' in end\nlocal function phex(num)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_255382_phex.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = phex\n    lu.assertEquals(candidate(32), '20')\n    lu.assertEquals(candidate(31), '1F')\n    lu.assertEquals(candidate(42), '2A')\n    lu.assertEquals(candidate(129), '81')\n    lu.assertEquals(candidate(17), '11')\n    lu.assertEquals(candidate(65535), 'FFFF')\n    lu.assertEquals(candidate(10), '0A')\n    lu.assertEquals(candidate(100), '64')\n    lu.assertEquals(candidate(4660), '1234')\n    lu.assertEquals(candidate(1), '01')\n    lu.assertEquals(candidate(256), '100')\n    lu.assertEquals(candidate(10000), '2710')\n    lu.assertEquals(candidate(255), 'FF')\n    lu.assertEquals(candidate(1), '01')\n    lu.assertEquals(candidate(3), '03')\n    lu.assertEquals(candidate(1000), '3E8')\n    lu.assertEquals(candidate(0), '00')\n    lu.assertEquals(candidate(257), '101')\n    lu.assertEquals(candidate(16), '10')\n    lu.assertEquals(candidate(31), '1F')\n    lu.assertEquals(candidate(12), '0C')\n    lu.assertEquals(candidate(0), '00')\n    lu.assertEquals(candidate(128), '80')\n    lu.assertEquals(candidate(11), '0B')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_255677__prune_instance_label", "language": "lua", "prompt": "-- Deletes everything after the year, which ends in a closed parenthesis.\nlocal function _prune_instance_label(label)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_255677__prune_instance_label.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _prune_instance_label\n    lu.assertEquals(candidate('The Einstein Journal (1879-1934) (1944-1946) (1947-1948)'), 'The Einstein Journal (1879-1934)')\n    lu.assertEquals(candidate('n.d. (1827-04-17).???.'), 'n.d. (1827-04-17)')\n    lu.assertEquals(candidate('n.d. (1827-04-17)???'), 'n.d. (1827-04-17)')\n    lu.assertEquals(candidate('n.d. (1827-04-17).'), 'n.d. (1827-04-17)')\n    lu.assertEquals(candidate('n.d. (1827-04-17)'), 'n.d. (1827-04-17)')\n    lu.assertEquals(candidate('n.d. (1827-04-17)???.'), 'n.d. (1827-04-17)')\n    lu.assertEquals(candidate('The Einstein Journal (1879-1934) (1944-1946)'), 'The Einstein Journal (1879-1934)')\n    lu.assertEquals(candidate('n.d. (1827-04-17).???'), 'n.d. (1827-04-17)')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_255721_hp_state_bit_english", "language": "lua", "prompt": "--  Convert derog bit flag to English \nlocal function hp_state_bit_english(raw_table, base_index)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_255721_hp_state_bit_english.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = hp_state_bit_english\n    lu.assertEquals(candidate({255, 255, 255, 255, 255, 255, 255, 255}, 0), '[Defrosting] [Boiler Pump Backup] [Boiler Backup] [HP Pump] [Backup 2] [Backup 1] [Compressor] ')\n    lu.assertEquals(candidate({255, 255, 255, 255, 255, 255, 255, 255}, 1), '[Defrosting] [Boiler Pump Backup] [Boiler Backup] [HP Pump] [Backup 2] [Backup 1] [Compressor] ')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_256372_is_mer", "language": "lua", "prompt": "--  Checks if the rectangle is a MER\n-- NOTE: exclusive ur \nlocal function is_mer(grid, llx, lly, urx, ury)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_256372_is_mer.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_mer\n    lu.assertEquals(candidate({{1, 1, 1, 1, 1, 1, 0, 1}, {0, 0, 0, 1, 0, 1, 1, 1}, {0, 1, 1, 1, 0, 1, 1, 1}, {0, 0, 1, 1, 1, 1, 1, 1}}, 0, 0, 7, 7), false)\n    lu.assertEquals(candidate({{1, 1, 1, 0, 1, 1, 1, 1}, {0, 0, 1, 1, 1, 1, 1, 1}, {0, 1, 1, 1, 0, 1, 1, 1}, {0, 0, 1, 1, 1, 1, 1, 1}}, 0, 0, 7, 7), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_257729_get_die_base_hazard_rate", "language": "lua", "prompt": "-- Retrieve the base hazard rate for a VHISC/VLSI die.\n-- :param type_id: the VHISC/VLSI type identifier.\n-- :return: _lambda_bd; the base die hazard rate.\n-- :rtype: float\nlocal function get_die_base_hazard_rate(type_id)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_257729_get_die_base_hazard_rate.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_die_base_hazard_rate\n    lu.assertEquals(candidate(1), 0.16)\n    lu.assertEquals(candidate(2), 0.24)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_258216_parseMovie", "language": "lua", "prompt": "--     Parses a movie record in MovieLens format movieId::movieTitle .\nlocal function parseMovie(line)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_258216_parseMovie.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parseMovie\n    lu.assertEquals(candidate('6::Twelve Monkeys (a.k.a. 12 Monkeys) (1995)'), {6, 'Twelve Monkeys (a.k.a. 12 Monkeys) (1995)'})\n    lu.assertEquals(candidate('1::Sully (1965)::http://us.imdb.com/M/title-exact?Sully%20(1965)'), {1, 'Sully (1965)'})\n    lu.assertEquals(candidate('3::Grumpier Old Men (1995)::Comedy::Romance::8.0'), {3, 'Grumpier Old Men (1995)'})\n    lu.assertEquals(candidate('1::Toy Story (1995)'), {1, 'Toy Story (1995)'})\n    lu.assertEquals(candidate('1::Toy Story (1995)::Animation::Comedy::8.3'), {1, 'Toy Story (1995)'})\n    lu.assertEquals(candidate('2::Jumanji (1995)::Adventure::Childhood::8.1'), {2, 'Jumanji (1995)'})\n    lu.assertEquals(candidate('6::Heat (1995)::Action::Sci-Fi::7.9'), {6, 'Heat (1995)'})\n    lu.assertEquals(candidate(\"8::Tom and Huck (1995)::Adventure::Children's::8.5\"), {8, 'Tom and Huck (1995)'})\n    lu.assertEquals(candidate('3::Three Billboards Outside Ebbing, Missouri (2017)::http://us.imdb.com/M/title-exact?Three%20Billboards%20Outside%20Ebbing,%20Missouri%20(2017)'), {3, 'Three Billboards Outside Ebbing, Missouri (2017)'})\n    lu.assertEquals(candidate('2::Toy Story (1995)::http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)'), {2, 'Toy Story (1995)'})\n    lu.assertEquals(candidate('4::Get Shorty (1995)'), {4, 'Get Shorty (1995)'})\n    lu.assertEquals(candidate('3::Four Rooms (1995)'), {3, 'Four Rooms (1995)'})\n    lu.assertEquals(candidate('5::Copycat (1995)'), {5, 'Copycat (1995)'})\n    lu.assertEquals(candidate('5::Father of the Bride Part II (1995)::Comedy::Romance::8.5'), {5, 'Father of the Bride Part II (1995)'})\n    lu.assertEquals(candidate('32::Clerks (1994)'), {32, 'Clerks (1994)'})\n    lu.assertEquals(candidate('7::Sabrina (1995)::Comedy::Romance::8.3'), {7, 'Sabrina (1995)'})\n    lu.assertEquals(candidate('4::Waiting to Exhale (1995)::Comedy::Romance::8.2'), {4, 'Waiting to Exhale (1995)'})\n    lu.assertEquals(candidate('2::GoldenEye (1995)'), {2, 'GoldenEye (1995)'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_258575_consolidate_paragraphs", "language": "lua", "prompt": "-- This takes the array of paragraphs and returns point at which paragraph begins. \n-- NOTE that  for purposes of paragraphs, headers are counted as being within the\n-- paragraph following it\nlocal function consolidate_paragraphs(paragraph_offsets, header_offsets)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_258575_consolidate_paragraphs.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = consolidate_paragraphs\n    lu.assertEquals(candidate({{0, 0}, {2, 2}, {3, 3}, {4, 4}, {8, 8}}, {{0, 0}}), {0, 2, 3, 4, 8})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_258727_cell_cube_coord", "language": "lua", "prompt": "--  Returns a tuple with the cube coordinates corresponding to the \n-- given axial coordinates.\nlocal function cell_cube_coord(c)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_258727_cell_cube_coord.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = cell_cube_coord\n    lu.assertEquals(candidate({0, 2}), {0, -2, 2})\n    lu.assertEquals(candidate({3, 0}), {3, -3, 0})\n    lu.assertEquals(candidate({1, 1}), {1, -2, 1})\n    lu.assertEquals(candidate({12, 12}), {12, -24, 12})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_258869_get_geo_url", "language": "lua", "prompt": "--     :param geo_list: list of (geo, geo_id) pair (smallest first)\n-- e.g. [(block%20group, *), (state, 01), (county, 02), (track, *), ]\n--     :return: url for geo query\nlocal function get_geo_url(geo_list)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_258869_get_geo_url.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_geo_url\n    lu.assertEquals(candidate({{'county', '02'}, {'track', '*'}}), '&for=county:02&in=track:*')\n    lu.assertEquals(candidate({{'state', '01'}, {'county', '02'}, {'track', '*'}}), '&for=state:01&in=county:02&in=track:*')\n    lu.assertEquals(candidate({{'track', '*'}}), '&for=track:*')\n    lu.assertEquals(candidate({{'state', '06'}, {'county', '039'}}), '&for=state:06&in=county:039')\n    lu.assertEquals(candidate({}), '')\n    lu.assertEquals(candidate({{'state', '01'}, {'county', '*'}}), '&for=state:01&in=county:*')\n    lu.assertEquals(candidate({{'state', '01'}, {'county', '053'}, {'county', '005'}, {'county', '*'}}), '&for=state:01&in=county:053&in=county:005&in=county:*')\n    lu.assertEquals(candidate({{'state', '*'}}), '&for=state:*')\n    lu.assertEquals(candidate({{'state', '01'}}), '&for=state:01')\n    lu.assertEquals(candidate({{'state', '01'}, {'county', '001'}, {'tract', '001100'}}), '&for=state:01&in=county:001&in=tract:001100')\n    lu.assertEquals(candidate({{'state', '06'}, {'county', '031'}}), '&for=state:06&in=county:031')\n    lu.assertEquals(candidate({{'state', '01'}, {'county', '02'}}), '&for=state:01&in=county:02')\n    lu.assertEquals(candidate({{'state', '*'}, {'county', '*'}}), '&for=state:*&in=county:*')\n    lu.assertEquals(candidate({{'state', '01'}, {'county', '02'}, {'track', '*'}}), '&for=state:01&in=county:02&in=track:*')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_259430_is_pkg_url", "language": "lua", "prompt": "-- Check to see if the url is for a pkg file\nlocal function is_pkg_url(munki_url)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_259430_is_pkg_url.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_pkg_url\n    lu.assertEquals(candidate('https://pkgs.foo.bar.com/product/foo/1.0/i386/Foo-1.0.dmg'), true)\n    lu.assertEquals(candidate('https://pkgs.foo.bar.com/product/foo/1.0/x86_64/Foo-1.0.dmg'), true)\n    lu.assertEquals(candidate('https://pkgs.foo.bar.com/product/foo/1.0/Foo-1.0.pkg'), true)\n    lu.assertEquals(candidate('https://my.munki.example.org/pkgs/foo-bar-1.0.pkg'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_25952_coalesce_dates", "language": "lua", "prompt": "-- Coalesces all date pairs into combined date pairs that makes it easy to find free time gaps.\n-- >>> from date_collapse import coalesce_dates\n-- >>> dates = [(1,4),(2,8),(12,16),(16,21)]\n-- >>> cdates = coalesce_dates(dates)\n-- >>> print(cdates)\n-- [(1, 8), (12, 21)]\n-- >>> dates = [(1,4),(2,8),(8,10),(12,16),(16,21),(21,31)]\n-- >>> cdates = coalesce_dates(dates)\n-- >>> print(cdates)\n-- [(1, 10), (12, 31)]\nlocal function coalesce_dates(dates)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_25952_coalesce_dates.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = coalesce_dates\n    lu.assertEquals(candidate({{1, 4}, {2, 8}, {8, 10}, {12, 16}, {16, 21}, {21, 31}}), {{1, 10}, {12, 31}})\n    lu.assertEquals(candidate({{1, 4}, {2, 8}, {12, 16}, {16, 21}}), {{1, 8}, {12, 21}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_259671_conv_module_name_filter", "language": "lua", "prompt": "-- filter module name to have a short view\nlocal function conv_module_name_filter(name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_259671_conv_module_name_filter.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = conv_module_name_filter\n    lu.assertEquals(candidate('Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)'), 'Conv2d(3, 16, k=(1, 1), s=(1, 1), b=False)')\n    lu.assertEquals(candidate('Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)'), 'Conv2d(3, 32, k=(5, 5), s=(1, 1), pad=(2, 2), b=False)')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_259733_IsVersionNewer", "language": "lua", "prompt": "-- Determines if new Chrome version is higher than the installed one.\n-- Args:\n--   cur_version: Current version of Chrome.\n--   new_version: New version that will be installed.\n-- Returns:\n--   True, if new version is higher, otherwise False.\nlocal function IsVersionNewer(cur_version, new_version)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_259733_IsVersionNewer.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = IsVersionNewer\n    lu.assertEquals(candidate('1.2.3.4', '1.2.4.4'), true)\n    lu.assertEquals(candidate('1.2.3.4', '1.2.3.5'), true)\n    lu.assertEquals(candidate('1.2.3.4', '0.2.3.4'), false)\n    lu.assertEquals(candidate('1.2.3.4', '1.2.3.4'), false)\n    lu.assertEquals(candidate('1.2.3.4', '1.2.3.3'), false)\n    lu.assertEquals(candidate('1.2.3.4', '1.3.3.4'), true)\n    lu.assertEquals(candidate('1.2.3.4', '1.2.2.4'), false)\n    lu.assertEquals(candidate('1.2.3.4', '2.2.3.4'), true)\n    lu.assertEquals(candidate('1.2.3.4', '1.2.3.4'), false)\n    lu.assertEquals(candidate('1.0.0.0', '1.0.0.0'), false)\n    lu.assertEquals(candidate('1.2.3.4', '1.1.3.4'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_259839_interval_to_milliseconds", "language": "lua", "prompt": "-- Convert a Binance interval string to milliseconds\n-- For clarification see document or mail d3dileep@gmail.com\n-- :param interval: Binance interval string 1m, 3m, 5m, 15m, 30m, 1h, 2h, 4h, 6h, 8h, 12h, 1d, 3d, 1w\n-- :type interval: str\n-- :return:\n--          None if unit not one of m, h, d or w\n--          None if string not in correct format\n--          int value of interval in milliseconds\nlocal function interval_to_milliseconds(interval)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_259839_interval_to_milliseconds.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = interval_to_milliseconds\n    lu.assertEquals(candidate('1h'), 3600000)\n    lu.assertEquals(candidate('1M'), None)\n    lu.assertEquals(candidate('1m'), 60000)\n    lu.assertEquals(candidate('30m'), 1800000)\n    lu.assertEquals(candidate('4h'), 14400000)\n    lu.assertEquals(candidate('3d'), 259200000)\n    lu.assertEquals(candidate('2h'), 7200000)\n    lu.assertEquals(candidate('6h'), 21600000)\n    lu.assertEquals(candidate('1d'), 86400000)\n    lu.assertEquals(candidate('1W'), None)\n    lu.assertEquals(candidate('1d'), 86400000)\n    lu.assertEquals(candidate('1w'), 604800000)\n    lu.assertEquals(candidate('15m'), 900000)\n    lu.assertEquals(candidate('1w'), 604800000)\n    lu.assertEquals(candidate('8h'), 28800000)\n    lu.assertEquals(candidate('15m'), 900000)\n    lu.assertEquals(candidate('4h'), 14400000)\n    lu.assertEquals(candidate('1m'), 60000)\n    lu.assertEquals(candidate('12h'), 43200000)\n    lu.assertEquals(candidate('8h'), 28800000)\n    lu.assertEquals(candidate('6h'), 21600000)\n    lu.assertEquals(candidate('5m'), 300000)\n    lu.assertEquals(candidate('2h'), 7200000)\n    lu.assertEquals(candidate('3m'), 180000)\n    lu.assertEquals(candidate('3m'), 180000)\n    lu.assertEquals(candidate('12h'), 43200000)\n    lu.assertEquals(candidate('1h'), 3600000)\n    lu.assertEquals(candidate('3d'), 259200000)\n    lu.assertEquals(candidate('5m'), 300000)\n    lu.assertEquals(candidate('30m'), 1800000)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_260814_str2bool", "language": "lua", "prompt": "--  Convert string to boolean. \nlocal function str2bool(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_260814_str2bool.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = str2bool\n    lu.assertEquals(candidate('1'), true)\n    lu.assertEquals(candidate('True'), true)\n    lu.assertEquals(candidate('True'), true)\n    lu.assertEquals(candidate(None), None)\n    lu.assertEquals(candidate('false'), false)\n    lu.assertEquals(candidate('false'), false)\n    lu.assertEquals(candidate('False'), false)\n    lu.assertEquals(candidate('yes'), true)\n    lu.assertEquals(candidate('0'), false)\n    lu.assertEquals(candidate('False'), false)\n    lu.assertEquals(candidate('no'), false)\n    lu.assertEquals(candidate('true'), true)\n    lu.assertEquals(candidate('true'), true)\n    lu.assertEquals(candidate('0'), false)\n    lu.assertEquals(candidate('1'), true)\n    lu.assertEquals(candidate('no'), false)\n    lu.assertEquals(candidate('yes'), true)\n    lu.assertEquals(candidate(''), None)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_261308_get_eqn", "language": "lua", "prompt": "-- Returns the equation of a line in the form mx+b as a tuple of (m, b) for two points.\n-- Does not check for vertical lines.\nlocal function get_eqn(p0, p1)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_261308_get_eqn.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_eqn\n    lu.assertEquals(candidate({0, 0}, {100, 0}), {0, 0})\n    lu.assertEquals(candidate({0, 0}, {100, 100}), {1, 0})\n    lu.assertEquals(candidate({0, 0}, {1, 2}), {2, 0})\n    lu.assertEquals(candidate({0, 0}, {1, 1}), {1, 0})\n    lu.assertEquals(candidate({0, 0}, {-100, 100}), {-1, 0})\n    lu.assertEquals(candidate({0, 0}, {-100, 0}), {0, 0})\n    lu.assertEquals(candidate({0, 0}, {-1, 1}), {-1, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_261555_write_output", "language": "lua", "prompt": "--     Make tsv format output file.\nlocal function write_output(final, invcf)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_261555_write_output.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = write_output\n    lu.assertEquals(candidate('1\\t10\\tA\\tG\\n1\\t12\\tT\\tC\\n1\\t15\\tC\\tT\\n1\\t18\\tG\\tA\\n1\\t20\\tC\\tT\\n', 'my_data.vcf'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_261763_get_package_type", "language": "lua", "prompt": "-- :returns the package type [\"pypy_package\"|\"git_package\"|\"weblink\"]\n-- >>> assert get_package_type('pip') == 'pypy_package'\n-- >>> assert get_package_type('https://github.com/pypa/pip.git') == 'git_package'\n-- >>> assert get_package_type('git+https://github.com/pypa/pip.git') == 'git_package'\n-- >>> assert get_package_type('https://github.com/pypa/archive/master.zip') == 'git_package'\n-- >>> assert get_package_type('https://some_link/pypa/archive/master.zip') == 'weblink'\nlocal function get_package_type(package_link)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_261763_get_package_type.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_package_type\n    lu.assertEquals(candidate('pip'), 'pypy_package')\n    lu.assertEquals(candidate('https://github.com/pypa/pip.git'), 'git_package')\n    lu.assertEquals(candidate('https://github.com/pypa/pip.git'), 'git_package')\n    lu.assertEquals(candidate('git+https://github.com/pypa/pip.git'), 'git_package')\n    lu.assertEquals(candidate('https://some_link/pypa/archive/master.zip'), 'weblink')\n    lu.assertEquals(candidate('https://github.com/pypa/archive/master.zip'), 'git_package')\n    lu.assertEquals(candidate('https://github.com/pypa/pip'), 'git_package')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_262021_empty_columns", "language": "lua", "prompt": "-- Returns list of \"\" with length equal to length of expected column.\n-- >>> empty_columns(['***21**', '412453*', '423145*', '*543215', '*35214*', '*41532*', '*2*1***'])\n-- ['', '', '', '', '', '', '']\nlocal function empty_columns(board)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_262021_empty_columns.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = empty_columns\n    lu.assertEquals(candidate({'***21**', '412553*', '423145*', '*543215', '*35214*', '*41232*', '*2*1***'}), {'', '', '', '', '', '', ''})\n    lu.assertEquals(candidate({'*21**', '412453*'}), {'', '', '', '', ''})\n    lu.assertEquals(candidate({'***22**', '412453*', '423145*', '*543215', '*35214*', '*41532*', '*2*1***'}), {'', '', '', '', '', '', ''})\n    lu.assertEquals(candidate({'***21**', '412453*', '423145*', '*543215', '*35214*', '*41232*', '*2*1***'}), {'', '', '', '', '', '', ''})\n    lu.assertEquals(candidate({'***22**', '412453*', '423145*', '*543215', '*35214*', '*41232*', '*2*1***'}), {'', '', '', '', '', '', ''})\n    lu.assertEquals(candidate({'***21**', '412553*', '423145*', '*543215', '*35214*', '*41532*', '*2*1***'}), {'', '', '', '', '', '', ''})\n    lu.assertEquals(candidate({'***21**', '412453*', '423145*', '*543215', '*35214*', '*41532*', '*2*1***'}), {'', '', '', '', '', '', ''})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_262051_remove_numbers", "language": "lua", "prompt": "-- Remove any number in a string\n-- Args:\n--     s (str): A string that need to remove number\n-- Returns:\n--     A formatted string with no number\nlocal function remove_numbers(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_262051_remove_numbers.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_numbers\n    lu.assertEquals(candidate('10101010'), '')\n    lu.assertEquals(candidate('1234567890'), '')\n    lu.assertEquals(candidate('abc12345'), 'abc')\n    lu.assertEquals(candidate('abc123abc'), 'abcabc')\n    lu.assertEquals(candidate('There are no numbers in this string'), 'There are no numbers in this string')\n    lu.assertEquals(candidate('Hello World'), 'Hello World')\n    lu.assertEquals(candidate(\"2021 isn't a year\"), \" isn't a year\")\n    lu.assertEquals(candidate('1234567890-'), '-')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('hello'), 'hello')\n    lu.assertEquals(candidate('Hello123World'), 'HelloWorld')\n    lu.assertEquals(candidate('Hi there! 23 is my favorite number.'), 'Hi there!  is my favorite number.')\n    lu.assertEquals(candidate('What is the weather like tomorrow?'), 'What is the weather like tomorrow?')\n    lu.assertEquals(candidate('The 5 boxing wizards jump quickly.'), 'The  boxing wizards jump quickly.')\n    lu.assertEquals(candidate('1234567890'), '')\n    lu.assertEquals(candidate('abc 123 abc'), 'abc  abc')\n    lu.assertEquals(candidate('1234'), '')\n    lu.assertEquals(candidate('No numbers here'), 'No numbers here')\n    lu.assertEquals(candidate('2021 is a year'), ' is a year')\n    lu.assertEquals(candidate('0123456789'), '')\n    lu.assertEquals(candidate('1'), '')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('I am 20 years old.'), 'I am  years old.')\n    lu.assertEquals(candidate('123'), '')\n    lu.assertEquals(candidate('I am 100 years old.'), 'I am  years old.')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_262360_longest_substring", "language": "lua", "prompt": "-- Finds longest substring among list of strings\n-- :param str_list: strings to be searched\n-- :type str_list: list (of str)\n-- :rtype: str\nlocal function longest_substring(str_list)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_262360_longest_substring.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = longest_substring\n    lu.assertEquals(candidate(list('   ')), '')\n    lu.assertEquals(candidate({'  '}), '')\n    lu.assertEquals(candidate({'   '}), '')\n    lu.assertEquals(candidate({'abc', 'abc'}), 'abc')\n    lu.assertEquals(candidate({' '}), '')\n    lu.assertEquals(candidate({'a', 'a'}), 'a')\n    lu.assertEquals(candidate({'abc', 'xyz'}), '')\n    lu.assertEquals(candidate({'apple', 'apple'}), 'apple')\n    lu.assertEquals(candidate(list('  ')), '')\n    lu.assertEquals(candidate(list('')), '')\n    lu.assertEquals(candidate({''}), '')\n    lu.assertEquals(candidate({'', ''}), '')\n    lu.assertEquals(candidate({'abc', 'xyz', '123'}), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_26322_get_valid_step", "language": "lua", "prompt": "-- Checks if the current step is within boundaries and returns a corrected step.\n-- :param current_step: The current step to check.\n-- :param max_step: The maximum allowed step.\n-- :return: A corrected step between 1 and the maximum step.\nlocal function get_valid_step(current_step, max_step)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_26322_get_valid_step.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_valid_step\n    lu.assertEquals(candidate(4, 1), 1)\n    lu.assertEquals(candidate(1, 5), 1)\n    lu.assertEquals(candidate(0, 3), 1)\n    lu.assertEquals(candidate(2, 3), 2)\n    lu.assertEquals(candidate(5, 1), 1)\n    lu.assertEquals(candidate(11, 10), 10)\n    lu.assertEquals(candidate(6, 5), 5)\n    lu.assertEquals(candidate(1, 2), 1)\n    lu.assertEquals(candidate(7, 2), 2)\n    lu.assertEquals(candidate(5, 3), 3)\n    lu.assertEquals(candidate(1, 3), 1)\n    lu.assertEquals(candidate(1, 1), 1)\n    lu.assertEquals(candidate(4, 2), 2)\n    lu.assertEquals(candidate(5, 5), 5)\n    lu.assertEquals(candidate(7, 3), 3)\n    lu.assertEquals(candidate(6, 1), 1)\n    lu.assertEquals(candidate(2, 2), 2)\n    lu.assertEquals(candidate(7, 1), 1)\n    lu.assertEquals(candidate(5, 10), 5)\n    lu.assertEquals(candidate(3, 3), 3)\n    lu.assertEquals(candidate(6, 3), 3)\n    lu.assertEquals(candidate(4, 3), 3)\n    lu.assertEquals(candidate(5, 2), 2)\n    lu.assertEquals(candidate(100, 10), 10)\n    lu.assertEquals(candidate(2, 1), 1)\n    lu.assertEquals(candidate(3, 2), 2)\n    lu.assertEquals(candidate(0, 10), 1)\n    lu.assertEquals(candidate(6, 2), 2)\n    lu.assertEquals(candidate(0, 5), 1)\n    lu.assertEquals(candidate(3, 1), 1)\n    lu.assertEquals(candidate(3, 5), 3)\n    lu.assertEquals(candidate(0, 2), 1)\n    lu.assertEquals(candidate(-2, 5), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_263818_digit_count", "language": "lua", "prompt": "--     Returns the count of the digits (length) of the number\nlocal function digit_count(num)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_263818_digit_count.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = digit_count\n    lu.assertEquals(candidate(0), 1)\n    lu.assertEquals(candidate(1010), 4)\n    lu.assertEquals(candidate(999), 3)\n    lu.assertEquals(candidate(12), 2)\n    lu.assertEquals(candidate(123456), 6)\n    lu.assertEquals(candidate(25), 2)\n    lu.assertEquals(candidate(1000), 4)\n    lu.assertEquals(candidate(12345), 5)\n    lu.assertEquals(candidate(12345678), 8)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(100), 3)\n    lu.assertEquals(candidate(100000000), 9)\n    lu.assertEquals(candidate(123), 3)\n    lu.assertEquals(candidate(2), 1)\n    lu.assertEquals(candidate(1234), 4)\n    lu.assertEquals(candidate(123456789), 9)\n    lu.assertEquals(candidate(50), 2)\n    lu.assertEquals(candidate(1234567), 7)\n    lu.assertEquals(candidate(101), 3)\n    lu.assertEquals(candidate(10000), 5)\n    lu.assertEquals(candidate(10), 2)\n    lu.assertEquals(candidate(1234567890), 10)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_263912__split_kv", "language": "lua", "prompt": "-- Return dict for key=value.\nlocal function _split_kv(pair)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_263912__split_kv.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _split_kv\n    lu.assertEquals(candidate('foo='), {['foo'] = ''})\n    lu.assertEquals(candidate('foo=bar=baz'), {['foo'] = 'bar=baz'})\n    lu.assertEquals(candidate('a=b=c'), {['a'] = 'b=c'})\n    lu.assertEquals(candidate('foo=bar'), {['foo'] = 'bar'})\n    lu.assertEquals(candidate('a=b'), {['a'] = 'b'})\n    lu.assertEquals(candidate('=bar'), {[''] = 'bar'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_264475_get_test", "language": "lua", "prompt": "-- get the file name of the test data\nlocal function get_test(date)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_264475_get_test.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_test\n    lu.assertEquals(candidate('2012010'), '2012010pred.csv')\n    lu.assertEquals(candidate('20124010'), '20124010pred.csv')\n    lu.assertEquals(candidate('2012010100'), '2012010100pred.csv')\n    lu.assertEquals(candidate('201201020'), '201201020pred.csv')\n    lu.assertEquals(candidate(), '2013-05-27pred.csv')\n    lu.assertEquals(candidate(), '2013-05-29pred.csv')\n    lu.assertEquals(candidate(), '2013-05-28pred.csv')\n    lu.assertEquals(candidate('20190103'), '20190103pred.csv')\n    lu.assertEquals(candidate('20120103'), '20120103pred.csv')\n    lu.assertEquals(candidate('20120132'), '20120132pred.csv')\n    lu.assertEquals(candidate('20120140'), '20120140pred.csv')\n    lu.assertEquals(candidate('201201010'), '201201010pred.csv')\n    lu.assertEquals(candidate('20120100'), '20120100pred.csv')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_265233_parse_cookie_data", "language": "lua", "prompt": "--  Parse cookie data into key-value pairs \nlocal function parse_cookie_data(data)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_265233_parse_cookie_data.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_cookie_data\n    lu.assertEquals(candidate('CUSTOMER=WILE_E_COYOTE; PART_NUMBER=ROCKET_LAUNCHER_0001'), {['CUSTOMER'] = 'WILE_E_COYOTE', ['PART_NUMBER'] = 'ROCKET_LAUNCHER_0001'})\n    lu.assertEquals(candidate('theme=light; sessionToken=<PASSWORD>; likes_python=true'), {['theme'] = 'light', ['sessionToken'] = '<PASSWORD>', ['likes_python'] = 'true'})\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('a=b; c=d; e=f; g=h; i=j; k=l; m=n; o=p; q=r; s=t; u=v; w=x; y=z'), {['a'] = 'b', ['c'] = 'd', ['e'] = 'f', ['g'] = 'h', ['i'] = 'j', ['k'] = 'l', ['m'] = 'n', ['o'] = 'p', ['q'] = 'r', ['s'] = 't', ['u'] = 'v', ['w'] = 'x', ['y'] = 'z'})\n    lu.assertEquals(candidate('a=b; c=d; e=f'), {['a'] = 'b', ['c'] = 'd', ['e'] = 'f'})\n    lu.assertEquals(candidate('a=b'), {['a'] = 'b'})\n    lu.assertEquals(candidate('CUSTOMER=WILE_E_COYOTE; PART_NUMBER=ROCKET_LAUNCHER_0001; SHIPPING=FEDEX; CN=Ed'), {['CUSTOMER'] = 'WILE_E_COYOTE', ['PART_NUMBER'] = 'ROCKET_LAUNCHER_0001', ['SHIPPING'] = 'FEDEX', ['CN'] = 'Ed'})\n    lu.assertEquals(candidate('k1=v1; k2=v2; k3=v3'), {['k1'] = 'v1', ['k2'] = 'v2', ['k3'] = 'v3'})\n    lu.assertEquals(candidate('a=b; c=d'), {['a'] = 'b', ['c'] = 'd'})\n    lu.assertEquals(candidate('cookie1=value1'), {['cookie1'] = 'value1'})\n    lu.assertEquals(candidate('theme=light'), {['theme'] = 'light'})\n    lu.assertEquals(candidate('k1=v1; k2=v2; k3=v3; k4=v4'), {['k1'] = 'v1', ['k2'] = 'v2', ['k3'] = 'v3', ['k4'] = 'v4'})\n    lu.assertEquals(candidate('a=b; c=d; e=f; g=h; i=j; k=l; m=n; o=p; q=r; s=t; u=v; w=x; y=z'), {['a'] = 'b', ['c'] = 'd', ['e'] = 'f', ['g'] = 'h', ['i'] = 'j', ['k'] = 'l', ['m'] = 'n', ['o'] = 'p', ['q'] = 'r', ['s'] = 't', ['u'] = 'v', ['w'] = 'x', ['y'] = 'z'})\n    lu.assertEquals(candidate('cookie1=value1; cookie2=value2; cookie3=value3'), {['cookie1'] = 'value1', ['cookie2'] = 'value2', ['cookie3'] = 'value3'})\n    lu.assertEquals(candidate('theme=light; likes_python=true'), {['theme'] = 'light', ['likes_python'] = 'true'})\n    lu.assertEquals(candidate('theme=light; likes_python=true; sessionToken=<PASSWORD>'), {['theme'] = 'light', ['likes_python'] = 'true', ['sessionToken'] = '<PASSWORD>'})\n    lu.assertEquals(candidate('cookie1=value1; cookie2=value2'), {['cookie1'] = 'value1', ['cookie2'] = 'value2'})\n    lu.assertEquals(candidate('likes_python=true'), {['likes_python'] = 'true'})\n    lu.assertEquals(candidate('theme'), {})\n    lu.assertEquals(candidate('CUSTOMER=WILE_E_COYOTE'), {['CUSTOMER'] = 'WILE_E_COYOTE'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_265480_parseDbDummyFname", "language": "lua", "prompt": "-- given user data item which is dummy database name used for remesh and\n-- restart purposes, pull out the base name (minus -s0002, -sXXXX, etc.)\n-- and return the base name and extension (extension in an empty string\n-- if appropriate)\nlocal function parseDbDummyFname(dbDummyFname)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_265480_parseDbDummyFname.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parseDbDummyFname\n    lu.assertEquals(candidate('foo-s3'), {'foo', '-s3'})\n    lu.assertEquals(candidate('foo'), {'foo', ''})\n    lu.assertEquals(candidate('foo-s00003'), {'foo', '-s00003'})\n    lu.assertEquals(candidate('foo-s0002'), {'foo', '-s0002'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_265713_addContent", "language": "lua", "prompt": "-- Add html content together\nlocal function addContent(old_html, raw_html)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_265713_addContent.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = addContent\n    lu.assertEquals(candidate('<h1>Test</h1>', '<p>Paragraph content.</p>'), '<h1>Test</h1><p>Paragraph content.</p>')\n    lu.assertEquals(candidate('<div><span>Hello</span></div>', '<div><span>World</span></div>'), '<div><span>Hello</span></div><div><span>World</span></div>')\n    lu.assertEquals(candidate('<p>The first paragraph.</p><p>The second paragraph.</p>', '<h3>This is a header.</h3>'), '<p>The first paragraph.</p><p>The second paragraph.</p><h3>This is a header.</h3>')\n    lu.assertEquals(candidate('', '<div><span>World</span></div>'), '<div><span>World</span></div>')\n    lu.assertEquals(candidate('<p>The first paragraph.</p>', '<p>The second paragraph.</p>'), '<p>The first paragraph.</p><p>The second paragraph.</p>')\n    lu.assertEquals(candidate('<h1>Test</h1><h2>Subheading</h2>', '<h2>Another subheading</h2>'), '<h1>Test</h1><h2>Subheading</h2><h2>Another subheading</h2>')\n    lu.assertEquals(candidate('<h3>This is a header.</h3>', '<p>This is a paragraph.</p>'), '<h3>This is a header.</h3><p>This is a paragraph.</p>')\n    lu.assertEquals(candidate('<div><span>Hello</span></div>', '<div><span>World</span></div>'), '<div><span>Hello</span></div><div><span>World</span></div>')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_266228_scale_ticks_params", "language": "lua", "prompt": "--  Helper function for learning cureve plots.\n-- Args:\n--     tick_scale : available values are [linear, log2, log10]\nlocal function scale_ticks_params(tick_scale)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_266228_scale_ticks_params.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = scale_ticks_params\n    lu.assertEquals(candidate('log2'), {2, 'Log2 Scale'})\n    lu.assertEquals(candidate('linear'), {None, 'Linear Scale'})\n    lu.assertEquals(candidate('log10'), {10, 'Log10 Scale'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_266486_to_hex", "language": "lua", "prompt": "-- Given Image Id, return its hex value\nlocal function to_hex(image_id)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_266486_to_hex.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = to_hex\n    lu.assertEquals(candidate(4095), candidate(4095))\n    lu.assertEquals(candidate(16711680), '0000000000ff0000')\n    lu.assertEquals(candidate(4294967296), '0000000100000000')\n    lu.assertEquals(candidate(255), '00000000000000ff')\n    lu.assertEquals(candidate(15), '000000000000000f')\n    lu.assertEquals(candidate(255), candidate(255))\n    lu.assertEquals(candidate(0), '0000000000000000')\n    lu.assertEquals(candidate(256), '0000000000000100')\n    lu.assertEquals(candidate(255), '00000000000000ff')\n    lu.assertEquals(candidate(256), candidate(256))\n    lu.assertEquals(candidate(4294967295), '00000000ffffffff')\n    lu.assertEquals(candidate(16), '0000000000000010')\n    lu.assertEquals(candidate(65280), '000000000000ff00')\n    lu.assertEquals(candidate(18446744073709551615), 'ffffffffffffffff')\n    lu.assertEquals(candidate(1), '0000000000000001')\n    lu.assertEquals(candidate(1), '0000000000000001')\n    lu.assertEquals(candidate(0), '0000000000000000')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_266488_create_local_cluster_name", "language": "lua", "prompt": "-- Create the local service-color cluster name.\nlocal function create_local_cluster_name(service, color, index)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_266488_create_local_cluster_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = create_local_cluster_name\n    lu.assertEquals(candidate(), 'local-foo-bar-0')\n    lu.assertEquals(candidate('service', 'color', 1), 'local-service-color-1')\n    lu.assertEquals(candidate('service', 'color', '1'), 'local-service-color-1')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_266494_normalize_line", "language": "lua", "prompt": "-- Return line with fixed ending, if ending was present in line.\n-- Otherwise, does nothing.\nlocal function normalize_line(line, newline)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_266494_normalize_line.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = normalize_line\n    lu.assertEquals(candidate('1234567890\\n', ''), '1234567890')\n    lu.assertEquals(candidate('1234567890\\r', ''), '1234567890')\n    lu.assertEquals(candidate('1234567890\\r\\n', '\\n'), '1234567890\\n')\n    lu.assertEquals(candidate('1234567890\\n', '\\n'), '1234567890\\n')\n    lu.assertEquals(candidate('a\\nb\\n', '\\n'), 'a\\nb\\n')\n    lu.assertEquals(candidate('1234567890\\r', '\\n'), '1234567890\\n')\n    lu.assertEquals(candidate('1234567890\\n', '\\r\\n'), '1234567890\\r\\n')\n    lu.assertEquals(candidate('1234567890\\r\\n', ''), '1234567890')\n    lu.assertEquals(candidate('1234567890', ''), '1234567890')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_2664_fibonacci", "language": "lua", "prompt": "-- Get fibonacci sequence given it length.\n-- Parameters\n-- ----------\n-- length : int\n--     The length of the desired sequence.\n-- Returns\n-- -------\n-- sequence : list of int\n--     The desired Fibonacci sequence\nlocal function fibonacci(length)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_2664_fibonacci.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fibonacci\n    lu.assertEquals(candidate(1), {0})\n    lu.assertEquals(candidate(7), {0, 1, 1, 2, 3, 5, 8})\n    lu.assertEquals(candidate(10), {0, 1, 1, 2, 3, 5, 8, 13, 21, 34})\n    lu.assertEquals(candidate(4), {0, 1, 1, 2})\n    lu.assertEquals(candidate(6), {0, 1, 1, 2, 3, 5})\n    lu.assertEquals(candidate(2), {0, 1})\n    lu.assertEquals(candidate(8), {0, 1, 1, 2, 3, 5, 8, 13})\n    lu.assertEquals(candidate(5), {0, 1, 1, 2, 3})\n    lu.assertEquals(candidate(3), {0, 1, 1})\n    lu.assertEquals(candidate(9), {0, 1, 1, 2, 3, 5, 8, 13, 21})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_266766_re_remote_url", "language": "lua", "prompt": "--  Tests if a string is a \"remote\" URL, http, https, ftp. \nlocal function re_remote_url(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_266766_re_remote_url.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = re_remote_url\n    lu.assertEquals(candidate('https://foo.bar/baz'), true)\n    lu.assertEquals(candidate('https://foo.bar/baz#a?b=c'), true)\n    lu.assertEquals(candidate('https://foo.bar/baz?a=b'), true)\n    lu.assertEquals(candidate('http://foo.bar/baz'), true)\n    lu.assertEquals(candidate('ftp://foo.bar/baz'), true)\n    lu.assertEquals(candidate('https://foo.bar/baz'), true)\n    lu.assertEquals(candidate('https://foo.bar/baz#a'), true)\n    lu.assertEquals(candidate('foo.bar/baz'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_266834_sanitizeIOC", "language": "lua", "prompt": "--             Method to sanitize IOCs\nlocal function sanitizeIOC(ioc)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_266834_sanitizeIOC.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sanitizeIOC\n    lu.assertEquals(candidate('hxxp://example.com/path/to/file'), 'http://example.com/path/to/file')\n    lu.assertEquals(candidate('hxxp://test123.example.com'), 'http://test123.example.com')\n    lu.assertEquals(candidate('hxxp://example.com/test123'), 'http://example.com/test123')\n    lu.assertEquals(candidate('[.]abc.com'), '.abc.com')\n    lu.assertEquals(candidate('hxxp://google.com'), 'http://google.com')\n    lu.assertEquals(candidate('hxxp://example.com'), 'http://example.com')\n    lu.assertEquals(candidate('http://php.net/'), 'http://php.net/')\n    lu.assertEquals(candidate('hxxp://example.com'), 'http://example.com')\n    lu.assertEquals(candidate('hxxp://test.com'), 'http://test.com')\n    lu.assertEquals(candidate('[.]'), '.')\n    lu.assertEquals(candidate(''), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_267008_get_sr", "language": "lua", "prompt": "local function get_sr(rij, n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_267008_get_sr.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_sr\n    lu.assertEquals(candidate(1, 100), candidate(1, 10000))\n    lu.assertEquals(candidate(1, 100), 0.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_267051_hook_with_extra_is_in_hooks", "language": "lua", "prompt": "-- Determine if the word given is the name of a valid hook, with extra data\n-- hanging off of it (e.g., `validhookname=extradata`).\n--    hook_with_extra_is_in_hooks(\n--      'validhookname=stuff',\n--      ['validhookname', 'other'])\n--    #=> True\n--    hook_with_extra_is_in_hooks(\n--      'invalidhookname=stuff',\n--      ['validhookname', 'other'])\n--    #=> False\n--    hook_with_extra_is_in_hooks(\n--      'validhookname',\n--      ['validhookname', 'other'])\n--    #=> False\nlocal function hook_with_extra_is_in_hooks(word, hooks)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_267051_hook_with_extra_is_in_hooks.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = hook_with_extra_is_in_hooks\n    lu.assertEquals(candidate('validhookname=other=stuff', {'validhookname', 'other', 'other=stuff'}), true)\n    lu.assertEquals(candidate('validhookname=stuff', {'validhookname', 'other'}), true)\n    lu.assertEquals(candidate('validhookname=other=', {'validhookname', 'other'}), true)\n    lu.assertEquals(candidate('validhookname=other=stuff', {'validhookname', 'other', 'other=', 'other=stuff'}), true)\n    lu.assertEquals(candidate('validhookname', {'validhookname', 'other'}), false)\n    lu.assertEquals(candidate('invalidhookname=stuff', {'validhookname', 'other'}), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_267064_format_time", "language": "lua", "prompt": "--  Function to format the time according to Mysql syntax \nlocal function format_time(time_string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_267064_format_time.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = format_time\n    lu.assertEquals(candidate('2020-04-26T00:00:01.000Z'), '2020-04-26 00:00:01')\n    lu.assertEquals(candidate('2018-11-14T17:14:29.909Z'), '2018-11-14 17:14:29')\n    lu.assertEquals(candidate('2008-01-01T00:00:01.000123456'), '2008-01-01 00:00:01')\n    lu.assertEquals(candidate('2016-03-09T19:58:29.023000-05:00'), '2016-03-09 19:58:29')\n    lu.assertEquals(candidate('1900-01-01T00:00:00.000Z'), '1900-01-01 00:00:00')\n    lu.assertEquals(candidate('2008-01-01T00:00:00.000Z'), '2008-01-01 00:00:00')\n    lu.assertEquals(candidate('2016-03-10T12:06:29.023000-05:00'), '2016-03-10 12:06:29')\n    lu.assertEquals(candidate('2020-04-26T00:00:00.000Z'), '2020-04-26 00:00:00')\n    lu.assertEquals(candidate('2020-04-25T23:59:59.909Z'), '2020-04-25 23:59:59')\n    lu.assertEquals(candidate('2016-03-11T16:48:29.023000-05:00'), '2016-03-11 16:48:29')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_267473_subtract", "language": "lua", "prompt": "-- Subtract one 3-dimensional point from another\n-- Parameters\n--     coords1: coordinates of form [x,y,z]\n--     coords2: coordinates of form [x,y,z]\n-- Returns\n--     list:  List of coordinates equal to coords1 - coords2 (list)\nlocal function subtract(coords1, coords2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_267473_subtract.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = subtract\n    lu.assertEquals(candidate({1, 2, 3}, {4, 5, 6}), {-3, -3, -3})\n    lu.assertEquals(candidate({20, 30, 40}, {10, 10, 10}), {10, 20, 30})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_267485_check_none", "language": "lua", "prompt": "-- Return None if v is the empty string or the string 'None'.\nlocal function check_none(v)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_267485_check_none.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = check_none\n    lu.assertEquals(candidate('not none'), 'not none')\n    lu.assertEquals(candidate('None'), None)\n    lu.assertEquals(candidate('abc'), 'abc')\n    lu.assertEquals(candidate(''), None)\n    lu.assertEquals(candidate(None), None)\n    lu.assertEquals(candidate('some_string'), 'some_string')\n    lu.assertEquals(candidate('foo'), 'foo')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_268129_conflict", "language": "lua", "prompt": "-- Would putting two queens in (row1, col1) and (row2, col2) conflict?\nlocal function conflict(row1, col1, row2, col2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_268129_conflict.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = conflict\n    lu.assertEquals(candidate(1, 1, 2, 1), true)\n    lu.assertEquals(candidate(0, 0, 2, 3), false)\n    lu.assertEquals(candidate(1, 2, 1, 2), true)\n    lu.assertEquals(candidate(0, 0, 8, 8), true)\n    lu.assertEquals(candidate(1, 1, 6, 6), true)\n    lu.assertEquals(candidate(0, 0, 7, 7), true)\n    lu.assertEquals(candidate(1, 1, 4, 4), true)\n    lu.assertEquals(candidate(0, 0, 9, 9), true)\n    lu.assertEquals(candidate(3, 4, 1, 2), true)\n    lu.assertEquals(candidate(0, 0, 5, 5), true)\n    lu.assertEquals(candidate(0, 0, 6, 6), true)\n    lu.assertEquals(candidate(0, 0, 0, 1), true)\n    lu.assertEquals(candidate(0, 0, 4, 4), true)\n    lu.assertEquals(candidate(0, 0, 2, 1), false)\n    lu.assertEquals(candidate(2, 2, 2, 2), true)\n    lu.assertEquals(candidate(0, 0, 3, 3), true)\n    lu.assertEquals(candidate(2, 2, 1, 2), true)\n    lu.assertEquals(candidate(2, 1, 1, 1), true)\n    lu.assertEquals(candidate(1, 1, 5, 5), true)\n    lu.assertEquals(candidate(1, 1, 3, 3), true)\n    lu.assertEquals(candidate(1, 1, 8, 8), true)\n    lu.assertEquals(candidate(2, 2, 1, 1), true)\n    lu.assertEquals(candidate(0, 0, 1, 0), true)\n    lu.assertEquals(candidate(1, 1, 2, 2), true)\n    lu.assertEquals(candidate(0, 0, 1, 2), false)\n    lu.assertEquals(candidate(0, 1, 2, 2), false)\n    lu.assertEquals(candidate(0, 1, 3, 2), false)\n    lu.assertEquals(candidate(1, 2, 2, 1), true)\n    lu.assertEquals(candidate(0, 0, 3, 2), false)\n    lu.assertEquals(candidate(1, 1, 1, 1), true)\n    lu.assertEquals(candidate(0, 0, 2, 2), true)\n    lu.assertEquals(candidate(1, 1, 7, 7), true)\n    lu.assertEquals(candidate(1, 2, 1, 1), true)\n    lu.assertEquals(candidate(2, 3, 3, 2), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_268186_csv_addition", "language": "lua", "prompt": "--     Convert a csv string into ints and then add them.\nlocal function csv_addition(buf)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_268186_csv_addition.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = csv_addition\n    lu.assertEquals(candidate('1,2,3'), 6)\n    lu.assertEquals(candidate('5,10'), 15)\n    lu.assertEquals(candidate('1,2'), 3)\n    lu.assertEquals(candidate('2,1'), 3)\n    lu.assertEquals(candidate('1'), 1)\n    lu.assertEquals(candidate('1,2,3'), 6)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_268347_is_before", "language": "lua", "prompt": "-- return True if ones turn is before twos,\n-- where one, two = [time_spent, last_move_number]\nlocal function is_before(one, two)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_268347_is_before.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_before\n    lu.assertEquals(candidate({3, 3}, {3, 3}), false)\n    lu.assertEquals(candidate({1, 3}, {1, 1}), true)\n    lu.assertEquals(candidate({20, 200}, {20, 200}), false)\n    lu.assertEquals(candidate({20, 200}, {10, 100}), false)\n    lu.assertEquals(candidate({1, 2}, {1, 2}), false)\n    lu.assertEquals(candidate({3, 2}, {3, 1}), true)\n    lu.assertEquals(candidate({3, 1}, {3, 2}), false)\n    lu.assertEquals(candidate({10, 100}, {10, 100}), false)\n    lu.assertEquals(candidate({20, 200}, {10, 200}), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_268388_words", "language": "lua", "prompt": "-- function that counts the number of word occurance in the input and return a dictionary\n-- the dictionary contains the word as the key and the total number of occurance as the value\nlocal function words(word_statement)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_268388_words.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = words\n    lu.assertEquals(candidate('hello world  hello world'), {['hello'] = 2, ['world'] = 2})\n    lu.assertEquals(candidate('Hello World!'), {['Hello'] = 1, ['World!'] = 1})\n    lu.assertEquals(candidate('This is a test'), {['This'] = 1, ['is'] = 1, ['a'] = 1, ['test'] = 1})\n    lu.assertEquals(candidate('hello world  hello world hello world'), {['hello'] = 3, ['world'] = 3})\n    lu.assertEquals(candidate('hello world'), {['hello'] = 1, ['world'] = 1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_268775_update_sum_squares", "language": "lua", "prompt": "-- Compute the update of sum of squares of differences from the current mean\n-- From the previously computed sum SUM_n-1, the new and old mean M_n and\n-- M_n-1 and the new measurement X_n, we compute an update value of the new\n-- sum of squares differences noted SUM_n using the formula:\n-- SUM_n = SUM_n-1 +(X_n - M_n)*(X_n - M_n-1)\n-- See: https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance\n-- This SUM can be use to compute the variance and sample variance:\n-- Vn = SUM_n/n\n-- Sn = SUM_n/(n+1)\n-- This make the variance computation suffer less from floating point\n-- computation instabilities.\n-- Parameters\n-- ----------\n-- new_data: int or decimal\n--     The new measurement X_n\n-- old_sum_squares: int or decimal\n--     The sum of squares SUM_n-1 computed previously\n-- new_mean: int or decimal\n--     The mean M_n computed on the current step n\n-- old_mean: int or decimal\n--     The mean M_n-1 computed previously\n-- Returns\n-- -------\n-- float\n--     The new sum of squares SUM_n updated with X_n, SUM_n-1, M_n and M_n-1\nlocal function update_sum_squares(new_data, old_sum_squares, new_mean, old_mean)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_268775_update_sum_squares.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = update_sum_squares\n    lu.assertEquals(candidate(5, 4, 2, 2), 13)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_270511_transform_boolean", "language": "lua", "prompt": "-- Transform boolean values that are blank into NULL so that they are not\n-- imported as empty strings.\nlocal function transform_boolean(value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_270511_transform_boolean.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = transform_boolean\n    lu.assertEquals(candidate('F'), false)\n    lu.assertEquals(candidate(''), None)\n    lu.assertEquals(candidate('0   '), None)\n    lu.assertEquals(candidate('T'), true)\n    lu.assertEquals(candidate('True'), true)\n    lu.assertEquals(candidate('   '), None)\n    lu.assertEquals(candidate('0'), false)\n    lu.assertEquals(candidate('TRUE'), true)\n    lu.assertEquals(candidate('TRUE   '), None)\n    lu.assertEquals(candidate('1'), true)\n    lu.assertEquals(candidate('     '), None)\n    lu.assertEquals(candidate('f'), false)\n    lu.assertEquals(candidate('t'), true)\n    lu.assertEquals(candidate('FALSE   '), None)\n    lu.assertEquals(candidate('false'), false)\n    lu.assertEquals(candidate('False'), false)\n    lu.assertEquals(candidate(' '), None)\n    lu.assertEquals(candidate('FALSE'), false)\n    lu.assertEquals(candidate('true'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_271149_waiting_time", "language": "lua", "prompt": "-- Bus waiting time.\nlocal function waiting_time(timestamp, bus)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_271149_waiting_time.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = waiting_time\n    lu.assertEquals(candidate(0, 1), 1)\n    lu.assertEquals(candidate(100, 15), 5)\n    lu.assertEquals(candidate(10, 5), 5)\n    lu.assertEquals(candidate(11, 5), 4)\n    lu.assertEquals(candidate(939, 59), 5)\n    lu.assertEquals(candidate(10, 3), 2)\n    lu.assertEquals(candidate(14, 5), 1)\n    lu.assertEquals(candidate(12, 5), 3)\n    lu.assertEquals(candidate(13, 5), 2)\n    lu.assertEquals(candidate(11, 3), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_271792_make_content_dict", "language": "lua", "prompt": "-- Method that takes an input string and returns a dict with characters as keys and occurrences as values\nlocal function make_content_dict(input_string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_271792_make_content_dict.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = make_content_dict\n    lu.assertEquals(candidate('abc'), {['a'] = 1, ['b'] = 1, ['c'] = 1})\n    lu.assertEquals(candidate('abcde'), {['a'] = 1, ['b'] = 1, ['c'] = 1, ['d'] = 1, ['e'] = 1})\n    lu.assertEquals(candidate('abcb'), {['a'] = 1, ['b'] = 2, ['c'] = 1})\n    lu.assertEquals(candidate('a'), {['a'] = 1})\n    lu.assertEquals(candidate('aaaaaa'), {['a'] = 6})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_272497_count_saccades", "language": "lua", "prompt": "-- A Function that counts the number of distinct saccades\n-- :param saccades:    a list with values which indicate if the move from the previos is a saccade.\n-- :return:            a number of indicating the amount of different saccades\nlocal function count_saccades(saccades)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_272497_count_saccades.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = count_saccades\n    lu.assertEquals(candidate({}), 0)\n    lu.assertEquals(candidate({1, 0, 0, 1, 1, 0, 0, 1, 0}), 3)\n    lu.assertEquals(candidate({0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_272652_invert_injective", "language": "lua", "prompt": "--  invert a one-to-one map d \nlocal function invert_injective(d)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_272652_invert_injective.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = invert_injective\n    lu.assertEquals(candidate({[1] = 1, [2] = 2}), {[1] = 1, [2] = 2})\n    lu.assertEquals(candidate(dict(zip({1, 2}, {2, 1}))), {[1] = 2, [2] = 1})\n    lu.assertEquals(candidate(candidate({[1] = 2, [2] = 1, [3] = 3})), {[1] = 2, [2] = 1, [3] = 3})\n    lu.assertEquals(candidate({[1] = 2, [2] = 1}), {[1] = 2, [2] = 1})\n    lu.assertEquals(candidate({[1] = 1, [2] = 2}), {[1] = 1, [2] = 2})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({[1] = 2, [3] = 4, [5] = 5, [6] = 6}), {[2] = 1, [4] = 3, [5] = 5, [6] = 6})\n    lu.assertEquals(candidate({[1] = 2, [3] = 4, [5] = 5}), {[2] = 1, [4] = 3, [5] = 5})\n    lu.assertEquals(candidate({[1] = 2, [3] = 4, [5] = 5, [6] = 6, [7] = 7}), {[2] = 1, [4] = 3, [5] = 5, [6] = 6, [7] = 7})\n    lu.assertEquals(candidate(dict()), dict())\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_273233_write_group_author", "language": "lua", "prompt": "-- Given a string with a variable length of group author, insert into XML snippet, and return XML snippet\n-- NOTE: Group author does not require a primary key/unique ID\n-- :param group_authors: A string containing 1+ group authors, with multiple authors separated by || double pipes\n-- :return: XML snippet with group authors\n-- >>> write_group_author(\"Beauxbatons||Durmstrang\")   #doctest: +NORMALIZE_WHITESPACE\n-- '<v1:author>\n--     <v1:role>author</v1:role>\n--     <v1:groupAuthor>Beauxbatons</v1:groupAuthor>\n-- </v1:author>\n-- <v1:author>\n--     <v1:role>author</v1:role>\n--     <v1:groupAuthor>Durmstrang</v1:groupAuthor>\n-- </v1:author>'\n-- >>> write_group_author(\"Hogwarts School\")\n-- '<v1:author>\n--         <v1:role>author</v1:role>\n--         <v1:groupAuthor>Hogwarts School</v1:groupAuthor>\n--     </v1:author>\n--     '\nlocal function write_group_author(group_authors)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_273233_write_group_author.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = write_group_author\n    lu.assertEquals(candidate('Hogwarts School'), '<v1:author>\\n            <v1:role>author</v1:role>\\n            <v1:groupAuthor>Hogwarts School</v1:groupAuthor>\\n        </v1:author>\\n        ')\n    lu.assertEquals(candidate('Durmstrang'), '<v1:author>\\n            <v1:role>author</v1:role>\\n            <v1:groupAuthor>Durmstrang</v1:groupAuthor>\\n        </v1:author>\\n        ')\n    lu.assertEquals(candidate('Hogwarts School'), '<v1:author>\\n            <v1:role>author</v1:role>\\n            <v1:groupAuthor>Hogwarts School</v1:groupAuthor>\\n        </v1:author>\\n        ')\n    lu.assertEquals(candidate('Beauxbatons||Durmstrang'), '<v1:author>\\n            <v1:role>author</v1:role>\\n            <v1:groupAuthor>Beauxbatons</v1:groupAuthor>\\n        </v1:author>\\n        <v1:author>\\n            <v1:role>author</v1:role>\\n            <v1:groupAuthor>Durmstrang</v1:groupAuthor>\\n        </v1:author>\\n        ')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_273455_calc_order", "language": "lua", "prompt": "-- Returns the FP interferential order.\n-- Parameters\n-- ----------\n-- wavelength (float):\n-- gap_size (float):\n-- Returns\n-- -------\n-- order (float)\nlocal function calc_order(wavelength, gap_size)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_273455_calc_order.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = calc_order\n    lu.assertEquals(candidate(0.8, 0.0), 0.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_273577_calculate_polynomial", "language": "lua", "prompt": "-- Computes the value of the interpolating polynomial.\n-- Parameters\n-- ----------\n-- degree : int\n--     The degree of the interpolating polynomial.\n-- x_data : list\n--     The values that were used when calculating the c of the interpolating polynomial.\n-- coefficients : list\n--     The coefficients of the interpolating polynomial, constant term first.\n-- x : int\n--     The point at which the polynomial will be calculated\n-- Returns\n-- -------\n-- value : float\n--     The value of the interpolating polynomial at point x.\nlocal function calculate_polynomial(degree, x_data, coefficients, x)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_273577_calculate_polynomial.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = calculate_polynomial\n    lu.assertEquals(candidate(3, {0, 1, 2}, {1, 1, 1, 1, 1, 1}, 0), 1)\n    lu.assertEquals(candidate(3, {1, 3, 4}, {0, 1, 2, 3, 4, 5}, 1), 0)\n    lu.assertEquals(candidate(0, {1, 2, 3}, {1}, 2), 1)\n    lu.assertEquals(candidate(3, {0, 1, 2, 3}, {1, 4, 1, 1}, 0), 1)\n    lu.assertEquals(candidate(3, {0, 1, 2}, {1, 1, 1, 1, 1, 1}, 1), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_273749_norm_page_cnt", "language": "lua", "prompt": "-- Normalize a integer (page).\n-- * Ensure that it is greater than Zero, and is not None.\n--     - If less than 1, or None, set it to 1\n-- * if max_number is None, then do not check for max_number\n--     * if greater than max_number, reset it to be max_number\nlocal function norm_page_cnt(page, max_number)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_273749_norm_page_cnt.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = norm_page_cnt\n    lu.assertEquals(candidate(0, 200), 1)\n    lu.assertEquals(candidate(10, 100), 10)\n    lu.assertEquals(candidate(2, 200), 2)\n    lu.assertEquals(candidate(20, 10), 10)\n    lu.assertEquals(candidate(3, 3), 3)\n    lu.assertEquals(candidate(100, 100), 100)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(-1, 10), 1)\n    lu.assertEquals(candidate(1000, 100), 100)\n    lu.assertEquals(candidate(100), 100)\n    lu.assertEquals(candidate(1, 100), 1)\n    lu.assertEquals(candidate(100000, 100), 100)\n    lu.assertEquals(candidate(-5), 1)\n    lu.assertEquals(candidate(-3), 1)\n    lu.assertEquals(candidate(0, 3), 1)\n    lu.assertEquals(candidate(200, 200), 200)\n    lu.assertEquals(candidate(100000, 99), 99)\n    lu.assertEquals(candidate(0), 1)\n    lu.assertEquals(candidate(1, 10), 1)\n    lu.assertEquals(candidate(None, 10), 1)\n    lu.assertEquals(candidate(None), 1)\n    lu.assertEquals(candidate(101, 101), 101)\n    lu.assertEquals(candidate(1, 3), 1)\n    lu.assertEquals(candidate(None, 200), 1)\n    lu.assertEquals(candidate(101, 100), 100)\n    lu.assertEquals(candidate(1, None), 1)\n    lu.assertEquals(candidate(1000, 99), 99)\n    lu.assertEquals(candidate(-3, 3), 1)\n    lu.assertEquals(candidate(-1), 1)\n    lu.assertEquals(candidate(100, 10), 10)\n    lu.assertEquals(candidate(-100), 1)\n    lu.assertEquals(candidate(2, 3), 2)\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(10, 99), 10)\n    lu.assertEquals(candidate(-5, 3), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_273807_make_node_pairs_along_route", "language": "lua", "prompt": "-- Converts a list of nodes into a list of tuples for indexing edges along a route.\nlocal function make_node_pairs_along_route(route)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_273807_make_node_pairs_along_route.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = make_node_pairs_along_route\n    lu.assertEquals(candidate(list('abcde')), {{'a', 'b'}, {'b', 'c'}, {'c', 'd'}, {'d', 'e'}})\n    lu.assertEquals(candidate(list('')), {})\n    lu.assertEquals(candidate(list('abc')), {{'a', 'b'}, {'b', 'c'}})\n    lu.assertEquals(candidate(list('abcdef')), {{'a', 'b'}, {'b', 'c'}, {'c', 'd'}, {'d', 'e'}, {'e', 'f'}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_274415_str2bool", "language": "lua", "prompt": "--     Helper method to convert string to bool\nlocal function str2bool(val)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_274415_str2bool.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = str2bool\n    lu.assertEquals(candidate('False'), false)\n    lu.assertEquals(candidate('tRuE'), true)\n    lu.assertEquals(candidate('True'), true)\n    lu.assertEquals(candidate('FalSe'), false)\n    lu.assertEquals(candidate('oN'), true)\n    lu.assertEquals(candidate('y'), true)\n    lu.assertEquals(candidate(None), false)\n    lu.assertEquals(candidate('n'), false)\n    lu.assertEquals(candidate('yes'), true)\n    lu.assertEquals(candidate('oFf'), false)\n    lu.assertEquals(candidate('on'), true)\n    lu.assertEquals(candidate('false'), false)\n    lu.assertEquals(candidate('true'), true)\n    lu.assertEquals(candidate('off'), false)\n    lu.assertEquals(candidate('FALSE'), false)\n    lu.assertEquals(candidate('no'), false)\n    lu.assertEquals(candidate('1'), true)\n    lu.assertEquals(candidate('t'), true)\n    lu.assertEquals(candidate('f'), false)\n    lu.assertEquals(candidate('TRUE'), true)\n    lu.assertEquals(candidate('0'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_274793_pow", "language": "lua", "prompt": "-- Efficiently exponentiates an integer :math:`a^k (\\textrm{mod}\\ m)`.\n-- The algorithm is more efficient than exponentiating first and then reducing modulo :math:`m`. This\n-- is the integer equivalent of :func:`galois.poly_pow`.\n-- Note\n-- ----\n-- This function is an alias of :func:`pow` in the standard library.\n-- Parameters\n-- ----------\n-- base : int\n--     The integer base :math:`a`.\n-- exp : int\n--     The integer exponent :math:`k`.\n-- mod : int\n--     The integer modulus :math:`m`.\n-- Returns\n-- -------\n-- int\n--     The modular exponentiation :math:`a^k (\\textrm{mod}\\ m)`.\n-- Examples\n-- --------\n-- .. ipython:: python\n--     galois.pow(3, 5, 7)\n--     (3**5) % 7\nlocal function pow(base, exp, mod)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_274793_pow.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = pow\n    lu.assertEquals(candidate(0, 20, 1), 0)\n    lu.assertEquals(candidate(1, 1, 5), 1)\n    lu.assertEquals(candidate(1, 1, 3), 1)\n    lu.assertEquals(candidate(1, 1, 7), 1)\n    lu.assertEquals(candidate(0, 2, 1), 0)\n    lu.assertEquals(candidate(0, 9, 1), 0)\n    lu.assertEquals(candidate(0, 4, 7), 0)\n    lu.assertEquals(candidate(1, 0, 5), 1)\n    lu.assertEquals(candidate(0, 8, 1), 0)\n    lu.assertEquals(candidate(0, 7, 1), 0)\n    lu.assertEquals(candidate(0, 15, 1), 0)\n    lu.assertEquals(candidate(0, 1, 2), 0)\n    lu.assertEquals(candidate(0, 16, 1), 0)\n    lu.assertEquals(candidate(0, 6, 2), 0)\n    lu.assertEquals(candidate(0, 3, 2), 0)\n    lu.assertEquals(candidate(1, 1, 4), 1)\n    lu.assertEquals(candidate(1, 0, 9), 1)\n    lu.assertEquals(candidate(0, 18, 1), 0)\n    lu.assertEquals(candidate(0, 6, 1), 0)\n    lu.assertEquals(candidate(0, 14, 1), 0)\n    lu.assertEquals(candidate(1, 0, 2), 1)\n    lu.assertEquals(candidate(0, 4, 1), 0)\n    lu.assertEquals(candidate(0, 1, 1), 0)\n    lu.assertEquals(candidate(0, 12, 1), 0)\n    lu.assertEquals(candidate(0, 2, 2), 0)\n    lu.assertEquals(candidate(0, 3, 7), 0)\n    lu.assertEquals(candidate(0, 7, 7), 0)\n    lu.assertEquals(candidate(1, 0, 4), 1)\n    lu.assertEquals(candidate(1, 0, 7), 1)\n    lu.assertEquals(candidate(0, 5, 1), 0)\n    lu.assertEquals(candidate(0, 5, 7), 0)\n    lu.assertEquals(candidate(1, 1, 10), 1)\n    lu.assertEquals(candidate(0, 13, 1), 0)\n    lu.assertEquals(candidate(0, 3, 1), 0)\n    lu.assertEquals(candidate(0, 10, 1), 0)\n    lu.assertEquals(candidate(0, 32, 1), 0)\n    lu.assertEquals(candidate(0, 2, 7), 0)\n    lu.assertEquals(candidate(0, 4, 2), 0)\n    lu.assertEquals(candidate(0, 63, 1), 0)\n    lu.assertEquals(candidate(1, 0, 6), 1)\n    lu.assertEquals(candidate(0, 8, 2), 0)\n    lu.assertEquals(candidate(0, 11, 1), 0)\n    lu.assertEquals(candidate(1, 1, 8), 1)\n    lu.assertEquals(candidate(1, 0, 12), 1)\n    lu.assertEquals(candidate(1, 1, 6), 1)\n    lu.assertEquals(candidate(1, 0, 8), 1)\n    lu.assertEquals(candidate(1, 1, 2), 1)\n    lu.assertEquals(candidate(1, 0, 10), 1)\n    lu.assertEquals(candidate(0, 1, 7), 0)\n    lu.assertEquals(candidate(1, 0, 3), 1)\n    lu.assertEquals(candidate(0, 6, 7), 0)\n    lu.assertEquals(candidate(1, 1, 9), 1)\n    lu.assertEquals(candidate(1, 0, 11), 1)\n    lu.assertEquals(candidate(0, 33, 1), 0)\n    lu.assertEquals(candidate(1, 1, 11), 1)\n    lu.assertEquals(candidate(0, 5, 2), 0)\n    lu.assertEquals(candidate(0, 31, 1), 0)\n    lu.assertEquals(candidate(0, 8, 7), 0)\n    lu.assertEquals(candidate(1, 0, 13), 1)\n    lu.assertEquals(candidate(0, 19, 1), 0)\n    lu.assertEquals(candidate(1, 1, 12), 1)\n    lu.assertEquals(candidate(2, 3, 10), 8)\n    lu.assertEquals(candidate(1, 1, 13), 1)\n    lu.assertEquals(candidate(0, 7, 2), 0)\n    lu.assertEquals(candidate(0, 17, 1), 0)\n    lu.assertEquals(candidate(0, 0, 1), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_274795_column_index_to_integer", "language": "lua", "prompt": "-- Convert XLS-style column index into equivalent integer\n-- Given a column index e.g. 'A', 'BZ' etc, converts it\n-- to the integer equivalent using zero-based counting\n-- system (so 'A' is equivalent to zero, 'B' to 1 etc).\nlocal function column_index_to_integer(col)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_274795_column_index_to_integer.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = column_index_to_integer\n    lu.assertEquals(candidate('A'), 0)\n    lu.assertEquals(candidate('AA'), 26)\n    lu.assertEquals(candidate('Z'), 25)\n    lu.assertEquals(candidate('BZ'), 77)\n    lu.assertEquals(candidate('AZ'), 51)\n    lu.assertEquals(candidate('BA'), 52)\n    lu.assertEquals(candidate('AB'), 27)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_274982_NormalizeTargetPath", "language": "lua", "prompt": "-- Normalizes the target path.\n-- Adds leading slash if needed, strips ending slashes.\n-- Args:\n--   target: The target path (fusion db publish point).\n-- Returns:\n--   Normalized target path.\nlocal function NormalizeTargetPath(target)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_274982_NormalizeTargetPath.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = NormalizeTargetPath\n    lu.assertEquals(candidate('  test  '), '/test')\n    lu.assertEquals(candidate('/test/'), '/test')\n    lu.assertEquals(candidate('  test'), '/test')\n    lu.assertEquals(candidate(None), None)\n    lu.assertEquals(candidate(' '), '')\n    lu.assertEquals(candidate('test/'), '/test')\n    lu.assertEquals(candidate('test'), '/test')\n    lu.assertEquals(candidate('/foo'), '/foo')\n    lu.assertEquals(candidate('/foo/'), '/foo')\n    lu.assertEquals(candidate('foo'), '/foo')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('/test'), '/test')\n    lu.assertEquals(candidate('foo/'), '/foo')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_276253_sub_dir_source", "language": "lua", "prompt": "--  build out the source portion of the directory structure.\n-- :param dict d: A dictionary holding BIDS terms for path-building\nlocal function sub_dir_source(d)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_276253_sub_dir_source.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sub_dir_source\n    lu.assertEquals(candidate({['sub'] = '02', ['hem'] = 'L', ['samp'] = '1', ['prob'] = '1'}), 'sub-02_hem-L_samp-1_prob-1')\n    lu.assertEquals(candidate({['sub'] = '01', ['hem'] = 'R', ['samp'] = '1', ['prob'] = '1'}), 'sub-01_hem-R_samp-1_prob-1')\n    lu.assertEquals(candidate({['sub'] = '01', ['hem'] = 'L', ['samp'] = '2', ['prob'] = '2'}), 'sub-01_hem-L_samp-2_prob-2')\n    lu.assertEquals(candidate({['sub'] = '01', ['hem'] = 'R', ['samp'] = '2', ['prob'] = '2'}), 'sub-01_hem-R_samp-2_prob-2')\n    lu.assertEquals(candidate({['sub'] = '02', ['hem'] = 'L', ['samp'] = '2', ['prob'] = '2'}), 'sub-02_hem-L_samp-2_prob-2')\n    lu.assertEquals(candidate({['sub'] = '01', ['hem'] = 'L', ['samp'] = '1', ['prob'] = '1'}), 'sub-01_hem-L_samp-1_prob-1')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_276589_make_key", "language": "lua", "prompt": "--     function to combine two coordinates into a valid dict key\nlocal function make_key(x, y)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_276589_make_key.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = make_key\n    lu.assertEquals(candidate(10, 10), '10, 10')\n    lu.assertEquals(candidate(1, 1), '1, 1')\n    lu.assertEquals(candidate(1, 0), '1, 0')\n    lu.assertEquals(candidate(11, 12), '11, 12')\n    lu.assertEquals(candidate(3, 2), '3, 2')\n    lu.assertEquals(candidate(1, 3), '1, 3')\n    lu.assertEquals(candidate(-3, 3), '-3, 3')\n    lu.assertEquals(candidate(50, 50), '50, 50')\n    lu.assertEquals(candidate(0, 1), '0, 1')\n    lu.assertEquals(candidate(-1, -1), '-1, -1')\n    lu.assertEquals(candidate(0, 0), '0, 0')\n    lu.assertEquals(candidate(3, 3), '3, 3')\n    lu.assertEquals(candidate(1, 3), '1, 3')\n    lu.assertEquals(candidate(10, 10), '10, 10')\n    lu.assertEquals(candidate(-20, 20), '-20, 20')\n    lu.assertEquals(candidate(1, 2), '1, 2')\n    lu.assertEquals(candidate(10, 1), '10, 1')\n    lu.assertEquals(candidate(3, 4), '3, 4')\n    lu.assertEquals(candidate(0, 0), '0, 0')\n    lu.assertEquals(candidate(2, 3), '2, 3')\n    lu.assertEquals(candidate(-1, -1), '-1, -1')\n    lu.assertEquals(candidate(1, 0), '1, 0')\n    lu.assertEquals(candidate(1, 0), '1, 0')\n    lu.assertEquals(candidate(-10000, 10000), '-10000, 10000')\n    lu.assertEquals(candidate(-10000, -10000), '-10000, -10000')\n    lu.assertEquals(candidate(-3, -3), '-3, -3')\n    lu.assertEquals(candidate(1, 1), '1, 1')\n    lu.assertEquals(candidate(2, 1), '2, 1')\n    lu.assertEquals(candidate(0, 1), '0, 1')\n    lu.assertEquals(candidate(10000, -10000), '10000, -10000')\n    lu.assertEquals(candidate(0, 0), '0, 0')\n    lu.assertEquals(candidate(2, 1), '2, 1')\n    lu.assertEquals(candidate(3, -3), '3, -3')\n    lu.assertEquals(candidate(3, 4), '3, 4')\n    lu.assertEquals(candidate(10000, 10000), '10000, 10000')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_276945_floatToString5", "language": "lua", "prompt": "-- Return float f as a string with five decimal places without trailing zeros\n-- and dot.\n-- Intended for places where five decimals are needed, e.g. transformations.\nlocal function floatToString5(f)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_276945_floatToString5.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = floatToString5\n    lu.assertEquals(candidate(3.141592653589793), '3.14159')\n    lu.assertEquals(candidate(3.141592653589793), '3.14159')\n    lu.assertEquals(candidate(-1.12345), '-1.12345')\n    lu.assertEquals(candidate(0.000123456789), '0.00012')\n    lu.assertEquals(candidate(12.3456789), '12.34568')\n    lu.assertEquals(candidate(1.23456789), '1.23457')\n    lu.assertEquals(candidate(-1.2345e-05), '-0.00001')\n    lu.assertEquals(candidate(123.45678), '123.45678')\n    lu.assertEquals(candidate(1.12345), '1.12345')\n    lu.assertEquals(candidate(-1.12345), '-1.12345')\n    lu.assertEquals(candidate(1.2345e-05), '0.00001')\n    lu.assertEquals(candidate(1.2345e-05), '0.00001')\n    lu.assertEquals(candidate(1.2345e-05), '0.00001')\n    lu.assertEquals(candidate(0), '0')\n    lu.assertEquals(candidate(0.00012345678900001), '0.00012')\n    lu.assertEquals(candidate(1.12345), '1.12345')\n    lu.assertEquals(candidate(123.456789), '123.45679')\n    lu.assertEquals(candidate(1), '1')\n    lu.assertEquals(candidate(-1.2345e-05), '-0.00001')\n    lu.assertEquals(candidate(-1.0), '-1')\n    lu.assertEquals(candidate(-1.12345), '-1.12345')\n    lu.assertEquals(candidate(-1), '-1')\n    lu.assertEquals(candidate(1.0), '1')\n    lu.assertEquals(candidate(0.0), '0')\n    lu.assertEquals(candidate(1.12345), '1.12345')\n    lu.assertEquals(candidate(0), '0')\n    lu.assertEquals(candidate(1234.56789), '1234.56789')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_277039_urlify", "language": "lua", "prompt": "-- Question 3: Write a method to replace all spaces in a string with '%20'. You may\n-- assume that the string has suffcient space at the end to hold the additional characters,\n-- and that you are given the \"true\" length of the string.\n-- In python I can use the replace method. string.replace(' ', '%20')\nlocal function urlify(string, length)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_277039_urlify.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = urlify\n    lu.assertEquals(candidate('abc', 10), 'abc')\n    lu.assertEquals(candidate('Hello, world', 4), 'Hello')\n    lu.assertEquals(candidate('a bc', 4), 'a%20bc')\n    lu.assertEquals(candidate('abc  def', 10), 'abc%20def')\n    lu.assertEquals(candidate('hello', 5), 'hello')\n    lu.assertEquals(candidate('abc def ghi', 1000), 'abc%20def%20ghi')\n    lu.assertEquals(candidate(None, 0), None)\n    lu.assertEquals(candidate('abc def ghi', 10), 'abc%20def%20ghi')\n    lu.assertEquals(candidate('a b', 2), 'a%20b')\n    lu.assertEquals(candidate('abcdefg', 6), 'abcdefg')\n    lu.assertEquals(candidate('a', 1), 'a')\n    lu.assertEquals(candidate('a bc', 5), 'a%20bc')\n    lu.assertEquals(candidate('abcdefg ', 8), 'abcdefg%20')\n    lu.assertEquals(candidate('a b', 4), 'a%20b')\n    lu.assertEquals(candidate('abcdefg', 0), None)\n    lu.assertEquals(candidate('abc defg ', 8), 'abc%20defg%20')\n    lu.assertEquals(candidate('a b', 3), 'a%20b')\n    lu.assertEquals(candidate(' ', 1), '%20')\n    lu.assertEquals(candidate('hello world', 11), 'hello%20world')\n    lu.assertEquals(candidate('hello world', 13), 'hello%20world')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_277349_pingpong", "language": "lua", "prompt": "-- Return the nth element of the ping-pong sequence.\n-- >>> pingpong(8)\n-- 8\n-- >>> pingpong(10)\n-- 6\n-- >>> pingpong(15)\n-- 1\n-- >>> pingpong(21)\n-- -1\n-- >>> pingpong(22)\n-- -2\n-- >>> pingpong(30)\n-- -2\n-- >>> pingpong(68)\n-- 0\n-- >>> pingpong(69)\n-- -1\n-- >>> pingpong(80)\n-- 0\n-- >>> pingpong(81)\n-- 1\n-- >>> pingpong(82)\n-- 0\n-- >>> pingpong(100)\n-- -6\n-- >>> from construct_check import check\n-- >>> # ban assignment statements\n-- >>> check(HW_SOURCE_FILE, 'pingpong',\n-- ...       ['Assign', 'AnnAssign', 'AugAssign', 'NamedExpr'])\n-- True\nlocal function pingpong(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_277349_pingpong.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = pingpong\n    lu.assertEquals(candidate(100), -6)\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(81), 1)\n    lu.assertEquals(candidate(14), 2)\n    lu.assertEquals(candidate(19), 1)\n    lu.assertEquals(candidate(69), -1)\n    lu.assertEquals(candidate(21), -1)\n    lu.assertEquals(candidate(22), -2)\n    lu.assertEquals(candidate(10), 6)\n    lu.assertEquals(candidate(17), 1)\n    lu.assertEquals(candidate(80), 0)\n    lu.assertEquals(candidate(15), 1)\n    lu.assertEquals(candidate(18), 2)\n    lu.assertEquals(candidate(82), 0)\n    lu.assertEquals(candidate(68), 0)\n    lu.assertEquals(candidate(8), 8)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(30), -2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_277573_covers_alphabet", "language": "lua", "prompt": "-- This function takes a string and returns if the given string contains all the alphabets\nlocal function covers_alphabet(sentence)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_277573_covers_alphabet.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = covers_alphabet\n    lu.assertEquals(candidate('Hello World'), false)\n    lu.assertEquals(candidate('1234567890'), false)\n    lu.assertEquals(candidate('This is a sentence. This is another sentence.'), false)\n    lu.assertEquals(candidate('abc def'), false)\n    lu.assertEquals(candidate('abcdefghijklmnopqrstuvwxyz'), true)\n    lu.assertEquals(candidate('The quick brown fox jumps over the lazy dog.'), true)\n    lu.assertEquals(candidate('abc def ghi'), false)\n    lu.assertEquals(candidate('This is a sentence.'), false)\n    lu.assertEquals(candidate('abc def ghi jkl'), false)\n    lu.assertEquals(candidate('The narwhal bacons at midnight.'), false)\n    lu.assertEquals(candidate('abc de'), false)\n    lu.assertEquals(candidate('ABCDEFGHIJKLMNOPQRSTUVWXYZ'), true)\n    lu.assertEquals(candidate('The quick brown fox jumps over the lazy eog.'), false)\n    lu.assertEquals(candidate('a'), false)\n    lu.assertEquals(candidate('abc'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_278103_check_parens", "language": "lua", "prompt": "-- check_parens takes a string and:\n-- returns 0 if the number of parentheses is balanced and matched.\n-- returns 1 if more left parentheses than right.\n-- returns -1 if string has broken (unmatched) parentheses.\nlocal function check_parens(str)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_278103_check_parens.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = check_parens\n    lu.assertEquals(candidate('())(())'), -1)\n    lu.assertEquals(candidate('((()))'), 0)\n    lu.assertEquals(candidate('(()()))'), -1)\n    lu.assertEquals(candidate('()'), 0)\n    lu.assertEquals(candidate(')'), -1)\n    lu.assertEquals(candidate('(()()())'), 0)\n    lu.assertEquals(candidate('(()'), 1)\n    lu.assertEquals(candidate('((())'), 1)\n    lu.assertEquals(candidate('()()()()'), 0)\n    lu.assertEquals(candidate('((()())(())())'), 0)\n    lu.assertEquals(candidate(')('), -1)\n    lu.assertEquals(candidate(')()('), -1)\n    lu.assertEquals(candidate('())'), -1)\n    lu.assertEquals(candidate('()()())'), -1)\n    lu.assertEquals(candidate('()()()'), 0)\n    lu.assertEquals(candidate('())'), -1)\n    lu.assertEquals(candidate('('), 1)\n    lu.assertEquals(candidate('(())'), 0)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('(()())'), 0)\n    lu.assertEquals(candidate(')()(())'), -1)\n    lu.assertEquals(candidate('(()))'), -1)\n    lu.assertEquals(candidate('()'), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_278605_convert_mwh_bbtu", "language": "lua", "prompt": "-- converts energy in MWh to energy in billion btu.\n-- :param value:           value in megawatt-hours of energy\n-- :type value:            float\n-- :return:                value in bbtu\nlocal function convert_mwh_bbtu(value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_278605_convert_mwh_bbtu.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = convert_mwh_bbtu\n    lu.assertEquals(candidate(0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_279010_prepare_url", "language": "lua", "prompt": "--     Prepare the URL\nlocal function prepare_url(valip, valch)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_279010_prepare_url.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = prepare_url\n    lu.assertEquals(candidate('1.1.1.1', 'ch1'), 'http://1.1.1.1/api/v100/dali_devices.ssi?action=get&ch=ch1')\n    lu.assertEquals(candidate('1', '1'), 'http://1/api/v100/dali_devices.ssi?action=get&ch=1')\n    lu.assertEquals(candidate('1.2.3.4', '1'), 'http://1.2.3.4/api/v100/dali_devices.ssi?action=get&ch=1')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_279176_check_port", "language": "lua", "prompt": "-- return port value\nlocal function check_port(port)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_279176_check_port.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = check_port\n    lu.assertEquals(candidate('None'), '-1')\n    lu.assertEquals(candidate('12345'), '12345')\n    lu.assertEquals(candidate('1234'), '1234')\n    lu.assertEquals(candidate('None'), '-1')\n    lu.assertEquals(candidate('1'), '1')\n    lu.assertEquals(candidate(None), '-1')\n    lu.assertEquals(candidate('-1'), '-1')\n    lu.assertEquals(candidate('0'), '0')\n    lu.assertEquals(candidate('8080'), '8080')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_279297_get_best_indexes", "language": "lua", "prompt": "-- Gets the indices of the n-best logits from a list.\nlocal function get_best_indexes(logits, n_best_size)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_279297_get_best_indexes.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_best_indexes\n    lu.assertEquals(candidate({0.1, 0.2}, 0), {})\n    lu.assertEquals(candidate({0.1, 0.3, 0.2}, 2), {1, 2})\n    lu.assertEquals(candidate({}, 1), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_279313_next_question_id", "language": "lua", "prompt": "-- Incrementally fetches the next question ID based on the base passage ID.\n-- Some questions have the same ID in the RACE dataset (if they are\n-- in the same file). We try to make those unique by appending an\n-- index before the id. @q_ids is used to keep the counter for each\n-- question ID - it is essentially a map from the file name to the count.\n-- It will generate ids as follows:\n-- 1) 1-middle1548.txt\n-- 2) 2-middle1548.txt\n-- 3) 3-middle1548.txt\n-- 4) ...\n-- Use this function to get incremental question IDs.\nlocal function next_question_id(next_ids, id_base)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_279313_next_question_id.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = next_question_id\n    lu.assertEquals(candidate({['0-1-1548.txt'] = 1, ['0-2-1548.txt'] = 1}, '0-2-1548.txt'), '1-0-2-1548.txt')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_279421_hex_to_long", "language": "lua", "prompt": "-- Convert hex to long.\nlocal function hex_to_long(hex_string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_279421_hex_to_long.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = hex_to_long\n    lu.assertEquals(candidate('0x4141'), 16705)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_279964_enable_option", "language": "lua", "prompt": "-- Converts a boolean option to a CMake ON/OFF switch\nlocal function enable_option(value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_279964_enable_option.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = enable_option\n    lu.assertEquals(candidate(true), 'ON')\n    lu.assertEquals(candidate(false), 'OFF')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_280016__get_by_path_kw", "language": "lua", "prompt": "--  Used by :meth:`get_by_path` to create the required kwargs for\n-- Node.objects.get(). Might be a starting point for more sophisticated\n-- queries including paths. Example::\n--     ifi = Node.objects.get(**Node._get_by_path_kw(['uio', 'ifi']))\n-- :param pathlist: A list of node-names, like ``['uio', 'ifi']``.\nlocal function _get_by_path_kw(pathlist)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_280016__get_by_path_kw.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _get_by_path_kw\n    lu.assertEquals(candidate({'uio', 'ifi', 'studentservices', 'exams'}), {['short_name'] = 'exams', ['parentnode__short_name'] = 'studentservices', ['parentnode__parentnode__short_name'] = 'ifi', ['parentnode__parentnode__parentnode__short_name'] = 'uio'})\n    lu.assertEquals(candidate({'uio', 'ifi', 'studentservices', 'exams', 'test', 'blabla'}), {['short_name'] = 'blabla', ['parentnode__short_name'] = 'test', ['parentnode__parentnode__short_name'] = 'exams', ['parentnode__parentnode__parentnode__short_name'] = 'studentservices', ['parentnode__parentnode__parentnode__parentnode__short_name'] = 'ifi', ['parentnode__parentnode__parentnode__parentnode__parentnode__short_name'] = 'uio'})\n    lu.assertEquals(candidate({'uio', 'ifi', 'studentservices', 'exams', 'test'}), {['short_name'] = 'test', ['parentnode__short_name'] = 'exams', ['parentnode__parentnode__short_name'] = 'studentservices', ['parentnode__parentnode__parentnode__short_name'] = 'ifi', ['parentnode__parentnode__parentnode__parentnode__short_name'] = 'uio'})\n    lu.assertEquals(candidate({'uio', 'ifi', 'ifiok', 'test'}), {['short_name'] = 'test', ['parentnode__short_name'] = 'ifiok', ['parentnode__parentnode__short_name'] = 'ifi', ['parentnode__parentnode__parentnode__short_name'] = 'uio'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_280991_str_to_dict", "language": "lua", "prompt": "-- Input example: \"{0: 214, 1: 224}\".\nlocal function str_to_dict(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_280991_str_to_dict.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = str_to_dict\n    lu.assertEquals(candidate('{0: 1, 1: 2}'), {[0] = 1, [1] = 2})\n    lu.assertEquals(candidate('{0: 214, 1: 224, 2: 253, 3: 254, 4: 255}'), {[0] = 214, [1] = 224, [2] = 253, [3] = 254, [4] = 255})\n    lu.assertEquals(candidate('{0: 214, 1: 224}'), {[0] = 214, [1] = 224})\n    lu.assertEquals(candidate('{0: 1, 1: 2, 2: 3}'), {[0] = 1, [1] = 2, [2] = 3})\n    lu.assertEquals(candidate('{0: 1}'), {[0] = 1})\n    lu.assertEquals(candidate('{0: 1, 1: 2, 2: 3, 3: 4}'), {[0] = 1, [1] = 2, [2] = 3, [3] = 4})\n    lu.assertEquals(candidate('{1: 1, 2: 2}'), {[1] = 1, [2] = 2})\n    lu.assertEquals(candidate('{0: 214, 2: 253, 4: 255}'), {[0] = 214, [2] = 253, [4] = 255})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_282648_get_keywords_prefix", "language": "lua", "prompt": "-- Return the correct keyword's file prefix given the model\n-- :param model: name of the model\n-- :return: keyword's file prefix\nlocal function get_keywords_prefix(model)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_282648_get_keywords_prefix.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_keywords_prefix\n    lu.assertEquals(candidate('cyclerank'), 'keywords_cyclerank')\n    lu.assertEquals(candidate('pagerank_pageviews'), 'keywords_pagerank')\n    lu.assertEquals(candidate('pagerank'), 'keywords_pagerank')\n    lu.assertEquals(candidate('cyclerank_pageviews'), 'keywords_cyclerank')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_282664_make_anagram_1", "language": "lua", "prompt": "-- Using a dictionary: O(n_a+n_b) time\nlocal function make_anagram_1(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_282664_make_anagram_1.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = make_anagram_1\n    lu.assertEquals(candidate(list('codewars'), list('code')), 4)\n    lu.assertEquals(candidate(list('abcd'), list('abcd')), 0)\n    lu.assertEquals(candidate(list('code'), list('code')), 0)\n    lu.assertEquals(candidate(list('codewars'), list('codewars')), 0)\n    lu.assertEquals(candidate(list('aab'), list('aab')), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_282812_extract_bits", "language": "lua", "prompt": "-- Extract bits which is turend on (1).\n-- Args:\n--     bit (int): Bit to check.\n--     bit_dict (dict): Correspondance dict of bit and status.\n-- Return:\n--     valid_bit (:obj:`list` of :obj:`str`): List of bit which is\n--         turned on (1).\n-- Example:\n--     >>> sample_dict = {\n--     ...     \"S1\": 0b001,\n--     ...     \"S2\": 0b010,\n--     ...     \"S3\": 0b100,\n--     ... }\n--     >>> extract_bits(0b101, sample_dict)\n--     [\"S1\", \"S3\"]\nlocal function extract_bits(bit, bit_dict)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_282812_extract_bits.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = extract_bits\n    lu.assertEquals(candidate(7, {['S1'] = 1, ['S2'] = 2, ['S3'] = 4}), {'S1', 'S2', 'S3'})\n    lu.assertEquals(candidate(6, {['S1'] = 1, ['S2'] = 2, ['S3'] = 4}), {'S2', 'S3'})\n    lu.assertEquals(candidate(7, {['S1'] = 1, ['S2'] = 2, ['S3'] = 4}), {'S1', 'S2', 'S3'})\n    lu.assertEquals(candidate(6, {['S1'] = 1, ['S2'] = 2, ['S3'] = 4}), {'S2', 'S3'})\n    lu.assertEquals(candidate(3, {['S1'] = 1, ['S2'] = 2, ['S3'] = 4}), {'S1', 'S2'})\n    lu.assertEquals(candidate(2, {['S1'] = 1, ['S2'] = 2, ['S3'] = 4}), {'S2'})\n    lu.assertEquals(candidate(0, {['S1'] = 1, ['S2'] = 2, ['S3'] = 4}), {})\n    lu.assertEquals(candidate(1, {['S1'] = 1, ['S2'] = 2, ['S3'] = 4}), {'S1'})\n    lu.assertEquals(candidate(4, {['S1'] = 1, ['S2'] = 2, ['S3'] = 4}), {'S3'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_283724__string_tolist", "language": "lua", "prompt": "-- Convert the authorization comma separated string to list\nlocal function _string_tolist(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_283724__string_tolist.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _string_tolist\n    lu.assertEquals(candidate('abc\\ndef'), {'abc\\ndef'})\n    lu.assertEquals(candidate('foo,bar'), {'foo', 'bar'})\n    lu.assertEquals(candidate(' abc '), {'abc'})\n    lu.assertEquals(candidate(' a, b, c '), {'a', 'b', 'c'})\n    lu.assertEquals(candidate('foo'), {'foo'})\n    lu.assertEquals(candidate('a'), {'a'})\n    lu.assertEquals(candidate(' abc,def '), {'abc', 'def'})\n    lu.assertEquals(candidate('a,b,c'), {'a', 'b', 'c'})\n    lu.assertEquals(candidate(' a,b,c '), {'a', 'b', 'c'})\n    lu.assertEquals(candidate('a, b, c, d'), {'a', 'b', 'c', 'd'})\n    lu.assertEquals(candidate(',a,b,'), {'a', 'b'})\n    lu.assertEquals(candidate('a b c'), {'a b c'})\n    lu.assertEquals(candidate('a,,b'), {'a', 'b'})\n    lu.assertEquals(candidate('a,'), {'a'})\n    lu.assertEquals(candidate(',a'), {'a'})\n    lu.assertEquals(candidate('abc,def'), {'abc', 'def'})\n    lu.assertEquals(candidate(''), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_283945_to_bin", "language": "lua", "prompt": "-- convert number to binary \nlocal function to_bin(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_283945_to_bin.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = to_bin\n    lu.assertEquals(candidate(2), '10')\n    lu.assertEquals(candidate(2), '10')\n    lu.assertEquals(candidate(6), '110')\n    lu.assertEquals(candidate(0), '0')\n    lu.assertEquals(candidate(3), '11')\n    lu.assertEquals(candidate(23), '10111')\n    lu.assertEquals(candidate(1), '1')\n    lu.assertEquals(candidate(5), '101')\n    lu.assertEquals(candidate(0), '0')\n    lu.assertEquals(candidate(42), '101010')\n    lu.assertEquals(candidate(1), '1')\n    lu.assertEquals(candidate(4), '100')\n    lu.assertEquals(candidate(42), '101010')\n    lu.assertEquals(candidate(3), '11')\n    lu.assertEquals(candidate(11), '1011')\n    lu.assertEquals(candidate(7), '111')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_284769_make_stat", "language": "lua", "prompt": "-- Called by loanpy.sanity.postprocess2.\n-- Calculates  statistics from optimum, max nr of guesses and length     of input data frame.\n-- :param opt_fp: The optimal false positive rate as a fraction of the     maximal false positive rate, i.e. last (=highest) element of     list passed to param <guesslist> in loanpy.sanity.eval_all.\n-- :type opt_fp: float\n-- :param opt_tp: The optimal true positive rate as a fraction of the     total number of input words for predictions, i.e. length of data frame.\n-- :type opt_tp: float\n-- :param max_fp: The maximal false positive rate is the     highest number of possible guesses, i.e. the last element of the list     passed to param <guesslist> in loanpy.sanity.eval_all.\n-- :type max_fp: int | float\n-- :param len_df: The total number of input words for predictions.\n-- :type len_df: int\n-- :returns: The optimal setting for param <howmany> in     loanpy.adrc.Adrc.adapt or loanpy.adrc.Adrc.reconstruct.\n-- :rtype: tuple of int, str, str\n-- :Example:\n-- >>> from loanpy.sanity import make_stat\n-- >>> make_stat(opt_fp=0.099, opt_tp=0.6, max_fp=1000, len_df=10)\n-- (100, \"6/10\", \"60%\")\nlocal function make_stat(opt_fp, opt_tp, max_fp, len_df)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_284769_make_stat.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = make_stat\n    lu.assertEquals(candidate(0.099, 0.9, 1000, 10), {100, '9/10', '90%'})\n    lu.assertEquals(candidate(0.099, 0.4, 1000, 10), {100, '4/10', '40%'})\n    lu.assertEquals(candidate(0.099, 0.0, 1000, 10), {100, '0/10', '0%'})\n    lu.assertEquals(candidate(0.099, 0.3, 1000, 10), {100, '3/10', '30%'})\n    lu.assertEquals(candidate(0.099, 0.8, 1000, 10), {100, '8/10', '80%'})\n    lu.assertEquals(candidate(0.099, 0.2, 1000, 10), {100, '2/10', '20%'})\n    lu.assertEquals(candidate(0.099, 0.7, 1000, 10), {100, '7/10', '70%'})\n    lu.assertEquals(candidate(0.099, 0.1, 1000, 10), {100, '1/10', '10%'})\n    lu.assertEquals(candidate(0.099, 0.6, 1000, 10), {100, '6/10', '60%'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_285975_get_alphas", "language": "lua", "prompt": "-- Return a tuple of the first non-digit characters of a revision (which\n-- may be empty) and the remaining characters.\nlocal function get_alphas(revision_str)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_285975_get_alphas.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_alphas\n    lu.assertEquals(candidate('b'), {'b', ''})\n    lu.assertEquals(candidate('a'), {'a', ''})\n    lu.assertEquals(candidate('None'), {'None', ''})\n    lu.assertEquals(candidate('abc'), {'abc', ''})\n    lu.assertEquals(candidate('abc-'), {'abc-', ''})\n    lu.assertEquals(candidate(''), {'', ''})\n    lu.assertEquals(candidate('34'), {'', '34'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_28615_split_instruction", "language": "lua", "prompt": "-- Split an assembly instruction into seperate parts.\n-- :param ins: The assembly line.\n-- :return: A list with the parts of the instruction.\nlocal function split_instruction(ins)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_28615_split_instruction.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = split_instruction\n    lu.assertEquals(candidate('addi $t1, $t2, 3'), {'addi', '$t1', '$t2', '3'})\n    lu.assertEquals(candidate('addi $10, $1, 1000,'), {'addi', '$10', '$1', '1000'})\n    lu.assertEquals(candidate(' addi 3, 5, 7  '), {'addi', '3', '5', '7'})\n    lu.assertEquals(candidate('add    $t0,  $t1, $t2'), {'add', '$t0', '$t1', '$t2'})\n    lu.assertEquals(candidate('bltz $t1, 100000'), {'bltz', '$t1', '100000'})\n    lu.assertEquals(candidate(' slti $t7, $t8, -20'), {'slti', '$t7', '$t8', '-20'})\n    lu.assertEquals(candidate('add.d $f4, $f5, $f2'), {'add.d', '$f4', '$f5', '$f2'})\n    lu.assertEquals(candidate('lw $t1, 0($t2)'), {'lw', '$t1', '0($t2)'})\n    lu.assertEquals(candidate('addi $10, $1, 1000, 123'), {'addi', '$10', '$1', '1000', '123'})\n    lu.assertEquals(candidate('b 100000'), {'b', '100000'})\n    lu.assertEquals(candidate('bnez $t1, 100000'), {'bnez', '$t1', '100000'})\n    lu.assertEquals(candidate('add $t0, $t1, $t2'), {'add', '$t0', '$t1', '$t2'})\n    lu.assertEquals(candidate(' bltz  10, 12  '), {'bltz', '10', '12'})\n    lu.assertEquals(candidate(' jal  10  '), {'jal', '10'})\n    lu.assertEquals(candidate(' jal  10, 12  '), {'jal', '10', '12'})\n    lu.assertEquals(candidate('addi $10, $1, 1000, 123, 5'), {'addi', '$10', '$1', '1000', '123', '5'})\n    lu.assertEquals(candidate('add $t1, $t2, $t3'), {'add', '$t1', '$t2', '$t3'})\n    lu.assertEquals(candidate(' move $s1, $s2'), {'move', '$s1', '$s2'})\n    lu.assertEquals(candidate('   sub   $t3, $t4'), {'sub', '$t3', '$t4'})\n    lu.assertEquals(candidate(' move $t5, $t6'), {'move', '$t5', '$t6'})\n    lu.assertEquals(candidate('add $t1, $t2, 0x10'), {'add', '$t1', '$t2', '0x10'})\n    lu.assertEquals(candidate('addi $10, $1, 1000'), {'addi', '$10', '$1', '1000'})\n    lu.assertEquals(candidate('add $t1, $t2'), {'add', '$t1', '$t2'})\n    lu.assertEquals(candidate('add $t1, $t2, $zero'), {'add', '$t1', '$t2', '$zero'})\n    lu.assertEquals(candidate('j 0x10'), {'j', '0x10'})\n    lu.assertEquals(candidate('addi $10, $1, 1000, '), {'addi', '$10', '$1', '1000'})\n    lu.assertEquals(candidate('sw $t1, 0($t2)'), {'sw', '$t1', '0($t2)'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_287521_normalize_alef_maksura_hsb", "language": "lua", "prompt": "-- Normalize all occurences of Alef Maksura characters to a Yeh character\n-- in a Habash-Soudi-Buckwalter encoded string.\n-- Args:\n--     s (:obj:`str`): The string to be normalized.\n-- Returns:\n--     :obj:`str`: The normalized string.\nlocal function normalize_alef_maksura_hsb(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_287521_normalize_alef_maksura_hsb.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = normalize_alef_maksura_hsb\n    lu.assertEquals(candidate('z\u00fd'), 'zy')\n    lu.assertEquals(candidate('z\u00fd\u00fd'), 'zyy')\n    lu.assertEquals(candidate('x\u00fd\u00fd\u00fd'), 'xyyy')\n    lu.assertEquals(candidate('\u00fd'), 'y')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_287855_binary_combinations", "language": "lua", "prompt": "--     Returns all possible combinations of length n binary numbers as strings\nlocal function binary_combinations(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_287855_binary_combinations.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = binary_combinations\n    lu.assertEquals(candidate(3), {'000', '001', '010', '011', '100', '101', '110', '111'})\n    lu.assertEquals(candidate(2), {'00', '01', '10', '11'})\n    lu.assertEquals(candidate(1), {'0', '1'})\n    lu.assertEquals(candidate(1), {'0', '1'})\n    lu.assertEquals(candidate(2), {'00', '01', '10', '11'})\n    lu.assertEquals(candidate(3), {'000', '001', '010', '011', '100', '101', '110', '111'})\n    lu.assertEquals(candidate(0), {'0'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_291839_format_hostmaster", "language": "lua", "prompt": "-- The DNS encodes the <local-part> as a single label, and encodes the\n-- <mail-domain> as a domain name.  The single label from the <local-part>\n-- is prefaced to the domain name from <mail-domain> to form the domain\n-- name corresponding to the mailbox.  Thus the mailbox HOSTMASTER@SRI-\n-- NIC.ARPA is mapped into the domain name HOSTMASTER.SRI-NIC.ARPA.  If the\n-- <local-part> contains dots or other special characters, its\n-- representation in a master file will require the use of backslash\n-- quoting to ensure that the domain name is properly encoded.  For\n-- example, the mailbox Action.domains@ISI.EDU would be represented as\n-- Action\\.domains.ISI.EDU.\n-- http://www.ietf.org/rfc/rfc1035.txt\nlocal function format_hostmaster(hostmaster)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_291839_format_hostmaster.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = format_hostmaster\n    lu.assertEquals(candidate('foo@bar'), 'foo.bar.')\n    lu.assertEquals(candidate('hostmaster@example.com'), 'hostmaster.example.com.')\n    lu.assertEquals(candidate('HOSTMASTER@SRI-NIC.ARPA'), 'HOSTMASTER.SRI-NIC.ARPA.')\n    lu.assertEquals(candidate('mail-hostmaster@example.com'), 'mail-hostmaster.example.com.')\n    lu.assertEquals(candidate('mailhostmaster@example.com'), 'mailhostmaster.example.com.')\n    lu.assertEquals(candidate('foo@bar.baz'), 'foo.bar.baz.')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_291887_is_templated_secret", "language": "lua", "prompt": "--     Filters secrets that are shaped like: {secret}, <secret>, or ${secret}.\nlocal function is_templated_secret(secret)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_291887_is_templated_secret.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_templated_secret\n    lu.assertEquals(candidate('password}'), false)\n    lu.assertEquals(candidate('pass${'), false)\n    lu.assertEquals(candidate('${password}'), true)\n    lu.assertEquals(candidate('password'), false)\n    lu.assertEquals(candidate('<<PASSWORD>>'), true)\n    lu.assertEquals(candidate('{password'), false)\n    lu.assertEquals(candidate('}password'), false)\n    lu.assertEquals(candidate('pass<PASSWORD>'), false)\n    lu.assertEquals(candidate('${password'), false)\n    lu.assertEquals(candidate('$password}'), false)\n    lu.assertEquals(candidate('password{'), false)\n    lu.assertEquals(candidate('{password}'), true)\n    lu.assertEquals(candidate('pass$'), false)\n    lu.assertEquals(candidate('pass}'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_291988_virtual_temperature", "language": "lua", "prompt": "-- Convert temperature and mixing ratio to virtual temperature.\n-- Args:\n--     temperature_k: The temperature or potential temperature in units K.\n--     mixing_ratio_kg_kg: The mixing ratio in units kg kg-1.\n-- Returns:\n--     The virtual temperature in units K.\nlocal function virtual_temperature(temperature_k, mixing_ratio_g_kg)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_291988_virtual_temperature.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = virtual_temperature\n    lu.assertEquals(candidate(290.0, 0.0), 290.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_292668_rearrange_unsorted", "language": "lua", "prompt": "-- Solution to exercise C-4.20.\n-- Given an unsorted sequence, S, of integers and an integer k, describe a\n-- recursive algorithm for rearranging the elements in S so that all elements\n-- less than or equal to k come before any elements larger than k. What is\n-- the running time of your algorithm on a sequence of n values?\n-- --------------------------------------------------------------------------\n-- Solution:\n-- --------------------------------------------------------------------------\n-- The algorithm terminates when the start index equals the stop index.  That\n-- requires n recursive calls.  Each recursive call will worst case swap two\n-- values in the list.  Replacing a value in a list is O(1) according to the\n-- text (table 5.4), and so this algorithm is O(n).\nlocal function rearrange_unsorted(nums, k)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_292668_rearrange_unsorted.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rearrange_unsorted\n    lu.assertEquals(candidate({3, 1, 4, 2, 5}, 6), {3, 1, 4, 2, 5})\n    lu.assertEquals(candidate({3, 1, 4, 2, 5}, 4), {3, 1, 4, 2, 5})\n    lu.assertEquals(candidate({9, 8, 7, 6, 5, 4, 3, 2, 1, 0}, 4), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9})\n    lu.assertEquals(candidate(list(range(10)), 9), list(range(10)))\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_292769_get_board_columns", "language": "lua", "prompt": "-- Get board columns\n-- >>> get_board_columns(['***21**', '412453*', '423145*', '*543215',     '*35214*', '*41532*', '*2*1***'])\n-- ['*125342', '*23451*', '2413251', '154213*', '*35142*']\nlocal function get_board_columns(board)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_292769_get_board_columns.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_board_columns\n    lu.assertEquals(candidate({'***21**', '412453*', '423145*', '*543215', '*35214*', '*41532*', '*2*1***'}), {'*125342', '*23451*', '2413251', '154213*', '*35142*'})\n    lu.assertEquals(candidate({'***21**', '412453*', '423145*', '*543215', '*35214*', '*41532*', '*2*1***'}), {'*125342', '*23451*', '2413251', '154213*', '*35142*'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_292929_edit_distance_dp", "language": "lua", "prompt": "-- Compute the Edit Distance between 2 strings.\nlocal function edit_distance_dp(str1, str2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_292929_edit_distance_dp.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = edit_distance_dp\n    lu.assertEquals(candidate('A', 'B'), 1)\n    lu.assertEquals(candidate('gumbo', 'gambol'), 2)\n    lu.assertEquals(candidate('Saturday', 'Sunday'), 3)\n    lu.assertEquals(candidate('TCA', 'TAAA'), 2)\n    lu.assertEquals(candidate('kitten', 'kitten'), 0)\n    lu.assertEquals(candidate('GAGATTCTACGGA', 'GAGCATTCTACGAG'), 3)\n    lu.assertEquals(candidate('', ''), 0)\n    lu.assertEquals(candidate('A', 'A'), 0)\n    lu.assertEquals(candidate('GAGATTCTACGGA', 'GAGATTCTACGGC'), 1)\n    lu.assertEquals(candidate('test', 'text'), 1)\n    lu.assertEquals(candidate('GAGATTCTACGGA', 'GAGCATTCTACGGC'), 2)\n    lu.assertEquals(candidate('foo', 'bar'), 3)\n    lu.assertEquals(candidate('TCA', 'TCAA'), 1)\n    lu.assertEquals(candidate('book', 'back'), 2)\n    lu.assertEquals(candidate('GAGATTCTACGGA', 'GAGATTCTACGGC'), 1)\n    lu.assertEquals(candidate('kitten', 'sitting'), 3)\n    lu.assertEquals(candidate('A', 'AG'), 1)\n    lu.assertEquals(candidate('AG', 'A'), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_293032_greatest_common_divisor_with_coefficient", "language": "lua", "prompt": "-- calc the greatest common divisor between a and b, and find two numbers x, y to fit formula:\n-- a * x + b * y = the greatest common divisor.\n-- :param a: (int)\n-- :param b: (int)\n-- :return: (tuple) the greatest common divisor, x, y\nlocal function greatest_common_divisor_with_coefficient(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_293032_greatest_common_divisor_with_coefficient.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = greatest_common_divisor_with_coefficient\n    lu.assertEquals(candidate(0, 1), {1, 0, 1})\n    lu.assertEquals(candidate(4, 2), {2, 0, 1})\n    lu.assertEquals(candidate(12, 14), {2, -1, 1})\n    lu.assertEquals(candidate(1, 2), {1, 1, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_294243_is_hidden", "language": "lua", "prompt": "-- Get boolean if a file (or a directory) is hidden or not, with linux based OS.\n-- Raises\n-- ------\n-- TypeError\n--     If the input data is not a string.\n-- Parameters\n-- ----------\n-- file_name : String\n--     Target file (required)\n-- Returns\n-- -------\n-- Boolean\n--     True if a file is hidden, False elsewhere\nlocal function is_hidden(file_name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_294243_is_hidden.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_hidden\n    lu.assertEquals(candidate('/.git/info/refs/remotes/origin/master/'), false)\n    lu.assertEquals(candidate('/.git/info/refs/remotes/origin'), false)\n    lu.assertEquals(candidate('a.'), false)\n    lu.assertEquals(candidate('/.git/info/refs/remotes/origin/'), false)\n    lu.assertEquals(candidate('/.git'), false)\n    lu.assertEquals(candidate('/.git/info/refs/heads/'), false)\n    lu.assertEquals(candidate('/.git/info/refs/remotes'), false)\n    lu.assertEquals(candidate('/..'), false)\n    lu.assertEquals(candidate('/.git/info/refs/remotes/'), false)\n    lu.assertEquals(candidate('.'), true)\n    lu.assertEquals(candidate('/.git/info/'), false)\n    lu.assertEquals(candidate('.test.py.swp'), true)\n    lu.assertEquals(candidate('test.py.swp'), false)\n    lu.assertEquals(candidate('/.'), false)\n    lu.assertEquals(candidate('/.git/HEAD'), false)\n    lu.assertEquals(candidate('/.git/info/refs'), false)\n    lu.assertEquals(candidate('/.git/'), false)\n    lu.assertEquals(candidate('/.git/info'), false)\n    lu.assertEquals(candidate('/.git/info/refs/heads/master/'), false)\n    lu.assertEquals(candidate(' '), false)\n    lu.assertEquals(candidate('a.a.a'), false)\n    lu.assertEquals(candidate('..test.py'), true)\n    lu.assertEquals(candidate('/.git/info/refs/remotes/origin/master'), false)\n    lu.assertEquals(candidate('/.git/HEAD/master'), false)\n    lu.assertEquals(candidate('.a'), true)\n    lu.assertEquals(candidate('/.git/info/refs/heads/master'), false)\n    lu.assertEquals(candidate('a.a.'), false)\n    lu.assertEquals(candidate('/.git/info/refs/'), false)\n    lu.assertEquals(candidate('a'), false)\n    lu.assertEquals(candidate('/.git/HEAD/'), false)\n    lu.assertEquals(candidate('Test.py'), false)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('a.a'), false)\n    lu.assertEquals(candidate('test.py'), false)\n    lu.assertEquals(candidate('.test.py'), true)\n    lu.assertEquals(candidate('/.git/info/refs/heads'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_294425_signExp", "language": "lua", "prompt": "--     Opens the brackets, depending upon the Sign\nlocal function signExp(expression, sign)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_294425_signExp.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = signExp\n    lu.assertEquals(candidate('-2 - 2 + 1', '+'), '-2 - 2 + 1')\n    lu.assertEquals(candidate('a-b-c', '-'), '-a+b+c')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_295062_prime", "language": "lua", "prompt": "--  To Check If n Is Prime Or Not \nlocal function prime(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_295062_prime.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = prime\n    lu.assertEquals(candidate(2), 1)\n    lu.assertEquals(candidate(25), 0)\n    lu.assertEquals(candidate(9), 0)\n    lu.assertEquals(candidate(30), 0)\n    lu.assertEquals(candidate(13), 1)\n    lu.assertEquals(candidate(32), 0)\n    lu.assertEquals(candidate(35), 0)\n    lu.assertEquals(candidate(22), 0)\n    lu.assertEquals(candidate(19), 1)\n    lu.assertEquals(candidate(3), 1)\n    lu.assertEquals(candidate(10000), 0)\n    lu.assertEquals(candidate(200), 0)\n    lu.assertEquals(candidate(17), 1)\n    lu.assertEquals(candidate(4), 0)\n    lu.assertEquals(candidate(12), 0)\n    lu.assertEquals(candidate(28), 0)\n    lu.assertEquals(candidate(24), 0)\n    lu.assertEquals(candidate(5), 1)\n    lu.assertEquals(candidate(18), 0)\n    lu.assertEquals(candidate(34), 0)\n    lu.assertEquals(candidate(36), 0)\n    lu.assertEquals(candidate(37), 1)\n    lu.assertEquals(candidate(10), 0)\n    lu.assertEquals(candidate(7), 1)\n    lu.assertEquals(candidate(40), 0)\n    lu.assertEquals(candidate(8), 0)\n    lu.assertEquals(candidate(11), 1)\n    lu.assertEquals(candidate(6), 0)\n    lu.assertEquals(candidate(31), 1)\n    lu.assertEquals(candidate(16), 0)\n    lu.assertEquals(candidate(38), 0)\n    lu.assertEquals(candidate(341), 0)\n    lu.assertEquals(candidate(15), 0)\n    lu.assertEquals(candidate(14), 0)\n    lu.assertEquals(candidate(26), 0)\n    lu.assertEquals(candidate(4000), 0)\n    lu.assertEquals(candidate(23), 1)\n    lu.assertEquals(candidate(1000), 0)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(29), 1)\n    lu.assertEquals(candidate(199), 1)\n    lu.assertEquals(candidate(2000), 0)\n    lu.assertEquals(candidate(21), 0)\n    lu.assertEquals(candidate(20), 0)\n    lu.assertEquals(candidate(400), 0)\n    lu.assertEquals(candidate(41), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_295233_char_count", "language": "lua", "prompt": "-- Function to return total character counts in a text,\n-- pass the following parameter `ignore_spaces = False`\n-- to ignore whitespaces\nlocal function char_count(text, ignore_spaces)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_295233_char_count.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = char_count\n    lu.assertEquals(candidate('hello'), 5)\n    lu.assertEquals(candidate('abc'), 3)\n    lu.assertEquals(candidate('a '), 1)\n    lu.assertEquals(candidate('abc   '), 3)\n    lu.assertEquals(candidate('123 45'), 5)\n    lu.assertEquals(candidate('Hello world ', false), 12)\n    lu.assertEquals(candidate('hi 123'), 5)\n    lu.assertEquals(candidate('hi'), 2)\n    lu.assertEquals(candidate('123 456 7890'), 10)\n    lu.assertEquals(candidate('abc d e '), 5)\n    lu.assertEquals(candidate('Hello'), 5)\n    lu.assertEquals(candidate('12345'), 5)\n    lu.assertEquals(candidate('1234567890'), 10)\n    lu.assertEquals(candidate('abc d e'), 5)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_295406_code_snippet", "language": "lua", "prompt": "-- Change a string-typed code snippet into Markdown-style code fence.\n-- # Argument\n--     snippet: `str`. A code snippet.\n-- # Return\n--     `str`: Markdown-style code fence.\nlocal function code_snippet(snippet)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_295406_code_snippet.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = code_snippet\n    lu.assertEquals(candidate(''), '```python\\n\\n```')\n    lu.assertEquals(candidate('snippet'), '```python\\nsnippet\\n```')\n    lu.assertEquals(candidate('2_snippet'), '```python\\n2_snippet\\n```')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_295538_unchunk", "language": "lua", "prompt": "--     Remove spaces in string.\nlocal function unchunk(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_295538_unchunk.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = unchunk\n    lu.assertEquals(candidate('abc  def'), 'abcdef')\n    lu.assertEquals(candidate('Wonderful'), 'Wonderful')\n    lu.assertEquals(candidate('I   am   a    cat!'), 'Iamacat!')\n    lu.assertEquals(candidate('abc def'), 'abcdef')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_295921_day_to_iso", "language": "lua", "prompt": "--     day to iso format\nlocal function day_to_iso(day)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_295921_day_to_iso.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = day_to_iso\n    lu.assertEquals(candidate({['year'] = 2020, ['month'] = 1, ['day'] = 1}), '2020-1-1')\n    lu.assertEquals(candidate({['year'] = 2020, ['month'] = 1, ['day'] = 31}), '2020-1-31')\n    lu.assertEquals(candidate({['year'] = 2016, ['month'] = 12, ['day'] = 31}), '2016-12-31')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_296478__Indentation", "language": "lua", "prompt": "-- Returns the indentation string.\nlocal function _Indentation(indentation_level)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_296478__Indentation.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _Indentation\n    lu.assertEquals(candidate(-2), '')\n    lu.assertEquals(candidate(1), '    ')\n    lu.assertEquals(candidate(6), '                        ')\n    lu.assertEquals(candidate(8), '                                ')\n    lu.assertEquals(candidate(10), '                                        ')\n    lu.assertEquals(candidate(9), '                                    ')\n    lu.assertEquals(candidate(4), '                ')\n    lu.assertEquals(candidate(1), candidate(1))\n    lu.assertEquals(candidate(7), '                            ')\n    lu.assertEquals(candidate(-1), '')\n    lu.assertEquals(candidate(2), '        ')\n    lu.assertEquals(candidate(5), '                    ')\n    lu.assertEquals(candidate(0), '')\n    lu.assertEquals(candidate(-4), '')\n    lu.assertEquals(candidate(3), '            ')\n    lu.assertEquals(candidate(-3), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_296667_lower_case", "language": "lua", "prompt": "-- Simple function to convert text to lowercase\n-- Used in pipeline as workaround\nlocal function lower_case(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_296667_lower_case.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = lower_case\n    lu.assertEquals(candidate('lower case'), 'lower case')\n    lu.assertEquals(candidate('This is another sentence'), 'this is another sentence')\n    lu.assertEquals(candidate('THIS IS A MIXED CASE STRING'), 'this is a mixed case string')\n    lu.assertEquals(candidate('This is a sentence'), 'this is a sentence')\n    lu.assertEquals(candidate('A new sentence.'), 'a new sentence.')\n    lu.assertEquals(candidate('ANOTHER STRING'), 'another string')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_29671_get_node_flow", "language": "lua", "prompt": "-- Returns the sum of the flow into minus the sum of the flow out from the\n-- node.\n-- In a maximum flow network, this function returns 0 for all nodes except\n-- for the source (wich returns -max_flow) and drain (wich returns max_flow).\nlocal function get_node_flow(flow_net, node)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_29671_get_node_flow.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_node_flow\n    lu.assertEquals(candidate({{0, 1, 1, 0}, {0, 0, 1, 0}, {0, 0, 0, 1}, {0, 0, 0, 0}}, 2), 1)\n    lu.assertEquals(candidate({{0, 0, 0, 0, 0, 0}, {0, 0, 0, 1, 0, 0}, {0, 0, 1, 1, 1, 0}, {0, 0, 1, 0, 1, 0}, {0, 0, 0, 0, 0, 0}, {0, 0, 0, 0, 0, 0}}, 0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_296818_multistep_lr", "language": "lua", "prompt": "-- MultiStep learning rate\nlocal function multistep_lr(lr, milestones, gamma, iters)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_296818_multistep_lr.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = multistep_lr\n    lu.assertEquals(candidate(0.5, {2, 3}, 0.1, 1), 0.5)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_298293_url_to_repo_org", "language": "lua", "prompt": "-- Extract owner and repository from GitHub url.\nlocal function url_to_repo_org(url)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_298293_url_to_repo_org.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = url_to_repo_org\n    lu.assertEquals(candidate('https://github.com/lsst-sqre/templatekit'), {'lsst-sqre', 'templatekit'})\n    lu.assertEquals(candidate('https://github.com/lsst-sqre/nbreport'), {'lsst-sqre', 'nbreport'})\n    lu.assertEquals(candidate('https://github.com/pytorch/pytorch'), {'pytorch', 'pytorch'})\n    lu.assertEquals(candidate('https://github.com/pytorch/vision'), {'pytorch', 'vision'})\n    lu.assertEquals(candidate('https://github.com/pytorch/vision/'), {'pytorch', 'vision'})\n    lu.assertEquals(candidate('https://github.com/fairlearn/fairlearn/blob/master/README.md'), {'fairlearn', 'fairlearn'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_298370_timestamp_seconds", "language": "lua", "prompt": "-- Returns seconds float from value generated by `timestamp`.\nlocal function timestamp_seconds(ts)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_298370_timestamp_seconds.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = timestamp_seconds\n    lu.assertEquals(candidate(0), 0.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_298424_is_sane_slack_webhook", "language": "lua", "prompt": "-- Really basic sanity checking.\nlocal function is_sane_slack_webhook(url)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_298424_is_sane_slack_webhook.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_sane_slack_webhook\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('   '), false)\n    lu.assertEquals(candidate('http://hooks.slack.com'), false)\n    lu.assertEquals(candidate('https://hooks.slack/A/B/C'), false)\n    lu.assertEquals(candidate(None), false)\n    lu.assertEquals(candidate('https://hooks.com/A/B/C'), false)\n    lu.assertEquals(candidate('not a url'), false)\n    lu.assertEquals(candidate('https://hooks.slack.com/services/ABC123/ABC123/ABC123'), true)\n    lu.assertEquals(candidate('https://hooks.com/A/B/C/D'), false)\n    lu.assertEquals(candidate('https://hooks.slack.com/services/A/B/C'), true)\n    lu.assertEquals(candidate('https://hooks.slack/A/B/C/D'), false)\n    lu.assertEquals(candidate('https://hooks.slack.com/services/ABC123/DEF456/XYZ789'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_299447_any", "language": "lua", "prompt": "-- Return True if at least one element is set to True.\n-- This function does not support predicates explicitely,\n-- but this behaviour can be simulated easily using\n-- list comprehension.\n-- >>> any( [False, False, False] )\n-- False\n-- >>> any( [False, True, False] )\n-- True\n-- >>> any( [ x % 2 == 1 for x in [2, 6, 8] ] )\n-- False\n-- >>> any( [ x % 2 == 1 for x in [2, 6, 7] ] )\n-- True\n-- NOTE: Starting from Python 2.5 this a built-in.\nlocal function any(iterable)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_299447_any.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = any\n    lu.assertEquals(candidate({false, false, false}), false)\n    lu.assertEquals(candidate({false, true, false}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_299708_get_command_from_argument", "language": "lua", "prompt": "--  extract command from the command line arguments \nlocal function get_command_from_argument(argv)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_299708_get_command_from_argument.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_command_from_argument\n    lu.assertEquals(candidate({'foo', 'bar'}), 'bar')\n    lu.assertEquals(candidate({'prog', 'subcommand'}), 'subcommand')\n    lu.assertEquals(candidate({'prog', 'subcommand', 'argument'}), 'subcommand')\n    lu.assertEquals(candidate({'/path/to/cli', 'list'}), 'list')\n    lu.assertEquals(candidate({'/path/to/cli', 'list', 'foo'}), 'list')\n    lu.assertEquals(candidate({'foo', 'bar', '-abc'}), 'bar')\n    lu.assertEquals(candidate({'foo', '-abc', 'bar', 'baz'}), 'bar')\n    lu.assertEquals(candidate({'prog', 'subcommand', '--flag'}), 'subcommand')\n    lu.assertEquals(candidate({'/path/to/cli', 'list', 'foo', '--bar'}), 'list')\n    lu.assertEquals(candidate({'/path/to/cli', 'list', '--foo', 'foo'}), 'list')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_300012_solution", "language": "lua", "prompt": "-- Write a function to find the longest common prefix string amongst an array of strings.\n-- If there is no common prefix, return an empty string \"\".\n-- >>> solution(['flower', 'flow', 'flight'])\n-- 'fl'\n-- >>> solution(['dog', 'racecar', 'car'])\n-- ''\n-- >>> solution(['amazing', 'amazingly', 'amazing'])\n-- 'amazing'\n-- >>> solution([])\n-- ''\nlocal function solution(strs)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_300012_solution.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = solution\n    lu.assertEquals(candidate({}), '')\n    lu.assertEquals(candidate({'dog', 'racecar', 'car'}), '')\n    lu.assertEquals(candidate({'amazing', 'amazingly', 'amazing'}), 'amazing')\n    lu.assertEquals(candidate({'amazing', 'amazingly', 'amazing'}), 'amazing')\n    lu.assertEquals(candidate({'flower', 'flow', 'flight'}), 'fl')\n    lu.assertEquals(candidate({'dog', 'racecar', 'car'}), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_300495_previous_month", "language": "lua", "prompt": "--     Returns a tuple of the month prior to the year and month provided.\nlocal function previous_month(year, month)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_300495_previous_month.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = previous_month\n    lu.assertEquals(candidate(2017, 12), {2017, 11})\n    lu.assertEquals(candidate(2018, 1), {2017, 12})\n    lu.assertEquals(candidate(1999, 1), {1998, 12})\n    lu.assertEquals(candidate(2018, 12), {2018, 11})\n    lu.assertEquals(candidate(2017, 1), {2016, 12})\n    lu.assertEquals(candidate(2020, 7), {2020, 6})\n    lu.assertEquals(candidate(2019, 2), {2019, 1})\n    lu.assertEquals(candidate(2000, 2), {2000, 1})\n    lu.assertEquals(candidate(1999, 2), {1999, 1})\n    lu.assertEquals(candidate(2021, 11), {2021, 10})\n    lu.assertEquals(candidate(2016, 1), {2015, 12})\n    lu.assertEquals(candidate(2017, 2), {2017, 1})\n    lu.assertEquals(candidate(2017, 3), {2017, 2})\n    lu.assertEquals(candidate(2012, 12), {2012, 11})\n    lu.assertEquals(candidate(2018, 2), {2018, 1})\n    lu.assertEquals(candidate(2012, 2), {2012, 1})\n    lu.assertEquals(candidate(2016, 12), {2016, 11})\n    lu.assertEquals(candidate(2018, 10), {2018, 9})\n    lu.assertEquals(candidate(2000, 1), {1999, 12})\n    lu.assertEquals(candidate(2020, 1), {2019, 12})\n    lu.assertEquals(candidate(2012, 1), {2011, 12})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_300533_difference_p", "language": "lua", "prompt": "-- Calculate difference between 2 values in percent\nlocal function difference_p(first, second)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_300533_difference_p.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = difference_p\n    lu.assertEquals(candidate(10, 10), 0)\n    lu.assertEquals(candidate(2, 1), 100)\n    lu.assertEquals(candidate(10, 10), 0)\n    lu.assertEquals(candidate(30, 30), 0)\n    lu.assertEquals(candidate(1, 1), 0)\n    lu.assertEquals(candidate(2, 10), 80)\n    lu.assertEquals(candidate(5, 10), 50)\n    lu.assertEquals(candidate(1000, 1000), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_300987_cu_mask_to_int", "language": "lua", "prompt": "--  A utility function that takes an array of booleans and returns an\n-- integer with 1s wherever there was a \"True\" in the array. The value at\n-- index 0 is the least significant bit. \nlocal function cu_mask_to_int(cu_mask)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_300987_cu_mask_to_int.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = cu_mask_to_int\n    lu.assertEquals(candidate({true, true, true, true}), 15)\n    lu.assertEquals(candidate({false, false, false, false}), 0)\n    lu.assertEquals(candidate({true, true, true, false, false, false, false, false}), 7)\n    lu.assertEquals(candidate({true, true, true, true}), 15)\n    lu.assertEquals(candidate({true, false, true, false, false, false, false, false}), 5)\n    lu.assertEquals(candidate({true, true, false, false, false, false, false, false}), 3)\n    lu.assertEquals(candidate({false, false, false, false, false, false, false, false}), 0)\n    lu.assertEquals(candidate({false, false, false, false}), 0)\n    lu.assertEquals(candidate({true, false, false, false, false, false, false, false}), 1)\n    lu.assertEquals(candidate({true, false, false, true}), 9)\n    lu.assertEquals(candidate({true, true, true, true, false, false, false, false}), 15)\n    lu.assertEquals(candidate({true, true, true, true, true, false, false, false}), 31)\n    lu.assertEquals(candidate({true, true, true, true, true, true, false, false}), 63)\n    lu.assertEquals(candidate({false, true, true, false}), 6)\n    lu.assertEquals(candidate({true, true, true, true, true, true, true, false}), 127)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_301359_shift_leftward", "language": "lua", "prompt": "-- Shift positive left, or negative right.  Same as n * 2**nbits\nlocal function shift_leftward(n, nbits)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_301359_shift_leftward.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = shift_leftward\n    lu.assertEquals(candidate(1024, -2), 256)\n    lu.assertEquals(candidate(16, 5), 512)\n    lu.assertEquals(candidate(-1, 2), -4)\n    lu.assertEquals(candidate(128, 4), 2048)\n    lu.assertEquals(candidate(16, 0), 16)\n    lu.assertEquals(candidate(0, 0), 0)\n    lu.assertEquals(candidate(127, 6), 8128)\n    lu.assertEquals(candidate(0, 1), 0)\n    lu.assertEquals(candidate(1024, 0), 1024)\n    lu.assertEquals(candidate(16, 1), 32)\n    lu.assertEquals(candidate(2, 4), 32)\n    lu.assertEquals(candidate(2, -1), 1)\n    lu.assertEquals(candidate(1, 6), 64)\n    lu.assertEquals(candidate(16, 6), 1024)\n    lu.assertEquals(candidate(19088743, 32), 81985526906748928)\n    lu.assertEquals(candidate(-1, 31), -2147483648)\n    lu.assertEquals(candidate(127, 1), 254)\n    lu.assertEquals(candidate(-1, 7), -128)\n    lu.assertEquals(candidate(0, 31), 0)\n    lu.assertEquals(candidate(1, 1), 2)\n    lu.assertEquals(candidate(5, 0), 5)\n    lu.assertEquals(candidate(128, 3), 1024)\n    lu.assertEquals(candidate(16, 9), 8192)\n    lu.assertEquals(candidate(-1, 20), -1048576)\n    lu.assertEquals(candidate(-2, 1), -4)\n    lu.assertEquals(candidate(256, 0), 256)\n    lu.assertEquals(candidate(31, 1), 62)\n    lu.assertEquals(candidate(0, 5), 0)\n    lu.assertEquals(candidate(1, 32), 4294967296)\n    lu.assertEquals(candidate(1, 7), 128)\n    lu.assertEquals(candidate(16, 3), 128)\n    lu.assertEquals(candidate(128, 5), 4096)\n    lu.assertEquals(candidate(1, 5), 32)\n    lu.assertEquals(candidate(1, 63), 9223372036854775808)\n    lu.assertEquals(candidate(256, 2), 1024)\n    lu.assertEquals(candidate(256, 3), 2048)\n    lu.assertEquals(candidate(128, 0), 128)\n    lu.assertEquals(candidate(0, 64), 0)\n    lu.assertEquals(candidate(16, 2), 64)\n    lu.assertEquals(candidate(-2, 0), -2)\n    lu.assertEquals(candidate(2, 7), 256)\n    lu.assertEquals(candidate(128, 2), 512)\n    lu.assertEquals(candidate(2, 0), 2)\n    lu.assertEquals(candidate(-1, 32), -4294967296)\n    lu.assertEquals(candidate(16, -1), 8)\n    lu.assertEquals(candidate(1, 3), 8)\n    lu.assertEquals(candidate(5, 2), 20)\n    lu.assertEquals(candidate(31, 2), 124)\n    lu.assertEquals(candidate(2, 3), 16)\n    lu.assertEquals(candidate(-31, 2), -124)\n    lu.assertEquals(candidate(128, 1), 256)\n    lu.assertEquals(candidate(127, 2), 508)\n    lu.assertEquals(candidate(1, -20), 0)\n    lu.assertEquals(candidate(1024, 10), 1048576)\n    lu.assertEquals(candidate(16, 4), 256)\n    lu.assertEquals(candidate(1, 4), 16)\n    lu.assertEquals(candidate(255, -1), 127)\n    lu.assertEquals(candidate(0, 63), 0)\n    lu.assertEquals(candidate(0, -4), 0)\n    lu.assertEquals(candidate(31, 0), 31)\n    lu.assertEquals(candidate(127, 3), 1016)\n    lu.assertEquals(candidate(-1, -20), -1)\n    lu.assertEquals(candidate(1024, -1), 512)\n    lu.assertEquals(candidate(2, 5), 64)\n    lu.assertEquals(candidate(255, 1), 510)\n    lu.assertEquals(candidate(255, 3), 2040)\n    lu.assertEquals(candidate(-1, 5), -32)\n    lu.assertEquals(candidate(1, 1), 2)\n    lu.assertEquals(candidate(1, 20), 1048576)\n    lu.assertEquals(candidate(1, 0), 1)\n    lu.assertEquals(candidate(0, 32), 0)\n    lu.assertEquals(candidate(0, 3), 0)\n    lu.assertEquals(candidate(-128, 0), -128)\n    lu.assertEquals(candidate(-1, 1), -2)\n    lu.assertEquals(candidate(0, 4), 0)\n    lu.assertEquals(candidate(0, 4), 0)\n    lu.assertEquals(candidate(-1, 0), -1)\n    lu.assertEquals(candidate(-1, 63), -9223372036854775808)\n    lu.assertEquals(candidate(16, 10), 16384)\n    lu.assertEquals(candidate(2, 2), 8)\n    lu.assertEquals(candidate(1024, -3), 128)\n    lu.assertEquals(candidate(-1, 4), -16)\n    lu.assertEquals(candidate(255, 0), 255)\n    lu.assertEquals(candidate(125, 0), 125)\n    lu.assertEquals(candidate(2, 6), 128)\n    lu.assertEquals(candidate(0, 2), 0)\n    lu.assertEquals(candidate(2, 0), 2)\n    lu.assertEquals(candidate(127, 4), 2032)\n    lu.assertEquals(candidate(10, 4), 160)\n    lu.assertEquals(candidate(16, 7), 2048)\n    lu.assertEquals(candidate(0, -3), 0)\n    lu.assertEquals(candidate(15, 0), 15)\n    lu.assertEquals(candidate(1, 64), 18446744073709551616)\n    lu.assertEquals(candidate(16, 8), 4096)\n    lu.assertEquals(candidate(127, 5), 4064)\n    lu.assertEquals(candidate(1024, 1), 2048)\n    lu.assertEquals(candidate(-1, 6), -64)\n    lu.assertEquals(candidate(1, 0), 1)\n    lu.assertEquals(candidate(-31, 0), -31)\n    lu.assertEquals(candidate(1, 2), 4)\n    lu.assertEquals(candidate(0, 0), 0)\n    lu.assertEquals(candidate(1, 4), 16)\n    lu.assertEquals(candidate(0, 1), 0)\n    lu.assertEquals(candidate(1, 31), 2147483648)\n    lu.assertEquals(candidate(255, 2), 1020)\n    lu.assertEquals(candidate(-2, 2), -8)\n    lu.assertEquals(candidate(-125, 0), -125)\n    lu.assertEquals(candidate(2, 1), 4)\n    lu.assertEquals(candidate(-31, 1), -62)\n    lu.assertEquals(candidate(31, 3), 248)\n    lu.assertEquals(candidate(256, 1), 512)\n    lu.assertEquals(candidate(1, -1), 0)\n    lu.assertEquals(candidate(2, 1), 4)\n    lu.assertEquals(candidate(-31, 3), -248)\n    lu.assertEquals(candidate(2, 4), 32)\n    lu.assertEquals(candidate(128, 6), 8192)\n    lu.assertEquals(candidate(16, -2), 4)\n    lu.assertEquals(candidate(-1, 3), -8)\n    lu.assertEquals(candidate(127, 0), 127)\n    lu.assertEquals(candidate(128, -1), 64)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_301474__string_lower", "language": "lua", "prompt": "-- Convenience function to lowercase a string.\n-- :param string:\n--     The string which will be lower-cased.\n-- :returns:\n--     Lower-cased copy of string s.\nlocal function _string_lower(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_301474__string_lower.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _string_lower\n    lu.assertEquals(candidate('HELLO'), 'hello')\n    lu.assertEquals(candidate('Hello'), 'hello')\n    lu.assertEquals(candidate('HELLO WORLD'), 'hello world')\n    lu.assertEquals(candidate('hello world'), 'hello world')\n    lu.assertEquals(candidate('hello     world'), 'hello     world')\n    lu.assertEquals(candidate('HeLlO wOrLd'), 'hello world')\n    lu.assertEquals(candidate('hello'), 'hello')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_301724_suffixer", "language": "lua", "prompt": "--     Provides the suffix for printing out a podium spot based on the spot number.\nlocal function suffixer(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_301724_suffixer.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = suffixer\n    lu.assertEquals(candidate(1113), 'th')\n    lu.assertEquals(candidate(3), 'rd')\n    lu.assertEquals(candidate(14), 'th')\n    lu.assertEquals(candidate(30), 'th')\n    lu.assertEquals(candidate(6), 'th')\n    lu.assertEquals(candidate(9), 'th')\n    lu.assertEquals(candidate(10), 'th')\n    lu.assertEquals(candidate(111), 'th')\n    lu.assertEquals(candidate(28), 'th')\n    lu.assertEquals(candidate(1115), 'th')\n    lu.assertEquals(candidate(1114), 'th')\n    lu.assertEquals(candidate(11), 'th')\n    lu.assertEquals(candidate(4), 'th')\n    lu.assertEquals(candidate(12), 'th')\n    lu.assertEquals(candidate(16), 'th')\n    lu.assertEquals(candidate(18), 'th')\n    lu.assertEquals(candidate(1112), 'th')\n    lu.assertEquals(candidate(25), 'th')\n    lu.assertEquals(candidate(17), 'th')\n    lu.assertEquals(candidate(27), 'th')\n    lu.assertEquals(candidate(1), 'st')\n    lu.assertEquals(candidate(15), 'th')\n    lu.assertEquals(candidate(2), 'nd')\n    lu.assertEquals(candidate(7), 'th')\n    lu.assertEquals(candidate(29), 'th')\n    lu.assertEquals(candidate(1011), 'th')\n    lu.assertEquals(candidate(8), 'th')\n    lu.assertEquals(candidate(1111), 'th')\n    lu.assertEquals(candidate(19), 'th')\n    lu.assertEquals(candidate(24), 'th')\n    lu.assertEquals(candidate(34), 'th')\n    lu.assertEquals(candidate(20), 'th')\n    lu.assertEquals(candidate(5), 'th')\n    lu.assertEquals(candidate(13), 'th')\n    lu.assertEquals(candidate(26), 'th')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_303347_fake_headers", "language": "lua", "prompt": "--     Bricklink does referrer and user-agent checks so we need to fake those.\nlocal function fake_headers(url)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_303347_fake_headers.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fake_headers\n    lu.assertEquals(candidate('https://www.bricklink.com/catalogPG.asp?catID=25&colorID=5&page=4'), {['referrer'] = 'https://www.bricklink.com/catalogPG.asp?catID=25&colorID=5&page=4', ['User-agent'] = 'Mozilla/5.0'})\n    lu.assertEquals(candidate('https://www.bricklink.com/v2/api/register_consumer.page'), {['referrer'] = 'https://www.bricklink.com/v2/api/register_consumer.page', ['User-agent'] = 'Mozilla/5.0'})\n    lu.assertEquals(candidate(''), {['referrer'] = '', ['User-agent'] = 'Mozilla/5.0'})\n    lu.assertEquals(candidate('https://www.bricklink.com/catalogPG.asp?catID=25&colorID=5&page=1'), {['referrer'] = 'https://www.bricklink.com/catalogPG.asp?catID=25&colorID=5&page=1', ['User-agent'] = 'Mozilla/5.0'})\n    lu.assertEquals(candidate('https://www.bricklink.com/catalogPG.asp?catID=25&colorID=5&page=3'), {['referrer'] = 'https://www.bricklink.com/catalogPG.asp?catID=25&colorID=5&page=3', ['User-agent'] = 'Mozilla/5.0'})\n    lu.assertEquals(candidate('https://example.com'), {['referrer'] = 'https://example.com', ['User-agent'] = 'Mozilla/5.0'})\n    lu.assertEquals(candidate('https://www.bricklink.com/catalogPG.asp?catID=25&colorID=5&page=2'), {['referrer'] = 'https://www.bricklink.com/catalogPG.asp?catID=25&colorID=5&page=2', ['User-agent'] = 'Mozilla/5.0'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_303816__ps", "language": "lua", "prompt": "--  Convenience function for score printing\nlocal function _ps(score)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_303816__ps.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _ps\n    lu.assertEquals(candidate(0.0), '0.000')\n    lu.assertEquals(candidate(0.001234), '0.001')\n    lu.assertEquals(candidate(0.0012349), '0.001')\n    lu.assertEquals(candidate(0.0012345), '0.001')\n    lu.assertEquals(candidate(0.1234), '0.123')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_304953_common_prefix_length", "language": "lua", "prompt": "-- Determine the common prefix of two strings.\n-- Args:\n--     text1: First string.\n--     text2: Second string.\n-- Returns:\n--     The number of characters common to the start of each string.\nlocal function common_prefix_length(text1, text2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_304953_common_prefix_length.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = common_prefix_length\n    lu.assertEquals(candidate('abc', 'abc'), 3)\n    lu.assertEquals(candidate('ab', 'abc'), 2)\n    lu.assertEquals(candidate('aa', 'a'), 1)\n    lu.assertEquals(candidate('abc', 'abcabc'), 3)\n    lu.assertEquals(candidate('abc', 'a'), 1)\n    lu.assertEquals(candidate('', ''), 0)\n    lu.assertEquals(candidate('', ''), 0)\n    lu.assertEquals(candidate('abc', 'ab'), 2)\n    lu.assertEquals(candidate('abc', 'ab'), 2)\n    lu.assertEquals(candidate('abc', 'xabc'), 0)\n    lu.assertEquals(candidate('abc', 'ab'), 2)\n    lu.assertEquals(candidate('abc', 'abc'), 3)\n    lu.assertEquals(candidate('a', 'b'), 0)\n    lu.assertEquals(candidate('abc', 'abd'), 2)\n    lu.assertEquals(candidate('a', 'aa'), 1)\n    lu.assertEquals(candidate('abc', ''), 0)\n    lu.assertEquals(candidate('aaa', 'aaa'), 3)\n    lu.assertEquals(candidate('aaaa', 'aaaa'), 4)\n    lu.assertEquals(candidate('', ''), 0)\n    lu.assertEquals(candidate('abcd', 'abc'), 3)\n    lu.assertEquals(candidate('a', 'a'), 1)\n    lu.assertEquals(candidate('a', 'abc'), 1)\n    lu.assertEquals(candidate('abc', 'abbc'), 2)\n    lu.assertEquals(candidate('xabc', 'abc'), 0)\n    lu.assertEquals(candidate('abc', 'abcx'), 3)\n    lu.assertEquals(candidate('abc', ''), 0)\n    lu.assertEquals(candidate('ab', 'abc'), 2)\n    lu.assertEquals(candidate('aaa', 'a'), 1)\n    lu.assertEquals(candidate('abc', 'abcd'), 3)\n    lu.assertEquals(candidate('a', 'a'), 1)\n    lu.assertEquals(candidate('abc', 'abcd'), 3)\n    lu.assertEquals(candidate('a', 'aaa'), 1)\n    lu.assertEquals(candidate('abc', 'abc'), 3)\n    lu.assertEquals(candidate('abc', 'abcx'), 3)\n    lu.assertEquals(candidate('ab', 'abc'), 2)\n    lu.assertEquals(candidate('abc', 'a'), 1)\n    lu.assertEquals(candidate('abcx', 'abc'), 3)\n    lu.assertEquals(candidate('', 'abc'), 0)\n    lu.assertEquals(candidate('abc', 'xabc'), 0)\n    lu.assertEquals(candidate('', 'abc'), 0)\n    lu.assertEquals(candidate('ab', 'ab'), 2)\n    lu.assertEquals(candidate('abc', 'abcd'), 3)\n    lu.assertEquals(candidate('a', 'abc'), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_305196_count_words", "language": "lua", "prompt": "--  dirty code for count word \nlocal function count_words(content)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_305196_count_words.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = count_words\n    lu.assertEquals(candidate('Python is a programming language and is fun to learn'), 10)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_305323_string_to_ascii_html", "language": "lua", "prompt": "-- Convert unicode chars of str to HTML entities if chars are not ASCII.\nlocal function string_to_ascii_html(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_305323_string_to_ascii_html.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = string_to_ascii_html\n    lu.assertEquals(candidate('abc'), 'abc')\n    lu.assertEquals(candidate('hello world'), 'hello world')\n    lu.assertEquals(candidate('123'), '123')\n    lu.assertEquals(candidate('Hello \u4f60\u597d World'), 'Hello &#20320;&#22909; World')\n    lu.assertEquals(candidate('\ud83d\udc18'), '&#128024;')\n    lu.assertEquals(candidate('123 abc ABC'), '123 abc ABC')\n    lu.assertEquals(candidate('Hello World'), 'Hello World')\n    lu.assertEquals(candidate('ABC'), 'ABC')\n    lu.assertEquals(candidate('This is a test.'), 'This is a test.')\n    lu.assertEquals(candidate('ABC 123'), 'ABC 123')\n    lu.assertEquals(candidate('123 abc ABC 123'), '123 abc ABC 123')\n    lu.assertEquals(candidate('a'), 'a')\n    lu.assertEquals(candidate('Hello World!'), 'Hello World!')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_305496__hex_to_char", "language": "lua", "prompt": "--  '61' => 'a' \nlocal function _hex_to_char(chr_pair)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_305496__hex_to_char.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _hex_to_char\n    lu.assertEquals(candidate('7e'), '~')\n    lu.assertEquals(candidate('01'), '\\x01')\n    lu.assertEquals(candidate('00'), '\\x00')\n    lu.assertEquals(candidate('61'), 'a')\n    lu.assertEquals(candidate('02'), '\\x02')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_305558_make_shard_files", "language": "lua", "prompt": "--  Make sharding files when shard_equal_rows is False. \nlocal function make_shard_files(dataset_files, num_shards, shard_id)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_305558_make_shard_files.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = make_shard_files\n    lu.assertEquals(candidate({'dataset_file1.csv', 'dataset_file2.csv', 'dataset_file3.csv'}, 2, 1), {{'dataset_file2.csv', -1, -1, true}})\n    lu.assertEquals(candidate({'dataset_file1.csv', 'dataset_file2.csv', 'dataset_file3.csv'}, 3, 2), {{'dataset_file3.csv', -1, -1, true}})\n    lu.assertEquals(candidate({'dataset_file1.csv', 'dataset_file2.csv', 'dataset_file3.csv'}, 3, 0), {{'dataset_file1.csv', -1, -1, true}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_305605_idx2off", "language": "lua", "prompt": "--  Produces [0, 32, 64,   88, 120, 152,   176, 208, 240,   264, 296, 328]\n-- These are the byte offsets when dividing into 44-coeff chunks\nlocal function idx2off(i)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_305605_idx2off.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = idx2off\n    lu.assertEquals(candidate(13), 384)\n    lu.assertEquals(candidate(1), 32)\n    lu.assertEquals(candidate(14), 416)\n    lu.assertEquals(candidate(9), 264)\n    lu.assertEquals(candidate(10), 296)\n    lu.assertEquals(candidate(3), 88)\n    lu.assertEquals(candidate(12), 352)\n    lu.assertEquals(candidate(11), 328)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(5), 152)\n    lu.assertEquals(candidate(4), 120)\n    lu.assertEquals(candidate(7), 208)\n    lu.assertEquals(candidate(6), 176)\n    lu.assertEquals(candidate(2), 64)\n    lu.assertEquals(candidate(8), 240)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_305774_translate", "language": "lua", "prompt": "-- Translate vector(x,y) by (dx,dy).\nlocal function translate(x, y, dx, dy)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_305774_translate.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = translate\n    lu.assertEquals(candidate(100, 200, 10, -10), {110, 190})\n    lu.assertEquals(candidate(-100, 200, 10, -10), {-90, 190})\n    lu.assertEquals(candidate(2, 2, 1, 0), {3, 2})\n    lu.assertEquals(candidate(100, 200, -10, 10), {90, 210})\n    lu.assertEquals(candidate(2, 2, 1, 1), {3, 3})\n    lu.assertEquals(candidate(-1, -2, 2, -2), {1, -4})\n    lu.assertEquals(candidate(0, 0, 1, 1), {1, 1})\n    lu.assertEquals(candidate(1, 1, 1, 0), {2, 1})\n    lu.assertEquals(candidate(0, 0, 10, -10), {10, -10})\n    lu.assertEquals(candidate(0, 0, -10, 10), {-10, 10})\n    lu.assertEquals(candidate(1, 1, 0, 0), {1, 1})\n    lu.assertEquals(candidate(100, 200, 10, 10), {110, 210})\n    lu.assertEquals(candidate(0, 0, 0, 0), {0, 0})\n    lu.assertEquals(candidate(0, 0, 10, 10), {10, 10})\n    lu.assertEquals(candidate(0, 1, 0, 0), {0, 1})\n    lu.assertEquals(candidate(0, 1, 0, 2), {0, 3})\n    lu.assertEquals(candidate(0, 0, 0, 0), {0, 0})\n    lu.assertEquals(candidate(1, 0, 0, 2), {1, 2})\n    lu.assertEquals(candidate(100, 200, -10, -10), {90, 190})\n    lu.assertEquals(candidate(-100, 200, 10, 10), {-90, 210})\n    lu.assertEquals(candidate(1, 0, 2, 0), {3, 0})\n    lu.assertEquals(candidate(-1, -1, 1, 1), {0, 0})\n    lu.assertEquals(candidate(2, 2, 0, 1), {2, 3})\n    lu.assertEquals(candidate(1, 2, 0, 0), {1, 2})\n    lu.assertEquals(candidate(1, 2, 3, 4), {4, 6})\n    lu.assertEquals(candidate(0, 1, 2, 0), {2, 1})\n    lu.assertEquals(candidate(0, 0, -10, -10), {-10, -10})\n    lu.assertEquals(candidate(1, 2, 2, -2), {3, 0})\n    lu.assertEquals(candidate(-100, 200, -10, 10), {-110, 210})\n    lu.assertEquals(candidate(2, 2, 0, 0), {2, 2})\n    lu.assertEquals(candidate(1, 1, 1, 1), {2, 2})\n    lu.assertEquals(candidate(-100, 200, -10, -10), {-110, 190})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_306162_get_target_delta", "language": "lua", "prompt": "-- Generate target delta given the size of a dataset. Delta should be\n-- less than the inverse of the datasize.\n-- Parameters\n-- ----------\n-- data_size : int\n--     The size of the dataset.\n-- Returns\n-- -------\n-- float\n--     The target delta value.\nlocal function get_target_delta(data_size)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_306162_get_target_delta.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_target_delta\n    lu.assertEquals(candidate(10000000), 1e-08)\n    lu.assertEquals(candidate(1), 0.1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_306499_getKmers", "language": "lua", "prompt": "-- Generate k-mers of size k\nlocal function getKmers(k, bases)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_306499_getKmers.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = getKmers\n    lu.assertEquals(candidate(1, 'ACGT'), {'A', 'C', 'G', 'T'})\n    lu.assertEquals(candidate(2, 'ACGT'), {'AA', 'AC', 'AG', 'AT', 'CA', 'CC', 'CG', 'CT', 'GA', 'GC', 'GG', 'GT', 'TA', 'TC', 'TG', 'TT'})\n    lu.assertEquals(candidate(3, 'ACGT'), {'AAA', 'AAC', 'AAG', 'AAT', 'ACA', 'ACC', 'ACG', 'ACT', 'AGA', 'AGC', 'AGG', 'AGT', 'ATA', 'ATC', 'ATG', 'ATT', 'CAA', 'CAC', 'CAG', 'CAT', 'CCA', 'CCC', 'CCG', 'CCT', 'CGA', 'CGC', 'CGG', 'CGT', 'CTA', 'CTC', 'CTG', 'CTT', 'GAA', 'GAC', 'GAG', 'GAT', 'GCA', 'GCC', 'GCG', 'GCT', 'GGA', 'GGC', 'GGG', 'GGT', 'GTA', 'GTC', 'GTG', 'GTT', 'TAA', 'TAC', 'TAG', 'TAT', 'TCA', 'TCC', 'TCG', 'TCT', 'TGA', 'TGC', 'TGG', 'TGT', 'TTA', 'TTC', 'TTG', 'TTT'})\n    lu.assertEquals(candidate(2, 'ACGT'), {'AA', 'AC', 'AG', 'AT', 'CA', 'CC', 'CG', 'CT', 'GA', 'GC', 'GG', 'GT', 'TA', 'TC', 'TG', 'TT'})\n    lu.assertEquals(candidate(1, 'A'), {'A'})\n    lu.assertEquals(candidate(1, 'ATCGT'), {'A', 'T', 'C', 'G', 'T'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_306534_alphabetical", "language": "lua", "prompt": "--  Sorts a list of tuples in reverse alphabetical order by the first key\n-- in the tuple.\n-- Arguments:\n-- lst -- the list to sort\n-- Returns:\n-- the sorted list\nlocal function alphabetical(lst)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_306534_alphabetical.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = alphabetical\n    lu.assertEquals(candidate({{'a', 1}, {'a', 2}, {'a', 3}, {'a', 4}, {'a', 5}, {'a', 6}, {'a', 7}, {'a', 8}, {'a', 9}, {'a', 10}}), {{'a', 10}, {'a', 9}, {'a', 8}, {'a', 7}, {'a', 6}, {'a', 5}, {'a', 4}, {'a', 3}, {'a', 2}, {'a', 1}})\n    lu.assertEquals(candidate(list()), list())\n    lu.assertEquals(candidate({{'a', 1}, {'b', 2}, {'c', 3}, {'d', 4}, {'e', 5}, {'f', 6}, {'g', 7}, {'h', 8}, {'i', 9}, {'j', 10}}), {{'j', 10}, {'i', 9}, {'h', 8}, {'g', 7}, {'f', 6}, {'e', 5}, {'d', 4}, {'c', 3}, {'b', 2}, {'a', 1}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_307233_toWidthHeightInverse", "language": "lua", "prompt": "--  Transforms from [w, h, x, y] to [x0,y0,x1,y1] format\nlocal function toWidthHeightInverse(wh)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_307233_toWidthHeightInverse.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = toWidthHeightInverse\n    lu.assertEquals(candidate({2, 2, 1, 1}), {0, 0, 1, 1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_307309_binV2_to_A2", "language": "lua", "prompt": "--     Used to convert SII(t)[bin_V**2] to SII(t)[A**2]\nlocal function binV2_to_A2(S2, R_acq, mv_per_bin)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_307309_binV2_to_A2.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = binV2_to_A2\n    lu.assertEquals(candidate(0, 1, 1), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_307930_find_all", "language": "lua", "prompt": "-- returns a list of locations where substr occurs in searchin\n-- locations are not allowed to overlap\nlocal function find_all(searchin, substr)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_307930_find_all.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = find_all\n    lu.assertEquals(candidate('aa', 'aaaa'), {})\n    lu.assertEquals(candidate('abracadabra', 'bra'), {1, 8})\n    lu.assertEquals(candidate('a a a a a a a a a', 'b'), {})\n    lu.assertEquals(candidate('aa', 'a'), {0, 1})\n    lu.assertEquals(candidate('a', 'a'), {0})\n    lu.assertEquals(candidate('', 'a'), {})\n    lu.assertEquals(candidate('aaa', 'aaaaaaa'), {})\n    lu.assertEquals(candidate('abcdefghijklmnopqrstuvwxyz', 'xyz'), {23})\n    lu.assertEquals(candidate('aa', 'aabbaa'), {})\n    lu.assertEquals(candidate('aaaa', 'aa'), {0, 2})\n    lu.assertEquals(candidate('', 'x'), {})\n    lu.assertEquals(candidate('a', 'aa'), {})\n    lu.assertEquals(candidate('abcde', 'cde'), {2})\n    lu.assertEquals(candidate('123456', '0'), {})\n    lu.assertEquals(candidate('aaa', 'a'), {0, 1, 2})\n    lu.assertEquals(candidate('a', 'aaa'), {})\n    lu.assertEquals(candidate('x    y', 'x'), {0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_308818_event_independence_check", "language": "lua", "prompt": "-- Checks if two events are independent.\n-- This function accepts the probability of 2 events and their joint probability.\n-- And prints if the events are independent or not.\n-- Keyword arguments:\n-- prob_event1 -- probability of event1\n-- prob_event2 -- probability of event2\n-- prob_event1_event2 -- probability of event1 and event2\nlocal function event_independence_check(prob_event1, prob_event2, prob_event1_event2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_308818_event_independence_check.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = event_independence_check\n    lu.assertEquals(candidate(0.33, 0.67, 0.19), false)\n    lu.assertEquals(candidate(0.3, 0.6, 0.132), false)\n    lu.assertEquals(candidate(0.2, 0.8, 0.08), false)\n    lu.assertEquals(candidate(0.25, 0.75, 0.2), false)\n    lu.assertEquals(candidate(0.5, 0.5, 0.25), true)\n    lu.assertEquals(candidate(0.3, 0.6, 0.054), false)\n    lu.assertEquals(candidate(0.9, 0.7, 0.635), false)\n    lu.assertEquals(candidate(0.6, 0.6, 0.36), true)\n    lu.assertEquals(candidate(0.2, 0.6, 0.096), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_309108_deserialize_sanitizer_options", "language": "lua", "prompt": "-- Read options from a variable like ASAN_OPTIONS into a dict.\nlocal function deserialize_sanitizer_options(options)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_309108_deserialize_sanitizer_options.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = deserialize_sanitizer_options\n    lu.assertEquals(candidate('handle_segv=1'), {['handle_segv'] = '1'})\n    lu.assertEquals(candidate('handle_segv=1:detect_stack_use_after_return=1'), {['handle_segv'] = '1', ['detect_stack_use_after_return'] = '1'})\n    lu.assertEquals(candidate('foo=bar:baz=123'), {['foo'] = 'bar', ['baz'] = '123'})\n    lu.assertEquals(candidate('allocator_may_return_null=1'), {['allocator_may_return_null'] = '1'})\n    lu.assertEquals(candidate('detect_leaks=0'), {['detect_leaks'] = '0'})\n    lu.assertEquals(candidate('handle_segv=1'), {['handle_segv'] = '1'})\n    lu.assertEquals(candidate('detect_odr_violation=0'), {['detect_odr_violation'] = '0'})\n    lu.assertEquals(candidate('strict_memcmp=1:detect_leaks=0:allocator_may_return_null=1'), {['strict_memcmp'] = '1', ['detect_leaks'] = '0', ['allocator_may_return_null'] = '1'})\n    lu.assertEquals(candidate('allow_user_segv_handler=0'), {['allow_user_segv_handler'] = '0'})\n    lu.assertEquals(candidate('detect_leaks=0:allocator_may_return_null=1'), {['detect_leaks'] = '0', ['allocator_may_return_null'] = '1'})\n    lu.assertEquals(candidate('allocator_may_return_null=1'), {['allocator_may_return_null'] = '1'})\n    lu.assertEquals(candidate('detect_stack_use_after_return=1'), {['detect_stack_use_after_return'] = '1'})\n    lu.assertEquals(candidate('detect_leaks=0:handle_segv=1'), {['detect_leaks'] = '0', ['handle_segv'] = '1'})\n    lu.assertEquals(candidate('print_suppressions=1'), {['print_suppressions'] = '1'})\n    lu.assertEquals(candidate('detect_stack_use_after_return=1:handle_segv=1'), {['detect_stack_use_after_return'] = '1', ['handle_segv'] = '1'})\n    lu.assertEquals(candidate('detect_leaks=0'), {['detect_leaks'] = '0'})\n    lu.assertEquals(candidate('detect_leaks=0'), {['detect_leaks'] = '0'})\n    lu.assertEquals(candidate('detect_leaks=1'), {['detect_leaks'] = '1'})\n    lu.assertEquals(candidate('detect_leaks=1:allocator_may_return_null=0'), {['detect_leaks'] = '1', ['allocator_may_return_null'] = '0'})\n    lu.assertEquals(candidate('coverage=1:coverage_dir=/somewhere'), {['coverage'] = '1', ['coverage_dir'] = '/somewhere'})\n    lu.assertEquals(candidate('print_suppressions=0'), {['print_suppressions'] = '0'})\n    lu.assertEquals(candidate('detect_leaks=0:handle_segv=1:detect_stack_use_after_return=1'), {['detect_leaks'] = '0', ['handle_segv'] = '1', ['detect_stack_use_after_return'] = '1'})\n    lu.assertEquals(candidate('handle_sigbus=1'), {['handle_sigbus'] = '1'})\n    lu.assertEquals(candidate('detect_leaks=0:detect_leaks=1'), {['detect_leaks'] = '1'})\n    lu.assertEquals(candidate('allocator_may_return_null=0'), {['allocator_may_return_null'] = '0'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_310088_indentation_value", "language": "lua", "prompt": "-- Given an indentation string of spaces and tabs,\n-- returns the equivalent number of spaces per Python\n-- indentation rule.\nlocal function indentation_value(spaces)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_310088_indentation_value.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = indentation_value\n    lu.assertEquals(candidate('      '), 6)\n    lu.assertEquals(candidate('        '), 8)\n    lu.assertEquals(candidate('    '), 4)\n    lu.assertEquals(candidate('\\t'), 8)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('        '), 8)\n    lu.assertEquals(candidate('  '), 2)\n    lu.assertEquals(candidate('  '), 2)\n    lu.assertEquals(candidate('    '), 4)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_3108_lines_in_file", "language": "lua", "prompt": "-- Count the number of lines in a file\n-- :param filename: A string containing the relative or absolute path to a file\n-- :returns: The number of lines in the file\nlocal function lines_in_file(filename)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_3108_lines_in_file.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = lines_in_file\n    lu.assertEquals(candidate('no_such_file'), 0)\n    lu.assertEquals(candidate('no_such_file'), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_312017_deserialize_datetime", "language": "lua", "prompt": "-- Deserializes string to datetime.\n-- The string should be in iso8601 datetime format.\n-- :param string: str.\n-- :type string: str\n-- :return: datetime.\n-- :rtype: datetime\nlocal function deserialize_datetime(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_312017_deserialize_datetime.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = deserialize_datetime\n    lu.assertEquals(candidate('2018-01-01T12:34:56'), '2018-01-01T12:34:56')\n    lu.assertEquals(candidate('2018-01-01T12:34:56.123456-01:00'), '2018-01-01T12:34:56.123456-01:00')\n    lu.assertEquals(candidate('2018-01-01T12:34:56.123456Z'), '2018-01-01T12:34:56.123456Z')\n    lu.assertEquals(candidate('2018-01-01T12:34:56Z'), '2018-01-01T12:34:56Z')\n    lu.assertEquals(candidate('2018-01-01T12:34:56.123456'), '2018-01-01T12:34:56.123456')\n    lu.assertEquals(candidate('2018-01-01T12:34:56.123456-01:00Z'), '2018-01-01T12:34:56.123456-01:00Z')\n    lu.assertEquals(candidate(None), None)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_312491_unsignedIntegerToBytes", "language": "lua", "prompt": "-- Converts an unsigned integer into a sequence of bytes, LSB first.\n-- integer -- the number to be converted\n-- numbytes -- the number of bytes to be used in representing the integer\nlocal function unsignedIntegerToBytes(integer, numbytes)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_312491_unsignedIntegerToBytes.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = unsignedIntegerToBytes\n    lu.assertEquals(candidate(0, 2), {0, 0})\n    lu.assertEquals(candidate(65535, 3), {255, 255, 0})\n    lu.assertEquals(candidate(0, 3), {0, 0, 0})\n    lu.assertEquals(candidate(255, 1), {255})\n    lu.assertEquals(candidate(0, 4), {0, 0, 0, 0})\n    lu.assertEquals(candidate(0, 1), {0})\n    lu.assertEquals(candidate(1, 1), {1})\n    lu.assertEquals(candidate(257, 2), {1, 1})\n    lu.assertEquals(candidate(256, 4), {0, 1, 0, 0})\n    lu.assertEquals(candidate(1, 2), {1, 0})\n    lu.assertEquals(candidate(257, 4), {1, 1, 0, 0})\n    lu.assertEquals(candidate(42, 2), {42, 0})\n    lu.assertEquals(candidate(4294967295, 4), {255, 255, 255, 255})\n    lu.assertEquals(candidate(256, 3), {0, 1, 0})\n    lu.assertEquals(candidate(256, 2), {0, 1})\n    lu.assertEquals(candidate(65536, 4), {0, 0, 1, 0})\n    lu.assertEquals(candidate(257, 3), {1, 1, 0})\n    lu.assertEquals(candidate(1, 3), {1, 0, 0})\n    lu.assertEquals(candidate(65537, 4), {1, 0, 1, 0})\n    lu.assertEquals(candidate(65535, 2), {255, 255})\n    lu.assertEquals(candidate(1, 4), {1, 0, 0, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_314698_is_non_negative", "language": "lua", "prompt": "-- Check if the input dictionary values are non negative.\n-- Args:\n--     input_dict (dict): dictionary.\n-- Returns:\n--     bool: boolean variable indicating whether dict values are non negative or not.\nlocal function is_non_negative(input_dict)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_314698_is_non_negative.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_non_negative\n    lu.assertEquals(candidate({[1] = 1, [2] = 2}), true)\n    lu.assertEquals(candidate({[1] = 1, [2] = 2, [3] = -3, [4] = 4}), false)\n    lu.assertEquals(candidate({[1] = 1, [2] = 2, [3] = -3}), false)\n    lu.assertEquals(candidate({}), true)\n    lu.assertEquals(candidate({[1] = 1}), true)\n    lu.assertEquals(candidate({[1] = 1, [2] = 2, [3] = 3}), true)\n    lu.assertEquals(candidate({[1] = 1, [2] = 2, [3] = -3, [4] = -4}), false)\n    lu.assertEquals(candidate({[1] = 1, [2] = 2, [3] = 3, [4] = 4}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_315387_num_desc_seq_given_total_and_head", "language": "lua", "prompt": "-- Subproblem in dynamic programming.\n-- Count the number of descending sequences given a total and the head.\n-- Note that a one-term sequence is also considered a sequence.\nlocal function num_desc_seq_given_total_and_head(total, head)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_315387_num_desc_seq_given_total_and_head.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = num_desc_seq_given_total_and_head\n    lu.assertEquals(candidate(5, 25), 0)\n    lu.assertEquals(candidate(10, 10), 1)\n    lu.assertEquals(candidate(2, 3), 0)\n    lu.assertEquals(candidate(4, 3), 1)\n    lu.assertEquals(candidate(2, 1), 1)\n    lu.assertEquals(candidate(5, 3), 2)\n    lu.assertEquals(candidate(4, 30), 0)\n    lu.assertEquals(candidate(1, 1), 1)\n    lu.assertEquals(candidate(4, 7), 0)\n    lu.assertEquals(candidate(1, 2), 0)\n    lu.assertEquals(candidate(4, 2), 2)\n    lu.assertEquals(candidate(3, 2), 1)\n    lu.assertEquals(candidate(10, 100), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_316104_fontname", "language": "lua", "prompt": "--  Sets the current font used when drawing text.\nlocal function fontname(name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_316104_fontname.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fontname\n    lu.assertEquals(candidate('Arial'), 'Arial')\n    lu.assertEquals(candidate('Helvetica'), 'Helvetica')\n    lu.assertEquals(candidate('Arial'), 'Arial')\n    lu.assertEquals(candidate('Courier'), 'Courier')\n    lu.assertEquals(candidate('Times-Roman'), 'Times-Roman')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_316766_get_flowcell_name_from_desc", "language": "lua", "prompt": "-- Get the flowcell name from the description\n-- Parameters\n-- ----------\n-- description_dict: dict\n--     A parsed dictionary created from the description from the fastq record\n-- user_run_name: str\n--     The user run name that we have been given on the command line\n-- Returns\n-- -------\n-- flowcell_name: str\n--     The flowcell name that we are gonna be using\nlocal function get_flowcell_name_from_desc(description_dict, user_run_name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_316766_get_flowcell_name_from_desc.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_flowcell_name_from_desc\n    lu.assertEquals(candidate({}, 'my_run'), 'my_run')\n    lu.assertEquals(candidate({}, 'foo'), 'foo')\n    lu.assertEquals(candidate({['sampleid'] = 'ABCD1234'}, 'ignored'), 'ABCD1234')\n    lu.assertEquals(candidate({['flow_cell_id'] = '1234'}, 'ignored'), '1234')\n    lu.assertEquals(candidate({['sampleid'] = 'foo'}, 'bar'), 'foo')\n    lu.assertEquals(candidate({['flow_cell_id'] = 'AB12345'}, None), 'AB12345')\n    lu.assertEquals(candidate({['sample_id'] = 'ABCD1234'}, 'ignored'), 'ABCD1234')\n    lu.assertEquals(candidate({['flow_cell_id'] = '12345', ['sample_id'] = '54321', ['sampleid'] = '55555'}, 'user_run_name'), '12345')\n    lu.assertEquals(candidate({}, 'user_run_name'), 'user_run_name')\n    lu.assertEquals(candidate({['flow_cell_id'] = 'foo'}, 'bar'), 'foo')\n    lu.assertEquals(candidate({['sample_id'] = 'AB12345'}, None), 'AB12345')\n    lu.assertEquals(candidate({['sampleid'] = 'AB12345'}, 'user_run_name'), 'AB12345')\n    lu.assertEquals(candidate({['flow_cell_id'] = '1234'}, '1111'), '1234')\n    lu.assertEquals(candidate({}, '1234'), '1234')\n    lu.assertEquals(candidate({['flow_cell_id'] = 'AB12345'}, 'user_run_name'), 'AB12345')\n    lu.assertEquals(candidate({['sampleid'] = '1234'}, '1111'), '1234')\n    lu.assertEquals(candidate({['sample_id'] = '1234'}, '1111'), '1234')\n    lu.assertEquals(candidate({['sample_id'] = '54321', ['sampleid'] = '55555'}, 'user_run_name'), '54321')\n    lu.assertEquals(candidate({['sample_id'] = 'AB12345'}, 'user_run_name'), 'AB12345')\n    lu.assertEquals(candidate({['sample_id'] = 'foo'}, 'bar'), 'foo')\n    lu.assertEquals(candidate({['flow_cell_id'] = '12345', ['sample_id'] = '54321'}, 'user_run_name'), '12345')\n    lu.assertEquals(candidate({['sample_id'] = '54321', ['sampleid'] = '555555'}, 'user_run_name'), '54321')\n    lu.assertEquals(candidate({}, 'bar'), 'bar')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_316829_pretty_print_ec2_res_id", "language": "lua", "prompt": "--  Pretty-print the EC2 reservation ID \nlocal function pretty_print_ec2_res_id(res)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_316829_pretty_print_ec2_res_id.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = pretty_print_ec2_res_id\n    lu.assertEquals(candidate({['ReservedInstancesId'] = '73599745-9067-4a6c-8629-99a4154e1606'}), '73599745...')\n    lu.assertEquals(candidate({['ReservedInstancesId'] = '4a928483-9067-4a6c-8629-99a4154e1606'}), '4a928483...')\n    lu.assertEquals(candidate({['ReservedInstancesId'] = '89599745-9067-4a6c-8629-99a4154e1606'}), '89599745...')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_316883_code_to_name", "language": "lua", "prompt": "--  returns a country name if the given dictionary contains a code for it\n-- if the code is not in the dictionary it will return an empty string\n-- Args:\n--     code (str):         country code\n--     code_dict (dict):   dictionary with code as key and name as value\n-- Returns:\n--     geo_name (str):     name of country\nlocal function code_to_name(code, code_dict)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_316883_code_to_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = code_to_name\n    lu.assertEquals(candidate('XY', {['AL'] = 'Albania'}), '')\n    lu.assertEquals(candidate('AL', {['AL'] = 'Albania'}), 'Albania')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_317662_delete_keys_from_dict", "language": "lua", "prompt": "-- Utility to remove specific keys from a dictionary.\n-- Parameters\n-- ----------\n-- dictionary : dict\n--     Input dictionary.\n-- keys_to_remove : list\n--     list of keys to remove from the dictionary. If this list is\n--     non-unique (i.e. has repeats), then there will be an error. Also, if\n--     any element in this list is not a key in the dictionary, there will\n--     be an error as well.\n-- Returns\n-- -------\n-- dictionary : dict\n--     Dictionary with keys removed.\nlocal function delete_keys_from_dict(dictionary, keys_to_remove)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_317662_delete_keys_from_dict.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = delete_keys_from_dict\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3}, {}), {['a'] = 1, ['b'] = 2, ['c'] = 3})\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3}, {'a', 'c', 'b'}), {})\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3}, {'a', 'c'}), {['b'] = 2})\n    lu.assertEquals(candidate({['a'] = 0, ['b'] = 1, ['c'] = 2}, {'a'}), {['b'] = 1, ['c'] = 2})\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3}, {'a', 'b'}), {['c'] = 3})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_317743_wordCount", "language": "lua", "prompt": "-- This function counts words from a text and returns a dictionary. \n-- Does not fix for punctuation and special characters, so for example 'why' and 'why?' will be counted as two different words. This doesn't matter in the case of youtube subtitles.\n-- INPUT: string\n-- OUTPUT: dictionary where keys are words, and the values are counts.\nlocal function wordCount(cleantext)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_317743_wordCount.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = wordCount\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate(' '), {})\n    lu.assertEquals(candidate('It was a bright cold day in April, and the clocks were striking thirteen.'), {['It'] = 1, ['was'] = 1, ['a'] = 1, ['bright'] = 1, ['cold'] = 1, ['day'] = 1, ['in'] = 1, ['April,'] = 1, ['and'] = 1, ['the'] = 1, ['clocks'] = 1, ['were'] = 1, ['striking'] = 1, ['thirteen.'] = 1})\n    lu.assertEquals(candidate('Hello world'), {['Hello'] = 1, ['world'] = 1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_317929_get_split_parts", "language": "lua", "prompt": "-- get split parts\nlocal function get_split_parts(num, num_part)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_317929_get_split_parts.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_split_parts\n    lu.assertEquals(candidate(26, 2), {13, 13})\n    lu.assertEquals(candidate(1000, 10), {100, 100, 100, 100, 100, 100, 100, 100, 100, 100})\n    lu.assertEquals(candidate(10, 2), {5, 5})\n    lu.assertEquals(candidate(10, 5), {2, 2, 2, 2, 2})\n    lu.assertEquals(candidate(100, 1), {100})\n    lu.assertEquals(candidate(12, 1), {12})\n    lu.assertEquals(candidate(11, 1), {11})\n    lu.assertEquals(candidate(12, 3), {4, 4, 4})\n    lu.assertEquals(candidate(26, 1), {26})\n    lu.assertEquals(candidate(10, 1), {10})\n    lu.assertEquals(candidate(13, 1), {13})\n    lu.assertEquals(candidate(100, 5), {20, 20, 20, 20, 20})\n    lu.assertEquals(candidate(100, 4), {25, 25, 25, 25})\n    lu.assertEquals(candidate(15, 3), {5, 5, 5})\n    lu.assertEquals(candidate(25, 1), {25})\n    lu.assertEquals(candidate(100, 2), {50, 50})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_318311__safe_parse", "language": "lua", "prompt": "-- Parse an irc message.\n-- Args:\n--     msg (str): raw message\n-- Return:\n--     dict: {'user': user, 'msg': message}\nlocal function _safe_parse(msg)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_318311__safe_parse.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _safe_parse\n    lu.assertEquals(candidate('PRIVMSG 12345!@#$%^&*()'), None)\n    lu.assertEquals(candidate('PRIVMSG!@#$%^&*()!@#$%^&*()'), None)\n    lu.assertEquals(candidate('PRIVMSG 12345 12345'), None)\n    lu.assertEquals(candidate(':nick!<EMAIL> PRIVMSG'), None)\n    lu.assertEquals(candidate('PRIVMSG'), None)\n    lu.assertEquals(candidate('PRIVMSG'), None)\n    lu.assertEquals(candidate(':nick!<EMAIL> PRIVMSG #chan :I have a message'), {['user'] = 'nick', ['msg'] = 'I have a message'})\n    lu.assertEquals(candidate('PRIVMSG!@#$%^&*() 12345'), None)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_319216_sum_digits", "language": "lua", "prompt": "-- assumes s a string\n-- Returns an int that is the sum of all of the digits in s.\n-- If there are no digits in s it raises a ValueError exception.\nlocal function sum_digits(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_319216_sum_digits.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sum_digits\n    lu.assertEquals(candidate('-123'), 6)\n    lu.assertEquals(candidate(str(-123)), 6)\n    lu.assertEquals(candidate(str(123)), 6)\n    lu.assertEquals(candidate('a0123456789b'), 45)\n    lu.assertEquals(candidate('123'), 6)\n    lu.assertEquals(candidate('987'), 24)\n    lu.assertEquals(candidate('abc123'), 6)\n    lu.assertEquals(candidate('123abc'), 6)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_319388_bit_len", "language": "lua", "prompt": "-- Helper function returning the number of bits required to binary encode an integer.\nlocal function bit_len(int_type)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_319388_bit_len.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = bit_len\n    lu.assertEquals(candidate(5), 3)\n    lu.assertEquals(candidate(7), 3)\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(127), 7)\n    lu.assertEquals(candidate(6), 3)\n    lu.assertEquals(candidate(23), 5)\n    lu.assertEquals(candidate(30), 5)\n    lu.assertEquals(candidate(26), 5)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(29), 5)\n    lu.assertEquals(candidate(19), 5)\n    lu.assertEquals(candidate(13), 4)\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(3), 2)\n    lu.assertEquals(candidate(20), 5)\n    lu.assertEquals(candidate(128), 8)\n    lu.assertEquals(candidate(4), 3)\n    lu.assertEquals(candidate(24), 5)\n    lu.assertEquals(candidate(63), 6)\n    lu.assertEquals(candidate(25), 5)\n    lu.assertEquals(candidate(16383), 14)\n    lu.assertEquals(candidate(17), 5)\n    lu.assertEquals(candidate(511), 9)\n    lu.assertEquals(candidate(512), 10)\n    lu.assertEquals(candidate(4), 3)\n    lu.assertEquals(candidate(2048), 12)\n    lu.assertEquals(candidate(31), 5)\n    lu.assertEquals(candidate(21), 5)\n    lu.assertEquals(candidate(25), 5)\n    lu.assertEquals(candidate(64), 7)\n    lu.assertEquals(candidate(33), 6)\n    lu.assertEquals(candidate(7), 3)\n    lu.assertEquals(candidate(16), 5)\n    lu.assertEquals(candidate(21), 5)\n    lu.assertEquals(candidate(8), 4)\n    lu.assertEquals(candidate(11), 4)\n    lu.assertEquals(candidate(15), 4)\n    lu.assertEquals(candidate(5), 3)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(100), 7)\n    lu.assertEquals(candidate(28), 5)\n    lu.assertEquals(candidate(16), 5)\n    lu.assertEquals(candidate(18), 5)\n    lu.assertEquals(candidate(10), 4)\n    lu.assertEquals(candidate(8191), 13)\n    lu.assertEquals(candidate(19), 5)\n    lu.assertEquals(candidate(14), 4)\n    lu.assertEquals(candidate(255), 8)\n    lu.assertEquals(candidate(1023), 10)\n    lu.assertEquals(candidate(14), 4)\n    lu.assertEquals(candidate(12), 4)\n    lu.assertEquals(candidate(27), 5)\n    lu.assertEquals(candidate(256), 9)\n    lu.assertEquals(candidate(22), 5)\n    lu.assertEquals(candidate(22), 5)\n    lu.assertEquals(candidate(4096), 13)\n    lu.assertEquals(candidate(12), 4)\n    lu.assertEquals(candidate(9), 4)\n    lu.assertEquals(candidate(2047), 11)\n    lu.assertEquals(candidate(34), 6)\n    lu.assertEquals(candidate(3), 2)\n    lu.assertEquals(candidate(17), 5)\n    lu.assertEquals(candidate(16384), 15)\n    lu.assertEquals(candidate(32), 6)\n    lu.assertEquals(candidate(28), 5)\n    lu.assertEquals(candidate(4095), 12)\n    lu.assertEquals(candidate(20), 5)\n    lu.assertEquals(candidate(10), 4)\n    lu.assertEquals(candidate(13), 4)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(6), 3)\n    lu.assertEquals(candidate(26), 5)\n    lu.assertEquals(candidate(8), 4)\n    lu.assertEquals(candidate(24), 5)\n    lu.assertEquals(candidate(27), 5)\n    lu.assertEquals(candidate(23), 5)\n    lu.assertEquals(candidate(18), 5)\n    lu.assertEquals(candidate(8192), 14)\n    lu.assertEquals(candidate(15), 4)\n    lu.assertEquals(candidate(1024), 11)\n    lu.assertEquals(candidate(11), 4)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(9), 4)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_320259_bitInBitmap", "language": "lua", "prompt": "-- bit map decoding\nlocal function bitInBitmap(bitmap, bit)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_320259_bitInBitmap.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = bitInBitmap\n    lu.assertEquals(candidate(23, 10), false)\n    lu.assertEquals(candidate(10, 100), false)\n    lu.assertEquals(candidate(255, 128), true)\n    lu.assertEquals(candidate(13, 100), false)\n    lu.assertEquals(candidate(42, 7), false)\n    lu.assertEquals(candidate(0, 1), false)\n    lu.assertEquals(candidate(2, 1), false)\n    lu.assertEquals(candidate(2047, 128), true)\n    lu.assertEquals(candidate(0, 0), false)\n    lu.assertEquals(candidate(128, 128), true)\n    lu.assertEquals(candidate(1, 1), true)\n    lu.assertEquals(candidate(8, 1), false)\n    lu.assertEquals(candidate(256, 128), false)\n    lu.assertEquals(candidate(42, 4), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_320360_get_rounds", "language": "lua", "prompt": "-- Get list of current and next rounds\n-- :param number: int - current round number.\n-- :return: list - current round and the two that follow.\nlocal function get_rounds(number)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_320360_get_rounds.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_rounds\n    lu.assertEquals(candidate(3), {3, 4, 5})\n    lu.assertEquals(candidate(12), {12, 13, 14})\n    lu.assertEquals(candidate(0), {0, 1, 2})\n    lu.assertEquals(candidate(2), {2, 3, 4})\n    lu.assertEquals(candidate(25), {25, 26, 27})\n    lu.assertEquals(candidate(1), {1, 2, 3})\n    lu.assertEquals(candidate(7), {7, 8, 9})\n    lu.assertEquals(candidate(5), {5, 6, 7})\n    lu.assertEquals(candidate(20), {20, 21, 22})\n    lu.assertEquals(candidate(100), {100, 101, 102})\n    lu.assertEquals(candidate(17), {17, 18, 19})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_32048_color_str_yellow", "language": "lua", "prompt": "-- Color string YELLOW for writing to STDIN.\nlocal function color_str_yellow(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_32048_color_str_yellow.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = color_str_yellow\n    lu.assertEquals(candidate('hello'), '\\x1b[93mhello\\x1b[00m')\n    lu.assertEquals(candidate('foo'), '\\x1b[93mfoo\\x1b[00m')\n    lu.assertEquals(candidate('hello'), '\\x1b[93mhello\\x1b[00m')\n    lu.assertEquals(candidate('\u2603'), '\\x1b[93m\u2603\\x1b[00m')\n    lu.assertEquals(candidate(str(1)), '\\x1b[93m1\\x1b[00m')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_321019_decompose_dateint", "language": "lua", "prompt": "-- Decomposes the given dateint into its year, month and day components.\n-- Arguments\n-- ---------\n-- dateint : int\n--     An integer object decipting a specific calendaric day; e.g. 20161225.\n-- Returns\n-- -------\n-- year : int\n--     The year component of the given dateint.\n-- month : int\n--     The month component of the given dateint.\n-- day : int\n--     The day component of the given dateint.\nlocal function decompose_dateint(dateint)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_321019_decompose_dateint.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = decompose_dateint\n    lu.assertEquals(candidate(20161225), {2016, 12, 25})\n    lu.assertEquals(candidate(19860915), {1986, 9, 15})\n    lu.assertEquals(candidate(19000101), {1900, 1, 1})\n    lu.assertEquals(candidate(20120229), {2012, 2, 29})\n    lu.assertEquals(candidate(20160229), {2016, 2, 29})\n    lu.assertEquals(candidate(19130814), {1913, 8, 14})\n    lu.assertEquals(candidate(10102030), {1010, 20, 30})\n    lu.assertEquals(candidate(20101231), {2010, 12, 31})\n    lu.assertEquals(candidate(20210615), {2021, 6, 15})\n    lu.assertEquals(candidate(20110101), {2011, 1, 1})\n    lu.assertEquals(candidate(19000229), {1900, 2, 29})\n    lu.assertEquals(candidate(20000229), {2000, 2, 29})\n    lu.assertEquals(candidate(21000229), {2100, 2, 29})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_321523_get_voxel_coord", "language": "lua", "prompt": "-- Based on provided integer voxel index and lateral size of the 3D neighborhood, determines the coordinates of the\n-- voxel in the neighborhood\n-- :type index: int\n-- :param index:\n-- :type s: int\n-- :param s:\n-- :return:\nlocal function get_voxel_coord(index, s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_321523_get_voxel_coord.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_voxel_coord\n    lu.assertEquals(candidate(14, 4), {2, 3, 0})\n    lu.assertEquals(candidate(16, 3), {1, 2, 1})\n    lu.assertEquals(candidate(2, 4), {2, 0, 0})\n    lu.assertEquals(candidate(4, 3), {1, 1, 0})\n    lu.assertEquals(candidate(14, 3), {2, 1, 1})\n    lu.assertEquals(candidate(7, 3), {1, 2, 0})\n    lu.assertEquals(candidate(15, 3), {0, 2, 1})\n    lu.assertEquals(candidate(11, 3), {2, 0, 1})\n    lu.assertEquals(candidate(8, 3), {2, 2, 0})\n    lu.assertEquals(candidate(5, 3), {2, 1, 0})\n    lu.assertEquals(candidate(10, 3), {1, 0, 1})\n    lu.assertEquals(candidate(6, 4), {2, 1, 0})\n    lu.assertEquals(candidate(1, 3), {1, 0, 0})\n    lu.assertEquals(candidate(1, 4), {1, 0, 0})\n    lu.assertEquals(candidate(0, 3), {0, 0, 0})\n    lu.assertEquals(candidate(3, 4), {3, 0, 0})\n    lu.assertEquals(candidate(0, 4), {0, 0, 0})\n    lu.assertEquals(candidate(10, 4), {2, 2, 0})\n    lu.assertEquals(candidate(5, 4), {1, 1, 0})\n    lu.assertEquals(candidate(3, 3), {0, 1, 0})\n    lu.assertEquals(candidate(12, 3), {0, 1, 1})\n    lu.assertEquals(candidate(9, 4), {1, 2, 0})\n    lu.assertEquals(candidate(3, 2), {1, 1, 0})\n    lu.assertEquals(candidate(2, 3), {2, 0, 0})\n    lu.assertEquals(candidate(13, 3), {1, 1, 1})\n    lu.assertEquals(candidate(16, 4), {0, 0, 1})\n    lu.assertEquals(candidate(4, 4), {0, 1, 0})\n    lu.assertEquals(candidate(12, 4), {0, 3, 0})\n    lu.assertEquals(candidate(7, 4), {3, 1, 0})\n    lu.assertEquals(candidate(9, 3), {0, 0, 1})\n    lu.assertEquals(candidate(11, 4), {3, 2, 0})\n    lu.assertEquals(candidate(8, 4), {0, 2, 0})\n    lu.assertEquals(candidate(13, 4), {1, 3, 0})\n    lu.assertEquals(candidate(6, 3), {0, 2, 0})\n    lu.assertEquals(candidate(15, 4), {3, 3, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_321626_truncate_string", "language": "lua", "prompt": "-- Truncate a string.\n-- Params:\n-- - in_string: (type: string) string to truncate.\n-- - length: (type: int) length of output string.\n-- Returns:\n-- - result: (type: string) truncated string.\nlocal function truncate_string(input_string, length)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_321626_truncate_string.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = truncate_string\n    lu.assertEquals(candidate('1234567890', 10), '1234567890')\n    lu.assertEquals(candidate('12345678901', 11), '12345678901')\n    lu.assertEquals(candidate('12345678901', 12), '12345678901')\n    lu.assertEquals(candidate('a', 1), 'a')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_321996_join_env", "language": "lua", "prompt": "-- Convert a single intercepted environment variable from dictionary to envs.txt line.\nlocal function join_env(env)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_321996_join_env.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = join_env\n    lu.assertEquals(candidate({['a'] = 'b'}), 'a=b')\n    lu.assertEquals(candidate({['USER'] = 'root'}), 'USER=root')\n    lu.assertEquals(candidate({['a'] = '1'}), 'a=1')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_322935_isNarcissistic", "language": "lua", "prompt": "-- Returns whether or not a given number is Narcissistic.\n-- A positive integer is called a narcissistic number if it\n-- is equal to the sum of its own digits each raised to the\n-- power of the number of digits.\n-- Example: 153 is narcissistic because 1^3 + 5^3 + 3^3 = 1 + 125 + 27 = 153.\n-- Note that by this definition all single digit numbers are narcissistic.\nlocal function isNarcissistic(x)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_322935_isNarcissistic.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = isNarcissistic\n    lu.assertEquals(candidate(1), true)\n    lu.assertEquals(candidate(10000000), false)\n    lu.assertEquals(candidate(9926315), true)\n    lu.assertEquals(candidate(0), true)\n    lu.assertEquals(candidate(370), true)\n    lu.assertEquals(candidate(153), true)\n    lu.assertEquals(candidate(122), false)\n    lu.assertEquals(candidate(409), false)\n    lu.assertEquals(candidate(4888), false)\n    lu.assertEquals(candidate(88), false)\n    lu.assertEquals(candidate(371), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_323207_validate_color", "language": "lua", "prompt": "-- Check whether or not an RGB tuple is acceptable.\nlocal function validate_color(color)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_323207_validate_color.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = validate_color\n    lu.assertEquals(candidate({0, 0, 255}), true)\n    lu.assertEquals(candidate({255, 255, 0}), true)\n    lu.assertEquals(candidate({-10, 255, 255}), false)\n    lu.assertEquals(candidate({1, 2, 3}), true)\n    lu.assertEquals(candidate({10, 10, 255}), true)\n    lu.assertEquals(candidate({0, -20, 0}), false)\n    lu.assertEquals(candidate({255, 256, 255}), false)\n    lu.assertEquals(candidate({255, 255, 255}), true)\n    lu.assertEquals(candidate({255, 10, 10}), true)\n    lu.assertEquals(candidate({254, 253, 252}), true)\n    lu.assertEquals(candidate({0, 255, 0}), true)\n    lu.assertEquals(candidate({10, 0, 255}), true)\n    lu.assertEquals(candidate({0, 10, 0}), true)\n    lu.assertEquals(candidate({255, 255, -10}), false)\n    lu.assertEquals(candidate({255, 0, 0}), true)\n    lu.assertEquals(candidate({10, 255, 10}), true)\n    lu.assertEquals(candidate({255, 10, 255}), true)\n    lu.assertEquals(candidate({10, 255, 255}), true)\n    lu.assertEquals(candidate({10, 255, 0}), true)\n    lu.assertEquals(candidate({255, 255, 254}), true)\n    lu.assertEquals(candidate({0, 255, 255}), true)\n    lu.assertEquals(candidate({10, 10, 10}), true)\n    lu.assertEquals(candidate({255, 0, 255}), true)\n    lu.assertEquals(candidate({0, 255, 10}), true)\n    lu.assertEquals(candidate({0, 10, 255}), true)\n    lu.assertEquals(candidate({0, 0, 0}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_323236_int2signed", "language": "lua", "prompt": "--  Given a Python integer, return its 2s complement \n-- word representation.\nlocal function int2signed(num, nbits)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_323236_int2signed.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = int2signed\n    lu.assertEquals(candidate(-20), 4294967276)\n    lu.assertEquals(candidate(-1, 2), 3)\n    lu.assertEquals(candidate(1, 2), 1)\n    lu.assertEquals(candidate(2, 2), 2)\n    lu.assertEquals(candidate(32767), 32767)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(65535), 65535)\n    lu.assertEquals(candidate(2147483647), 2147483647)\n    lu.assertEquals(candidate(-2147483648), 2147483648)\n    lu.assertEquals(candidate(42), 42)\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(0, 3), 0)\n    lu.assertEquals(candidate(1, 3), 1)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(-1, 3), 7)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_323414_urlstring", "language": "lua", "prompt": "-- Forms a string with the full url from a filename and base url.\n-- Keyword arguments:\n-- f - filename\n-- baseUrl - address of the root of the website\nlocal function urlstring(f, baseUrl)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_323414_urlstring.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = urlstring\n    lu.assertEquals(candidate('/images/google.png', 'http://code.google.com'), 'http://code.google.com/images/google.png')\n    lu.assertEquals(candidate('./images/google.png', 'http://code.google.com/'), 'http://code.google.com/images/google.png')\n    lu.assertEquals(candidate('images/google.png', 'http://code.google.com/'), 'http://code.google.com/images/google.png')\n    lu.assertEquals(candidate('about.html', 'http://code.google.com'), 'http://code.google.com/about.html')\n    lu.assertEquals(candidate('./my_page.html', 'http://codeskulptor.org/'), 'http://codeskulptor.org/my_page.html')\n    lu.assertEquals(candidate('/my_page.html', 'http://codeskulptor.org'), 'http://codeskulptor.org/my_page.html')\n    lu.assertEquals(candidate('./a/b/c/', 'http://example.com'), 'http://example.com/a/b/c/')\n    lu.assertEquals(candidate('my_page.html', 'http://codeskulptor.org/'), 'http://codeskulptor.org/my_page.html')\n    lu.assertEquals(candidate('a/b/c/index.html', 'http://example.com/'), 'http://example.com/a/b/c/')\n    lu.assertEquals(candidate('images/google.png', 'http://code.google.com'), 'http://code.google.com/images/google.png')\n    lu.assertEquals(candidate('./about.html', 'http://code.google.com'), 'http://code.google.com/about.html')\n    lu.assertEquals(candidate('./a/b/c/', 'http://example.com/'), 'http://example.com/a/b/c/')\n    lu.assertEquals(candidate('./images/google.png', 'http://code.google.com'), 'http://code.google.com/images/google.png')\n    lu.assertEquals(candidate('index.html', 'http://example.com/'), 'http://example.com/')\n    lu.assertEquals(candidate('./my_page.html', 'http://codeskulptor.org'), 'http://codeskulptor.org/my_page.html')\n    lu.assertEquals(candidate('my_page.html', 'http://codeskulptor.org'), 'http://codeskulptor.org/my_page.html')\n    lu.assertEquals(candidate('/images/google.png', 'http://code.google.com/'), 'http://code.google.com/images/google.png')\n    lu.assertEquals(candidate('./a/b/c/index.html', 'http://example.com/'), 'http://example.com/a/b/c/')\n    lu.assertEquals(candidate('/my_page.html', 'http://codeskulptor.org/'), 'http://codeskulptor.org/my_page.html')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_323665_ini_value", "language": "lua", "prompt": "-- Strips key= from key=value from ini configuration data\nlocal function ini_value(key_value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_323665_ini_value.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = ini_value\n    lu.assertEquals(candidate('key=value with spaces and\\nnewlines'), 'value with spaces and\\nnewlines')\n    lu.assertEquals(candidate('key=value with spaces and\\ttabs'), 'value with spaces and\\ttabs')\n    lu.assertEquals(candidate('key=value\\twith\\ttabs'), 'value\\twith\\ttabs')\n    lu.assertEquals(candidate('key=value'), 'value')\n    lu.assertEquals(candidate('key=value\\n\\nwith\\n\\nnewlines\\n\\n'), 'value\\n\\nwith\\n\\nnewlines\\n\\n')\n    lu.assertEquals(candidate('key=value with spaces'), 'value with spaces')\n    lu.assertEquals(candidate('key=value\\nwith\\nnewlines'), 'value\\nwith\\nnewlines')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_325056_toggle_collapse", "language": "lua", "prompt": "--     collapse the side bar\nlocal function toggle_collapse(n, is_open)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_325056_toggle_collapse.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = toggle_collapse\n    lu.assertEquals(candidate(3, false), true)\n    lu.assertEquals(candidate(5, false), true)\n    lu.assertEquals(candidate(2, true), false)\n    lu.assertEquals(candidate(1, true), false)\n    lu.assertEquals(candidate(0, false), false)\n    lu.assertEquals(candidate(4, false), true)\n    lu.assertEquals(candidate(1, false), true)\n    lu.assertEquals(candidate(3, true), false)\n    lu.assertEquals(candidate(2, false), true)\n    lu.assertEquals(candidate(4, true), false)\n    lu.assertEquals(candidate(5, true), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_325573_format_data", "language": "lua", "prompt": "-- Takes the account data and returns in a printable format.\nlocal function format_data(account)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_325573_format_data.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = format_data\n    lu.assertEquals(candidate({['name'] = 'John', ['description'] = 'Doctor', ['country'] = 'USA'}), 'John, a Doctor, from USA')\n    lu.assertEquals(candidate({['name'] = 'Alice', ['description'] = 'A normal account', ['country'] = 'Canada'}), 'Alice, a A normal account, from Canada')\n    lu.assertEquals(candidate({['name'] = 'Bob', ['description'] = 'The bad account', ['country'] = 'France'}), 'Bob, a The bad account, from France')\n    lu.assertEquals(candidate({['name'] = 'Charlie', ['description'] = 'An alright account', ['country'] = 'Mexico'}), 'Charlie, a An alright account, from Mexico')\n    lu.assertEquals(candidate({['name'] = '', ['description'] = 'Doctor', ['country'] = 'USA'}), ', a Doctor, from USA')\n    lu.assertEquals(candidate({['name'] = 'John', ['description'] = 'Doctor', ['country'] = ''}), 'John, a Doctor, from ')\n    lu.assertEquals(candidate({['name'] = '<NAME>', ['description'] = 'Super Mario Maker 2', ['country'] = 'Japan'}), '<NAME>, a Super Mario Maker 2, from Japan')\n    lu.assertEquals(candidate({['name'] = 'Bob', ['description'] = 'The bad account', ['country'] = 'France'}), 'Bob, a The bad account, from France')\n    lu.assertEquals(candidate({['name'] = 'Alice', ['description'] = 'A normal account', ['country'] = 'Canada'}), 'Alice, a A normal account, from Canada')\n    lu.assertEquals(candidate({['name'] = 'Charlie', ['description'] = 'An alright account', ['country'] = 'Mexico'}), 'Charlie, a An alright account, from Mexico')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_325906_strQ2B", "language": "lua", "prompt": "--     Converting full-width characters to half-width characters\nlocal function strQ2B(ustring)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_325906_strQ2B.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = strQ2B\n    lu.assertEquals(candidate('\uff54\uff45\uff53\uff54'), 'test')\n    lu.assertEquals(candidate('\uff21\uff22\uff23'), 'ABC')\n    lu.assertEquals(candidate('\uff41\uff42\uff43\uff21\uff22\uff23'), 'abcABC')\n    lu.assertEquals(candidate('\uff11\uff12\uff13456'), '123456')\n    lu.assertEquals(candidate('\uff10\uff11\uff12\uff13'), '0123')\n    lu.assertEquals(candidate(candidate('abc')), 'abc')\n    lu.assertEquals(candidate('\uff05\uff41\uff42\uff43\uff44\uff45\uff46\uff47\uff48\uff49\uff4a\uff4b\uff4c\uff4d\uff4e\uff4f\uff50\uff51\uff52\uff53\uff54\uff55\uff56\uff57\uff58\uff59\uff5a'), '%abcdefghijklmnopqrstuvwxyz')\n    lu.assertEquals(candidate('\uff11\uff12\uff13'), '123')\n    lu.assertEquals(candidate('\uff21\uff22\uff23\uff10\uff11\uff12\uff13'), 'ABC0123')\n    lu.assertEquals(candidate('123'), '123')\n    lu.assertEquals(candidate('\uff21\uff22\uff23'), 'ABC')\n    lu.assertEquals(candidate('\uff41\uff42\uff43\uff41\uff42\uff43\uff21\uff22\uff23\uff21\uff22\uff23'), 'abcabcABCABC')\n    lu.assertEquals(candidate('abc'), 'abc')\n    lu.assertEquals(candidate('\u554a\u9f44\u4e02\u72db\u72dc'), '\u554a\u9f44\u4e02\u72db\u72dc')\n    lu.assertEquals(candidate('\uff41\uff42\uff43'), 'abc')\n    lu.assertEquals(candidate('\uff3a\uff41\uff42\uff43\uff11\uff12\uff13'), 'Zabc123')\n    lu.assertEquals(candidate('abc'), 'abc')\n    lu.assertEquals(candidate('\u4f60\u597d'), '\u4f60\u597d')\n    lu.assertEquals(candidate('\uff21\uff22\uff23'), 'ABC')\n    lu.assertEquals(candidate('\uff41\uff42\uff43\uff41\uff42\uff43'), 'abcabc')\n    lu.assertEquals(candidate('\uff41\uff42\uff43'), 'abc')\n    lu.assertEquals(candidate('\uff41\uff42\uff43\uff10\uff11\uff12\uff13'), 'abc0123')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_326010_job_id_from_reponse", "language": "lua", "prompt": "-- Return a string representation of integer job id from the qsub response to stdout\nlocal function job_id_from_reponse(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_326010_job_id_from_reponse.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = job_id_from_reponse\n    lu.assertEquals(candidate('Your job-array 4321.1-3:1 (\"wrfpost\") has been submitted'), '4321')\n    lu.assertEquals(candidate(\"Your job-array 4321.1-3:1 ('wrfpost') has been submitted\"), '4321')\n    lu.assertEquals(candidate('Your job 4321.1 (\"wrfpost\") has been submitted'), '4321')\n    lu.assertEquals(candidate('Your job 3681 (\"TEST\") has been submitted'), '3681')\n    lu.assertEquals(candidate('Your job-array 4321.1-3:1 (\"wrfpost\") has been submitted'), '4321')\n    lu.assertEquals(candidate('Your job 3681 () has been submitted'), '3681')\n    lu.assertEquals(candidate('Your job 3681 (\"TEST\") has been submitted'), '3681')\n    lu.assertEquals(candidate(\"Your job 3681 ('TEST') has been submitted\"), '3681')\n    lu.assertEquals(candidate('Your job 4321 (\"wrfpost\") has been submitted'), '4321')\n    lu.assertEquals(candidate('Your job-array 4321.1-3:1 (\"wrfpost\") has been submitted'), '4321')\n    lu.assertEquals(candidate('Your job 3681 (\"TEST\") has been submitted'), '3681')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_326484_vectorize", "language": "lua", "prompt": "-- Converts a list of words into a list of frequency position numbers.\n-- Args:\n--     dictionary(dict): Dictionary containing the words in the vocabulary together\n--         with their frequency position.\n--     words(list): List of words that are to be converted.\n-- Returns:\n--     A list of frequency position numbers in place of the actual words in the list.\nlocal function vectorize(dictionary, words)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_326484_vectorize.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = vectorize\n    lu.assertEquals(candidate(dict({['first'] = 1, ['second'] = 2}), {'first', 'second', 'third'}), {1, 2, 0})\n    lu.assertEquals(candidate(dict({['first'] = 0, ['second'] = 0}), {'first', 'second'}), {0, 0})\n    lu.assertEquals(candidate(dict({['first'] = 0, ['second'] = 0}), {'first', 'second', 'third'}), {0, 0, 0})\n    lu.assertEquals(candidate(dict({['first'] = 1, ['second'] = 2}), {}), {})\n    lu.assertEquals(candidate(dict(), {}), {})\n    lu.assertEquals(candidate(dict({['first'] = 1, ['second'] = 2}), {'first', 'first'}), {1, 1})\n    lu.assertEquals(candidate(dict(), {'first', 'second'}), {0, 0})\n    lu.assertEquals(candidate(dict({['first'] = 0}), {}), {})\n    lu.assertEquals(candidate(dict({['first'] = 1, ['second'] = 2}), {'first', 'first', 'third'}), {1, 1, 0})\n    lu.assertEquals(candidate(dict({['first'] = 1, ['second'] = 2}), {'first', 'second'}), {1, 2})\n    lu.assertEquals(candidate(dict({['first'] = 0}), {'first', 'second'}), {0, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_327793_encode_pdf", "language": "lua", "prompt": "-- Encode the probability density function.\nlocal function encode_pdf(pdf)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_327793_encode_pdf.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = encode_pdf\n    lu.assertEquals(candidate({{1, 1}}), '[(1, 1)]')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_327885_is_between_strict", "language": "lua", "prompt": "-- Shorthand for `(lo < val < hi) or (lo > val > hi)`.\nlocal function is_between_strict(lo, val, hi)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_327885_is_between_strict.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_between_strict\n    lu.assertEquals(candidate(2, 3, 2), false)\n    lu.assertEquals(candidate(3, 2, 3), false)\n    lu.assertEquals(candidate(5, 10, 10), false)\n    lu.assertEquals(candidate(2, 1, 2), false)\n    lu.assertEquals(candidate(1, 3, 2), false)\n    lu.assertEquals(candidate(3, 3, 1), false)\n    lu.assertEquals(candidate(3, 1, 3), false)\n    lu.assertEquals(candidate(0, 1, 2), true)\n    lu.assertEquals(candidate(3, 2, 5), false)\n    lu.assertEquals(candidate(2, 2, 3), false)\n    lu.assertEquals(candidate(3, 3, 5), false)\n    lu.assertEquals(candidate(3, 4, 5), true)\n    lu.assertEquals(candidate(1, 3, 3), false)\n    lu.assertEquals(candidate(0, 1, -1), false)\n    lu.assertEquals(candidate(3, 1, 1), false)\n    lu.assertEquals(candidate(1, 2, 3), true)\n    lu.assertEquals(candidate(10, 10, 15), false)\n    lu.assertEquals(candidate(3, 6, 5), false)\n    lu.assertEquals(candidate(1, 3, 1), false)\n    lu.assertEquals(candidate(1, 2, 2), false)\n    lu.assertEquals(candidate(5, 6, 3), false)\n    lu.assertEquals(candidate(1, 4, 3), false)\n    lu.assertEquals(candidate(5, 10, 5), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_328378_parse_line", "language": "lua", "prompt": "-- Takes a line of space seperated values, returns the values in a list.\nlocal function parse_line(line)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_328378_parse_line.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_line\n    lu.assertEquals(candidate('1111 22'), {'1111', '22'})\n    lu.assertEquals(candidate('1111 22 3'), {'1111', '22', '3'})\n    lu.assertEquals(candidate('   This is a line with 10 spaces in front of it.   '), {'This', 'is', 'a', 'line', 'with', '10', 'spaces', 'in', 'front', 'of', 'it.'})\n    lu.assertEquals(candidate('This is a line without spaces.'), {'This', 'is', 'a', 'line', 'without', 'spaces.'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_328945_loop_add", "language": "lua", "prompt": "-- An imperative implementation using a loop and in-place mutation.\nlocal function loop_add(x, y)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_328945_loop_add.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = loop_add\n    lu.assertEquals(candidate(123, 456), 579)\n    lu.assertEquals(candidate(2, 2), 4)\n    lu.assertEquals(candidate(-700, 300), -400)\n    lu.assertEquals(candidate(-123, 456), 333)\n    lu.assertEquals(candidate(0, 100), 100)\n    lu.assertEquals(candidate(3, 2), 5)\n    lu.assertEquals(candidate(1, 1), 2)\n    lu.assertEquals(candidate(0, 1), 1)\n    lu.assertEquals(candidate(10, 0), 10)\n    lu.assertEquals(candidate(1, 2), 3)\n    lu.assertEquals(candidate(2, 3), 5)\n    lu.assertEquals(candidate(1000, 0), 1000)\n    lu.assertEquals(candidate(-10, 0), -10)\n    lu.assertEquals(candidate(-10, 1), -9)\n    lu.assertEquals(candidate(0, 1000), 1000)\n    lu.assertEquals(candidate(1, 0), 1)\n    lu.assertEquals(candidate(0, 0), 0)\n    lu.assertEquals(candidate(100, 20), 120)\n    lu.assertEquals(candidate(-1, 1000), 999)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_329540_invertEvent", "language": "lua", "prompt": "-- Return the inverted event.\nlocal function invertEvent(e)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_329540_invertEvent.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = invertEvent\n    lu.assertEquals(candidate(0), 1)\n    lu.assertEquals(candidate(1), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_33050_check_event_attrs", "language": "lua", "prompt": "--     Verify the event has the expected attributes for Flog Apache logs and custom app logs\nlocal function check_event_attrs(attrs)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_33050_check_event_attrs.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = check_event_attrs\n    lu.assertEquals(candidate({['id'] = '1', ['source_component'] = '1.2.3.4'}), false)\n    lu.assertEquals(candidate({['app'] = 'customApp', ['id'] = '99999', ['activity_type'] = 'ssh', ['categories'] = 'auth, ssh', ['dest_country'] = 'US', ['dest_ip'] = '192.168.1.1', ['dest_port'] = '3389', ['device_type'] = 'desktop', ['domain'] = 'myDomain.com', ['forwarder'] = 'my.forwarder.net', ['is_phishing_domain'] = 'False', ['is_ransomware_dest_ip'] = 'False', ['is_ransomware_src_ip'] = 'False', ['is_threat_dest_ip'] = 'False', ['is_threat_src_ip'] = 'False', ['outcome'] = 'failure', ['source_component'] = 'ssh-desktop', ['src_country'] = 'US', ['src_ip'] = '192.168.1.2', ['src_port'] = '53269', ['subcategory'] = 'auth, ssh', ['username'] = 'joeuser', ['version'] = '0.1.0'}), true)\n    lu.assertEquals(candidate({['app'] = 'customApp', ['activity_type'] = 'activity', ['categories'] = 'cat1', ['dest_country'] = 'US', ['dest_ip'] = '172.16.17.32', ['dest_port'] = '35084', ['device_type'] = 'Laptop', ['domain'] = 'example.com', ['forwarder'] = 'forwarder1', ['id'] = '123', ['is_phishing_domain'] = 'False', ['is_ransomware_dest_ip'] = 'False', ['is_ransomware_src_ip'] = 'False', ['is_threat_dest_ip'] = 'False', ['is_threat_src_ip'] = 'False', ['outcome'] = 'success', ['source_component'] = 'source_component1', ['src_country'] = 'US', ['src_ip'] = '172.16.17.32', ['src_port'] = '443', ['subcategory'] = 'subcategory1', ['username'] = 'username1', ['version'] = 'version1'}), true)\n    lu.assertEquals(candidate({['dataset'] = 'accesslog', ['agent'] = 'client', ['authUser'] = 'joeuser', ['bytes'] = '1234', ['ip'] = '192.168.1.1', ['protocol'] = 'http', ['referrer'] = 'http://myDomain.com/login', ['status'] = '404', ['uriPath'] = '/login', ['user'] = 'joeuser'}), true)\n    lu.assertEquals(candidate({['app'] = 'customApp', ['activity_type'] = 'fileDownload', ['categories'] = 'fileDownload', ['dest_country'] = 'US', ['dest_ip'] = '1.2.3.4', ['dest_port'] = '80', ['device_type'] = 'server', ['domain'] = 'example.com', ['forwarder'] = 'filebeat-8.0.0-darwin-x86_64', ['id'] = '80071', ['is_phishing_domain'] = 'no', ['is_ransomware_dest_ip'] = 'no', ['is_ransomware_src_ip'] = 'no', ['is_threat_dest_ip'] = 'no', ['is_threat_src_ip'] = 'no', ['outcome'] = 'success', ['source_component'] = 'Falcon', ['src_country'] = 'US', ['src_ip'] = '1.2.3.4', ['src_port'] = '5672', ['subcategory'] = 'File Downloads', ['username'] = 'user', ['version'] = '20.2.0.19344'}), true)\n    lu.assertEquals(candidate({['id'] = '1', ['app'] = 'customApp', ['source_component'] = '1.2.3.4', ['outcome'] = 'succeded'}), false)\n    lu.assertEquals(candidate({['id'] = '1', ['source_component'] = '1.2.3.4', ['outcome'] = 'succeded'}), false)\n    lu.assertEquals(candidate({['id'] = '1', ['app'] = 'customApp', ['outcome'] = 'succeded'}), false)\n    lu.assertEquals(candidate({['id'] = '1', ['app'] = 'customApp'}), false)\n    lu.assertEquals(candidate({['id'] = '1', ['outcome'] = 'succeded'}), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_330601_makeHtmlText", "language": "lua", "prompt": "-- add formatting for an html textarea to a string\nlocal function makeHtmlText(str_in)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_330601_makeHtmlText.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = makeHtmlText\n    lu.assertEquals(candidate('I eat\\ncats.'), '<textarea rows=\"2\" cols=\"100\" style=\"border:double 2px blue;\">I eat\\ncats.</textarea>')\n    lu.assertEquals(candidate('I eat cats!'), '<textarea rows=\"2\" cols=\"100\" style=\"border:double 2px blue;\">I eat cats!</textarea>')\n    lu.assertEquals(candidate('hello world'), '<textarea rows=\"2\" cols=\"100\" style=\"border:double 2px blue;\">hello world</textarea>')\n    lu.assertEquals(candidate('It was the best of times, it was the worst of times. It was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way \u2013 in short, the period was so far like the present period, that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only...'), '<textarea rows=\"2\" cols=\"100\" style=\"border:double 2px blue;\">It was the best of times, it was the worst of times. It was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way \u2013 in short, the period was so far like the present period, that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only...</textarea>')\n    lu.assertEquals(candidate('hello world'), '<textarea rows=\"2\" cols=\"100\" style=\"border:double 2px blue;\">hello world</textarea>')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_331914_is_tracked_zone", "language": "lua", "prompt": "--     Is the root domain for the provided cname one of the known domains?\nlocal function is_tracked_zone(cname, zones)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_331914_is_tracked_zone.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_tracked_zone\n    lu.assertEquals(candidate('example.gov', {'example.org', 'example.net', 'example.biz', 'example.gov'}), true)\n    lu.assertEquals(candidate('example.net', {'example.org', 'example.net', 'example.biz', 'example.gov'}), true)\n    lu.assertEquals(candidate('example.com', {'example.org', 'example.net', 'example.biz', 'example.gov'}), false)\n    lu.assertEquals(candidate('example.com', {'example.org', 'example.net', 'example.biz'}), false)\n    lu.assertEquals(candidate('example.com', {'example.com', 'example.org', 'example.net', 'example.biz'}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_332162_dict_bool", "language": "lua", "prompt": "-- Implementation of `dict_bool`.\nlocal function dict_bool(x)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_332162_dict_bool.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = dict_bool\n    lu.assertEquals(candidate(dict()), false)\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3}), true)\n    lu.assertEquals(candidate({['a'] = 1}), true)\n    lu.assertEquals(candidate({['a'] = 1}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_332746_month_str", "language": "lua", "prompt": "-- Returns the string e.g. 'JAN' corresponding to month\nlocal function month_str(month, upper)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_332746_month_str.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = month_str\n    lu.assertEquals(candidate(5, false), 'may')\n    lu.assertEquals(candidate(8), 'AUG')\n    lu.assertEquals(candidate(1), 'JAN')\n    lu.assertEquals(candidate(6), 'JUN')\n    lu.assertEquals(candidate(4, false), 'apr')\n    lu.assertEquals(candidate(10, false), 'oct')\n    lu.assertEquals(candidate(12), 'DEC')\n    lu.assertEquals(candidate(9, true), 'SEP')\n    lu.assertEquals(candidate(3, false), 'mar')\n    lu.assertEquals(candidate(6, false), 'jun')\n    lu.assertEquals(candidate(7), 'JUL')\n    lu.assertEquals(candidate(3, true), 'MAR')\n    lu.assertEquals(candidate(1, true), 'JAN')\n    lu.assertEquals(candidate(6, true), 'JUN')\n    lu.assertEquals(candidate(3), 'MAR')\n    lu.assertEquals(candidate(2, false), 'feb')\n    lu.assertEquals(candidate(6), 'JUN')\n    lu.assertEquals(candidate(9, false), 'sep')\n    lu.assertEquals(candidate(11), 'NOV')\n    lu.assertEquals(candidate(1, false), 'jan')\n    lu.assertEquals(candidate(9), 'SEP')\n    lu.assertEquals(candidate(10), 'OCT')\n    lu.assertEquals(candidate(11, false), 'nov')\n    lu.assertEquals(candidate(7, true), 'JUL')\n    lu.assertEquals(candidate(2), 'FEB')\n    lu.assertEquals(candidate(12, false), 'dec')\n    lu.assertEquals(candidate(8, false), 'aug')\n    lu.assertEquals(candidate(4), 'APR')\n    lu.assertEquals(candidate(7, false), 'jul')\n    lu.assertEquals(candidate(5), 'MAY')\n    lu.assertEquals(candidate(12), 'DEC')\n    lu.assertEquals(candidate(8, true), 'AUG')\n    lu.assertEquals(candidate(5, true), 'MAY')\n    lu.assertEquals(candidate(1), 'JAN')\n    lu.assertEquals(candidate(4, true), 'APR')\n    lu.assertEquals(candidate(7), 'JUL')\n    lu.assertEquals(candidate(2, true), 'FEB')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_333098_to_bool", "language": "lua", "prompt": "-- Helper function for translating strings into booleans\n-- @see test/TestReadConfig.py\nlocal function to_bool(value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_333098_to_bool.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = to_bool\n    lu.assertEquals(candidate('f'), false)\n    lu.assertEquals(candidate('y'), true)\n    lu.assertEquals(candidate('TRUE'), true)\n    lu.assertEquals(candidate('true'), true)\n    lu.assertEquals(candidate('false'), false)\n    lu.assertEquals(candidate('n'), false)\n    lu.assertEquals(candidate('N'), false)\n    lu.assertEquals(candidate('0'), false)\n    lu.assertEquals(candidate('true'), true)\n    lu.assertEquals(candidate('f'), false)\n    lu.assertEquals(candidate('N'), false)\n    lu.assertEquals(candidate('y'), true)\n    lu.assertEquals(candidate('T'), true)\n    lu.assertEquals(candidate('t'), true)\n    lu.assertEquals(candidate('1'), true)\n    lu.assertEquals(candidate('n'), false)\n    lu.assertEquals(candidate('F'), false)\n    lu.assertEquals(candidate('1'), true)\n    lu.assertEquals(candidate('Y'), true)\n    lu.assertEquals(candidate('f'), false)\n    lu.assertEquals(candidate('1'), true)\n    lu.assertEquals(candidate('0'), false)\n    lu.assertEquals(candidate('y'), true)\n    lu.assertEquals(candidate('1'), true)\n    lu.assertEquals(candidate('FALSE'), false)\n    lu.assertEquals(candidate('T'), true)\n    lu.assertEquals(candidate('y'), true)\n    lu.assertEquals(candidate('t'), true)\n    lu.assertEquals(candidate('t'), true)\n    lu.assertEquals(candidate('n'), false)\n    lu.assertEquals(candidate('false'), false)\n    lu.assertEquals(candidate('Y'), true)\n    lu.assertEquals(candidate('F'), false)\n    lu.assertEquals(candidate('t'), true)\n    lu.assertEquals(candidate('true'), true)\n    lu.assertEquals(candidate('0'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_333149_manhattan_distance", "language": "lua", "prompt": "-- Number of steps between two squares allowing only\n-- up, down, left and right steps.\nlocal function manhattan_distance(xy_a, xy_b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_333149_manhattan_distance.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = manhattan_distance\n    lu.assertEquals(candidate({0, 0}, {1, 0}), 1)\n    lu.assertEquals(candidate({0, 0}, {1, 1}), 2)\n    lu.assertEquals(candidate({0, 0}, {0, -1}), 1)\n    lu.assertEquals(candidate({3, 2}, {2, 3}), 2)\n    lu.assertEquals(candidate({0, 0}, {1, 0}), 1)\n    lu.assertEquals(candidate({0, 0}, {0, 0}), 0)\n    lu.assertEquals(candidate({0, 0}, {0, 1}), 1)\n    lu.assertEquals(candidate({3, 4}, {2, 3}), 2)\n    lu.assertEquals(candidate({0, 0}, {1, -1}), 2)\n    lu.assertEquals(candidate({0, 0}, {1, 1}), 2)\n    lu.assertEquals(candidate({1, 1}, {2, 2}), 2)\n    lu.assertEquals(candidate({2, 2}, {2, 2}), 0)\n    lu.assertEquals(candidate({-2, 2}, {-4, -2}), 6)\n    lu.assertEquals(candidate({0, 0}, {2, 2}), 4)\n    lu.assertEquals(candidate({0, 0}, {0, 0}), 0)\n    lu.assertEquals(candidate({2, 3}, {3, 4}), 2)\n    lu.assertEquals(candidate({0, 0}, {2, 2}), 4)\n    lu.assertEquals(candidate({0, 0}, {0, 1}), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_333447_urlsafe_address", "language": "lua", "prompt": "-- Make an address safe to use in a URL.\n-- Args:\n--     address: A tuple of address information.\n-- Returns:\n--     A 2-tuple of url-safe (address, port)\nlocal function urlsafe_address(address)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_333447_urlsafe_address.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = urlsafe_address\n    lu.assertEquals(candidate({'localhost', 80}), {'localhost', 80})\n    lu.assertEquals(candidate({'localhost', 8080}), {'localhost', 8080})\n    lu.assertEquals(candidate({'example.com', 8080}), {'example.com', 8080})\n    lu.assertEquals(candidate({'::1', 80}), {'::1', 80})\n    lu.assertEquals(candidate({'127.0.0.1', 80}), {'127.0.0.1', 80})\n    lu.assertEquals(candidate({'example.com', 80}), {'example.com', 80})\n    lu.assertEquals(candidate({'127.0.0.1', 8080}), {'127.0.0.1', 8080})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_333685_get_name", "language": "lua", "prompt": "--         get name from idx2name\nlocal function get_name(idx2name, info)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_333685_get_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_name\n    lu.assertEquals(candidate(), 'a#b#c')\n    lu.assertEquals(candidate(), 'a')\n    lu.assertEquals(candidate({['3'] = '3', ['4'] = '4'}, '3'), '3')\n    lu.assertEquals(candidate({['1'] = 'tom', ['2'] = 'dick', ['3'] = 'harry'}, '3'), 'harry')\n    lu.assertEquals(candidate({['1'] = '1', ['2'] = '2', ['3'] = '3', ['4'] = '4'}, '1#2#3#4#5'), '1#2#3#4#5')\n    lu.assertEquals(candidate({['1'] = 'Alice', ['2'] = 'Bob', ['3'] = 'Charlie', ['4'] = 'David', ['5'] = 'Eve', ['6'] = 'Fred', ['7'] = 'Ginny', ['8'] = 'Harriet', ['9'] = 'Ileana', ['10'] = 'Joseph', ['11'] = 'Kincaid', ['12'] = 'Larry'}, '12'), 'Larry')\n    lu.assertEquals(candidate({['1'] = 'tom', ['2'] = 'dick', ['3'] = 'harry'}, '1'), 'tom')\n    lu.assertEquals(candidate({['1'] = '1', ['2'] = '2', ['3'] = '3', ['4'] = '4'}, '3#4'), '3#4')\n    lu.assertEquals(candidate({['1'] = '1', ['2'] = '2', ['3'] = '3', ['4'] = '4'}, '1#2#3'), '1#2#3')\n    lu.assertEquals(candidate({['1'] = '1', ['2'] = '2', ['3'] = '3', ['4'] = '4'}, '2#3#4'), '2#3#4')\n    lu.assertEquals(candidate({['1'] = '1', ['2'] = '2', ['3'] = '3', ['4'] = '4'}, '1#2#3#4'), '1#2#3#4')\n    lu.assertEquals(candidate({['1'] = 'tom', ['2'] = 'dick', ['3'] = 'harry'}, '5'), '5')\n    lu.assertEquals(candidate(), 'a#a#a#b#c')\n    lu.assertEquals(candidate({['3'] = '3', ['4'] = '4'}, '4'), '4')\n    lu.assertEquals(candidate({['1'] = '1', ['2'] = '2', ['3'] = '3', ['4'] = '4', ['5'] = '5', ['6'] = '6', ['7'] = '7', ['8'] = '8', ['9'] = '9', ['10'] = '10'}, '1'), '1')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_334071_prepend_scheme", "language": "lua", "prompt": "-- Prepend scheme to a remote path.\n-- Scheme is only prepended if not already present\n-- Parameters\n-- ----------\n-- scheme: str\n--     a scheme like 'file', 's3' or 'gs'\n-- path: str\n--     path which will possibly get a scheme prepended\n-- Returns\n-- -------\n-- full_path: str\nlocal function prepend_scheme(scheme, path)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_334071_prepend_scheme.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = prepend_scheme\n    lu.assertEquals(candidate('gs', '/tmp/test_folder/file.txt'), 'gs://tmp/test_folder/file.txt')\n    lu.assertEquals(candidate('', '/test/test.txt'), 'file://test/test.txt')\n    lu.assertEquals(candidate('file', 'tmp/test_folder/file.txt'), 'file://tmp/test_folder/file.txt')\n    lu.assertEquals(candidate('gs', 'tmp/test_folder/file.txt'), 'gs://tmp/test_folder/file.txt')\n    lu.assertEquals(candidate('s3', '/tmp/test_folder/file.txt'), 's3://tmp/test_folder/file.txt')\n    lu.assertEquals(candidate('file', '/tmp/test_folder/'), 'file://tmp/test_folder/')\n    lu.assertEquals(candidate('gs', '/tmp/test_folder/'), 'gs://tmp/test_folder/')\n    lu.assertEquals(candidate('s3', 'tmp/test_folder/file.txt'), 's3://tmp/test_folder/file.txt')\n    lu.assertEquals(candidate('', 'test.txt'), 'file://test.txt')\n    lu.assertEquals(candidate('file', '/tmp/test_folder/file.txt'), 'file://tmp/test_folder/file.txt')\n    lu.assertEquals(candidate('file', 'tmp/test_folder/'), 'file://tmp/test_folder/')\n    lu.assertEquals(candidate('s3', '/tmp/test_folder/'), 's3://tmp/test_folder/')\n    lu.assertEquals(candidate('s3', 'tmp/test_folder/'), 's3://tmp/test_folder/')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_3342_parse_cigar", "language": "lua", "prompt": "--  for a specific operation (mismach, match, insertion, deletion... see above)\n-- return occurences and index in the alignment \nlocal function parse_cigar(cigarlist, ope)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_3342_parse_cigar.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_cigar\n    lu.assertEquals(candidate({{2, 100}}, 1), {})\n    lu.assertEquals(candidate(candidate({{'M', 5}, {'M', 3}, {'I', 5}}, 'D'), 'D'), {})\n    lu.assertEquals(candidate({{0, 100}}, 2), {})\n    lu.assertEquals(candidate({{1, 100}}, 1), {{100, 0}})\n    lu.assertEquals(candidate({{1, 100}}, 0), {})\n    lu.assertEquals(candidate({{0, 100}}, 8), {})\n    lu.assertEquals(candidate({{1, 100}}, 2), {})\n    lu.assertEquals(candidate({{2, 100}}, 0), {})\n    lu.assertEquals(candidate({{1, 100}}, 7), {})\n    lu.assertEquals(candidate({{2, 100}}, 8), {})\n    lu.assertEquals(candidate({{0, 100}}, 1), {})\n    lu.assertEquals(candidate(candidate({{'M', 5}, {'M', 3}, {'I', 5}}, 'N'), 'N'), {})\n    lu.assertEquals(candidate({{2, 100}}, 7), {})\n    lu.assertEquals(candidate({{0, 100}}, 0), {{100, 0}})\n    lu.assertEquals(candidate({{7, 100}}, 0), {})\n    lu.assertEquals(candidate({{0, 100}}, 7), {})\n    lu.assertEquals(candidate({{7, 100}}, 2), {})\n    lu.assertEquals(candidate({{2, 100}}, 2), {{100, 0}})\n    lu.assertEquals(candidate({{7, 100}}, 1), {})\n    lu.assertEquals(candidate({{1, 100}}, 8), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_33486_is_int_type_malicious_score", "language": "lua", "prompt": "--         determine if integer type confidence score is malicious in reputation_params\nlocal function is_int_type_malicious_score(confidence_score, params)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_33486_is_int_type_malicious_score.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_int_type_malicious_score\n    lu.assertEquals(candidate(100, {['override_confidence_score_malicious_threshold'] = 100000}), false)\n    lu.assertEquals(candidate(0, {['override_confidence_score_malicious_threshold'] = 100000}), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_335015_base10_to_7", "language": "lua", "prompt": "-- Take a base 10 number and convert it to an ASCII string.\n-- :param num: the base 10 number\n-- :return: the ASCII string\nlocal function base10_to_7(num)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_335015_base10_to_7.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = base10_to_7\n    lu.assertEquals(candidate(0), '')\n    lu.assertEquals(candidate(0), '')\n    lu.assertEquals(candidate(127), '\\x7f')\n    lu.assertEquals(candidate(1), '\\x01')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_335336_gcd_by_subtracting", "language": "lua", "prompt": "-- Computes the greatest common divisor of two numbers by continuously subtracting the smaller\n-- number from the bigger one till they became equal.\n-- :param int m: First number.\n-- :param int n: Second number.\n-- :returns: GCD as a number.\nlocal function gcd_by_subtracting(m, n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_335336_gcd_by_subtracting.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = gcd_by_subtracting\n    lu.assertEquals(candidate(1, 7), 1)\n    lu.assertEquals(candidate(18, 12), 6)\n    lu.assertEquals(candidate(200, 100), 100)\n    lu.assertEquals(candidate(6, 90), 6)\n    lu.assertEquals(candidate(24, 36), 12)\n    lu.assertEquals(candidate(42, 42), 42)\n    lu.assertEquals(candidate(6, 12), 6)\n    lu.assertEquals(candidate(252, 105), 21)\n    lu.assertEquals(candidate(100, 10), 10)\n    lu.assertEquals(candidate(12, 16), 4)\n    lu.assertEquals(candidate(1, 1), 1)\n    lu.assertEquals(candidate(12, 28), 4)\n    lu.assertEquals(candidate(10, 100), 10)\n    lu.assertEquals(candidate(6, 24), 6)\n    lu.assertEquals(candidate(13, 27), 1)\n    lu.assertEquals(candidate(7, 1), 1)\n    lu.assertEquals(candidate(10, 20), 10)\n    lu.assertEquals(candidate(6, 8), 2)\n    lu.assertEquals(candidate(12, 18), 6)\n    lu.assertEquals(candidate(5, 125), 5)\n    lu.assertEquals(candidate(6, 14), 2)\n    lu.assertEquals(candidate(22, 13), 1)\n    lu.assertEquals(candidate(6, 18), 6)\n    lu.assertEquals(candidate(10000000000, 123456789), 1)\n    lu.assertEquals(candidate(6, 30), 6)\n    lu.assertEquals(candidate(3, 5), 1)\n    lu.assertEquals(candidate(24, 8), 8)\n    lu.assertEquals(candidate(9, 6), 3)\n    lu.assertEquals(candidate(12, 6), 6)\n    lu.assertEquals(candidate(2000, 1000), 1000)\n    lu.assertEquals(candidate(999, 1), 1)\n    lu.assertEquals(candidate(2, 10), 2)\n    lu.assertEquals(candidate(20, 10), 10)\n    lu.assertEquals(candidate(1000, 2000), 1000)\n    lu.assertEquals(candidate(125, 5), 5)\n    lu.assertEquals(candidate(5, 3), 1)\n    lu.assertEquals(candidate(6, 15), 3)\n    lu.assertEquals(candidate(12, 20), 4)\n    lu.assertEquals(candidate(100, 200), 100)\n    lu.assertEquals(candidate(20, 25), 5)\n    lu.assertEquals(candidate(25, 20), 5)\n    lu.assertEquals(candidate(6, 4), 2)\n    lu.assertEquals(candidate(23456789, 123456789), 1)\n    lu.assertEquals(candidate(6, 10), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_336336_format_role_order", "language": "lua", "prompt": "-- Given roles, returns them in the format: role_arn,principal_arn.\n-- The format of the attribute value should be role_arn,principal_arn\n-- but lots of blogs list it as principal_arn,role_arn so let's reverse\n-- them if needed.\n-- Args:\n--     roles: List of roles.\n-- Returns:\n--     List of roles in the format: role_arn,principal_arn\nlocal function format_role_order(roles)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_336336_format_role_order.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = format_role_order\n    lu.assertEquals(candidate({'role1,principal1', 'role2,principal2'}), {'role1,principal1', 'role2,principal2'})\n    lu.assertEquals(candidate({'role1,principal1', 'role2,principal2', 'role3,principal3', 'role4,principal4'}), {'role1,principal1', 'role2,principal2', 'role3,principal3', 'role4,principal4'})\n    lu.assertEquals(candidate({'role1', 'role2'}), {'role1', 'role2'})\n    lu.assertEquals(candidate({'arn:aws:iam::123456789012:saml-provider/ADFS,arn:aws:iam::123456789012:role/Admin'}), {'arn:aws:iam::123456789012:role/Admin,arn:aws:iam::123456789012:saml-provider/ADFS'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_337003_power", "language": "lua", "prompt": "-- Compute x to the power of n (with n>=0)\nlocal function power(x, n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_337003_power.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = power\n    lu.assertEquals(candidate(2, 4), 16)\n    lu.assertEquals(candidate(2, 6), 64)\n    lu.assertEquals(candidate(5, 2), 25)\n    lu.assertEquals(candidate(2, 5), 32)\n    lu.assertEquals(candidate(5, 3), 125)\n    lu.assertEquals(candidate(5, 5), 3125)\n    lu.assertEquals(candidate(10, 1), 10)\n    lu.assertEquals(candidate(2, 0), 1)\n    lu.assertEquals(candidate(3, 0), 1)\n    lu.assertEquals(candidate(3, 4), 81)\n    lu.assertEquals(candidate(2, 1), 2)\n    lu.assertEquals(candidate(2, 2), 4)\n    lu.assertEquals(candidate(5, 4), 625)\n    lu.assertEquals(candidate(10, 0), 1)\n    lu.assertEquals(candidate(5, 0), 1)\n    lu.assertEquals(candidate(2, 3), 8)\n    lu.assertEquals(candidate(10, 2), 100)\n    lu.assertEquals(candidate(3, 5), 243)\n    lu.assertEquals(candidate(3, 3), 27)\n    lu.assertEquals(candidate(3, 1), 3)\n    lu.assertEquals(candidate(10, 4), 10000)\n    lu.assertEquals(candidate(1, 0), 1)\n    lu.assertEquals(candidate(3, 6), 729)\n    lu.assertEquals(candidate(10, 3), 1000)\n    lu.assertEquals(candidate(5, 1), 5)\n    lu.assertEquals(candidate(3, 2), 9)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_338620_get_distance", "language": "lua", "prompt": "-- Get distance between two point in a tore space.\n-- Parameters\n-- ----------\n-- coord1: coordinate of the first point (tupe(int, int)).\n-- coord2: coordinate of the second point (tupe(int, int)).\n-- size: size of the tore (tupe(int, int))\n-- Return\n-- ------\n-- Distance: distance between the two points (int).\n-- Version\n-- -------\n-- Specification: Alisson Leist, Bayron Mahy, Nicolas Van Bossuyt (v1. 10/02/17)\n--                Bayron Mahy (v2. 19/03/17)\n-- Implementation: Nicolas Van Bossuyt, Alisson Leist (v1. 14/02/17)\n--                 Nicolas Van Bossuyt (v2. 09/03/17)\n--                 Nicolas Van Bossuyt (v3. 03/05/17)\nlocal function get_distance(coord1, coord2, size)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_338620_get_distance.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_distance\n    lu.assertEquals(candidate({0, 1}, {1, 0}, {2, 3}), 2)\n    lu.assertEquals(candidate({0, 0}, {3, 7}, {10, 10}), 6)\n    lu.assertEquals(candidate({1, 0}, {0, 0}, {2, 1}), 1)\n    lu.assertEquals(candidate({0, 1}, {1, 0}, {2, 2}), 2)\n    lu.assertEquals(candidate({0, 0}, {0, 0}, {10, 10}), 0)\n    lu.assertEquals(candidate({0, 0}, {7, 3}, {10, 10}), 6)\n    lu.assertEquals(candidate({0, 0}, {1, 0}, {2, 1}), 1)\n    lu.assertEquals(candidate({0, 0}, {1, 0}, {2, 2}), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_338738_power", "language": "lua", "prompt": "-- Raise term to exponent.\n-- This function raises ``term`` to ``exponent``.\n-- Parameters\n-- ----------\n-- term : Number\n--     Term to be raised.\n-- exponent : int\n--     Exponent.\n-- Returns\n-- -------\n-- result : Number\n--     Result of the operation.\n-- Raises\n-- ------\n-- ValueError\n--     If exponent is not an integer.\n-- See Also\n-- --------\n-- add : Addition\n-- subtract : Subtraction\n-- multiply : Multiplication\n-- divide : Division\n-- Examples\n-- --------\n-- >>> power(1, 1)\n-- 1\n-- >>> power(2, 2)\n-- 4\n-- >>> power(4, 2)\n-- 16\n-- >>> power(10, 2)\n-- 100\n-- >>> power(100, 1)\n-- 100\n-- >>> power(10, 3)\n-- 1000\nlocal function power(term, exponent)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_338738_power.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = power\n    lu.assertEquals(candidate(10, 2), 100)\n    lu.assertEquals(candidate(2, 0), 1)\n    lu.assertEquals(candidate(-2, 3), -8)\n    lu.assertEquals(candidate(5, 4), 625)\n    lu.assertEquals(candidate(2, 2), 4)\n    lu.assertEquals(candidate(100, 1), 100)\n    lu.assertEquals(candidate(2, 3), 8)\n    lu.assertEquals(candidate(10, 3), 1000)\n    lu.assertEquals(candidate(0, 0), 1)\n    lu.assertEquals(candidate(4, 2), 16)\n    lu.assertEquals(candidate(1, 1), 1)\n    lu.assertEquals(candidate(5, 2), 25)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_339249_urlsplit", "language": "lua", "prompt": "-- Split an arbitrary url into protocol, host, rest\n-- The standard urlsplit does not want to provide 'netloc' for arbitrary\n-- protocols, this works around that.\n-- :param url: The url to split into component parts\nlocal function urlsplit(url)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_339249_urlsplit.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = urlsplit\n    lu.assertEquals(candidate('http://www.python.org/doc/2.5.2/lib/module-time.html'), {'http', 'www.python.org', '/doc/2.5.2/lib/module-time.html'})\n    lu.assertEquals(candidate('http://www.example.com/a/b/c'), {'http', 'www.example.com', '/a/b/c'})\n    lu.assertEquals(candidate('https://127.0.0.1/foo/bar'), {'https', '127.0.0.1', '/foo/bar'})\n    lu.assertEquals(candidate('http://www.example.com/'), {'http', 'www.example.com', '/'})\n    lu.assertEquals(candidate('http://www.example.com/foo'), {'http', 'www.example.com', '/foo'})\n    lu.assertEquals(candidate('http://www.example.com/a/b/c?a=1&b=2'), {'http', 'www.example.com', '/a/b/c?a=1&b=2'})\n    lu.assertEquals(candidate('http://www.example.com/a/b/c?a=1&b=2#frag'), {'http', 'www.example.com', '/a/b/c?a=1&b=2#frag'})\n    lu.assertEquals(candidate('http://www.python.org/'), {'http', 'www.python.org', '/'})\n    lu.assertEquals(candidate('http://www.example.com/?a=1&b=2'), {'http', 'www.example.com', '/?a=1&b=2'})\n    lu.assertEquals(candidate('ftp://ftp.debian.org/debian/README'), {'ftp', 'ftp.debian.org', '/debian/README'})\n    lu.assertEquals(candidate('http://www.python.org:80/'), {'http', 'www.python.org:80', '/'})\n    lu.assertEquals(candidate('https://localhost/foo/bar'), {'https', 'localhost', '/foo/bar'})\n    lu.assertEquals(candidate('file:///foo/bar/baz.html'), {'file', '', '/foo/bar/baz.html'})\n    lu.assertEquals(candidate('http://localhost/foo/bar'), {'http', 'localhost', '/foo/bar'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_339342__extract_prop_option", "language": "lua", "prompt": "-- Extract the (key,value)-tuple from a string like:\n-- >>> \"option foobar 123\"\n-- :param line:\n-- :return: tuple (key, value)\nlocal function _extract_prop_option(line)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_339342__extract_prop_option.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _extract_prop_option\n    lu.assertEquals(candidate('option foobar:baz 123'), {'foobar:baz', '123'})\n    lu.assertEquals(candidate('option foobar 123'), {'foobar', '123'})\n    lu.assertEquals(candidate('option foobar -123'), {'foobar', '-123'})\n    lu.assertEquals(candidate('option foobar 123'), {'foobar', '123'})\n    lu.assertEquals(candidate('option foobar 123.4e5_0'), {'foobar', '123.4e5_0'})\n    lu.assertEquals(candidate('option foobar 123'), {'foobar', '123'})\n    lu.assertEquals(candidate('option foobar 123.4e5'), {'foobar', '123.4e5'})\n    lu.assertEquals(candidate('option foobar:baz 123 123 123'), {'foobar:baz', '123 123 123'})\n    lu.assertEquals(candidate('option foobar 123'), {'foobar', '123'})\n    lu.assertEquals(candidate('option foobar 123 123 123'), {'foobar', '123 123 123'})\n    lu.assertEquals(candidate('option foobar +123.4'), {'foobar', '+123.4'})\n    lu.assertEquals(candidate('option foobar 123'), {'foobar', '123'})\n    lu.assertEquals(candidate('option foobar -123.4'), {'foobar', '-123.4'})\n    lu.assertEquals(candidate('option foobar 123 456'), {'foobar', '123 456'})\n    lu.assertEquals(candidate('option foobar 123.4e-5'), {'foobar', '123.4e-5'})\n    lu.assertEquals(candidate('option foobar 123.4'), {'foobar', '123.4'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_340491_int_with_radix", "language": "lua", "prompt": "-- Parse integer with or without a base prefix\n-- :param string: String representation of integer\n-- :type string: str\n-- :return: Parsed integer\n-- :rtype: int\n-- :raise ValueError: If string is no valid integer representation\nlocal function int_with_radix(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_340491_int_with_radix.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = int_with_radix\n    lu.assertEquals(candidate('0xFF'), 255)\n    lu.assertEquals(candidate('0b10'), 2)\n    lu.assertEquals(candidate('-0b00011011'), -27)\n    lu.assertEquals(candidate('0'), 0)\n    lu.assertEquals(candidate('1010101'), 1010101)\n    lu.assertEquals(candidate('0x10'), 16)\n    lu.assertEquals(candidate('0x0000'), 0)\n    lu.assertEquals(candidate('1'), 1)\n    lu.assertEquals(candidate('0x100'), 256)\n    lu.assertEquals(candidate('0x100'), 256)\n    lu.assertEquals(candidate('0x00'), 0)\n    lu.assertEquals(candidate('0x0'), 0)\n    lu.assertEquals(candidate('10'), 10)\n    lu.assertEquals(candidate('0x000'), 0)\n    lu.assertEquals(candidate('-0x1234'), -4660)\n    lu.assertEquals(candidate('0x1234'), 4660)\n    lu.assertEquals(candidate('0b00011011'), 27)\n    lu.assertEquals(candidate('-0o1234'), -668)\n    lu.assertEquals(candidate('0o1234'), 668)\n    lu.assertEquals(candidate('0b10101010'), 170)\n    lu.assertEquals(candidate('0x1234'), 4660)\n    lu.assertEquals(candidate('-1'), -1)\n    lu.assertEquals(candidate('0x10'), 16)\n    lu.assertEquals(candidate('0o77'), 63)\n    lu.assertEquals(candidate('1'), 1)\n    lu.assertEquals(candidate('0o10'), 8)\n    lu.assertEquals(candidate('0x1234567890abcdefabcdef'), 22007822917795467892608495)\n    lu.assertEquals(candidate('1234'), 1234)\n    lu.assertEquals(candidate('0x1234567890abcdef'), 1311768467294899695)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_34192_parse_envs", "language": "lua", "prompt": "-- Parse environment configs as a dict.\n-- Support format 'k1=v1,k2=v2,k3=v3..'. Note that comma is supported\n-- in value field.\nlocal function parse_envs(arg)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_34192_parse_envs.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_envs\n    lu.assertEquals(candidate('key'), {})\n    lu.assertEquals(candidate('k1=v1,,'), {['k1'] = 'v1,,'})\n    lu.assertEquals(candidate('a=1'), {['a'] = '1'})\n    lu.assertEquals(candidate('x=y,z=z'), {['x'] = 'y', ['z'] = 'z'})\n    lu.assertEquals(candidate('a=a,b=b,c=c,d=d,e=e'), {['a'] = 'a', ['b'] = 'b', ['c'] = 'c', ['d'] = 'd', ['e'] = 'e'})\n    lu.assertEquals(candidate('A=B,C=D,E=F,G=H'), {['A'] = 'B', ['C'] = 'D', ['E'] = 'F', ['G'] = 'H'})\n    lu.assertEquals(candidate('foo=bar'), {['foo'] = 'bar'})\n    lu.assertEquals(candidate('k1=v1'), {['k1'] = 'v1'})\n    lu.assertEquals(candidate('key=value,key1=value1,key2=value2'), {['key'] = 'value', ['key1'] = 'value1', ['key2'] = 'value2'})\n    lu.assertEquals(candidate('key=value'), {['key'] = 'value'})\n    lu.assertEquals(candidate('a='), {['a'] = ''})\n    lu.assertEquals(candidate('a=1,b=2,c=3,d=a,b,c'), {['a'] = '1', ['b'] = '2', ['c'] = '3', ['d'] = 'a,b,c'})\n    lu.assertEquals(candidate('key=value1,value2'), {['key'] = 'value1,value2'})\n    lu.assertEquals(candidate('k1=v1,k2=v2,k3='), {['k1'] = 'v1', ['k2'] = 'v2', ['k3'] = ''})\n    lu.assertEquals(candidate('key1='), {['key1'] = ''})\n    lu.assertEquals(candidate('a=1,b=2'), {['a'] = '1', ['b'] = '2'})\n    lu.assertEquals(candidate('a=b,c=d,e=f,g=h'), {['a'] = 'b', ['c'] = 'd', ['e'] = 'f', ['g'] = 'h'})\n    lu.assertEquals(candidate('foo=bar,baz=qux,quux=corge'), {['foo'] = 'bar', ['baz'] = 'qux', ['quux'] = 'corge'})\n    lu.assertEquals(candidate(' a '), {})\n    lu.assertEquals(candidate('abc'), {})\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('key1=value1,key2=value2'), {['key1'] = 'value1', ['key2'] = 'value2'})\n    lu.assertEquals(candidate('A=B,C=D,E=F,G=H,I=J,K=L,M=N'), {['A'] = 'B', ['C'] = 'D', ['E'] = 'F', ['G'] = 'H', ['I'] = 'J', ['K'] = 'L', ['M'] = 'N'})\n    lu.assertEquals(candidate(' '), {})\n    lu.assertEquals(candidate('A=B'), {['A'] = 'B'})\n    lu.assertEquals(candidate('a=a,b=b,c=c,d=d'), {['a'] = 'a', ['b'] = 'b', ['c'] = 'c', ['d'] = 'd'})\n    lu.assertEquals(candidate('A=B,C=D,E=F,G=H,I=J,K=L,M=N,O=P'), {['A'] = 'B', ['C'] = 'D', ['E'] = 'F', ['G'] = 'H', ['I'] = 'J', ['K'] = 'L', ['M'] = 'N', ['O'] = 'P'})\n    lu.assertEquals(candidate('a=b'), {['a'] = 'b'})\n    lu.assertEquals(candidate(' a b '), {})\n    lu.assertEquals(candidate('A=B,C=D'), {['A'] = 'B', ['C'] = 'D'})\n    lu.assertEquals(candidate('key=value,key2=value2'), {['key'] = 'value', ['key2'] = 'value2'})\n    lu.assertEquals(candidate('a=b,c=d,e=f'), {['a'] = 'b', ['c'] = 'd', ['e'] = 'f'})\n    lu.assertEquals(candidate('a=a'), {['a'] = 'a'})\n    lu.assertEquals(candidate('a=b,c=d,e=f,g=h,i=j,k=l,m=n'), {['a'] = 'b', ['c'] = 'd', ['e'] = 'f', ['g'] = 'h', ['i'] = 'j', ['k'] = 'l', ['m'] = 'n'})\n    lu.assertEquals(candidate('A=B,C=D,E=F'), {['A'] = 'B', ['C'] = 'D', ['E'] = 'F'})\n    lu.assertEquals(candidate('hello=world'), {['hello'] = 'world'})\n    lu.assertEquals(candidate('a=a,b=b'), {['a'] = 'a', ['b'] = 'b'})\n    lu.assertEquals(candidate('A=B,C=D,E=F,G=H,I=J'), {['A'] = 'B', ['C'] = 'D', ['E'] = 'F', ['G'] = 'H', ['I'] = 'J'})\n    lu.assertEquals(candidate('k1=v1,k2=v2,k3=v3'), {['k1'] = 'v1', ['k2'] = 'v2', ['k3'] = 'v3'})\n    lu.assertEquals(candidate('k1=v1,k2=v2,k3=v3'), {['k1'] = 'v1', ['k2'] = 'v2', ['k3'] = 'v3'})\n    lu.assertEquals(candidate('k1=,k2=v3'), {['k1'] = '', ['k2'] = 'v3'})\n    lu.assertEquals(candidate('key1=value1'), {['key1'] = 'value1'})\n    lu.assertEquals(candidate('a=a,b=b,c=c'), {['a'] = 'a', ['b'] = 'b', ['c'] = 'c'})\n    lu.assertEquals(candidate('key=value,key2=value2,key3=value3'), {['key'] = 'value', ['key2'] = 'value2', ['key3'] = 'value3'})\n    lu.assertEquals(candidate('k1=v1,k2=v2,k3=v3,k4=v4'), {['k1'] = 'v1', ['k2'] = 'v2', ['k3'] = 'v3', ['k4'] = 'v4'})\n    lu.assertEquals(candidate('k1=v1,k2=v2'), {['k1'] = 'v1', ['k2'] = 'v2'})\n    lu.assertEquals(candidate(' a b c '), {})\n    lu.assertEquals(candidate('a=b,c=d,e=f,g=h,i=j,k=l,m=n,o=p,q=r,s=t,u=v,w=x,y=z'), {['a'] = 'b', ['c'] = 'd', ['e'] = 'f', ['g'] = 'h', ['i'] = 'j', ['k'] = 'l', ['m'] = 'n', ['o'] = 'p', ['q'] = 'r', ['s'] = 't', ['u'] = 'v', ['w'] = 'x', ['y'] = 'z'})\n    lu.assertEquals(candidate('a=b'), {['a'] = 'b'})\n    lu.assertEquals(candidate('x=y'), {['x'] = 'y'})\n    lu.assertEquals(candidate(None), {})\n    lu.assertEquals(candidate('k1=v1,k2=v2,k3=v3,k4=v4,k5=v5'), {['k1'] = 'v1', ['k2'] = 'v2', ['k3'] = 'v3', ['k4'] = 'v4', ['k5'] = 'v5'})\n    lu.assertEquals(candidate('a=b,c=d,e=f,g=h,i=j'), {['a'] = 'b', ['c'] = 'd', ['e'] = 'f', ['g'] = 'h', ['i'] = 'j'})\n    lu.assertEquals(candidate('a=1,b=2,c=3'), {['a'] = '1', ['b'] = '2', ['c'] = '3'})\n    lu.assertEquals(candidate('a=b,c=d'), {['a'] = 'b', ['c'] = 'd'})\n    lu.assertEquals(candidate('k1=,k2='), {['k1'] = '', ['k2'] = ''})\n    lu.assertEquals(candidate('hello'), {})\n    lu.assertEquals(candidate('hello=world,foo=bar,baz=qux'), {['hello'] = 'world', ['foo'] = 'bar', ['baz'] = 'qux'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_342149_checkpid", "language": "lua", "prompt": "-- return the pid of the engine\nlocal function checkpid(pid)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_342149_checkpid.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = checkpid\n    lu.assertEquals(candidate(12345), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_342437_problem48", "language": "lua", "prompt": "-- Problem 48 - Self powers\nlocal function problem48(limit)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_342437_problem48.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = problem48\n    lu.assertEquals(candidate(1000), 9110846700)\n    lu.assertEquals(candidate(10), 405071317)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_342875_naive_add", "language": "lua", "prompt": "-- A naive implementation which can blow the call stack.\nlocal function naive_add(x, y)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_342875_naive_add.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = naive_add\n    lu.assertEquals(candidate(1000, 0), 1000)\n    lu.assertEquals(candidate(3, 10), 13)\n    lu.assertEquals(candidate(100, 100), 200)\n    lu.assertEquals(candidate(1, 10), 11)\n    lu.assertEquals(candidate(1, 1), 2)\n    lu.assertEquals(candidate(100, 500), 600)\n    lu.assertEquals(candidate(2, 0), 2)\n    lu.assertEquals(candidate(2, 3), 5)\n    lu.assertEquals(candidate(10, 100), 110)\n    lu.assertEquals(candidate(1, 0), 1)\n    lu.assertEquals(candidate(0, 0), 0)\n    lu.assertEquals(candidate(1, 2), 3)\n    lu.assertEquals(candidate(5, 100), 105)\n    lu.assertEquals(candidate(0, 100), 100)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_344339__estim_determ_p", "language": "lua", "prompt": "-- An estimator that beliefs just in\n-- deterministic memory-less models.\nlocal function _estim_determ_p(num_zeros, num_ones)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_344339__estim_determ_p.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _estim_determ_p\n    lu.assertEquals(candidate(1, 0), 0.5)\n    lu.assertEquals(candidate(0, 1), 0.5)\n    lu.assertEquals(candidate(1, 1), 0.0)\n    lu.assertEquals(candidate(2, 2), 0.0)\n    lu.assertEquals(candidate(2, 1), 0.0)\n    lu.assertEquals(candidate(0, 2), 0.5)\n    lu.assertEquals(candidate(0, 3), 0.5)\n    lu.assertEquals(candidate(3, 0), 0.5)\n    lu.assertEquals(candidate(1, 2), 0.0)\n    lu.assertEquals(candidate(2, 0), 0.5)\n    lu.assertEquals(candidate(0, 0), 1.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_345591_categorizeClass", "language": "lua", "prompt": "-- Greeble classification with respect to horns [0 down, 1 up]\n-- h1  |h2     |class\n-- 0   |0      |1\n-- 0   |1      |2\n-- 1   |0      |3\n-- 1   |1      |4\nlocal function categorizeClass(h1, h2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_345591_categorizeClass.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = categorizeClass\n    lu.assertEquals(candidate(0, 0), 0)\n    lu.assertEquals(candidate(0, 1), 1)\n    lu.assertEquals(candidate(1, 1), 3)\n    lu.assertEquals(candidate(1, 0), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_346321_reverse_int", "language": "lua", "prompt": "-- Late to the party, but here's a good one.\n-- Integer Reverse:\n-- Given: Any random integer in decimal.\n-- Challenge: Reverse it, without using any of the obvious toString tricks, or transient conversions to a data type other than an int.\nlocal function reverse_int(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_346321_reverse_int.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = reverse_int\n    lu.assertEquals(candidate(88888888), 88888888)\n    lu.assertEquals(candidate(1000), 1)\n    lu.assertEquals(candidate(987654321), 123456789)\n    lu.assertEquals(candidate(10), 1)\n    lu.assertEquals(candidate(123456789), 987654321)\n    lu.assertEquals(candidate(987), 789)\n    lu.assertEquals(candidate(4), 4)\n    lu.assertEquals(candidate(4321), 1234)\n    lu.assertEquals(candidate(4560), 654)\n    lu.assertEquals(candidate(12345), 54321)\n    lu.assertEquals(candidate(123), 321)\n    lu.assertEquals(candidate(321), 123)\n    lu.assertEquals(candidate(123), 321)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_34678_url", "language": "lua", "prompt": "-- Url\n-- Args:\n--     text (str): text for url.\n--     url (str): url for text.\n-- Returns:\n--     str: url.\nlocal function url(text, url_)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_34678_url.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = url\n    lu.assertEquals(candidate('title', 'candidate'), '[title](candidate)')\n    lu.assertEquals(candidate('title with underscore', 'candidate'), '[title with underscore](candidate)')\n    lu.assertEquals(candidate('title with space', 'candidate'), '[title with space](candidate)')\n    lu.assertEquals(candidate('title with underscore and space', 'candidate'), '[title with underscore and space](candidate)')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_348306_is_allowed_conference", "language": "lua", "prompt": "-- Return True if at least one of c1/c2 is an allowed_conference\n-- conf_names is a list of all defined conferences (used to group things into an \"other\" category)\nlocal function is_allowed_conference(c1, c2, conf_names, allowed_confs)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_348306_is_allowed_conference.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_allowed_conference\n    lu.assertEquals(candidate(1, 2, {'a', 'b'}, {}), false)\n    lu.assertEquals(candidate(1, 2, {'a', 'b'}, {'other', 'a'}), true)\n    lu.assertEquals(candidate(1, 2, {'a', 'b'}, {'other', 'a', 'b'}), true)\n    lu.assertEquals(candidate(1, 2, {'a', 'b'}, {'a', 'other'}), true)\n    lu.assertEquals(candidate(1, 2, {'a', 'b'}, {'other', 'b', 'c'}), true)\n    lu.assertEquals(candidate(1, 2, {'a', 'b'}, {'a'}), false)\n    lu.assertEquals(candidate(1, 2, {'a', 'b'}, {'c'}), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_349011_mml_namelist", "language": "lua", "prompt": "-- padding to be same length\nlocal function mml_namelist(namelist)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_349011_mml_namelist.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = mml_namelist\n    lu.assertEquals(candidate({'a', 'b'}), {\"'a'\", \"'b'\"})\n    lu.assertEquals(candidate({'foo', 'bar', 'baz'}), {\"'foo'\", \"'bar'\", \"'baz'\"})\n    lu.assertEquals(candidate({'a', 'bbbb', 'ccccc'}), {\"'a    '\", \"'bbbb '\", \"'ccccc'\"})\n    lu.assertEquals(candidate({'foo', 'bar'}), {\"'foo'\", \"'bar'\"})\n    lu.assertEquals(candidate({'a', 'b', 'c'}), {\"'a'\", \"'b'\", \"'c'\"})\n    lu.assertEquals(candidate({'a', 'b', 'c', 'd'}), {\"'a'\", \"'b'\", \"'c'\", \"'d'\"})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_350170_welcome", "language": "lua", "prompt": "--  Welcome to API Star. Personalized for name \nlocal function welcome(name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_350170_welcome.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = welcome\n    lu.assertEquals(candidate('Michael'), {['message'] = 'Welcome to API Star, Michael!'})\n    lu.assertEquals(candidate(None), {['message'] = 'Welcome to API Star!'})\n    lu.assertEquals(candidate('Python'), {['message'] = 'Welcome to API Star, Python!'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_350340__get_acl_username", "language": "lua", "prompt": "-- Port of ``copyAclUserName`` from ``dumputils.c``\nlocal function _get_acl_username(acl)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_350340__get_acl_username.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _get_acl_username\n    lu.assertEquals(candidate('foo'), {3, 'foo'})\n    lu.assertEquals(candidate('='), {0, ''})\n    lu.assertEquals(candidate('\"foo\"'), {5, 'foo'})\n    lu.assertEquals(candidate('\"a\"'), {3, 'a'})\n    lu.assertEquals(candidate('\"foo\"\"=bar\"'), {11, 'foo\"=bar'})\n    lu.assertEquals(candidate('a'), {1, 'a'})\n    lu.assertEquals(candidate(''), {0, ''})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_350862_count_values", "language": "lua", "prompt": "-- :param input_dict:\n-- :return:\n-- Takes a dict and counts the unique values in that dict.\nlocal function count_values(input_dict)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_350862_count_values.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = count_values\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 1, ['c'] = 1, ['d'] = 2, ['e'] = 2, ['f'] = 3}), 3)\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 1, ['c'] = 1}), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_351488_hexToBytes", "language": "lua", "prompt": "-- Provide hex sting in format 'ab ab ab...'\n-- Returns the byte values\nlocal function hexToBytes(hexStr)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_351488_hexToBytes.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = hexToBytes\n    lu.assertEquals(candidate('123'), {18})\n    lu.assertEquals(candidate(''), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_351618_substring_edit_distance", "language": "lua", "prompt": "-- The minimum number of edits required to make t a substring of s.\n-- An edit is the addition, deletion, or replacement of a character.\nlocal function substring_edit_distance(s, t)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_351618_substring_edit_distance.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = substring_edit_distance\n    lu.assertEquals(candidate('abcd', 'abcdef'), 2)\n    lu.assertEquals(candidate('abcd', 'abcd'), 0)\n    lu.assertEquals(candidate('abcdefghij', 'abcdefghijk'), 1)\n    lu.assertEquals(candidate('abcde', 'abcde'), 0)\n    lu.assertEquals(candidate('abcdefghijklmnopqrstuvwxyz', 'abcdefghijklmnopqrstuvwxyza'), 1)\n    lu.assertEquals(candidate('abc', 'def'), 3)\n    lu.assertEquals(candidate('abc', 'abc'), 0)\n    lu.assertEquals(candidate('abcdefghij', 'abcdefghij'), 0)\n    lu.assertEquals(candidate('', 'abcd'), 4)\n    lu.assertEquals(candidate('abcd', 'abc'), 0)\n    lu.assertEquals(candidate('a', 'abcdef'), 5)\n    lu.assertEquals(candidate('abcdef', 'abccef'), 1)\n    lu.assertEquals(candidate('abc', 'abcd'), 1)\n    lu.assertEquals(candidate('abc', 'abc'), 0)\n    lu.assertEquals(candidate('abc', 'abcde'), 2)\n    lu.assertEquals(candidate('abcdefghijklmnop', 'abcdefghijklmnopq'), 1)\n    lu.assertEquals(candidate('abc', 'abcdef'), 3)\n    lu.assertEquals(candidate('abcdefghijklmnopqrstuvwxyz', 'abcdefghijklmnopqrstuvwxyzab'), 2)\n    lu.assertEquals(candidate('abcdefghijklmnopqrstuvwxyz', 'abcdefghijklmnopqrstuvwxyz'), 0)\n    lu.assertEquals(candidate('', ''), 0)\n    lu.assertEquals(candidate('', 'abc'), 3)\n    lu.assertEquals(candidate('abc', 'abcxyz'), 3)\n    lu.assertEquals(candidate('abcdef', 'abcdef'), 0)\n    lu.assertEquals(candidate('abcd', 'abcde'), 1)\n    lu.assertEquals(candidate('abc', 'xyz'), 3)\n    lu.assertEquals(candidate('', 'abcdef'), 6)\n    lu.assertEquals(candidate('abcd', 'ac'), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_351752_xyminmax_to_xywh", "language": "lua", "prompt": "-- convert box coordinates from (xmin, ymin, xmax, ymax) form to (x, y, w , h) form\nlocal function xyminmax_to_xywh(xmin, ymin, xmax, ymax)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_351752_xyminmax_to_xywh.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = xyminmax_to_xywh\n    lu.assertEquals(candidate(1, 2, 1, 2), {1, 2, 0, 0})\n    lu.assertEquals(candidate(1, 2, 3, 3), {1, 2, 2, 1})\n    lu.assertEquals(candidate(-1, -1, 1, 1), {-1, -1, 2, 2})\n    lu.assertEquals(candidate(1, 1, 3, 5), {1, 1, 2, 4})\n    lu.assertEquals(candidate(1, 1, 3, 4), {1, 1, 2, 3})\n    lu.assertEquals(candidate(1, 2, 3, 4), {1, 2, 2, 2})\n    lu.assertEquals(candidate(1, 2, 3, 2), {1, 2, 2, 0})\n    lu.assertEquals(candidate(1, 2, 1, 4), {1, 2, 0, 2})\n    lu.assertEquals(candidate(0, 0, 1, 1), {0, 0, 1, 1})\n    lu.assertEquals(candidate(3, 7, 5, 9), {3, 7, 2, 2})\n    lu.assertEquals(candidate(1, 1, 3, 3), {1, 1, 2, 2})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_351898_lat_to_km", "language": "lua", "prompt": "-- Expresses given latitude in kilometers to the north\n-- Args:\n--     latitude (float): Latitude in degrees.\n-- Returns:\n--     float: Latitude expressed in kilometers to the north\nlocal function lat_to_km(latitude)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_351898_lat_to_km.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = lat_to_km\n    lu.assertEquals(candidate(0.0), 0.0)\n    lu.assertEquals(candidate(0.0), 0.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_35240_int_to_str", "language": "lua", "prompt": "-- Formats integer to string.\n-- This function is used for operating with image names.\n-- Example: int_to_str(2) -> '02'\nlocal function int_to_str(number)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_35240_int_to_str.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = int_to_str\n    lu.assertEquals(candidate(8), '08')\n    lu.assertEquals(candidate(2), '02')\n    lu.assertEquals(candidate(99), '99')\n    lu.assertEquals(candidate(13), '13')\n    lu.assertEquals(candidate(18), '18')\n    lu.assertEquals(candidate(7), '07')\n    lu.assertEquals(candidate(40), '40')\n    lu.assertEquals(candidate(1), '01')\n    lu.assertEquals(candidate(9), '09')\n    lu.assertEquals(candidate(16), '16')\n    lu.assertEquals(candidate(20), '20')\n    lu.assertEquals(candidate(1000), '1000')\n    lu.assertEquals(candidate(11), '11')\n    lu.assertEquals(candidate(14), '14')\n    lu.assertEquals(candidate(30), '30')\n    lu.assertEquals(candidate(50), '50')\n    lu.assertEquals(candidate(6), '06')\n    lu.assertEquals(candidate(19), '19')\n    lu.assertEquals(candidate(4), '04')\n    lu.assertEquals(candidate(38), '38')\n    lu.assertEquals(candidate(100), '100')\n    lu.assertEquals(candidate(0), '00')\n    lu.assertEquals(candidate(5), '05')\n    lu.assertEquals(candidate(15), '15')\n    lu.assertEquals(candidate(3), '03')\n    lu.assertEquals(candidate(12), '12')\n    lu.assertEquals(candidate(10), '10')\n    lu.assertEquals(candidate(17), '17')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_352460_mat_mul", "language": "lua", "prompt": "-- Function to performs matrix multiplication\n-- Returns the a new matrix\nlocal function mat_mul(mat1, mat2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_352460_mat_mul.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = mat_mul\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}, {{1, 2}, {3, 4}, {5, 6}}), {{22, 28}, {49, 64}, {76, 100}})\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}}, {{7, 8}, {9, 10}}), None)\n    lu.assertEquals(candidate({{1, 2}, {3, 4}}, {{5, 6}, {7, 8}}), {{19, 22}, {43, 50}})\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}}, {{1, 2}, {3, 4}, {5, 6}}), {{22, 28}, {49, 64}})\n    lu.assertEquals(candidate({{1, 2, 3, 4}, {5, 6, 7, 8}}, {{1, 2, 3}, {4, 5, 6}}), None)\n    lu.assertEquals(candidate({{1, 2}, {3, 4}}, {{1, 2}, {3, 4}}), {{7, 10}, {15, 22}})\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}}, {{7, 8}, {9, 10}, {11, 12}, {13, 14}}), None)\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}}, {{1}, {2}, {3}}), {{14}, {32}})\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}}, {{7, 8}, {9, 10}, {11, 12}}), {{58, 64}, {139, 154}})\n    lu.assertEquals(candidate({{1, 2}, {3, 4}}, {{1, 2}, {3, 4}, {5, 6}}), None)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_353572_name_cleanup", "language": "lua", "prompt": "-- cleanup a register name\nlocal function name_cleanup(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_353572_name_cleanup.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = name_cleanup\n    lu.assertEquals(candidate('a'), 'a')\n    lu.assertEquals(candidate('a'), 'a')\n    lu.assertEquals(candidate(None), None)\n    lu.assertEquals(candidate('Foo'), 'Foo')\n    lu.assertEquals(candidate('r1'), 'r1')\n    lu.assertEquals(candidate('reg'), 'reg')\n    lu.assertEquals(candidate('[%s]'), '%s')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('foo'), 'foo')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_354029_get_full_path_file_name", "language": "lua", "prompt": "--  Build full path to file given folder and file name \nlocal function get_full_path_file_name(folder_name, file_name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_354029_get_full_path_file_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_full_path_file_name\n    lu.assertEquals(candidate('my_folder', 'my_file.txt'), 'my_folder/my_file.txt')\n    lu.assertEquals(candidate('test_folder', 'test_file'), 'test_folder/test_file')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_354107__version2int", "language": "lua", "prompt": "--     X.X.X => X0X0X\nlocal function _version2int(v)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_354107__version2int.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _version2int\n    lu.assertEquals(candidate('1.0.2'), 10002)\n    lu.assertEquals(candidate('1.1.3'), 10103)\n    lu.assertEquals(candidate('0.0.*'), 0)\n    lu.assertEquals(candidate('1.2.3-dev'), 10203)\n    lu.assertEquals(candidate('1.0.12'), 10012)\n    lu.assertEquals(candidate('1.2.3'), 10203)\n    lu.assertEquals(candidate('0.0.0'), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_354564_enforce_key_consistency", "language": "lua", "prompt": "--  Forces all keys to lowercase and replaces spaces with underscores \nlocal function enforce_key_consistency(key)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_354564_enforce_key_consistency.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = enforce_key_consistency\n    lu.assertEquals(candidate('snake case'), 'snake_case')\n    lu.assertEquals(candidate('Test'), 'test')\n    lu.assertEquals(candidate('UPPERCASE'), 'uppercase')\n    lu.assertEquals(candidate('FOO'), 'foo')\n    lu.assertEquals(candidate('snake_Case'), 'snake_case')\n    lu.assertEquals(candidate(' 100'), '_100')\n    lu.assertEquals(candidate('Test Test'), 'test_test')\n    lu.assertEquals(candidate('snake_case'), 'snake_case')\n    lu.assertEquals(candidate('lowercase'), 'lowercase')\n    lu.assertEquals(candidate('Foo'), 'foo')\n    lu.assertEquals(candidate('foo'), 'foo')\n    lu.assertEquals(candidate('UPPER SNAKE CASE'), 'upper_snake_case')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_35470_rgb_to_tk", "language": "lua", "prompt": "-- Converts rgb values to tkinter color codes.\n-- :param rgb: Tuple of 3 ints.\n-- :return: tk color code string\nlocal function rgb_to_tk(rgb)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_35470_rgb_to_tk.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rgb_to_tk\n    lu.assertEquals(candidate({0, 128, 255}), '#0080ff')\n    lu.assertEquals(candidate({255, 0, 0}), '#ff0000')\n    lu.assertEquals(candidate({255, 255, 255}), '#ffffff')\n    lu.assertEquals(candidate({0, 0, 0}), '#000000')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_355601_g_speed", "language": "lua", "prompt": "-- returns a speed from a g-code\nlocal function g_speed(parameters, actual_speed)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_355601_g_speed.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = g_speed\n    lu.assertEquals(candidate('f1000 x0 y0 z0', 1000), 1000)\n    lu.assertEquals(candidate('x0 y0 z0', 1000), 1000)\n    lu.assertEquals(candidate('f500', 200), 500)\n    lu.assertEquals(candidate('f200', 500), 200)\n    lu.assertEquals(candidate('f1000', 1000), 1000)\n    lu.assertEquals(candidate('f2000 x0 y0 z0', 1000), 2000)\n    lu.assertEquals(candidate('f2000', 1000), 2000)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_356550_substitute_file_extension", "language": "lua", "prompt": "-- Substitutes file extension, respecting known shader extensions.\n-- foo.vert -> foo.vert.[extension] [similarly for .frag, .comp, etc.]\n-- foo.glsl -> foo.[extension]\n-- foo.unknown -> foo.[extension]\n-- foo -> foo.[extension]\nlocal function substitute_file_extension(filename, extension)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_356550_substitute_file_extension.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = substitute_file_extension\n    lu.assertEquals(candidate('foo', 'frag'), 'foo.frag')\n    lu.assertEquals(candidate('foo.vert.frag', 'frag'), 'foo.vert.frag.frag')\n    lu.assertEquals(candidate('foo.vert.frag.frag', 'frag'), 'foo.vert.frag.frag.frag')\n    lu.assertEquals(candidate('foo.vert', 'spvasm'), 'foo.vert.spvasm')\n    lu.assertEquals(candidate('foo.vert', 'frag'), 'foo.vert.frag')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_356733_strip_article_title_word", "language": "lua", "prompt": "-- Used when tokenizing the titles of articles\n-- in order to index them for search\nlocal function strip_article_title_word(word)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_356733_strip_article_title_word.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = strip_article_title_word\n    lu.assertEquals(candidate('\"\"'), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_356963_FunList", "language": "lua", "prompt": "-- [Takes list and prints it vertically assigning each item its index number on CLI]\n-- Args:\n--     List ([string]): [The items to be displayed]\n-- Returns:\n--     [string]: [a string displaying entries vertically with its indexes]\nlocal function FunList(List)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_356963_FunList.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = FunList\n    lu.assertEquals(candidate({'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'}), '\\n1 - a\\n2 - b\\n3 - c\\n4 - d\\n5 - e\\n6 - f\\n7 - g\\n8 - h\\n')\n    lu.assertEquals(candidate({'a', 'b', 'c'}), '\\n1 - a\\n2 - b\\n3 - c\\n')\n    lu.assertEquals(candidate({'a', 'b', 'c', 'd', 'e', 'f', 'g'}), '\\n1 - a\\n2 - b\\n3 - c\\n4 - d\\n5 - e\\n6 - f\\n7 - g\\n')\n    lu.assertEquals(candidate({'a'}), '\\n1 - a\\n')\n    lu.assertEquals(candidate({}), '\\n')\n    lu.assertEquals(candidate({}), '\\n')\n    lu.assertEquals(candidate({'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i'}), '\\n1 - a\\n2 - b\\n3 - c\\n4 - d\\n5 - e\\n6 - f\\n7 - g\\n8 - h\\n9 - i\\n')\n    lu.assertEquals(candidate({}), '\\n')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_357580_ld_to_m", "language": "lua", "prompt": "--     Converts the input distance (or velocity) of the input from Lunar distances to meters.\nlocal function ld_to_m(ld)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_357580_ld_to_m.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = ld_to_m\n    lu.assertEquals(candidate(-1), -384402000)\n    lu.assertEquals(candidate(0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_357625_phase", "language": "lua", "prompt": "-- Returns the layer thermodynamical phase, as identified from the\n-- feature classification flag\n-- 0 = unknown / not determined 1 = randomly oriented ice\n-- 2 = water\n-- 3 = horizontally oriented ice\nlocal function phase(flags)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_357625_phase.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = phase\n    lu.assertEquals(candidate(63), 1)\n    lu.assertEquals(candidate(18), 0)\n    lu.assertEquals(candidate(29), 0)\n    lu.assertEquals(candidate(4), 0)\n    lu.assertEquals(candidate(255), 3)\n    lu.assertEquals(candidate(11), 0)\n    lu.assertEquals(candidate(5), 0)\n    lu.assertEquals(candidate(17), 0)\n    lu.assertEquals(candidate(9), 0)\n    lu.assertEquals(candidate(22), 0)\n    lu.assertEquals(candidate(10), 0)\n    lu.assertEquals(candidate(21), 0)\n    lu.assertEquals(candidate(31), 0)\n    lu.assertEquals(candidate(6), 0)\n    lu.assertEquals(candidate(27), 0)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(23), 0)\n    lu.assertEquals(candidate(112), 3)\n    lu.assertEquals(candidate(48), 1)\n    lu.assertEquals(candidate(19), 0)\n    lu.assertEquals(candidate(26), 0)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(12), 0)\n    lu.assertEquals(candidate(208), 2)\n    lu.assertEquals(candidate(208), 2)\n    lu.assertEquals(candidate(8), 0)\n    lu.assertEquals(candidate(7), 0)\n    lu.assertEquals(candidate(28), 0)\n    lu.assertEquals(candidate(24), 0)\n    lu.assertEquals(candidate(20), 0)\n    lu.assertEquals(candidate(256), 0)\n    lu.assertEquals(candidate(64), 2)\n    lu.assertEquals(candidate(14), 0)\n    lu.assertEquals(candidate(1), 0)\n    lu.assertEquals(candidate(25), 0)\n    lu.assertEquals(candidate(2124414975), 3)\n    lu.assertEquals(candidate(16), 0)\n    lu.assertEquals(candidate(13), 0)\n    lu.assertEquals(candidate(30), 0)\n    lu.assertEquals(candidate(15), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_357773_new_mean_temperature", "language": "lua", "prompt": "-- Calculates a new mean temperature for the volume.\n-- :param area: in m^2\n-- :param height_external: in m\n-- :param temperature_external: in K\n-- :param heat: in J\n-- :return: temperature in K\nlocal function new_mean_temperature(area, height_external, temperature_external, heat)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_357773_new_mean_temperature.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = new_mean_temperature\n    lu.assertEquals(candidate(1, 1, 273.15, 0), 273.15)\n    lu.assertEquals(candidate(1, 1, 274.15, 0), 274.15)\n    lu.assertEquals(candidate(1, 1, 373.15, 0), 373.15)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_358759_pep8_to_camel_case", "language": "lua", "prompt": "-- Convert a PEP8 style name to camel case.\nlocal function pep8_to_camel_case(name, initial)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_358759_pep8_to_camel_case.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = pep8_to_camel_case\n    lu.assertEquals(candidate('the_quick_brown_fox_jumps_over_the_lazy_dog', false), 'theQuickBrownFoxJumpsOverTheLazyDog')\n    lu.assertEquals(candidate('the_quick_brown_fox_jumps_over_the_lazy_dog', true), 'TheQuickBrownFoxJumpsOverTheLazyDog')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_35877__if_unmodified_since_passes", "language": "lua", "prompt": "-- Test the If-Unmodified-Since comparison as defined in section 3.4 of\n-- RFC 7232.\nlocal function _if_unmodified_since_passes(last_modified, if_unmodified_since)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_35877__if_unmodified_since_passes.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _if_unmodified_since_passes\n    lu.assertEquals(candidate(0, 1), false)\n    lu.assertEquals(candidate(1, 1), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_359341_rfact", "language": "lua", "prompt": "-- Recursive\nlocal function rfact(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_359341_rfact.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rfact\n    lu.assertEquals(candidate(17), 355687428096000)\n    lu.assertEquals(candidate(10), 3628800)\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(19), 121645100408832000)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(16), 20922789888000)\n    lu.assertEquals(candidate(11), 39916800)\n    lu.assertEquals(candidate(14), 87178291200)\n    lu.assertEquals(candidate(12), 479001600)\n    lu.assertEquals(candidate(6), 720)\n    lu.assertEquals(candidate(7), 5040)\n    lu.assertEquals(candidate(5), 120)\n    lu.assertEquals(candidate(4), 24)\n    lu.assertEquals(candidate(18), 6402373705728000)\n    lu.assertEquals(candidate(3), 6)\n    lu.assertEquals(candidate(0), 1)\n    lu.assertEquals(candidate(9), 362880)\n    lu.assertEquals(candidate(15), 1307674368000)\n    lu.assertEquals(candidate(8), 40320)\n    lu.assertEquals(candidate(13), 6227020800)\n    lu.assertEquals(candidate(20), 2432902008176640000)\n    lu.assertEquals(candidate(21), 51090942171709440000)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_35954_trunc32", "language": "lua", "prompt": "--  Return the bottom 32 bits of w as a Python int.\n-- This creates longs temporarily, but returns an int. \nlocal function trunc32(w)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_35954_trunc32.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = trunc32\n    lu.assertEquals(candidate(candidate(19088743)), 19088743)\n    lu.assertEquals(candidate(4294967295), -1)\n    lu.assertEquals(candidate(18446744073709551615), -1)\n    lu.assertEquals(candidate(4294967297), 1)\n    lu.assertEquals(candidate(-1), -1)\n    lu.assertEquals(candidate(123456789), 123456789)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(2147483647), 2147483647)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(2147483648), -2147483648)\n    lu.assertEquals(candidate(4294967295), -1)\n    lu.assertEquals(candidate(4294967296), 0)\n    lu.assertEquals(candidate(-17), -17)\n    lu.assertEquals(candidate(candidate(0)), 0)\n    lu.assertEquals(candidate(19088743), 19088743)\n    lu.assertEquals(candidate(87112285931760246646623899502532662132736), 0)\n    lu.assertEquals(candidate(2147483647), 2147483647)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(candidate(2147483647)), 2147483647)\n    lu.assertEquals(candidate(147573952589676412928), 0)\n    lu.assertEquals(candidate(18446744073709551616), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_359972_add_to_whitelist", "language": "lua", "prompt": "--  Given a fingerprint, add to the whitelist \nlocal function add_to_whitelist(fingerprint, additions)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_359972_add_to_whitelist.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = add_to_whitelist\n    lu.assertEquals(candidate({{['1'] = '1', ['2'] = '2', ['3'] = '3'}, '2012-12-13T12:12:12Z', '2012-12-13T12:12:12Z'}, {['4'] = '4', ['5'] = '5', ['6'] = '6'}), {{['1'] = '1', ['2'] = '2', ['3'] = '3', ['4'] = '4', ['5'] = '5', ['6'] = '6'}, '2012-12-13T12:12:12Z', '2012-12-13T12:12:12Z'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_360740_subtractFrom", "language": "lua", "prompt": "-- Subtraction formatter\nlocal function subtractFrom(acc, curr)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_360740_subtractFrom.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = subtractFrom\n    lu.assertEquals(candidate(5, 6), '5 - 6')\n    lu.assertEquals(candidate(12, -5), '12 - -5')\n    lu.assertEquals(candidate(5, 3), '5 - 3')\n    lu.assertEquals(candidate(0, 0), '0 - 0')\n    lu.assertEquals(candidate(0, 5), '0 - 5')\n    lu.assertEquals(candidate(3, 2), '3 - 2')\n    lu.assertEquals(candidate(12, 5), '12 - 5')\n    lu.assertEquals(candidate(5, 0), '5 - 0')\n    lu.assertEquals(candidate(-5, -5), '-5 - -5')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_361436_get_actual_objname", "language": "lua", "prompt": "-- Given a object string full name (e.g 0&0&DEFINING_ORIGIN), returns\n-- its name (e.g DEFINING_ORIGIN).\nlocal function get_actual_objname(full_object_name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_361436_get_actual_objname.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_actual_objname\n    lu.assertEquals(candidate('0&0&DEFINING_ORIGIN&0'), 'DEFINING_ORIGIN')\n    lu.assertEquals(candidate('0&0&DEFINING_ORIGIN'), 'DEFINING_ORIGIN')\n    lu.assertEquals(candidate('0&0&DEFINING_ORIGIN'), 'DEFINING_ORIGIN')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_362047_make_divisible", "language": "lua", "prompt": "-- This function is taken from the original tf repo.\n-- It ensures that all layers have a channel number that is divisible by 8\n-- It can be seen here:\n-- https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n-- :param v:\n-- :param divisor:\n-- :param min_value:\n-- :return:\nlocal function make_divisible(v, divisor, min_value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_362047_make_divisible.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = make_divisible\n    lu.assertEquals(candidate(12, 2), 12)\n    lu.assertEquals(candidate(3, 4), 4)\n    lu.assertEquals(candidate(64, 4), 64)\n    lu.assertEquals(candidate(13, 4), 12)\n    lu.assertEquals(candidate(17, 8), 16)\n    lu.assertEquals(candidate(5, 2), 6)\n    lu.assertEquals(candidate(18, 2), 18)\n    lu.assertEquals(candidate(12, 8), 16)\n    lu.assertEquals(candidate(13, 8), 16)\n    lu.assertEquals(candidate(24, 8), 24)\n    lu.assertEquals(candidate(3, 3), 3)\n    lu.assertEquals(candidate(256, 8), 256)\n    lu.assertEquals(candidate(8, 2), 8)\n    lu.assertEquals(candidate(33, 8), 32)\n    lu.assertEquals(candidate(256, 32), 256)\n    lu.assertEquals(candidate(7, 4), 8)\n    lu.assertEquals(candidate(23, 8), 24)\n    lu.assertEquals(candidate(20, 2), 20)\n    lu.assertEquals(candidate(22, 8), 24)\n    lu.assertEquals(candidate(100, 128), 128)\n    lu.assertEquals(candidate(21, 4), 20)\n    lu.assertEquals(candidate(15, 16), 16)\n    lu.assertEquals(candidate(32, 4), 32)\n    lu.assertEquals(candidate(17, 32), 32)\n    lu.assertEquals(candidate(512, 32), 512)\n    lu.assertEquals(candidate(25, 16), 32)\n    lu.assertEquals(candidate(17, 3), 18)\n    lu.assertEquals(candidate(10, 2), 10)\n    lu.assertEquals(candidate(32, 8), 32)\n    lu.assertEquals(candidate(16, 16), 16)\n    lu.assertEquals(candidate(100, 64), 128)\n    lu.assertEquals(candidate(6, 2), 6)\n    lu.assertEquals(candidate(14, 2), 14)\n    lu.assertEquals(candidate(14, 8), 16)\n    lu.assertEquals(candidate(14, 4), 16)\n    lu.assertEquals(candidate(5, 4), 8)\n    lu.assertEquals(candidate(128, 8), 128)\n    lu.assertEquals(candidate(4, 8), 8)\n    lu.assertEquals(candidate(7, 2), 8)\n    lu.assertEquals(candidate(256, 16), 256)\n    lu.assertEquals(candidate(25, 4), 24)\n    lu.assertEquals(candidate(4, 2), 4)\n    lu.assertEquals(candidate(25, 8), 24)\n    lu.assertEquals(candidate(21, 2), 22)\n    lu.assertEquals(candidate(16, 4), 16)\n    lu.assertEquals(candidate(16, 8), 16)\n    lu.assertEquals(candidate(5, 3), 6)\n    lu.assertEquals(candidate(40, 16), 48)\n    lu.assertEquals(candidate(12, 4), 12)\n    lu.assertEquals(candidate(4, 4), 4)\n    lu.assertEquals(candidate(8, 8), 8)\n    lu.assertEquals(candidate(21, 8), 24)\n    lu.assertEquals(candidate(8, 3), 9)\n    lu.assertEquals(candidate(15, 8), 16)\n    lu.assertEquals(candidate(15, 4), 16)\n    lu.assertEquals(candidate(6, 4), 8)\n    lu.assertEquals(candidate(15, 2), 16)\n    lu.assertEquals(candidate(3, 2), 4)\n    lu.assertEquals(candidate(24, 4), 24)\n    lu.assertEquals(candidate(128, 4), 128)\n    lu.assertEquals(candidate(11, 2), 12)\n    lu.assertEquals(candidate(23, 4), 24)\n    lu.assertEquals(candidate(8, 4), 8)\n    lu.assertEquals(candidate(512, 4), 512)\n    lu.assertEquals(candidate(5, 8), 8)\n    lu.assertEquals(candidate(100, 128, 256), 256)\n    lu.assertEquals(candidate(512, 16), 512)\n    lu.assertEquals(candidate(512, 8), 512)\n    lu.assertEquals(candidate(3, 8), 8)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_362264_compute_padding", "language": "lua", "prompt": "-- Computes the padding to be added on the left and on the right\n-- of the signal.\n-- It should hold that 2**J_pad >= N\n-- Parameters\n-- ----------\n-- J_pad : int\n--     2**J_pad is the support of the padded signal\n-- N : int\n--     original signal support size\n-- Returns\n-- -------\n-- pad_left: amount to pad on the left (\"beginning\" of the support)\n-- pad_right: amount to pad on the right (\"end\" of the support)\n-- References\n-- ----------\n-- This is a modification of\n-- https://github.com/kymatio/kymatio/blob/master/kymatio/scattering1d/utils.py\n-- Kymatio, (C) 2018-present. The Kymatio developers.\nlocal function compute_padding(J_pad, N)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_362264_compute_padding.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = compute_padding\n    lu.assertEquals(candidate(1, 2), {0, 0})\n    lu.assertEquals(candidate(12, 2048), {1024, 1024})\n    lu.assertEquals(candidate(5, 16), {8, 8})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_362650_scale_100_to_10", "language": "lua", "prompt": "-- Convert a value from 0-100 range to 0-10 range.\n-- Args:\n--   value: an integer from 0 to 100.\n-- Returns:\n--   an integer from 0 to 10\nlocal function scale_100_to_10(value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_362650_scale_100_to_10.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = scale_100_to_10\n    lu.assertEquals(candidate(), 10)\n    lu.assertEquals(candidate(None), 0)\n    lu.assertEquals(candidate(100), 10)\n    lu.assertEquals(candidate(10), 1)\n    lu.assertEquals(candidate(1000), 10)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(), 0)\n    lu.assertEquals(candidate(), 0)\n    lu.assertEquals(candidate(50), 5)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_36313_I_form", "language": "lua", "prompt": "--     returns Identity matrix of order n\nlocal function I_form(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_36313_I_form.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = I_form\n    lu.assertEquals(candidate(0), {})\n    lu.assertEquals(candidate(4), {{1, 0, 0, 0}, {0, 1, 0, 0}, {0, 0, 1, 0}, {0, 0, 0, 1}})\n    lu.assertEquals(candidate(2), {{1, 0}, {0, 1}})\n    lu.assertEquals(candidate(3), {{1, 0, 0}, {0, 1, 0}, {0, 0, 1}})\n    lu.assertEquals(candidate(3), {{1, 0, 0}, {0, 1, 0}, {0, 0, 1}})\n    lu.assertEquals(candidate(1), {{1}})\n    lu.assertEquals(candidate(5), {{1, 0, 0, 0, 0}, {0, 1, 0, 0, 0}, {0, 0, 1, 0, 0}, {0, 0, 0, 1, 0}, {0, 0, 0, 0, 1}})\n    lu.assertEquals(candidate(2), {{1, 0}, {0, 1}})\n    lu.assertEquals(candidate(2), {{1, 0}, {0, 1}})\n    lu.assertEquals(candidate(2), {{1, 0}, {0, 1}})\n    lu.assertEquals(candidate(3), {{1, 0, 0}, {0, 1, 0}, {0, 0, 1}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_363184_process", "language": "lua", "prompt": "-- Search the container for the element.\n-- :param container_: The list of elements\n-- :param search_element_: The element to search\n-- :return: return position of the element.\nlocal function process(container_, search_element_)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_363184_process.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = process\n    lu.assertEquals(candidate({0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, 8), 8)\n    lu.assertEquals(candidate({0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, 20), -1)\n    lu.assertEquals(candidate({0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, 3), 3)\n    lu.assertEquals(candidate({0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, 6), 6)\n    lu.assertEquals(candidate({0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, 9), 9)\n    lu.assertEquals(candidate({0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, 0), 0)\n    lu.assertEquals(candidate({0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, 4), 4)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_363888_escape_string", "language": "lua", "prompt": "--     Escape a string for command line use.\nlocal function escape_string(value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_363888_escape_string.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = escape_string\n    lu.assertEquals(candidate('foo\\\\nbar'), 'foo\\\\nbar')\n    lu.assertEquals(candidate('\"'), '\\\\\"')\n    lu.assertEquals(candidate('abc'), 'abc')\n    lu.assertEquals(candidate('foo'), 'foo')\n    lu.assertEquals(candidate('foo'), 'foo')\n    lu.assertEquals(candidate('foo'), 'foo')\n    lu.assertEquals(candidate('a'), 'a')\n    lu.assertEquals(candidate(\"{'a': 'b'}\"), \"{'a': 'b'}\")\n    lu.assertEquals(candidate('abc'), 'abc')\n    lu.assertEquals(candidate('abc'), 'abc')\n    lu.assertEquals(candidate('x'), 'x')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_364333__ConvertBoxToCOCOFormat", "language": "lua", "prompt": "-- Converts a box in [ymin, xmin, ymax, xmax] format to COCO format.\n-- This is a utility function for converting from our internal\n-- [ymin, xmin, ymax, xmax] convention to the convention used by the COCO API\n-- i.e., [xmin, ymin, width, height].\n-- Args:\n--   box: a [ymin, xmin, ymax, xmax] numpy array\n-- Returns:\n--   a list of floats representing [xmin, ymin, width, height]\nlocal function _ConvertBoxToCOCOFormat(box)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_364333__ConvertBoxToCOCOFormat.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _ConvertBoxToCOCOFormat\n    lu.assertEquals(candidate({0, 0, 100, 100}), {0.0, 0.0, 100.0, 100.0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_364399_allowed_file_models", "language": "lua", "prompt": "-- Check whether the type is allowed for a bpmn model file.\n-- :param filename: name of the file\n-- :return: True or False\nlocal function allowed_file_models(filename)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_364399_allowed_file_models.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = allowed_file_models\n    lu.assertEquals(candidate('my_filename.xml'), false)\n    lu.assertEquals(candidate('my_filename.jpeg'), false)\n    lu.assertEquals(candidate('my_filename.yaml'), false)\n    lu.assertEquals(candidate('my_filename.txt'), false)\n    lu.assertEquals(candidate('my_filename.png'), false)\n    lu.assertEquals(candidate('my_filename.bpmn'), true)\n    lu.assertEquals(candidate('my_filename.bpn'), false)\n    lu.assertEquals(candidate('my_filename.jpg'), false)\n    lu.assertEquals(candidate('my_filename.bpnm'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_364462_maybe_scream", "language": "lua", "prompt": "-- Returns given text input as caps lock text, if do_scream is true.\n-- Args:\n--     text (str): Some input text\n--     do_scream (bool): Decide, whether to scream or not\n-- Returns:\n--     str: May be in caps lock\nlocal function maybe_scream(text, do_scream)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_364462_maybe_scream.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = maybe_scream\n    lu.assertEquals(candidate('hello', true), 'HELLO')\n    lu.assertEquals(candidate('Some text', true), 'SOME TEXT')\n    lu.assertEquals(candidate('hello', false), 'hello')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_3645_wizard_active", "language": "lua", "prompt": "-- Return the proper classname for the step div in the badge wizard.\n-- The current step needs a 'selected' class while the following step needs a\n-- 'next-selected' class to color the tip of the arrow properly.\nlocal function wizard_active(step, current)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_3645_wizard_active.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = wizard_active\n    lu.assertEquals(candidate(4, 4), 'selected')\n    lu.assertEquals(candidate(3, 2), 'next-selected')\n    lu.assertEquals(candidate(3, 3), 'selected')\n    lu.assertEquals(candidate(2, 1), 'next-selected')\n    lu.assertEquals(candidate(5, 4), 'next-selected')\n    lu.assertEquals(candidate(2, 2), 'selected')\n    lu.assertEquals(candidate(1, 1), 'selected')\n    lu.assertEquals(candidate(4, 3), 'next-selected')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_364777_intervalsIntersect", "language": "lua", "prompt": "-- Returns True if the specified half-closed intervals [a1, b1)\n-- and [a2, b2) intersect.\nlocal function intervalsIntersect(a1, b1, a2, b2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_364777_intervalsIntersect.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = intervalsIntersect\n    lu.assertEquals(candidate(1, 2, 2, 3), false)\n    lu.assertEquals(candidate(0, 10, 11, 20), false)\n    lu.assertEquals(candidate(1, 3, 1, 3), true)\n    lu.assertEquals(candidate(0, 10, -1, 0), false)\n    lu.assertEquals(candidate(1, 3, 1, 2), true)\n    lu.assertEquals(candidate(2, 3, 2, 2), false)\n    lu.assertEquals(candidate(1, 3, 2, 4), true)\n    lu.assertEquals(candidate(0, 10, 5, 20), true)\n    lu.assertEquals(candidate(1, 2, 1, 3), true)\n    lu.assertEquals(candidate(1, 2, 1, 2), true)\n    lu.assertEquals(candidate(0, 10, 10, 100), false)\n    lu.assertEquals(candidate(0, 10, 10, 20), false)\n    lu.assertEquals(candidate(1, 3, 2, 3), true)\n    lu.assertEquals(candidate(2, 3, 1, 2), false)\n    lu.assertEquals(candidate(3, 4, 2, 3), false)\n    lu.assertEquals(candidate(1, 2, 2, 2), false)\n    lu.assertEquals(candidate(1, 1, 1, 2), false)\n    lu.assertEquals(candidate(1, 2, 3, 4), false)\n    lu.assertEquals(candidate(0, 10, 0, 10), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_364905_pick_username", "language": "lua", "prompt": "-- >>> pick_username([\"JonaThan TanoTo\", \"WeiYue Li\"])\n-- 'JonaThan TanoTo'\n-- >>> pick_username([\"JonaThan TanoTo\", \"WeiYue Li\", \"ShuBham KauShal\"])\n-- 'ShuBham KauShal'\n-- >>> pick_username([\"JonaThan TanoTo\", \"WeiYue Li\", \"ShuBham KauShal\", \"MARINA\"])\n-- 'MARINA'\nlocal function pick_username(names)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_364905_pick_username.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = pick_username\n    lu.assertEquals(candidate({'<NAME>', '<NAME>', '<NAME>', 'MARINA'}), 'MARINA')\n    lu.assertEquals(candidate({'JonaThan TanoTo', 'WeiYue Li'}), 'JonaThan TanoTo')\n    lu.assertEquals(candidate({'JonaThan TanoTo', 'WeiYue Li', 'ShuBham KauShal', 'MARINA'}), 'MARINA')\n    lu.assertEquals(candidate({'<NAME>', '<NAME>', '<NAME>'}), '<NAME>')\n    lu.assertEquals(candidate({'JonaThan TanoTo', 'WeiYue Li', 'ShuBham KauShal'}), 'ShuBham KauShal')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_365886_sanitize_phone_field", "language": "lua", "prompt": "-- Phone Number Format\n-- AAAEEENNNNXXXX, where\n-- AAA = Area Code\n-- EEE = Exchange\n-- NNNN = Number\n-- XXXX = Extension\nlocal function sanitize_phone_field(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_365886_sanitize_phone_field.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sanitize_phone_field\n    lu.assertEquals(candidate('5551212'), '5551212')\n    lu.assertEquals(candidate('800-555-1212'), '8005551212')\n    lu.assertEquals(candidate('(800)555-3211'), '8005553211')\n    lu.assertEquals(candidate('800-555-3535'), '8005553535')\n    lu.assertEquals(candidate('912-456-7890'), '9124567890')\n    lu.assertEquals(candidate('912.456.7890'), '9124567890')\n    lu.assertEquals(candidate('800-555-3211'), '8005553211')\n    lu.assertEquals(candidate('(123)456-7890'), '1234567890')\n    lu.assertEquals(candidate('123.456.7890'), '1234567890')\n    lu.assertEquals(candidate('8005551212'), '8005551212')\n    lu.assertEquals(candidate('800(555)3535'), '8005553535')\n    lu.assertEquals(candidate('555-1212'), '5551212')\n    lu.assertEquals(candidate('(800)555-3535'), '8005553535')\n    lu.assertEquals(candidate('123-456-7890'), '1234567890')\n    lu.assertEquals(candidate('546-234-8900'), '5462348900')\n    lu.assertEquals(candidate('800.555.3535'), '8005553535')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_366538_find_stem", "language": "lua", "prompt": "-- Find longest common substring in array of strings.\n-- From https://www.geeksforgeeks.org/longest-common-substring-array-strings/\nlocal function find_stem(arr)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_366538_find_stem.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = find_stem\n    lu.assertEquals(candidate({'Python', 'is', 'the', 'best', 'language'}), '')\n    lu.assertEquals(candidate({'Geeks', 'Geeks'}), 'Geeks')\n    lu.assertEquals(candidate({'Python', 'Python', 'Python'}), 'Python')\n    lu.assertEquals(candidate({'geek', 'gee', 'gee', 'geeksforgeeks'}), 'gee')\n    lu.assertEquals(candidate({'geeks', 'geeksforgeeks', 'geek'}), 'geeks')\n    lu.assertEquals(candidate({'geeksforgeeks', 'geeks', 'geek'}), 'geeks')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_366835_convertosides", "language": "lua", "prompt": "-- Takes polypoints describing the corners of a polygon and returns list of quadruples describing sides of polygon \n-- Input:\n-- polypointsx (list of float): corners of the polygon in a consecutive order, any format, x\n-- polypointsy (list of float): corners of the polygon in a consecutive order, any format, y\n-- Output will be [[x1,x2,y1,y2], ...]\nlocal function convertosides(polypointsx, polypointsy)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_366835_convertosides.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = convertosides\n    lu.assertEquals(candidate({1, 2, 3, 4}, {5, 6, 7, 8, 9}), {{1, 2, 5, 6}, {2, 3, 6, 7}, {3, 4, 7, 8}, {4, 1, 8, 5}})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6}, {7, 8, 9, 10, 11, 12}), {{1, 2, 7, 8}, {2, 3, 8, 9}, {3, 4, 9, 10}, {4, 5, 10, 11}, {5, 6, 11, 12}, {6, 1, 12, 7}})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5}, {6, 7, 8, 9, 10}), {{1, 2, 6, 7}, {2, 3, 7, 8}, {3, 4, 8, 9}, {4, 5, 9, 10}, {5, 1, 10, 6}})\n    lu.assertEquals(candidate({1, 2, 3, 4}, {5, 6, 7, 8}), {{1, 2, 5, 6}, {2, 3, 6, 7}, {3, 4, 7, 8}, {4, 1, 8, 5}})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6}, {7, 8, 9, 10, 11, 12}), {{1, 2, 7, 8}, {2, 3, 8, 9}, {3, 4, 9, 10}, {4, 5, 10, 11}, {5, 6, 11, 12}, {6, 1, 12, 7}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_366856_normalize_format", "language": "lua", "prompt": "-- Turns common shortenings into full format names.\nlocal function normalize_format(fmt)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_366856_normalize_format.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = normalize_format\n    lu.assertEquals(candidate('html'), 'html')\n    lu.assertEquals(candidate('html'), 'html')\n    lu.assertEquals(candidate('md'), 'markdown')\n    lu.assertEquals(candidate('markdown'), 'markdown')\n    lu.assertEquals(candidate('md'), 'markdown')\n    lu.assertEquals(candidate('mm'), 'moinmoin')\n    lu.assertEquals(candidate('rst'), 'rst')\n    lu.assertEquals(candidate('markdown'), 'markdown')\n    lu.assertEquals(candidate('mm'), 'moinmoin')\n    lu.assertEquals(candidate('txt'), 'txt')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_368353_GetComplimentaryHex", "language": "lua", "prompt": "--     :param color:\nlocal function GetComplimentaryHex(color)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_368353_GetComplimentaryHex.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = GetComplimentaryHex\n    lu.assertEquals(candidate('#0000000'), '#FFFFFF')\n    lu.assertEquals(candidate('#00000000000000'), '#FFFFFF')\n    lu.assertEquals(candidate('#000000000'), '#FFFFFF')\n    lu.assertEquals(candidate('#0000000000000'), '#FFFFFF')\n    lu.assertEquals(candidate('#FFFFFF'), '#000000')\n    lu.assertEquals(candidate('#00000000'), '#FFFFFF')\n    lu.assertEquals(candidate('#000000000000000'), '#FFFFFF')\n    lu.assertEquals(candidate('#00000000000'), '#FFFFFF')\n    lu.assertEquals(candidate('#0000000000'), '#FFFFFF')\n    lu.assertEquals(candidate('#000000000000'), '#FFFFFF')\n    lu.assertEquals(candidate('#000000'), '#FFFFFF')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_369037_levenshtein_distance", "language": "lua", "prompt": "-- The minimum amount of edits needed to make s2 into s1.\n-- Args:\n--     s1: string\n--     s2: string\n-- Returns:\n--     int\nlocal function levenshtein_distance(s1, s2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_369037_levenshtein_distance.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = levenshtein_distance\n    lu.assertEquals(candidate('kitten', 'sittingtt'), 5)\n    lu.assertEquals(candidate('abc', 'def'), 3)\n    lu.assertEquals(candidate('123456789', '123456789'), 0)\n    lu.assertEquals(candidate('abcd', 'abcd'), 0)\n    lu.assertEquals(candidate('kitten', 'sitting'), 3)\n    lu.assertEquals(candidate('abc', ''), 3)\n    lu.assertEquals(candidate('kitten', 'sitting'), 3)\n    lu.assertEquals(candidate('abcd', 'abc'), 1)\n    lu.assertEquals(candidate('abc', 'abcd'), 1)\n    lu.assertEquals(candidate('', 'abc'), 3)\n    lu.assertEquals(candidate('abc', 'abc'), 0)\n    lu.assertEquals(candidate('kitten', 'sitttnn'), 3)\n    lu.assertEquals(candidate('kitten', 'sitttn'), 2)\n    lu.assertEquals(candidate('', 'kitten'), 6)\n    lu.assertEquals(candidate('kitten', 'mittens'), 2)\n    lu.assertEquals(candidate('kitten', 'kitten'), 0)\n    lu.assertEquals(candidate('kitten', 'sittttttttnnn'), 9)\n    lu.assertEquals(candidate('one two three four', 'one two three five'), 3)\n    lu.assertEquals(candidate('hello', 'hello'), 0)\n    lu.assertEquals(candidate('kitten', 'kitten'), 0)\n    lu.assertEquals(candidate('kitten', 'sitting'), 3)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_37035_remove_cations", "language": "lua", "prompt": "--     Removes periodic table group 1 and 7 counterions from the SMILES\n-- strings.\n--     Args:\n--     -----\n-- SMILES (str) -- the SMILES string representation of the\n--     molecule.\n--     Returns:\n--     --------\n-- SMILES (str) -- the string representation of the molecule with\n--     the counterions omitted.\nlocal function remove_cations(SMILES)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_37035_remove_cations.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_cations\n    lu.assertEquals(candidate('N1CC(N=c2c(C(C)C)n(C(C)(C)C)c(=O)c2C)CC1'), 'N1CC(N=c2c(C(C)C)n(C(C)(C)C)c(=O)c2C)CC1')\n    lu.assertEquals(candidate('NC1=CC(=O)C(C(C)(C)C)=C1C(N)=O'), 'NC1=CC(=O)C(C(C)(C)C)=C1C(N)=O')\n    lu.assertEquals(candidate('CC(=O)N1CCC(C(=O)c2c(C)n(C(C)(C)C)c(=O)c2C(N)=O)CC1'), 'CC(=O)N1CCC(C(=O)c2c(C)n(C(C)(C)C)c(=O)c2C(N)=O)CC1')\n    lu.assertEquals(candidate('N[N+]1(CCCC1)C'), 'N[N+]1(CCCC1)C')\n    lu.assertEquals(candidate('CN1CCC(C(=O)c2c(C)n(C(C)(C)C)c(=O)c2C(N)=O)CC1'), 'CN1CCC(C(=O)c2c(C)n(C(C)(C)C)c(=O)c2C(N)=O)CC1')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_370597_inline_code", "language": "lua", "prompt": "-- Covert code to inline code\n-- Args:\n--     code (str) : code to be converted to inline code\n-- Returns:\n--     str: inline code\nlocal function inline_code(code)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_370597_inline_code.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = inline_code\n    lu.assertEquals(candidate(\"print('Hello, World!')\"), \"`print('Hello, World!')`\")\n    lu.assertEquals(candidate(\"print('Hello, World!')\"), \"`print('Hello, World!')`\")\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_370651_set_paths_chemkin_files", "language": "lua", "prompt": "-- Set the absolute path to required files on the current machine.\n-- *** only required if using chemkin files****\n-- Parameters\n-- -------\n-- my_path                 : str\n--                         path where all the imput files are located\n-- Returns\n-- -------\n-- thermo_path            : str\n--                         path to the chemkin thermo file\n-- smile_path             : str\n--                         path to the file `species_smiles.dat`\n-- reactionlist_path      : str\n--                         path to the chemkin reaction file\nlocal function set_paths_chemkin_files(my_path)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_370651_set_paths_chemkin_files.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = set_paths_chemkin_files\n    lu.assertEquals(candidate('path/to/data/directory'), {'path/to/data/directory/data/thermo.dat', 'path/to/data/directory/data/species_smiles.dat', 'path/to/data/directory/data/reaction.dat'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_37129_compare_log_to_resp", "language": "lua", "prompt": "--  Search the log list for the responses in the response list\n-- Search through the log list for the lines in the response list. The\n-- response list may contain substrings found in the log list lines. The\n-- response list lines must be found in the log list in the order they\n-- are specified in the response list (the log list may have extra lines\n-- which are ignored).\n-- Returns None if all the strings in the response list were found in the\n-- log list. Otherwise, returns the first missing response line.\nlocal function compare_log_to_resp(log, resp)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_37129_compare_log_to_resp.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = compare_log_to_resp\n    lu.assertEquals(candidate({'The quick brown fox jumps over the lazy dog'}, {'The quick brown fox jumps over the lazy dog', ' ', ' '}), None)\n    lu.assertEquals(candidate({'The quick brown fox jumps over the lazy dog'}, {'The quick brown fox jumps over the lazy dog'}), None)\n    lu.assertEquals(candidate({'The quick brown fox jumps over the lazy dog'}, {'The quick brown fox jumps over the lazy dog', ' ', ' ', ' ', ' '}), None)\n    lu.assertEquals(candidate({'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'}, {'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'}), None)\n    lu.assertEquals(candidate({'The quick brown fox jumps over the lazy dog'}, {'The quick brown fox jumps over the lazy dog', ' ', ' ', ' '}), None)\n    lu.assertEquals(candidate({'This is a test', 'This is another test'}, {'This is a test', 'This is another test'}), None)\n    lu.assertEquals(candidate({'The quick brown fox jumps over the lazy dog', 'The quick brown fox jumps over the lazy dog'}, {'The quick brown fox jumps over the lazy dog', 'The quick brown fox jumps over the lazy dog'}), None)\n    lu.assertEquals(candidate({'This is a test', 'This is another test'}, {'This is a test', 'This is yet another test'}), 'This is yet another test')\n    lu.assertEquals(candidate({'The quick brown fox jumps over the lazy dog'}, {'The quick brown fox jumps over the lazy dog', ''}), None)\n    lu.assertEquals(candidate({'The quick brown fox jumps over the lazy dog', 'The quick brown fox jumps over the lazy dog'}, {'The quick brown fox jumps over the lazy dog'}), None)\n    lu.assertEquals(candidate({'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'}, {'A', 'B', 'C', 'D', 'E', 'G', 'F'}), 'F')\n    lu.assertEquals(candidate({'This is a test', 'This is another test'}, {'This is a test', 'This is yet another test', ''}), 'This is yet another test')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_371762_query_delete_table", "language": "lua", "prompt": "-- Generate table delete query for table with name 'table'\nlocal function query_delete_table(table)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_371762_query_delete_table.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = query_delete_table\n    lu.assertEquals(candidate('books'), 'DROP TABLE IF EXISTS books')\n    lu.assertEquals(candidate(), 'DROP TABLE IF EXISTS students')\n    lu.assertEquals(candidate('students'), 'DROP TABLE IF EXISTS students')\n    lu.assertEquals(candidate('my_table'), 'DROP TABLE IF EXISTS my_table')\n    lu.assertEquals(candidate('Users'), 'DROP TABLE IF EXISTS Users')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_372605_boolean_to_xml", "language": "lua", "prompt": "-- serialize a boolean to XML\n-- :param obj: boolean\n-- :return: string in the XML accepted form\nlocal function boolean_to_xml(obj)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_372605_boolean_to_xml.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = boolean_to_xml\n    lu.assertEquals(candidate(true), 'true')\n    lu.assertEquals(candidate(false), 'false')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_372626_find_integer", "language": "lua", "prompt": "-- :params array: [[]]\n-- :params target: int\n-- :return bool\nlocal function find_integer(array, target)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_372626_find_integer.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = find_integer\n    lu.assertEquals(candidate({{1, 4}, {2, 3}, {3, 4}}, 5), false)\n    lu.assertEquals(candidate({{1, 4}, {2, 3}, {3, 4}}, 7), false)\n    lu.assertEquals(candidate({{1, 3, 5, 7, 9}, {10, 11, 16, 20}, {23, 30, 34, 50}}, 24), false)\n    lu.assertEquals(candidate({{1, 3, 5}, {7, 9, 11}, {20, 21}}, 21), true)\n    lu.assertEquals(candidate({{1, 2, 8, 9}, {2, 4, 9, 12}, {4, 7, 10, 13}, {6, 8, 11, 15}}, 7), true)\n    lu.assertEquals(candidate({{1, 4, 5, 8, 9}, {10, 11, 16, 20}, {23, 30, 34, 50}}, 15), false)\n    lu.assertEquals(candidate({{1, 3, 8, 9}, {2, 4, 9, 12}, {4, 7, 10, 13}, {6, 8, 11, 15}}, 12), true)\n    lu.assertEquals(candidate({}, 1), false)\n    lu.assertEquals(candidate({{1, 3, 5, 7, 9}, {10, 11, 16, 20}, {23, 30, 34, 50}}, 20), true)\n    lu.assertEquals(candidate({{1, 3, 8, 9}, {2, 4, 9, 12}, {4, 7, 10, 13}, {6, 8, 11, 15}}, 13), true)\n    lu.assertEquals(candidate({}, 100), false)\n    lu.assertEquals(candidate({{1, 3, 5}, {7, 9, 11}}, 15), false)\n    lu.assertEquals(candidate({{1, 3, 5, 7, 9}, {10, 11, 16, 20}, {23, 30, 34, 50}}, 10), true)\n    lu.assertEquals(candidate({{1, 3, 5, 7, 9}, {10, 11, 16, 20}, {23, 30, 34, 50}}, 3), true)\n    lu.assertEquals(candidate({{1, 4}, {2, 3}, {3, 4}}, 0), false)\n    lu.assertEquals(candidate({{1, 3, 8, 9}, {2, 4, 9, 12}, {4, 7, 10, 13}, {6, 8, 11, 15}}, 200), false)\n    lu.assertEquals(candidate({{1, 3, 5, 7, 9}, {10, 11, 16, 20}, {23, 30, 34, 50}}, 3), true)\n    lu.assertEquals(candidate({{1, 4}, {2, 3}, {3, 4}}, 4), true)\n    lu.assertEquals(candidate({{1, 4, 5, 8, 9}, {10, 11, 16, 20}, {23, 30, 34, 50}}, 45), false)\n    lu.assertEquals(candidate({{1, 3, 5, 7, 9}, {10, 11, 16, 20}, {23, 30, 34, 50}}, 20), true)\n    lu.assertEquals(candidate({{1, 4}, {2, 3}, {3, 4}}, 3), true)\n    lu.assertEquals(candidate({{1, 3, 5}, {7, 9, 11}}, 3), true)\n    lu.assertEquals(candidate({}, 10), false)\n    lu.assertEquals(candidate({{1, 3, 5, 7, 9}, {10, 11, 16, 20}, {23, 30, 34, 50}}, 4), false)\n    lu.assertEquals(candidate({{1, 3, 5, 7, 9}, {10, 11, 16, 20}, {23, 30, 34, 50}}, 23), true)\n    lu.assertEquals(candidate({{1, 3, 5}, {7, 9, 11}, {20, 21}}, 22), false)\n    lu.assertEquals(candidate({{1, 3, 8, 9}, {2, 4, 9, 12}, {4, 7, 10, 13}, {6, 8, 11, 15}}, 100), false)\n    lu.assertEquals(candidate({{1, 3, 8, 9}, {2, 4, 9, 12}, {4, 7, 10, 13}, {6, 8, 11, 15}}, 2), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_373273_merge_usage_periods", "language": "lua", "prompt": "-- Merge a time period into an existing set of usage periods\nlocal function merge_usage_periods(periods, new_period)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_373273_merge_usage_periods.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = merge_usage_periods\n    lu.assertEquals(candidate({{1, 2}, {3, 4}}, {2, 5}), {{1, 5}})\n    lu.assertEquals(candidate({{10, 20}, {30, 40}, {50, 60}}, {1, 100}), {{1, 100}})\n    lu.assertEquals(candidate({{1, 2}, {3, 4}}, {1, 3}), {{1, 4}})\n    lu.assertEquals(candidate({{1, 2}, {3, 4}}, {1, 5}), {{1, 5}})\n    lu.assertEquals(candidate({{1, 2}}, {3, 4}), {{1, 2}, {3, 4}})\n    lu.assertEquals(candidate({{1, 2}, {3, 4}}, {2, 4}), {{1, 4}})\n    lu.assertEquals(candidate({{1, 2}, {3, 4}}, {1, 4}), {{1, 4}})\n    lu.assertEquals(candidate({{1, 2}, {3, 4}}, {2, 3}), {{1, 4}})\n    lu.assertEquals(candidate({{1, 2}, {3, 4}}, {5, 6}), {{1, 2}, {3, 4}, {5, 6}})\n    lu.assertEquals(candidate({{10, 20}, {30, 40}}, {10, 30}), {{10, 40}})\n    lu.assertEquals(candidate({{10, 20}, {30, 40}, {50, 60}}, {30, 50}), {{10, 20}, {30, 60}})\n    lu.assertEquals(candidate({}, {1, 2}), {{1, 2}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_373677_S_VAR_ASSIGN", "language": "lua", "prompt": "-- Evaluates an S_STATEMENT node\nlocal function S_VAR_ASSIGN(vardec, assign, data)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_373677_S_VAR_ASSIGN.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = S_VAR_ASSIGN\n    lu.assertEquals(candidate('v3', '=', '4'), 'v3=4')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_373751_sort_array_for_min_number", "language": "lua", "prompt": "-- :param nums: int list\n-- :return: min number string\nlocal function sort_array_for_min_number(nums)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_373751_sort_array_for_min_number.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sort_array_for_min_number\n    lu.assertEquals(candidate({1, 2, 4, 5, 3}), '12345')\n    lu.assertEquals(candidate({5, 4, 3, 2, 1}), '12345')\n    lu.assertEquals(candidate({1, 2, 3, 5, 4}), '12345')\n    lu.assertEquals(candidate({5, 1, 2, 3, 4}), '12345')\n    lu.assertEquals(candidate({1, 2, 3, 4, 5}), '12345')\n    lu.assertEquals(candidate({1, 2, 5, 4, 3}), '12345')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_373808_parse_time_cmd", "language": "lua", "prompt": "--  Convert timing info from `time` into float seconds.\t\n-- E.g. parse_time('0m0.000s') -> 0.0\t\nlocal function parse_time_cmd(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_373808_parse_time_cmd.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_time_cmd\n    lu.assertEquals(candidate('10m0.000s'), 600.0)\n    lu.assertEquals(candidate('0m0.010s'), 0.01)\n    lu.assertEquals(candidate('0m0.000s'), 0.0)\n    lu.assertEquals(candidate('1m0.000s'), 60.0)\n    lu.assertEquals(candidate('0m0.001s'), 0.001)\n    lu.assertEquals(candidate('0m10.000s'), 10.0)\n    lu.assertEquals(candidate('0m0.010s'), 0.01)\n    lu.assertEquals(candidate('0m2.000s'), 2.0)\n    lu.assertEquals(candidate('0m0.100s'), 0.1)\n    lu.assertEquals(candidate('1m0.000s'), 60.0)\n    lu.assertEquals(candidate('100m0.000s'), 6000.0)\n    lu.assertEquals(candidate('0m0.000s'), 0.0)\n    lu.assertEquals(candidate('0m0.001s'), 0.001)\n    lu.assertEquals(candidate('0m0.100s'), 0.1)\n    lu.assertEquals(candidate('0m0.000s'), 0.0)\n    lu.assertEquals(candidate('0m1.000s'), 1.0)\n    lu.assertEquals(candidate('0m0.001s'), 0.001)\n    lu.assertEquals(candidate('0m1.000s'), 1.0)\n    lu.assertEquals(candidate('1000m0.000s'), 60000.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_374512__convert_ratio_to_int", "language": "lua", "prompt": "--     Round the ratio to 2 decimal places, multiply by 100, and take the integer part.\nlocal function _convert_ratio_to_int(ratio)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_374512__convert_ratio_to_int.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _convert_ratio_to_int\n    lu.assertEquals(candidate(0.03), 3)\n    lu.assertEquals(candidate(0.41), 41)\n    lu.assertEquals(candidate(0.19), 19)\n    lu.assertEquals(candidate(0.39), 39)\n    lu.assertEquals(candidate(0.49), 49)\n    lu.assertEquals(candidate(0.5), 50)\n    lu.assertEquals(candidate(1.01), 101)\n    lu.assertEquals(candidate(0.11), 11)\n    lu.assertEquals(candidate(0.5), 50)\n    lu.assertEquals(candidate(1.234567891234568), 123)\n    lu.assertEquals(candidate(0.51), 51)\n    lu.assertEquals(candidate(0.2), 20)\n    lu.assertEquals(candidate(0.125), 12)\n    lu.assertEquals(candidate(0.1), 10)\n    lu.assertEquals(candidate(0.3), 30)\n    lu.assertEquals(candidate(0.75), 75)\n    lu.assertEquals(candidate(1.0), 100)\n    lu.assertEquals(candidate(0.4), 40)\n    lu.assertEquals(candidate(0.6), 60)\n    lu.assertEquals(candidate(0.01), 1)\n    lu.assertEquals(candidate(0.31), 31)\n    lu.assertEquals(candidate(0.99), 99)\n    lu.assertEquals(candidate(0.1), 10)\n    lu.assertEquals(candidate(0.21), 21)\n    lu.assertEquals(candidate(0.61), 61)\n    lu.assertEquals(candidate(0.59), 59)\n    lu.assertEquals(candidate(1.23456789), 123)\n    lu.assertEquals(candidate(0.1234), 12)\n    lu.assertEquals(candidate(0.0), 0)\n    lu.assertEquals(candidate(0.0), 0)\n    lu.assertEquals(candidate(0.09), 9)\n    lu.assertEquals(candidate(0.25), 25)\n    lu.assertEquals(candidate(0.02), 2)\n    lu.assertEquals(candidate(1.2345678912345), 123)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_374778_str2float", "language": "lua", "prompt": "-- Converts a string to a float.\nlocal function str2float(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_374778_str2float.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = str2float\n    lu.assertEquals(candidate(1.0), 1.0)\n    lu.assertEquals(candidate('1.0/1.0'), 1.0)\n    lu.assertEquals(candidate('10'), 10.0)\n    lu.assertEquals(candidate('0'), 0.0)\n    lu.assertEquals(candidate('1/2'), 0.5)\n    lu.assertEquals(candidate('1'), 1.0)\n    lu.assertEquals(candidate('1/4'), 0.25)\n    lu.assertEquals(candidate('10.0'), 10.0)\n    lu.assertEquals(candidate('0.0/1.0'), 0.0)\n    lu.assertEquals(candidate(1), 1.0)\n    lu.assertEquals(candidate('1/1'), 1.0)\n    lu.assertEquals(candidate('1/2.0'), 0.5)\n    lu.assertEquals(candidate('0.0'), 0.0)\n    lu.assertEquals(candidate('0/1'), 0.0)\n    lu.assertEquals(candidate('1.0/2.0'), 0.5)\n    lu.assertEquals(candidate('1.0'), 1.0)\n    lu.assertEquals(candidate('1/1.0'), 1.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_375173_format_sequence", "language": "lua", "prompt": "--  Places the replacement character everywhere there is a False in the\n-- template list\n-- input: list list string\n-- returns: string\nlocal function format_sequence(template, sequence, repl_char)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_375173_format_sequence.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = format_sequence\n    lu.assertEquals(candidate(list('00000'), list('10011'), '?'), '10011')\n    lu.assertEquals(candidate(list('000'), list('011'), '?'), '011')\n    lu.assertEquals(candidate(list('0000'), list('1011'), '?'), '1011')\n    lu.assertEquals(candidate(list('000000'), list('100110'), '?'), '100110')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_375564_sort_list", "language": "lua", "prompt": "--  index: int number, according to it to sort data_list\nlocal function sort_list(data_list, index, reverse)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_375564_sort_list.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sort_list\n    lu.assertEquals(candidate({{'oranges', 5}, {'apples', 2}, {'bananas', 1}}, 1), {{'oranges', 5}, {'apples', 2}, {'bananas', 1}})\n    lu.assertEquals(candidate({{'oranges', 5}, {'apples', 2}, {'bananas', 1}}, 0, false), {{'apples', 2}, {'bananas', 1}, {'oranges', 5}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_375823_hreflang_formatter", "language": "lua", "prompt": "--     sitemap hreflang should follow correct format.\n-- Use hyphen instead of underscore in language and country value.\n--     ref: https://en.wikipedia.org/wiki/Hreflang#Common_Mistakes\n--     source: https://github.com/readthedocs/readthedocs.org/pull/5638\nlocal function hreflang_formatter(lang)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_375823_hreflang_formatter.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = hreflang_formatter\n    lu.assertEquals(candidate('en_GB'), 'en-GB')\n    lu.assertEquals(candidate('en_us'), 'en-us')\n    lu.assertEquals(candidate('zh-CN'), 'zh-CN')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('zh_CN'), 'zh-CN')\n    lu.assertEquals(candidate('zh-TW'), 'zh-TW')\n    lu.assertEquals(candidate('zh_TW'), 'zh-TW')\n    lu.assertEquals(candidate('zh_tw'), 'zh-tw')\n    lu.assertEquals(candidate('zh_cn'), 'zh-cn')\n    lu.assertEquals(candidate('en'), 'en')\n    lu.assertEquals(candidate('zh-tw'), 'zh-tw')\n    lu.assertEquals(candidate('zh-cn'), 'zh-cn')\n    lu.assertEquals(candidate('en'), 'en')\n    lu.assertEquals(candidate('en_US'), 'en-US')\n    lu.assertEquals(candidate('en-US'), 'en-US')\n    lu.assertEquals(candidate('en_gb'), 'en-gb')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_376349__to_swarming_dimensions", "language": "lua", "prompt": "-- Converts dimensions from buildbucket format to swarming format.\nlocal function _to_swarming_dimensions(dims)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_376349__to_swarming_dimensions.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _to_swarming_dimensions\n    lu.assertEquals(candidate({'os:mac', 'cpu:x86'}), {{['key'] = 'os', ['value'] = 'mac'}, {['key'] = 'cpu', ['value'] = 'x86'}})\n    lu.assertEquals(candidate({'pool:default', 'os:Ubuntu', 'cpu:x86-64', 'gce-vm:1', 'gpu:none'}), {{['key'] = 'pool', ['value'] = 'default'}, {['key'] = 'os', ['value'] = 'Ubuntu'}, {['key'] = 'cpu', ['value'] = 'x86-64'}, {['key'] = 'gce-vm', ['value'] = '1'}, {['key'] = 'gpu', ['value'] = 'none'}})\n    lu.assertEquals(candidate({'os:OS', 'cpu:arm', 'pool:Chrome', 'gpu:GTX660', 'device_type:tablet'}), {{['key'] = 'os', ['value'] = 'OS'}, {['key'] = 'cpu', ['value'] = 'arm'}, {['key'] = 'pool', ['value'] = 'Chrome'}, {['key'] = 'gpu', ['value'] = 'GTX660'}, {['key'] = 'device_type', ['value'] = 'tablet'}})\n    lu.assertEquals(candidate({'os:mac', 'cpu:x86', 'pool:'}), {{['key'] = 'os', ['value'] = 'mac'}, {['key'] = 'cpu', ['value'] = 'x86'}, {['key'] = 'pool', ['value'] = ''}})\n    lu.assertEquals(candidate({'os:Mac-10.9', 'pool:Chrome-perf', 'cpu:x86-64'}), {{['key'] = 'os', ['value'] = 'Mac-10.9'}, {['key'] = 'pool', ['value'] = 'Chrome-perf'}, {['key'] = 'cpu', ['value'] = 'x86-64'}})\n    lu.assertEquals(candidate({'os:Mac-10.9', 'pool:Chrome', 'cpu:x86-64'}), {{['key'] = 'os', ['value'] = 'Mac-10.9'}, {['key'] = 'pool', ['value'] = 'Chrome'}, {['key'] = 'cpu', ['value'] = 'x86-64'}})\n    lu.assertEquals(candidate({'os:mac', 'cpu:x86', 'pool:default'}), {{['key'] = 'os', ['value'] = 'mac'}, {['key'] = 'cpu', ['value'] = 'x86'}, {['key'] = 'pool', ['value'] = 'default'}})\n    lu.assertEquals(candidate({'os:Mac', 'pool:Chrome-perf'}), {{['key'] = 'os', ['value'] = 'Mac'}, {['key'] = 'pool', ['value'] = 'Chrome-perf'}})\n    lu.assertEquals(candidate({'os:Windows', 'pool:Chrome-perf'}), {{['key'] = 'os', ['value'] = 'Windows'}, {['key'] = 'pool', ['value'] = 'Chrome-perf'}})\n    lu.assertEquals(candidate({'os:mac', 'cpu:x86', 'pool:default:'}), {{['key'] = 'os', ['value'] = 'mac'}, {['key'] = 'cpu', ['value'] = 'x86'}, {['key'] = 'pool', ['value'] = 'default:'}})\n    lu.assertEquals(candidate({'os:Debian', 'cpu:x86-64', 'gce-vm:1', 'gpu:none'}), {{['key'] = 'os', ['value'] = 'Debian'}, {['key'] = 'cpu', ['value'] = 'x86-64'}, {['key'] = 'gce-vm', ['value'] = '1'}, {['key'] = 'gpu', ['value'] = 'none'}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_376708_build_matrix_row", "language": "lua", "prompt": "-- Populate row given all possible hits, accepted hits and an optional score\n-- :param all_vfs: a list of all virulence factor ids\n-- :param accepted_hits: a list of a hits that passed the cutoof\n-- :param score: the value to fill the matrix with (default = None which\n--               implies 0.5)\n-- :type all_vfs: list\n-- :type accepted_hits: list\n-- :type score: float\n-- :rtype: a list of floats\nlocal function build_matrix_row(all_vfs, accepted_hits, score)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_376708_build_matrix_row.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = build_matrix_row\n    lu.assertEquals(candidate({'10001', '10002', '10003', '10004', '10005'}, {'10001', '10002'}, 1.0), {1.0, 1.0, 0.5, 0.5, 0.5})\n    lu.assertEquals(candidate({'10001', '10002', '10003', '10004', '10005'}, {'10001', '10002'}, 0.0), {0.0, 0.0, 0.5, 0.5, 0.5})\n    lu.assertEquals(candidate({}, {}), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_376729_hosoya", "language": "lua", "prompt": "--  Calculates the hosoya triangle\n-- height -- height of the triangle\nlocal function hosoya(height, width)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_376729_hosoya.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = hosoya\n    lu.assertEquals(candidate(3, 1), 2)\n    lu.assertEquals(candidate(1, 1), 1)\n    lu.assertEquals(candidate(1, 3), 0)\n    lu.assertEquals(candidate(5, 5), 8)\n    lu.assertEquals(candidate(5, 4), 5)\n    lu.assertEquals(candidate(0, 2), 0)\n    lu.assertEquals(candidate(0, 2), 0)\n    lu.assertEquals(candidate(3, 2), 2)\n    lu.assertEquals(candidate(4, 4), 5)\n    lu.assertEquals(candidate(1, 1), 1)\n    lu.assertEquals(candidate(2, 1), 1)\n    lu.assertEquals(candidate(1, 0), 1)\n    lu.assertEquals(candidate(1, 3), 0)\n    lu.assertEquals(candidate(3, 3), 3)\n    lu.assertEquals(candidate(1, 0), 1)\n    lu.assertEquals(candidate(0, 0), 1)\n    lu.assertEquals(candidate(2, 1), 1)\n    lu.assertEquals(candidate(0, 0), 1)\n    lu.assertEquals(candidate(0, 3), 0)\n    lu.assertEquals(candidate(0, 3), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_37718_how_many_days", "language": "lua", "prompt": "-- Returns the number of days in a month.\n-- WARNING: This function doesn't account for leap years!\nlocal function how_many_days(month_number)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_37718_how_many_days.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = how_many_days\n    lu.assertEquals(candidate(5), 31)\n    lu.assertEquals(candidate(2), 28)\n    lu.assertEquals(candidate(9), 30)\n    lu.assertEquals(candidate(12), 31)\n    lu.assertEquals(candidate(11), 30)\n    lu.assertEquals(candidate(4), 30)\n    lu.assertEquals(candidate(8), 31)\n    lu.assertEquals(candidate(10), 31)\n    lu.assertEquals(candidate(6), 30)\n    lu.assertEquals(candidate(7), 31)\n    lu.assertEquals(candidate(1), 31)\n    lu.assertEquals(candidate(3), 31)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_379101_line_parameters_xy", "language": "lua", "prompt": "-- Used in lines_intersection\n-- from:\n-- https://stackoverflow.com/questions/20677795/how-do-i-compute-the-intersection-point-of-two-lines-in-python\nlocal function line_parameters_xy(pt_1, pt_2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_379101_line_parameters_xy.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = line_parameters_xy\n    lu.assertEquals(candidate({0, 0}, {1, 1}), {-1, 1, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_379304_countBits", "language": "lua", "prompt": "-- Count number of bits needed to store a (positive) integer number.\n-- >>> countBits(0)\n-- 1\n-- >>> countBits(1000)\n-- 10\n-- >>> countBits(44100)\n-- 16\n-- >>> countBits(18446744073709551615)\n-- 64\nlocal function countBits(value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_379304_countBits.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = countBits\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(3), 2)\n    lu.assertEquals(candidate(10), 4)\n    lu.assertEquals(candidate(44100), 16)\n    lu.assertEquals(candidate(100), 7)\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(6), 3)\n    lu.assertEquals(candidate(8), 4)\n    lu.assertEquals(candidate(1000), 10)\n    lu.assertEquals(candidate(0), 1)\n    lu.assertEquals(candidate(4), 3)\n    lu.assertEquals(candidate(9), 4)\n    lu.assertEquals(candidate(7), 3)\n    lu.assertEquals(candidate(5), 3)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_379324_int_max_value", "language": "lua", "prompt": "-- Returns the maximum int value of a signed or unsigned integer\n-- based on used bits.\n-- Arguments:\n-- bits -- How many bits, e.g., 16\n-- signed -- True if a signed int\n-- Returns:\n-- max_value -- The maximum int value based on given parameters\nlocal function int_max_value(bits, signed)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_379324_int_max_value.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = int_max_value\n    lu.assertEquals(candidate(8, true), 127)\n    lu.assertEquals(candidate(16, true), 32767)\n    lu.assertEquals(candidate(8, false), 255)\n    lu.assertEquals(candidate(8), 127)\n    lu.assertEquals(candidate(16, false), 65535)\n    lu.assertEquals(candidate(32, false), 4294967295)\n    lu.assertEquals(candidate(64, false), 18446744073709551615)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_379765_sum_numbers", "language": "lua", "prompt": "-- Calculate the sum of integers less than upper.\nlocal function sum_numbers(upper)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_379765_sum_numbers.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sum_numbers\n    lu.assertEquals(candidate(3), 3)\n    lu.assertEquals(candidate(5), 10)\n    lu.assertEquals(candidate(2), 1)\n    lu.assertEquals(candidate(1001), 500500)\n    lu.assertEquals(candidate(1), 0)\n    lu.assertEquals(candidate(101), 5050)\n    lu.assertEquals(candidate(10), 45)\n    lu.assertEquals(candidate(100), 4950)\n    lu.assertEquals(candidate(0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_380059_comment_lines", "language": "lua", "prompt": "-- Return commented lines\nlocal function comment_lines(lines, prefix)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_380059_comment_lines.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = comment_lines\n    lu.assertEquals(candidate({'This is a short comment.'}, '#'), {'# This is a short comment.'})\n    lu.assertEquals(candidate({'This is the first line.', 'This is the second line.'}, ''), {'This is the first line.', 'This is the second line.'})\n    lu.assertEquals(candidate({''}, ''), {''})\n    lu.assertEquals(candidate({}, '#'), {})\n    lu.assertEquals(candidate({'This is the first line.', 'This is the second line.'}, '#'), {'# This is the first line.', '# This is the second line.'})\n    lu.assertEquals(candidate({'This is a long comment', 'that contains multiple lines.'}, '#'), {'# This is a long comment', '# that contains multiple lines.'})\n    lu.assertEquals(candidate({''}, '#'), {'#'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_380282_dict_item", "language": "lua", "prompt": "-- 'Template filter to allow accessing dictionary value by variable key.\n-- Example use::\n--     {{ mydict|dict_item:keyvar }}\nlocal function dict_item(dictionary, key)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_380282_dict_item.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = dict_item\n    lu.assertEquals(candidate({['a'] = 'A', ['b'] = 'B', ['c'] = 'C'}, 'c'), 'C')\n    lu.assertEquals(candidate({['a'] = '1', ['b'] = '2'}, 'a'), '1')\n    lu.assertEquals(candidate({['a'] = 'A', ['b'] = 'B', ['c'] = 'C'}, 'a'), 'A')\n    lu.assertEquals(candidate({['a'] = '1', ['b'] = '2'}, 'b'), '2')\n    lu.assertEquals(candidate({['a'] = 'A', ['b'] = 'B', ['c'] = 'C'}, 'b'), 'B')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_38089_respuesta", "language": "lua", "prompt": "--  Funcion para formatear la respuesta. \nlocal function respuesta(res)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_38089_respuesta.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = respuesta\n    lu.assertEquals(candidate(true), 'iguales')\n    lu.assertEquals(candidate(false), 'diferentes')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_381395_camelize", "language": "lua", "prompt": "-- Make a camelcase string\n-- Args:\n--   strings (list[string]): list of strings\n-- DocTests:\n--   >>> camelize(['one', 'two', 'three'])\n--   'OneTwoThree'\nlocal function camelize(strings)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_381395_camelize.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = camelize\n    lu.assertEquals(candidate({'123', 'four'}), '123Four')\n    lu.assertEquals(candidate({'this', 'is', 'a', 'sentence'}), 'ThisIsASentence')\n    lu.assertEquals(candidate({'one', 'two', 'three', 'four', 'five'}), 'OneTwoThreeFourFive')\n    lu.assertEquals(candidate({'one', 'two', 'three'}), 'OneTwoThree')\n    lu.assertEquals(candidate({'candidate', 'me'}), 'CamelizeMe')\n    lu.assertEquals(candidate({'one', 'two', 'three'}), 'OneTwoThree')\n    lu.assertEquals(candidate(list()), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_382168__remove_by_index_list", "language": "lua", "prompt": "-- Remove all substrings inside a string, thanks to the given list of indexes \nlocal function _remove_by_index_list(text, index_list)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_382168__remove_by_index_list.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _remove_by_index_list\n    lu.assertEquals(candidate('Hello, World!', {{100, 200}}), 'Hello, World!')\n    lu.assertEquals(candidate('Hello, World!', {{100, 100}}), 'Hello, World!')\n    lu.assertEquals(candidate('Hello, World!', {{1, 1}, {1, 1}}), 'Hello, World!')\n    lu.assertEquals(candidate('Hello, World!', {{100, 101}, {100, 101}}), 'Hello, World!')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_382424_weight_path", "language": "lua", "prompt": "--  Get path of weights based on path to IR\n-- Params:\n-- model_path: the string contains path to IR file\n-- Return:\n-- Path to weights file\nlocal function weight_path(model_path)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_382424_weight_path.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = weight_path\n    lu.assertEquals(candidate('test.xml'), 'test.bin')\n    lu.assertEquals(candidate('/path/to/file/mobilenet-ssd.xml'), '/path/to/file/mobilenet-ssd.bin')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_382473_string_rotation", "language": "lua", "prompt": "-- :param x: string\n-- :param y: string\n-- :return:\nlocal function string_rotation(x, y)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_382473_string_rotation.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = string_rotation\n    lu.assertEquals(candidate('waterbottle', 'bottlewater'), true)\n    lu.assertEquals(candidate('waterbottle', 'waterbottle'), true)\n    lu.assertEquals(candidate('123456', '1234567'), false)\n    lu.assertEquals(candidate('12345', '12345'), true)\n    lu.assertEquals(candidate('waterbottle', 'waterbottle'), true)\n    lu.assertEquals(candidate('bottlewater', 'bottlewater'), true)\n    lu.assertEquals(candidate('12345', '12345'), true)\n    lu.assertEquals(candidate('waterbottle', 'bottlewater'), true)\n    lu.assertEquals(candidate('abcdefg', 'efgabcd'), true)\n    lu.assertEquals(candidate('waterbottle', 'erbottlewat'), true)\n    lu.assertEquals(candidate('waterbottle', 'waterbottle'), true)\n    lu.assertEquals(candidate('waterbottle', 'erbottlewa'), false)\n    lu.assertEquals(candidate('waterbottle', 'erbottlewat'), true)\n    lu.assertEquals(candidate('waterbottle', 'waterbottle'), true)\n    lu.assertEquals(candidate('waterbottle', 'erbottlewat'), true)\n    lu.assertEquals(candidate('a', 'b'), false)\n    lu.assertEquals(candidate('erbottlewax', 'erbottlewat'), false)\n    lu.assertEquals(candidate('', 'a'), false)\n    lu.assertEquals(candidate('waterbottle', 'erbottleaw'), false)\n    lu.assertEquals(candidate('123456', '123789'), false)\n    lu.assertEquals(candidate('123456', '123465'), false)\n    lu.assertEquals(candidate('123456', '123456'), true)\n    lu.assertEquals(candidate('a', 'a'), true)\n    lu.assertEquals(candidate('erbottlewat', 'waterbottle'), true)\n    lu.assertEquals(candidate('123456', '12345'), false)\n    lu.assertEquals(candidate('waterbottle', 'erbottlewat'), true)\n    lu.assertEquals(candidate('bottlewater', 'waterbottle'), true)\n    lu.assertEquals(candidate('waterbottle', 'waterrbottle'), false)\n    lu.assertEquals(candidate('waterbottle', 'erbottlewat'), true)\n    lu.assertEquals(candidate('erbottlewat', 'erbottlewax'), false)\n    lu.assertEquals(candidate('waterrbottle', 'waterbottle'), false)\n    lu.assertEquals(candidate('123456', '234567'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_383084_join_namespace", "language": "lua", "prompt": "-- Joins a namespace and a bare identifier into a full identifier.\n-- >>> join_namespace('a', 'b')\n-- 'a:b'\n-- >>> join_namespace('', 'b')\n-- ':b'\nlocal function join_namespace(namespace, ident)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_383084_join_namespace.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = join_namespace\n    lu.assertEquals(candidate('a', 'b'), 'a:b')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_383373_splitrip", "language": "lua", "prompt": "-- Pass.\nlocal function splitrip(obj, split)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_383373_splitrip.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = splitrip\n    lu.assertEquals(candidate(' a b c d ', ' '), {'a', 'b', 'c', 'd'})\n    lu.assertEquals(candidate('Hello\\tWorld\\tHow\\tAre\\tYou', '\\t'), {'Hello', 'World', 'How', 'Are', 'You'})\n    lu.assertEquals(candidate('a\\tb\\t\\tc\\t\\td', '\\t'), {'a', 'b', 'c', 'd'})\n    lu.assertEquals(candidate('\\tHello\\tWorld\\tHow\\tAre\\tYou\\t', '\\t'), {'Hello', 'World', 'How', 'Are', 'You'})\n    lu.assertEquals(candidate('Hello\\tWorld\\tHow\\tAre\\tYou', ' '), {'Hello\\tWorld\\tHow\\tAre\\tYou'})\n    lu.assertEquals(candidate('a b c d', 'x'), {'a b c d'})\n    lu.assertEquals(candidate('\\t\\t', '\\t'), {})\n    lu.assertEquals(candidate('Hello\\tWorld\\tHow\\tAre\\tYou\\t\\t', '\\t'), {'Hello', 'World', 'How', 'Are', 'You'})\n    lu.assertEquals(candidate('', '\\t'), {})\n    lu.assertEquals(candidate('a b c d', ' '), {'a', 'b', 'c', 'd'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_383429_bool_", "language": "lua", "prompt": "--  Convert boolean or string to boolean, also 'False' and 'F' to False \nlocal function bool_(input_)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_383429_bool_.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = bool_\n    lu.assertEquals(candidate('False'), false)\n    lu.assertEquals(candidate('Yes'), true)\n    lu.assertEquals(candidate('True'), true)\n    lu.assertEquals(candidate('Y'), true)\n    lu.assertEquals(candidate('T'), true)\n    lu.assertEquals(candidate('F'), false)\n    lu.assertEquals(candidate('f'), false)\n    lu.assertEquals(candidate('1'), true)\n    lu.assertEquals(candidate(''), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_383665_digitsaverage", "language": "lua", "prompt": "-- Return the average of the digits until number is one digit.\n-- input = integer\n-- output = integer, single digit\n-- ex. 246 = 4 i.e. avg of 2 and 4 is 3, average of 4 and 6 is 5\n--     so after first iteration 246 => 35\n--     avg of 3 and 5 is 4 so digitsAverage(246) returns 4\nlocal function digitsaverage(d)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_383665_digitsaverage.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = digitsaverage\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(7), 7)\n    lu.assertEquals(candidate(246), 4)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(987), 9)\n    lu.assertEquals(candidate(9), 9)\n    lu.assertEquals(candidate(6), 6)\n    lu.assertEquals(candidate(3), 3)\n    lu.assertEquals(candidate(10), 1)\n    lu.assertEquals(candidate(2222), 2)\n    lu.assertEquals(candidate(5), 5)\n    lu.assertEquals(candidate(8), 8)\n    lu.assertEquals(candidate(4), 4)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_384049__formatArraySplitWiden", "language": "lua", "prompt": "-- Private func that gets iterated over as part of enjambing multiple formatted arrays side-by-side.\n-- Adds spaces such that the mutable sequence arFmtSplit (if joined by `\n-- `) will print as a rectangle.\n-- Optionally also extends the \"height\" of the rectangle to match lineCount. If lineCount <= len(arFmtSplit), nothing happens.\nlocal function _formatArraySplitWiden(arFmtSplit, blank, linecount)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_384049__formatArraySplitWiden.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _formatArraySplitWiden\n    lu.assertEquals(candidate({'a1', 'b1', 'c1', 'd1'}, ' ', 4), {'a1', 'b1', 'c1', 'd1'})\n    lu.assertEquals(candidate({'a1', 'b1', 'c1', 'd1'}, '', 6), {'a1', 'b1', 'c1', 'd1', '', ''})\n    lu.assertEquals(candidate({'a1', 'b1', 'c1', 'd1'}, '', 5), {'a1', 'b1', 'c1', 'd1', ''})\n    lu.assertEquals(candidate({'a1', 'b1', 'c1', 'd1'}, '', 4), {'a1', 'b1', 'c1', 'd1'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_384332_pascal_case", "language": "lua", "prompt": "-- Convert the first letter of a string to uppercase, to make the identifier\n-- conform to PascalCase.\n-- If there are dots, remove the dots, and capitalize the letter following\n-- where the dot was. Letters that weren't following dots are left unchanged,\n-- except for the first letter of the string (which is made upper-case).\n-- Args:\n--   what: a string representing some identifier\n-- Returns:\n--   String with first letter capitalized\n-- Example:\n--   pascal_case(\"helloWorld\") == \"HelloWorld\"\n--   pascal_case(\"foo\") == \"Foo\"\n--   pascal_case(\"hello.world\") = \"HelloWorld\"\n--   pascal_case(\"fooBar.fooBar\") = \"FooBarFooBar\"\nlocal function pascal_case(what)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_384332_pascal_case.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = pascal_case\n    lu.assertEquals(candidate('HELLO WORLD'), 'HELLO WORLD')\n    lu.assertEquals(candidate('hello.world'), 'HelloWorld')\n    lu.assertEquals(candidate('foo'), 'Foo')\n    lu.assertEquals(candidate('abc'), 'Abc')\n    lu.assertEquals(candidate('fooBar.fooBar'), 'FooBarFooBar')\n    lu.assertEquals(candidate('helloWorld'), 'HelloWorld')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_384769_ip_to_binary", "language": "lua", "prompt": "-- Convert an IPv4 address to a string containing the binary conversion of the\n-- IP address.\n-- Args:\n--     ip - The ip address to convert\nlocal function ip_to_binary(ip)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_384769_ip_to_binary.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = ip_to_binary\n    lu.assertEquals(candidate('10.10.10.10'), '00001010000010100000101000001010')\n    lu.assertEquals(candidate('192.168.1.1'), '11000000101010000000000100000001')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_384893_remove_quotes", "language": "lua", "prompt": "--  remove all (double) quotes\nlocal function remove_quotes(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_384893_remove_quotes.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_quotes\n    lu.assertEquals(candidate('abc\"'), 'abc')\n    lu.assertEquals(candidate('a\"bc'), 'abc')\n    lu.assertEquals(candidate('\"a\"bc\"'), 'abc')\n    lu.assertEquals(candidate('\"abc'), 'abc')\n    lu.assertEquals(candidate('abc'), 'abc')\n    lu.assertEquals(candidate('a\"bc\"'), 'abc')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_385138_get_next_step_size", "language": "lua", "prompt": "-- Calculate next size of step for a TQDM progress-bar.\n-- :param total:\n-- :param block_size:\n-- :param current_offset:\n-- :return:\nlocal function get_next_step_size(total, block_size, current_offset)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_385138_get_next_step_size.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_next_step_size\n    lu.assertEquals(candidate(2, 2, 0), 0)\n    lu.assertEquals(candidate(10, 2, 10), 0)\n    lu.assertEquals(candidate(10, 5, 10), 0)\n    lu.assertEquals(candidate(1, 0, 0), 0)\n    lu.assertEquals(candidate(2, 1, 1), 1)\n    lu.assertEquals(candidate(2, 2, 1), 1)\n    lu.assertEquals(candidate(10, 2, 1), 1)\n    lu.assertEquals(candidate(100, 10, 100), 0)\n    lu.assertEquals(candidate(3, 0, 1), 1)\n    lu.assertEquals(candidate(3, 0, 0), 0)\n    lu.assertEquals(candidate(100, 10, 5), 5)\n    lu.assertEquals(candidate(2, 0, 0), 0)\n    lu.assertEquals(candidate(0, 0, 0), 0)\n    lu.assertEquals(candidate(2, 0, 2), 2)\n    lu.assertEquals(candidate(0, 1, 0), 0)\n    lu.assertEquals(candidate(1, 0, 1), 1)\n    lu.assertEquals(candidate(10, 5, 5), 5)\n    lu.assertEquals(candidate(2, 0, 1), 1)\n    lu.assertEquals(candidate(100, 10, 10), 10)\n    lu.assertEquals(candidate(2, 1, 0), 0)\n    lu.assertEquals(candidate(1, 1, 0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_385358_get_package_version_key", "language": "lua", "prompt": "-- Return unique key combining package name and version.\nlocal function get_package_version_key(pkg_name, pkg_version)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_385358_get_package_version_key.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_package_version_key\n    lu.assertEquals(candidate('package_name', 'package_version'), 'package_name@package_version')\n    lu.assertEquals(candidate('package_name', 'package_version'), 'package_name@package_version')\n    lu.assertEquals(candidate('foo', '1.0'), 'foo@1.0')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_385738_read_file", "language": "lua", "prompt": "-- Read file content\n-- :param filepath:\n-- :return:\nlocal function read_file(filepath)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_385738_read_file.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = read_file\n    lu.assertEquals(candidate(0), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_386243_sort_by_points", "language": "lua", "prompt": "-- Returns a sorted list of dictionaries from alternative_hacker_news to\n-- be ordered by score (highest first).\nlocal function sort_by_points(hn_list)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_386243_sort_by_points.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sort_by_points\n    lu.assertEquals(candidate({{['id'] = 1, ['score'] = 10}, {['id'] = 2, ['score'] = 10}, {['id'] = 3, ['score'] = 10}}), {{['id'] = 1, ['score'] = 10}, {['id'] = 2, ['score'] = 10}, {['id'] = 3, ['score'] = 10}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_38627__split_chunks", "language": "lua", "prompt": "-- Generates a list of lists of neighbouring ints. `l` must not be empty.\n-- >>> _split_chunks([1,2,3,5,6,7,9])\n-- [[1,2,3],[5,6,7],[9]]\n-- :type l: list[int]\n-- :rtype list[list[int]]\nlocal function _split_chunks(l)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_38627__split_chunks.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _split_chunks\n    lu.assertEquals(candidate(list(range(10))), {{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}})\n    lu.assertEquals(candidate(list(range(1, 6))), {{1, 2, 3, 4, 5}})\n    lu.assertEquals(candidate(list(range(3))), {{0, 1, 2}})\n    lu.assertEquals(candidate({1, 2, 3, 5, 6}), {{1, 2, 3}, {5, 6}})\n    lu.assertEquals(candidate({1, 2, 3, 5, 6, 7, 9}), {{1, 2, 3}, {5, 6, 7}, {9}})\n    lu.assertEquals(candidate({1, 2, 3}), {{1, 2, 3}})\n    lu.assertEquals(candidate(list(range(6))), {{0, 1, 2, 3, 4, 5}})\n    lu.assertEquals(candidate(list(range(9))), {{0, 1, 2, 3, 4, 5, 6, 7, 8}})\n    lu.assertEquals(candidate({1, 2, 3, 5}), {{1, 2, 3}, {5}})\n    lu.assertEquals(candidate(list(range(5))), {{0, 1, 2, 3, 4}})\n    lu.assertEquals(candidate({1, 2, 3, 4, 6, 7, 8}), {{1, 2, 3, 4}, {6, 7, 8}})\n    lu.assertEquals(candidate(list(range(1))), {{0}})\n    lu.assertEquals(candidate(list(range(2))), {{0, 1}})\n    lu.assertEquals(candidate({1}), {{1}})\n    lu.assertEquals(candidate({1, 2, 3, 5, 6, 7}), {{1, 2, 3}, {5, 6, 7}})\n    lu.assertEquals(candidate({1, 2}), {{1, 2}})\n    lu.assertEquals(candidate(list(range(7))), {{0, 1, 2, 3, 4, 5, 6}})\n    lu.assertEquals(candidate(list(range(3, 8))), {{3, 4, 5, 6, 7}})\n    lu.assertEquals(candidate(list(range(4))), {{0, 1, 2, 3}})\n    lu.assertEquals(candidate(list(range(8))), {{0, 1, 2, 3, 4, 5, 6, 7}})\n    lu.assertEquals(candidate(list(range(2, 7))), {{2, 3, 4, 5, 6}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_386910_format_seconds", "language": "lua", "prompt": "-- Format a floating point representing seconds into\n-- a nice readable string.\n-- Arguments:\n--     seconds    The seconds to format.\n-- Returns:\n--     A formatted string as either seconds, minutes, or hours.\nlocal function format_seconds(seconds)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_386910_format_seconds.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = format_seconds\n    lu.assertEquals(candidate(1.0), '1.00 seconds')\n    lu.assertEquals(candidate(5.9), '5.90 seconds')\n    lu.assertEquals(candidate(60.0), '1.00 minutes')\n    lu.assertEquals(candidate(3600.0), '1.00 hours')\n    lu.assertEquals(candidate(1.0), '1.00 seconds')\n    lu.assertEquals(candidate(5.1), '5.10 seconds')\n    lu.assertEquals(candidate(2.0), '2.00 seconds')\n    lu.assertEquals(candidate(7200.0), '2.00 hours')\n    lu.assertEquals(candidate(90.0), '1.50 minutes')\n    lu.assertEquals(candidate(2.5), '2.50 seconds')\n    lu.assertEquals(candidate(120.0), '2.00 minutes')\n    lu.assertEquals(candidate(1.001), '1.00 seconds')\n    lu.assertEquals(candidate(5.0), '5.00 seconds')\n    lu.assertEquals(candidate(123.0), '2.05 minutes')\n    lu.assertEquals(candidate(60.0), '1.00 minutes')\n    lu.assertEquals(candidate(2.3), '2.30 seconds')\n    lu.assertEquals(candidate(3600.0), '1.00 hours')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_386946_coverageIsFailing", "language": "lua", "prompt": "-- Checks if coverage or branchs coverage or both are\n-- below minimum to pass workflow run. Logs messages if it is.\n-- Actual failing behavior should be handled by caller.\n-- Keyword arguments:\n-- coverage - instructions coverage in interval 0.0 to 1.0.\n-- branches - branches coverage in interval 0.0 to 1.0.\n-- minCoverage - minimum instructions coverage to pass in interval 0.0 to 1.0.\n-- minBranches - minimum branches coverage to pass in interval 0.0 to 1.0.\nlocal function coverageIsFailing(coverage, branches, minCoverage, minBranches)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_386946_coverageIsFailing.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = coverageIsFailing\n    lu.assertEquals(candidate(0.0, 0.1, 0.0, 0.0), false)\n    lu.assertEquals(candidate(0.1, 0.1, 0.0, 0.0), false)\n    lu.assertEquals(candidate(0.1, 0.1, 0.0, 0.1), false)\n    lu.assertEquals(candidate(0.1, 0.0, 0.1, 0.0), false)\n    lu.assertEquals(candidate(0.0, 1.0, 1.0, 0.0), true)\n    lu.assertEquals(candidate(0.75, 0.8, 0.9, 0.95), true)\n    lu.assertEquals(candidate(1.0, 1.0, 1.0, 1.0), false)\n    lu.assertEquals(candidate(0.0, 1.0, 1.0, 1.0), true)\n    lu.assertEquals(candidate(0.0, 0.1, 0.0, 0.1), false)\n    lu.assertEquals(candidate(0.0, 0.0, 1.0, 1.0), true)\n    lu.assertEquals(candidate(0.0, 0.0, 0.0, 1.0), true)\n    lu.assertEquals(candidate(1.0, 0.0, 1.0, 1.0), true)\n    lu.assertEquals(candidate(0.5, 0.75, 0.5, 0.5), false)\n    lu.assertEquals(candidate(0.4, 0.75, 0.5, 0.5), true)\n    lu.assertEquals(candidate(0.0, 0.0, 1.0, 0.0), true)\n    lu.assertEquals(candidate(1.0, 0.0, 0.0, 1.0), true)\n    lu.assertEquals(candidate(0.75, 0.7, 0.8, 0.9), true)\n    lu.assertEquals(candidate(0.8, 0.8, 0.9, 0.8), true)\n    lu.assertEquals(candidate(0.0, 0.0, 0.0, 0.0), false)\n    lu.assertEquals(candidate(0.1, 0.0, 0.0, 0.0), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_387299_remove_length10_word", "language": "lua", "prompt": "-- remove any words have length more than 10 on str\nlocal function remove_length10_word(review_str)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_387299_remove_length10_word.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_length10_word\n    lu.assertEquals(candidate('The quick brown fox jumped over the lazy dog'), 'The quick brown fox jumped over the lazy dog')\n    lu.assertEquals(candidate('this film was amazingly bad'), 'this film was amazingly bad')\n    lu.assertEquals(candidate('The quick brown fox jumped over the lazy dog.'), 'The quick brown fox jumped over the lazy dog.')\n    lu.assertEquals(candidate('The quick brown fox jumped over the lazy dog the quick brown fox jumped over the lazy dog.'), 'The quick brown fox jumped over the lazy dog the quick brown fox jumped over the lazy dog.')\n    lu.assertEquals(candidate('The quick brown fox jumped over the lazy dog. The quick brown fox jumped over the lazy dog.'), 'The quick brown fox jumped over the lazy dog. The quick brown fox jumped over the lazy dog.')\n    lu.assertEquals(candidate('A'), 'A')\n    lu.assertEquals(candidate(''), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_388125_f", "language": "lua", "prompt": "--  function to find bifurcations for \nlocal function f(x, r)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_388125_f.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = f\n    lu.assertEquals(candidate(1, 1), 0)\n    lu.assertEquals(candidate(0, 1), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_388515_getLine", "language": "lua", "prompt": "-- Returns a list of (x, y) tuples of every point on a line between\n-- (x1, y1) and (x2, y2). The x and y values inside the tuple are integers.\n-- Line generated with the Bresenham algorithm.\n-- Args:\n--   x1 (int, float): The x coordinate of the line's start point.\n--   y1 (int, float): The y coordinate of the line's start point.\n--   x2 (int, float): The x coordinate of the line's end point.\n--   y2 (int, float): The y coordiante of the line's end point.\n-- Returns:\n--   [(x1, y1), (x2, y2), (x3, y3), ...]\n-- Example:\n-- >>> getLine(0, 0, 6, 6)\n-- [(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)]\n-- >>> getLine(0, 0, 3, 6)\n-- [(0, 0), (0, 1), (1, 2), (1, 3), (2, 4), (2, 5), (3, 6)]\n-- >>> getLine(3, 3, -3, -3)\n-- [(3, 3), (2, 2), (1, 1), (0, 0), (-1, -1), (-2, -2), (-3, -3)]\nlocal function getLine(x1, y1, x2, y2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_388515_getLine.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = getLine\n    lu.assertEquals(candidate(0, 1, 0, 0), {{0, 1}, {0, 0}})\n    lu.assertEquals(candidate(3, 3, -3, -3), {{3, 3}, {2, 2}, {1, 1}, {0, 0}, {-1, -1}, {-2, -2}, {-3, -3}})\n    lu.assertEquals(candidate(0, 0, 3, 6), {{0, 0}, {0, 1}, {1, 2}, {1, 3}, {2, 4}, {2, 5}, {3, 6}})\n    lu.assertEquals(candidate(0, 0, 6, 6), {{0, 0}, {1, 1}, {2, 2}, {3, 3}, {4, 4}, {5, 5}, {6, 6}})\n    lu.assertEquals(candidate(2, 2, 1, 1), {{2, 2}, {1, 1}})\n    lu.assertEquals(candidate(0, 0, 0, 1), {{0, 0}, {0, 1}})\n    lu.assertEquals(candidate(3, 3, 0, 0), {{3, 3}, {2, 2}, {1, 1}, {0, 0}})\n    lu.assertEquals(candidate(0, 0, 0, 0), {{0, 0}})\n    lu.assertEquals(candidate(1, 0, 0, 0), {{1, 0}, {0, 0}})\n    lu.assertEquals(candidate(0, 0, 1, 1), {{0, 0}, {1, 1}})\n    lu.assertEquals(candidate(0, 0, 1, 0), {{0, 0}, {1, 0}})\n    lu.assertEquals(candidate(0, 0, 2, 2), {{0, 0}, {1, 1}, {2, 2}})\n    lu.assertEquals(candidate(0, 0, 2, -2), {{0, 0}, {1, -1}, {2, -2}})\n    lu.assertEquals(candidate(1, 1, 1, 1), {{1, 1}})\n    lu.assertEquals(candidate(0, 0, 2, 0), {{0, 0}, {1, 0}, {2, 0}})\n    lu.assertEquals(candidate(1, 1, 1, 0), {{1, 1}, {1, 0}})\n    lu.assertEquals(candidate(1, 1, 2, 2), {{1, 1}, {2, 2}})\n    lu.assertEquals(candidate(0, 0, 0, 2), {{0, 0}, {0, 1}, {0, 2}})\n    lu.assertEquals(candidate(0, 0, 2, 1), {{0, 0}, {1, 0}, {2, 1}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_388654_inverse_interleave", "language": "lua", "prompt": "-- Given a coordinate where `a` has been interleaved and `b` hasn't, return \n-- the value that `a` would have at `b=0`.\nlocal function inverse_interleave(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_388654_inverse_interleave.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = inverse_interleave\n    lu.assertEquals(candidate(4, 2), 4)\n    lu.assertEquals(candidate(2, 2), 2)\n    lu.assertEquals(candidate(13, 7), 13)\n    lu.assertEquals(candidate(candidate(0, 0), 0), 0)\n    lu.assertEquals(candidate(0, 0), 0)\n    lu.assertEquals(candidate(2, 1), 3)\n    lu.assertEquals(candidate(5, 5), 5)\n    lu.assertEquals(candidate(candidate(2, 1), 0), 2)\n    lu.assertEquals(candidate(3, 3), 3)\n    lu.assertEquals(candidate(4, 0), 4)\n    lu.assertEquals(candidate(5, 1), 5)\n    lu.assertEquals(candidate(6, 0), 6)\n    lu.assertEquals(candidate(7, 7), 7)\n    lu.assertEquals(candidate(6, 1), 7)\n    lu.assertEquals(candidate(2, 0), 2)\n    lu.assertEquals(candidate(4, 1), 5)\n    lu.assertEquals(candidate(4, 4), 4)\n    lu.assertEquals(candidate(7, 1), 7)\n    lu.assertEquals(candidate(8, 8), 8)\n    lu.assertEquals(candidate(6, 6), 6)\n    lu.assertEquals(candidate(candidate(1, 0), 1), 1)\n    lu.assertEquals(candidate(0, 1), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_388924_escape_accent", "language": "lua", "prompt": "--     escape the following accented character(s) (e/i) into non-accented equivalent\nlocal function escape_accent(mystr)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_388924_escape_accent.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = escape_accent\n    lu.assertEquals(candidate('\u00c3\u00a9'), 'e')\n    lu.assertEquals(candidate(\"L'a\u00c3\u00a9roport\"), \"L'aeroport\")\n    lu.assertEquals(candidate(\"D'a\u00c3\u00a9roport\"), \"D'aeroport\")\n    lu.assertEquals(candidate(\"L'a\u00c3\\x89roport\"), \"L'aeroport\")\n    lu.assertEquals(candidate('\u00c3\u00ae'), 'i')\n    lu.assertEquals(candidate(\"Je ne suis pas \u00e0 l'\u00e9cole. Je suis \u00e0 l'\u00e9tablissement. Je suis \u00e0 l'\u00e9cole. Je ne suis pas \u00e0 l'\u00e9tablissement.\"), candidate(\"Je ne suis pas \u00e0 l'\u00e9cole. Je suis \u00e0 l'\u00e9tablissement. Je suis \u00e0 l'\u00e9cole. Je ne suis pas \u00e0 l'\u00e9tablissement.\"))\n    lu.assertEquals(candidate(\"D'a\u00c3\\x89roport\"), \"D'aeroport\")\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_389434_findAnEven", "language": "lua", "prompt": "-- Assumes l is a list of ints\n-- Returns the first even num in l\n-- Raises ValueError if l doesn't contain an even num\nlocal function findAnEven(l)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_389434_findAnEven.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = findAnEven\n    lu.assertEquals(candidate({2, 3, 5}), 2)\n    lu.assertEquals(candidate({2, 4, 6, 8, 10}), 2)\n    lu.assertEquals(candidate({2, 3, 6}), 2)\n    lu.assertEquals(candidate({2, 3, 4}), 2)\n    lu.assertEquals(candidate({1, 2, 3}), 2)\n    lu.assertEquals(candidate({2, 5, 6}), 2)\n    lu.assertEquals(candidate({3, 5, 6}), 6)\n    lu.assertEquals(candidate({2, 4, 6, 8, 10, 12, 14, 16, 18}), 2)\n    lu.assertEquals(candidate({2, 4, 6}), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_390316_moffat_r", "language": "lua", "prompt": "-- Moffat profile\n-- :param r: radial coordinate\n-- :param alpha:\n-- :param beta:\n-- :return:\nlocal function moffat_r(r, alpha, beta)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_390316_moffat_r.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = moffat_r\n    lu.assertEquals(candidate(2.0, 1.0, 1.0), 0.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_391663_f_to_k", "language": "lua", "prompt": "--     Convierte temperaturas de Fahrenheit a Kelvin\n-- Parameters:\n--         tf : Temperatura en grados Fahrenheit\n-- Returns:\n--         tk : Temperatura en grados Kelvin\nlocal function f_to_k(tf)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_391663_f_to_k.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = f_to_k\n    lu.assertEquals(candidate(32), 273.5)\n    lu.assertEquals(candidate(None), None)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_391695_get_first_key", "language": "lua", "prompt": "-- Get first key in a dict for a given value.\n-- :param dict dictionary:\n-- :param string value:\nlocal function get_first_key(dictionary, value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_391695_get_first_key.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_first_key\n    lu.assertEquals(candidate({['foo'] = 'bar', ['barfoo'] = 'foobar', ['foobar'] = 'barfoo'}, 'foobar'), 'barfoo')\n    lu.assertEquals(candidate({['foo'] = 'bar', ['foobar'] = 'barfoo'}, 'bar'), 'foo')\n    lu.assertEquals(candidate({['foo'] = 'bar', ['foobar'] = 'barfoo', ['bar'] = 'foo'}, 'bar'), 'foo')\n    lu.assertEquals(candidate({['foo'] = 'bar', ['barfoo'] = 'foobar', ['foobar'] = 'barfoo'}, 'bar'), 'foo')\n    lu.assertEquals(candidate({['foo'] = 'bar', ['foobar'] = 'barfoo', ['bar'] = 'foo'}, 'barfoo'), 'foobar')\n    lu.assertEquals(candidate({['foo'] = 'bar', ['foobar'] = 'barfoo'}, 'barfoo'), 'foobar')\n    lu.assertEquals(candidate({['foo'] = 'bar', ['foobar'] = 'barfoo', ['bar'] = 'foo'}, 'foo'), 'bar')\n    lu.assertEquals(candidate({['foo'] = 'bar', ['barfoo'] = 'foobar', ['foobar'] = 'barfoo'}, 'barfoo'), 'foobar')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_392592_startswith_word", "language": "lua", "prompt": "-- Check if a string starts with a word\n-- Basic startswith method doesn't separate into words, so checking if a string\n-- starts with '$foo' will return true for both '$foo' and '$fooooooo'.\n-- Parameters\n-- ==========\n-- phrase : str\n--     Phrase to check startswith against.\n-- startswith : str\n--     Word to check whether or not phrase starts with it.\n-- Returns\n-- =======\n-- bool\n--     True if the first word of phrase is startswith, False otherwise.\nlocal function startswith_word(phrase, startswith)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_392592_startswith_word.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = startswith_word\n    lu.assertEquals(candidate('test', 'test'), true)\n    lu.assertEquals(candidate('$bar $bar $foo', '$foo'), false)\n    lu.assertEquals(candidate('$foo $bar $foo', '$foo'), true)\n    lu.assertEquals(candidate('This is a $bar', '$foo'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_392962_is_prime", "language": "lua", "prompt": "-- Returns True if the number is prime\n-- else False.\nlocal function is_prime(num)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_392962_is_prime.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_prime\n    lu.assertEquals(candidate(6), false)\n    lu.assertEquals(candidate(24), false)\n    lu.assertEquals(candidate(33), false)\n    lu.assertEquals(candidate(36), false)\n    lu.assertEquals(candidate(14), false)\n    lu.assertEquals(candidate(27), false)\n    lu.assertEquals(candidate(29), true)\n    lu.assertEquals(candidate(35), false)\n    lu.assertEquals(candidate(17), true)\n    lu.assertEquals(candidate(2), true)\n    lu.assertEquals(candidate(0), false)\n    lu.assertEquals(candidate(30), false)\n    lu.assertEquals(candidate(12), false)\n    lu.assertEquals(candidate(22), false)\n    lu.assertEquals(candidate(16), false)\n    lu.assertEquals(candidate(7), true)\n    lu.assertEquals(candidate(28), false)\n    lu.assertEquals(candidate(9), false)\n    lu.assertEquals(candidate(19), true)\n    lu.assertEquals(candidate(34), false)\n    lu.assertEquals(candidate(10), false)\n    lu.assertEquals(candidate(11), true)\n    lu.assertEquals(candidate(5), true)\n    lu.assertEquals(candidate(23), true)\n    lu.assertEquals(candidate(1), false)\n    lu.assertEquals(candidate(26), false)\n    lu.assertEquals(candidate(32), false)\n    lu.assertEquals(candidate(3), true)\n    lu.assertEquals(candidate(13), true)\n    lu.assertEquals(candidate(38), false)\n    lu.assertEquals(candidate(20), false)\n    lu.assertEquals(candidate(21), false)\n    lu.assertEquals(candidate(15), false)\n    lu.assertEquals(candidate(8), false)\n    lu.assertEquals(candidate(-10000000001), true)\n    lu.assertEquals(candidate(100), false)\n    lu.assertEquals(candidate(25), false)\n    lu.assertEquals(candidate(18), false)\n    lu.assertEquals(candidate(37), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_394041_escape", "language": "lua", "prompt": "-- Replace special characters '&', \"'\", '<', '>' and '\"' by XML entities.\nlocal function escape(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_394041_escape.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = escape\n    lu.assertEquals(candidate('a>b'), 'a&gt;b')\n    lu.assertEquals(candidate('a<b'), 'a&lt;b')\n    lu.assertEquals(candidate('1 < 2'), '1 &lt; 2')\n    lu.assertEquals(candidate('one < two'), 'one &lt; two')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('<'), '&lt;')\n    lu.assertEquals(candidate('a\"b'), 'a&quot;b')\n    lu.assertEquals(candidate('\"1 < 2\"'), '&quot;1 &lt; 2&quot;')\n    lu.assertEquals(candidate(' a b c '), ' a b c ')\n    lu.assertEquals(candidate('\"'), '&quot;')\n    lu.assertEquals(candidate(\"'1 < 2'\"), '&apos;1 &lt; 2&apos;')\n    lu.assertEquals(candidate('<a>'), '&lt;a&gt;')\n    lu.assertEquals(candidate('>'), '&gt;')\n    lu.assertEquals(candidate(' '), ' ')\n    lu.assertEquals(candidate('abc '), 'abc ')\n    lu.assertEquals(candidate('foo'), 'foo')\n    lu.assertEquals(candidate('&'), '&amp;')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate(\"a'b\"), 'a&apos;b')\n    lu.assertEquals(candidate('a'), 'a')\n    lu.assertEquals(candidate(' abc'), ' abc')\n    lu.assertEquals(candidate(\"'\"), '&apos;')\n    lu.assertEquals(candidate(\"&<>'\"), '&amp;&lt;&gt;&apos;')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_395176_py_type_name", "language": "lua", "prompt": "-- Get the Python type name for a given model type.\n-- >>> py_type_name('list')\n-- 'list'\n-- >>> py_type_name('structure')\n-- 'dict'\n--     :rtype: string\nlocal function py_type_name(type_name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_395176_py_type_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = py_type_name\n    lu.assertEquals(candidate('list'), 'list')\n    lu.assertEquals(candidate('structure'), 'dict')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_396186_calculate_stations_adjoint", "language": "lua", "prompt": "--     get the files STATIONS_ADJOINT.\nlocal function calculate_stations_adjoint(py, stations_path, misfit_windows_directory, output_directory)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_396186_calculate_stations_adjoint.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = calculate_stations_adjoint\n    lu.assertEquals(candidate('seisflow/scripts/shared/get_stations_adjoint.py', 'asdf', 'asdf', 'asdf'), 'ibrun -n 1 seisflow/scripts/shared/get_stations_adjoint.py -m seisflow.scripts.shared.get_stations_adjoint --stations_path asdf --misfit_windows_directory asdf --output_directory asdf; \\n')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_396471_comment_string_with_block", "language": "lua", "prompt": "-- Return string commented using block comments\nlocal function comment_string_with_block(string, block_comment)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_396471_comment_string_with_block.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = comment_string_with_block\n    lu.assertEquals(candidate('', {'#', ''}), '')\n    lu.assertEquals(candidate('', {'/*', '*/'}), '')\n    lu.assertEquals(candidate('a', {'#begin', '#end'}), '#begin a #end')\n    lu.assertEquals(candidate('', None), '')\n    lu.assertEquals(candidate(None, {'#', ''}), None)\n    lu.assertEquals(candidate('abc', {'<!--', '-->'}), '<!-- abc -->')\n    lu.assertEquals(candidate('a = 1', {'/*', '*/'}), '/* a = 1 */')\n    lu.assertEquals(candidate('This is a string.', {'\"\"\"', '\"\"\"'}), '\"\"\" This is a string. \"\"\"')\n    lu.assertEquals(candidate('Hello World', {'/*', '*/'}), '/* Hello World */')\n    lu.assertEquals(candidate('', {'#begin', '#end'}), '')\n    lu.assertEquals(candidate('a = 1\\nb = 2\\nc = 3', {'/*', '*/'}), '/* a = 1\\nb = 2\\nc = 3 */')\n    lu.assertEquals(candidate('a', {'<!--', '-->'}), '<!-- a -->')\n    lu.assertEquals(candidate('This is a string.', {'/*', '*/'}), '/* This is a string. */')\n    lu.assertEquals(candidate('Hello World\\nHow are you?', {'/*', '*/'}), '/* Hello World\\nHow are you? */')\n    lu.assertEquals(candidate(None, {'/*', '*/'}), None)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_396730__remapLanguageCode", "language": "lua", "prompt": "--     Remap certain language codes to others, per the localization team\nlocal function _remapLanguageCode(code)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_396730__remapLanguageCode.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _remapLanguageCode\n    lu.assertEquals(candidate('zh-Hans'), 'zh_CN')\n    lu.assertEquals(candidate(None), None)\n    lu.assertEquals(candidate('zh-Hant'), 'zh_TW')\n    lu.assertEquals(candidate('en_US'), 'en_US')\n    lu.assertEquals(candidate('en_GB'), 'en_GB')\n    lu.assertEquals(candidate('ja_JP'), 'ja_JP')\n    lu.assertEquals(candidate('en'), 'en')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_397294_prism_item_in_list", "language": "lua", "prompt": "-- Compare a single prism specifiation to a list of PRISM files\n-- returned by pyPRISMClimate.prism_iterator\nlocal function prism_item_in_list(qury_item, list_of_items_to_check)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_397294_prism_item_in_list.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = prism_item_in_list\n    lu.assertEquals(candidate({['model'] = 'ACCESS1-3', ['experiment'] = 'rcp45', ['frequency'] = 'monthly', ['variable'] = 'ppt'}, {{['model'] = 'ACCESS1-3', ['experiment'] = 'rcp45', ['frequency'] = 'monthly', ['variable'] = 'tmax'}, {['model'] = 'ACCESS1-3', ['experiment'] = 'rcp45', ['frequency'] = 'monthly', ['variable'] = 'tmax'}, {['model'] = 'ACCESS1-3', ['experiment'] = 'historical', ['frequency'] = 'monthly', ['variable'] = 'ppt'}}), false)\n    lu.assertEquals(candidate({['model'] = 'ACCESS1-3', ['experiment'] = 'rcp45', ['frequency'] = 'monthly', ['variable'] = 'ppt'}, {{['model'] = 'ACCESS1-3', ['experiment'] = 'rcp45', ['frequency'] = 'monthly', ['variable'] = 'ppt'}, {['model'] = 'ACCESS1-3', ['experiment'] = 'rcp45', ['frequency'] = 'monthly', ['variable'] = 'tmax'}, {['model'] = 'ACCESS1-3', ['experiment'] = 'historical', ['frequency'] = 'monthly', ['variable'] = 'ppt'}}), true)\n    lu.assertEquals(candidate({['model'] = 'ACCESS1-3', ['experiment'] = 'rcp45', ['frequency'] = 'monthly', ['variable'] = 'ppt'}, {{['model'] = 'ACCESS1-3', ['experiment'] = 'rcp45', ['frequency'] = 'monthly', ['variable'] = 'ppt'}, {['model'] = 'ACCESS1-3', ['experiment'] = 'rcp45', ['frequency'] = 'monthly', ['variable'] = 'tmax'}, {['model'] = 'ACCESS1-3', ['experiment'] = 'historical', ['frequency'] = 'monthly', ['variable'] = 'ppt'}, {['model'] = 'ACCESS1-3', ['experiment'] = 'historical', ['frequency'] = 'monthly', ['variable'] = 'ppt'}}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_3974_str_igrep", "language": "lua", "prompt": "-- Returns a list of the indices of the strings wherein the substring S\n-- is found.\nlocal function str_igrep(S, strs)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_3974_str_igrep.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = str_igrep\n    lu.assertEquals(candidate('', {''}), {0})\n    lu.assertEquals(candidate('abc', {'aa', 'ab', 'abc'}), {2})\n    lu.assertEquals(candidate('a', {}), {})\n    lu.assertEquals(candidate('b', {'a', 'b'}), {1})\n    lu.assertEquals(candidate('b', {'b'}), {0})\n    lu.assertEquals(candidate('', {}), {})\n    lu.assertEquals(candidate('a', {'a', 'b', 'c', 'a'}), {0, 3})\n    lu.assertEquals(candidate('a', {'a', 'b'}), {0})\n    lu.assertEquals(candidate('ab', {}), {})\n    lu.assertEquals(candidate('z', {}), {})\n    lu.assertEquals(candidate('a', {'a', 'a', 'a'}), {0, 1, 2})\n    lu.assertEquals(candidate('a', {'a'}), {0})\n    lu.assertEquals(candidate('z', {'aa', 'ab', 'abc'}), {})\n    lu.assertEquals(candidate('a', {'b', 'a'}), {1})\n    lu.assertEquals(candidate('b', {'a', 'b', 'c'}), {1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_397801_make_msg", "language": "lua", "prompt": "-- Formats the error message with a file and line number that can be used by\n-- IDEs to quickly go to the exact line\nlocal function make_msg(err_or_warn, file, line, msg)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_397801_make_msg.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = make_msg\n    lu.assertEquals(candidate('warning', 'main.c', 10, 'variable used before assignment'), 'warning: main.c:10, variable used before assignment')\n    lu.assertEquals(candidate('error', 'test_messages.py', 27, 'this should be an error'), 'error: test_messages.py:27, this should be an error')\n    lu.assertEquals(candidate('error', 'main.c', 10, 'variable used before assignment'), 'error: main.c:10, variable used before assignment')\n    lu.assertEquals(candidate('warning', 'test_messages.py', 27, 'this should be a warning'), 'warning: test_messages.py:27, this should be a warning')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_397849_move_up", "language": "lua", "prompt": "--  A method that takes coordinates of bomb's\n-- position and returns coordinates of neighbour\n-- located above the bomb. It returns None if\n-- there isn't such a neighbour \nlocal function move_up(t)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_397849_move_up.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = move_up\n    lu.assertEquals(candidate({1, 2}), {0, 2})\n    lu.assertEquals(candidate({3, 3}), {2, 3})\n    lu.assertEquals(candidate({1, 1}), {0, 1})\n    lu.assertEquals(candidate({0, 1}), None)\n    lu.assertEquals(candidate({3, 2}), {2, 2})\n    lu.assertEquals(candidate({1, 5}), {0, 5})\n    lu.assertEquals(candidate({5, 5}), {4, 5})\n    lu.assertEquals(candidate({3, 4}), {2, 4})\n    lu.assertEquals(candidate({1, 2}), {0, 2})\n    lu.assertEquals(candidate({5, 2}), {4, 2})\n    lu.assertEquals(candidate({1, 0}), {0, 0})\n    lu.assertEquals(candidate({4, 6}), {3, 6})\n    lu.assertEquals(candidate({0, 0}), None)\n    lu.assertEquals(candidate({0, 0}), None)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_397872_fix_vidshape", "language": "lua", "prompt": "-- Compares two resolutions and get missing x and y coords\nlocal function fix_vidshape(res1, res2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_397872_fix_vidshape.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fix_vidshape\n    lu.assertEquals(candidate({1920, 1080}, {640, 360}), {0, 0})\n    lu.assertEquals(candidate({1920, 1080}, {1280, 1080}), {0, 0})\n    lu.assertEquals(candidate({1920, 1080}, {1280, 720}), {0, 0})\n    lu.assertEquals(candidate({1920, 1080}, {640, 1080}), {0, 0})\n    lu.assertEquals(candidate({1920, 1080}, {1920, 1080}), {0, 0})\n    lu.assertEquals(candidate({1920, 1080}, {640, 540}), {0, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_398023_remove_underline", "language": "lua", "prompt": "-- Remove the underline in reserved words.\n-- The parameters def and type are python reserved words so it is necessary\n-- to add a underline to use this words, this method remove the underline\n-- before make a http request.\n-- Args:\n--     params (dict): Url query parameters.\n-- Returns:\n--     (dict): Validated url query parameters.\nlocal function remove_underline(params)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_398023_remove_underline.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_underline\n    lu.assertEquals(candidate({['type_'] = 'type', ['format_'] = 'format'}), {['type'] = 'type', ['format'] = 'format'})\n    lu.assertEquals(candidate({['def_'] = 'def', ['type_'] = 'type', ['format_'] = 'format'}), {['def'] = 'def', ['type'] = 'type', ['format'] = 'format'})\n    lu.assertEquals(candidate({['def_'] = 'def', ['type_'] = 'type', ['format_'] = 'format'}), {['def'] = 'def', ['type'] = 'type', ['format'] = 'format'})\n    lu.assertEquals(candidate({['def_'] = 'def', ['format_'] = 'format'}), {['def'] = 'def', ['format'] = 'format'})\n    lu.assertEquals(candidate({['def_'] = 'def', ['type_'] = 'type'}), {['def'] = 'def', ['type'] = 'type'})\n    lu.assertEquals(candidate({['def_'] = 'def', ['format_'] = 'format'}), {['def'] = 'def', ['format'] = 'format'})\n    lu.assertEquals(candidate({['def_'] = 'def'}), {['def'] = 'def'})\n    lu.assertEquals(candidate({}), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_398191__intersect", "language": "lua", "prompt": "--  return the intersection of two lists \nlocal function _intersect(lst_a, lst_b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_398191__intersect.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _intersect\n    lu.assertEquals(candidate({'a', 'b', 'c', 'd'}, {'z', 'y', 'x', 'w'}), {})\n    lu.assertEquals(candidate({'a', 'b', 'c', 'd'}, {'a', 'a', 'a', 'a'}), {'a'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_3983_find_match_characters", "language": "lua", "prompt": "-- Find match match pattern string.\n-- Args:\n--     params: string\n--             pattern\n-- Returns:\n-- Raises:\nlocal function find_match_characters(string, pattern)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_3983_find_match_characters.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = find_match_characters\n    lu.assertEquals(candidate('ab', 'ab'), {{'a', 0}, {'b', 1}})\n    lu.assertEquals(candidate('', 'abc'), {})\n    lu.assertEquals(candidate('aabb', 'ab'), {{'a', 0}, {'b', 2}})\n    lu.assertEquals(candidate('abcz', 'abc'), {{'a', 0}, {'b', 1}, {'c', 2}})\n    lu.assertEquals(candidate('a', 'ab'), {})\n    lu.assertEquals(candidate('', 'a'), {})\n    lu.assertEquals(candidate('ab', 'aba'), {})\n    lu.assertEquals(candidate('abc', 'xyz'), {})\n    lu.assertEquals(candidate('a', ''), {})\n    lu.assertEquals(candidate('b', 'a'), {})\n    lu.assertEquals(candidate('aaab', 'ab'), {{'a', 0}, {'b', 3}})\n    lu.assertEquals(candidate('abab', 'babab'), {})\n    lu.assertEquals(candidate('', ''), {})\n    lu.assertEquals(candidate('a', 'a'), {{'a', 0}})\n    lu.assertEquals(candidate(None, None), {})\n    lu.assertEquals(candidate('abc', ''), {})\n    lu.assertEquals(candidate('aabb', 'aba'), {})\n    lu.assertEquals(candidate('babab', 'abab'), {})\n    lu.assertEquals(candidate('', ''), {})\n    lu.assertEquals(candidate('abc', 'abc'), {{'a', 0}, {'b', 1}, {'c', 2}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_398704__GenerateDeviceHVInfoStr", "language": "lua", "prompt": "-- Construct the -device option string for hvinfo dict\n-- PV disk: virtio-blk-pci,id=disk-1234,bus=pci.0,addr=0x9\n-- PV NIC:  virtio-net-pci,id=nic-1234,bus=pci.0,addr=0x9\n-- SG disk: scsi-generic,id=disk-1234,bus=scsi.0,channel=0,scsi-id=1,lun=0\n-- @type hvinfo: dict\n-- @param hvinfo: dictionary created by _GenerateDeviceHVInfo()\n-- @rtype: string\n-- @return: The constructed string to be passed along with a -device option\nlocal function _GenerateDeviceHVInfoStr(hvinfo)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_398704__GenerateDeviceHVInfoStr.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _GenerateDeviceHVInfoStr\n    lu.assertEquals(candidate({['driver'] = 'virtio-blk-pci', ['id'] = 'disk-1234', ['bus'] = 'pci.0', ['addr'] = '0x9', ['scsi-id'] = '1'}), 'virtio-blk-pci,id=disk-1234,bus=pci.0,addr=0x9,scsi-id=1')\n    lu.assertEquals(candidate({['driver'] = 'scsi-generic', ['id'] = 'disk-1234', ['bus'] = 'scsi.0', ['channel'] = '0', ['scsi-id'] = '1', ['lun'] = '0'}), 'scsi-generic,id=disk-1234,bus=scsi.0,channel=0,scsi-id=1,lun=0')\n    lu.assertEquals(candidate({['driver'] = 'virtio-net-pci', ['id'] = 'nic-1234', ['bus'] = 'pci.0'}), 'virtio-net-pci,id=nic-1234,bus=pci.0')\n    lu.assertEquals(candidate({['driver'] = 'virtio-blk-pci', ['id'] = 'disk-1234', ['bus'] = 'pci.0'}), 'virtio-blk-pci,id=disk-1234,bus=pci.0')\n    lu.assertEquals(candidate({['driver'] = 'scsi-generic', ['id'] = 'disk-1234', ['bus'] = 'scsi.0', ['channel'] = '0', ['scsi-id'] = '1', ['lun'] = '0'}), 'scsi-generic,id=disk-1234,bus=scsi.0,channel=0,scsi-id=1,lun=0')\n    lu.assertEquals(candidate({['driver'] = 'virtio-blk-pci', ['id'] = 'disk-1234', ['bus'] = 'pci.0', ['addr'] = '0x9'}), 'virtio-blk-pci,id=disk-1234,bus=pci.0,addr=0x9')\n    lu.assertEquals(candidate({['driver'] = 'virtio-net-pci', ['id'] = 'nic-1234', ['bus'] = 'pci.0', ['addr'] = '0x9'}), 'virtio-net-pci,id=nic-1234,bus=pci.0,addr=0x9')\n    lu.assertEquals(candidate({['driver'] = 'virtio-blk-pci', ['id'] = 'disk-1234', ['bus'] = 'pci.0', ['addr'] = '0x9'}), 'virtio-blk-pci,id=disk-1234,bus=pci.0,addr=0x9')\n    lu.assertEquals(candidate({['driver'] = 'virtio-net-pci', ['id'] = 'nic-1234', ['bus'] = 'pci.0', ['addr'] = '0x9'}), 'virtio-net-pci,id=nic-1234,bus=pci.0,addr=0x9')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_398734_insert", "language": "lua", "prompt": "-- >>> insert(('a', 'b', 'c'), 0, 'x')\n-- ('x', 'b', 'c')\nlocal function insert(tup, loc, val)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_398734_insert.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = insert\n    lu.assertEquals(candidate({'a', 'b', 'c'}, 0, 'x'), {'x', 'b', 'c'})\n    lu.assertEquals(candidate({'a', 'b', 'c'}, 2, 'x'), {'a', 'b', 'x'})\n    lu.assertEquals(candidate({'a', 'b', 'c'}, 0, 'x'), {'x', 'b', 'c'})\n    lu.assertEquals(candidate({'a', 'b', 'c'}, 2, 'z'), {'a', 'b', 'z'})\n    lu.assertEquals(candidate({'a', 'b', 'c'}, 1, 'x'), {'a', 'x', 'c'})\n    lu.assertEquals(candidate({'a', 'b', 'c'}, 1, 'y'), {'a', 'y', 'c'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_399266_expand_id_map", "language": "lua", "prompt": "--  Ensures all ids within all_ids are included as keys in the mapping \nlocal function expand_id_map(id_map, all_ids)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_399266_expand_id_map.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = expand_id_map\n    lu.assertEquals(candidate({}, {1, 2, 3}), {[1] = 1, [2] = 2, [3] = 3})\n    lu.assertEquals(candidate({[3] = 100}, {1, 2, 3, 4}), {[1] = 1, [2] = 2, [3] = 100, [4] = 4})\n    lu.assertEquals(candidate({[1] = 100, [2] = 100, [3] = 200}, {1, 2, 3}), {[1] = 100, [2] = 100, [3] = 200})\n    lu.assertEquals(candidate(dict(), {1, 2, 3}), {[1] = 1, [2] = 2, [3] = 3})\n    lu.assertEquals(candidate({[1] = 2}, {1, 2, 3}), {[1] = 2, [2] = 2, [3] = 3})\n    lu.assertEquals(candidate({[1] = 2}, {2, 3}), {[1] = 2, [2] = 2, [3] = 3})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_399332_volume_berbentuk_kubus", "language": "lua", "prompt": "-- kalkulasi volume kuboid\n-- >>> volume_berbentuk_kubus(1, 1, 1)\n-- 1.0\n-- >>> volume_berbentuk_kubus(1, 2, 3)\n-- 6.0\nlocal function volume_berbentuk_kubus(lebar, tinggi, panjang)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_399332_volume_berbentuk_kubus.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = volume_berbentuk_kubus\n    lu.assertEquals(candidate(1, 2, 3), 6.0)\n    lu.assertEquals(candidate(1, 1, 1), 1.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_400319_from_time", "language": "lua", "prompt": "-- Convenience wrapper to take a series of date/time elements and return a WMI time\n-- of the form `yyyymmddHHMMSS.mmmmmm+UUU`. All elements may be int, string or\n-- omitted altogether. If omitted, they will be replaced in the output string\n-- by a series of stars of the appropriate length.\n-- :param year: The year element of the date/time\n-- :param month: The month element of the date/time\n-- :param day: The day element of the date/time\n-- :param hours: The hours element of the date/time\n-- :param minutes: The minutes element of the date/time\n-- :param seconds: The seconds element of the date/time\n-- :param microseconds: The microseconds element of the date/time\n-- :param timezone: The timeezone element of the date/time\n-- :returns: A WMI datetime string of the form: `yyyymmddHHMMSS.mmmmmm+UUU`\nlocal function from_time(year, month, day, hours, minutes, seconds, microseconds, timezone)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_400319_from_time.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = from_time\n    lu.assertEquals(candidate(2015, 1, 1, 11, 3, 27, 123456, -1), '20150101110327.123456-001')\n    lu.assertEquals(candidate(2015, 1, 1, 11, 3, 27, 123456), '20150101110327.123456+')\n    lu.assertEquals(candidate(1979, 12, 31, 14, 59, 59, 999999, 0), '19791231145959.999999+')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_400320_find_last", "language": "lua", "prompt": "-- s and sub are non-empty strings\n-- Returns the index of the last occurrence of sub in s.\n-- Returns None if sub does not occur in s\nlocal function find_last(s, sub)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_400320_find_last.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = find_last\n    lu.assertEquals(candidate('123123123', '123123123'), 0)\n    lu.assertEquals(candidate('123123123', '123'), 6)\n    lu.assertEquals(candidate('123123123', '0'), None)\n    lu.assertEquals(candidate('ababc', 'd'), None)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_400967_is_id", "language": "lua", "prompt": "--     Return True if `s` is some kind of id.\nlocal function is_id(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_400967_is_id.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_id\n    lu.assertEquals(candidate('a b c d e f g h i j k l m n o'), false)\n    lu.assertEquals(candidate('a b'), false)\n    lu.assertEquals(candidate('foo'), true)\n    lu.assertEquals(candidate('__hello_world'), true)\n    lu.assertEquals(candidate('a b c d e f'), false)\n    lu.assertEquals(candidate('a b c d e f g'), false)\n    lu.assertEquals(candidate(' a b'), false)\n    lu.assertEquals(candidate('x'), true)\n    lu.assertEquals(candidate('a b c d'), false)\n    lu.assertEquals(candidate('a b c d e f g h i j k l m n'), false)\n    lu.assertEquals(candidate('a b c d e f g h i j k l'), false)\n    lu.assertEquals(candidate('123 456'), false)\n    lu.assertEquals(candidate('a b c d e f g h i j k'), false)\n    lu.assertEquals(candidate('12345'), true)\n    lu.assertEquals(candidate('a b c d e f g h'), false)\n    lu.assertEquals(candidate('a b c d e f g h i'), false)\n    lu.assertEquals(candidate('a b c d e'), false)\n    lu.assertEquals(candidate('a b c d e f g h i j'), false)\n    lu.assertEquals(candidate('12345 6789'), false)\n    lu.assertEquals(candidate('a b '), false)\n    lu.assertEquals(candidate('hello_world'), true)\n    lu.assertEquals(candidate('123'), true)\n    lu.assertEquals(candidate('a'), true)\n    lu.assertEquals(candidate('foo'), true)\n    lu.assertEquals(candidate('a b c'), false)\n    lu.assertEquals(candidate('hello world'), false)\n    lu.assertEquals(candidate('_hello_world'), true)\n    lu.assertEquals(candidate('a b c d e f g h i j k l m'), false)\n    lu.assertEquals(candidate('foo bar'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_401452_control_start", "language": "lua", "prompt": "--     Controls the start state\nlocal function control_start(cmd)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_401452_control_start.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = control_start\n    lu.assertEquals(candidate('no'), 'game')\n    lu.assertEquals(candidate('No'), 'game')\n    lu.assertEquals(candidate('y'), 'instructions')\n    lu.assertEquals(candidate('yeS'), 'instructions')\n    lu.assertEquals(candidate('n'), 'game')\n    lu.assertEquals(candidate('Yes'), 'instructions')\n    lu.assertEquals(candidate('Y'), 'instructions')\n    lu.assertEquals(candidate('y'), 'instructions')\n    lu.assertEquals(candidate('yes'), 'instructions')\n    lu.assertEquals(candidate('YES'), 'instructions')\n    lu.assertEquals(candidate('n'), 'game')\n    lu.assertEquals(candidate('No'), 'game')\n    lu.assertEquals(candidate('yes'), 'instructions')\n    lu.assertEquals(candidate('no'), 'game')\n    lu.assertEquals(candidate('yEs'), 'instructions')\n    lu.assertEquals(candidate('Yes'), 'instructions')\n    lu.assertEquals(candidate('NO'), 'game')\n    lu.assertEquals(candidate('YES'), 'instructions')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_401768__quote_arg", "language": "lua", "prompt": "--     Quote the argument for safe use in a shell command line.\nlocal function _quote_arg(arg)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_401768__quote_arg.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _quote_arg\n    lu.assertEquals(candidate('-I\"C:/Program Files/...\"'), '-I\"C:/Program Files/...\"')\n    lu.assertEquals(candidate('a'), 'a')\n    lu.assertEquals(candidate('\"foo\" bar'), '\"foo\" bar')\n    lu.assertEquals(candidate(\"'foo'\"), \"'foo'\")\n    lu.assertEquals(candidate('a b c'), '\"a b c\"')\n    lu.assertEquals(candidate('-I\"C:\\\\Program Files\\\\...\\\\include\"'), '-I\"C:\\\\Program Files\\\\...\\\\include\"')\n    lu.assertEquals(candidate('a'), 'a')\n    lu.assertEquals(candidate('C:\\\\Program Files\\\\Microsoft Visual Studio 12.0\\\\VC\\\\bin\\\\cl.exe'), '\"C:\\\\Program Files\\\\Microsoft Visual Studio 12.0\\\\VC\\\\bin\\\\cl.exe\"')\n    lu.assertEquals(candidate('a b'), '\"a b\"')\n    lu.assertEquals(candidate('\"foo bar\"'), '\"foo bar\"')\n    lu.assertEquals(candidate('\"'), '\"')\n    lu.assertEquals(candidate('-I\"C:/Program Files/.../include\"'), '-I\"C:/Program Files/.../include\"')\n    lu.assertEquals(candidate('C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 12.0\\\\VC\\\\bin\\\\cl.exe'), '\"C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 12.0\\\\VC\\\\bin\\\\cl.exe\"')\n    lu.assertEquals(candidate('a\\\\\\\\b'), 'a\\\\\\\\b')\n    lu.assertEquals(candidate('\"foo\"'), '\"foo\"')\n    lu.assertEquals(candidate('-I\"C:\\\\Program Files\\\\...\"'), '-I\"C:\\\\Program Files\\\\...\"')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('a b c'), '\"a b c\"')\n    lu.assertEquals(candidate('a\\\\\\\\\\\\\\\\b'), 'a\\\\\\\\\\\\\\\\b')\n    lu.assertEquals(candidate('a\\\\\"b'), 'a\\\\\"b')\n    lu.assertEquals(candidate('a\\\\b'), 'a\\\\b')\n    lu.assertEquals(candidate('-I\"C:\\\\Program Files\\\\.../include\"'), '-I\"C:\\\\Program Files\\\\.../include\"')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_402036_get_item_details", "language": "lua", "prompt": "-- This function finds packgen details using item\n-- :param item: item is a string containing packgen content type\n-- :return: it returns dict of details of packgen.\nlocal function get_item_details(item)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_402036_get_item_details.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_item_details\n    lu.assertEquals(candidate('Clothes'), {['priority'] = 'LP', ['cost'] = '150', ['Estimated Time of Delivery'] = '5', ['item'] = 'Clothes'})\n    lu.assertEquals(candidate('Food'), {['Estimated Time of Delivery'] = '3', ['priority'] = 'MP', ['cost'] = '250', ['item'] = 'Food'})\n    lu.assertEquals(candidate('Medicine'), {['priority'] = 'HP', ['cost'] = '450', ['Estimated Time of Delivery'] = '1', ['item'] = 'Medicines'})\n    lu.assertEquals(candidate('Medicine'), {['Estimated Time of Delivery'] = '1', ['priority'] = 'HP', ['cost'] = '450', ['item'] = 'Medicines'})\n    lu.assertEquals(candidate('Medicines'), {['Estimated Time of Delivery'] = '1', ['priority'] = 'HP', ['cost'] = '450', ['item'] = 'Medicines'})\n    lu.assertEquals(candidate('Clothes'), {['Estimated Time of Delivery'] = '5', ['priority'] = 'LP', ['cost'] = '150', ['item'] = 'Clothes'})\n    lu.assertEquals(candidate('Medicines'), {['Estimated Time of Delivery'] = '1', ['priority'] = 'HP', ['cost'] = '450', ['item'] = 'Medicines'})\n    lu.assertEquals(candidate('Food'), {['Estimated Time of Delivery'] = '3', ['cost'] = '250', ['item'] = 'Food', ['priority'] = 'MP'})\n    lu.assertEquals(candidate('Food'), {['priority'] = 'MP', ['cost'] = '250', ['Estimated Time of Delivery'] = '3', ['item'] = 'Food'})\n    lu.assertEquals(candidate('Clothes'), {['Estimated Time of Delivery'] = '5', ['cost'] = '150', ['item'] = 'Clothes', ['priority'] = 'LP'})\n    lu.assertEquals(candidate('Medicines'), {['Estimated Time of Delivery'] = '1', ['cost'] = '450', ['item'] = 'Medicines', ['priority'] = 'HP'})\n    lu.assertEquals(candidate('Medicines'), {['priority'] = 'HP', ['cost'] = '450', ['Estimated Time of Delivery'] = '1', ['item'] = 'Medicines'})\n    lu.assertEquals(candidate('Food'), {['Estimated Time of Delivery'] = '3', ['priority'] = 'MP', ['cost'] = '250', ['item'] = 'Food'})\n    lu.assertEquals(candidate('Clothes'), {['Estimated Time of Delivery'] = '5', ['priority'] = 'LP', ['cost'] = '150', ['item'] = 'Clothes'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_402199_multi_bracket_validation", "language": "lua", "prompt": "--     This function return True if brackets are all matched up in string, and     return False if there is unmatched brackets.\nlocal function multi_bracket_validation(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_402199_multi_bracket_validation.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = multi_bracket_validation\n    lu.assertEquals(candidate('(hi)()'), true)\n    lu.assertEquals(candidate('[[[]()]]'), true)\n    lu.assertEquals(candidate('(hi)[(hi)]{[()]}'), true)\n    lu.assertEquals(candidate('(hi)[(hi)]{[()]}(hi)hi'), true)\n    lu.assertEquals(candidate('{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{]}}}}}}}}}}}}}}}}}}}}}}}}}}'), false)\n    lu.assertEquals(candidate('(hi)[(hi)]{[()]}(hi)hi(hi})'), false)\n    lu.assertEquals(candidate('(hi)[(hi)]'), true)\n    lu.assertEquals(candidate('{}'), true)\n    lu.assertEquals(candidate('[({})]'), true)\n    lu.assertEquals(candidate('[({})]([({})])'), true)\n    lu.assertEquals(candidate('(hi)[(hi)]{[()]}()'), true)\n    lu.assertEquals(candidate('[[()]]]'), false)\n    lu.assertEquals(candidate('{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{}}}}}}}}}}}}}}}}}}}}}}}}'), false)\n    lu.assertEquals(candidate('[]'), true)\n    lu.assertEquals(candidate('[[{}]]'), true)\n    lu.assertEquals(candidate('hi())'), false)\n    lu.assertEquals(candidate('[[[]]]'), true)\n    lu.assertEquals(candidate('hi(hi)'), true)\n    lu.assertEquals(candidate('({[]})'), true)\n    lu.assertEquals(candidate('[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[['), false)\n    lu.assertEquals(candidate('{[()]}'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_402673__reconstruct_token", "language": "lua", "prompt": "-- Reconstruct a token from a key in a graph ('SomeName_<token>')\nlocal function _reconstruct_token(key)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_402673__reconstruct_token.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _reconstruct_token\n    lu.assertEquals(candidate('foo_1234567'), None)\n    lu.assertEquals(candidate('a_11111'), None)\n    lu.assertEquals(candidate('<KEY>'), None)\n    lu.assertEquals(candidate('some_name_l'), None)\n    lu.assertEquals(candidate('some_name_n'), None)\n    lu.assertEquals(candidate('some_name_b'), None)\n    lu.assertEquals(candidate('foo_123456789012345678901234567890_123'), None)\n    lu.assertEquals(candidate('a_'), None)\n    lu.assertEquals(candidate('some_name_m'), None)\n    lu.assertEquals(candidate('a_b'), None)\n    lu.assertEquals(candidate('SomeName_aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'), 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa')\n    lu.assertEquals(candidate(''), None)\n    lu.assertEquals(candidate('some_name_j'), None)\n    lu.assertEquals(candidate('a_111111111'), None)\n    lu.assertEquals(candidate('some_name_'), None)\n    lu.assertEquals(candidate('some_name_d'), None)\n    lu.assertEquals(candidate('some_name_k'), None)\n    lu.assertEquals(candidate('someKey'), None)\n    lu.assertEquals(candidate('someKey_'), None)\n    lu.assertEquals(candidate('foo'), None)\n    lu.assertEquals(candidate('some_name__'), None)\n    lu.assertEquals(candidate('foo_123456789012345678901234567890'), None)\n    lu.assertEquals(candidate('a_11111111'), None)\n    lu.assertEquals(candidate('a'), None)\n    lu.assertEquals(candidate('foo_bar_baz'), None)\n    lu.assertEquals(candidate('some_name_i'), None)\n    lu.assertEquals(candidate('foo_123'), None)\n    lu.assertEquals(candidate('foo_123456789'), None)\n    lu.assertEquals(candidate('a_1111111111111111'), None)\n    lu.assertEquals(candidate('foo_123_456'), None)\n    lu.assertEquals(candidate('foo_'), None)\n    lu.assertEquals(candidate('SomeName_0123456789abcdef0123456789abcdef'), '0123456789abcdef0123456789abcdef')\n    lu.assertEquals(candidate('some_name_p'), None)\n    lu.assertEquals(candidate('some_name_a'), None)\n    lu.assertEquals(candidate('foo_bar'), None)\n    lu.assertEquals(candidate('some_name_o'), None)\n    lu.assertEquals(candidate('a_111111111111111111'), None)\n    lu.assertEquals(candidate(''), None)\n    lu.assertEquals(candidate('some_name_f'), None)\n    lu.assertEquals(candidate('someKey_0123456789abcdef0123456789abcdef0123456789abcdef'), None)\n    lu.assertEquals(candidate('foo_12345678'), None)\n    lu.assertEquals(candidate('foo'), None)\n    lu.assertEquals(candidate('foo_bar'), None)\n    lu.assertEquals(candidate('some_name'), None)\n    lu.assertEquals(candidate('some_name_h'), None)\n    lu.assertEquals(candidate('some_name_g'), None)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_402950_remove_ssml_tags", "language": "lua", "prompt": "-- Remove the SSML tags from parm text. The tags are surrounded by <chevrons>.\nlocal function remove_ssml_tags(parm_text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_402950_remove_ssml_tags.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_ssml_tags\n    lu.assertEquals(candidate('<emphasis>Hello, World!</emphasis>'), 'Hello, World!')\n    lu.assertEquals(candidate('<break time=\"5s\"/>'), '')\n    lu.assertEquals(candidate('Hello, World!'), 'Hello, World!')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_403090_calculate_height", "language": "lua", "prompt": "--     Calculate real person height in centimeters.\nlocal function calculate_height(distance, y_max, y_min, focal_y)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_403090_calculate_height.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = calculate_height\n    lu.assertEquals(candidate(0, 0, 0, 2000), 0)\n    lu.assertEquals(candidate(0, 0, 1000, 2000), 0)\n    lu.assertEquals(candidate(1000, 0, 0, 2000), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_403991_node_vertex_name", "language": "lua", "prompt": "-- Returns the full name of the given node vertex\n-- :param mesh_node: str\n-- :param vertex_id: int\n-- :return: str\nlocal function node_vertex_name(mesh_node, vertex_id)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_403991_node_vertex_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = node_vertex_name\n    lu.assertEquals(candidate('mesh', 3), 'mesh.vtx[3]')\n    lu.assertEquals(candidate('MeshNode', 0), 'MeshNode.vtx[0]')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_404803_isQualified", "language": "lua", "prompt": "--     Check if a property name is qualified\nlocal function isQualified(name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_404803_isQualified.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = isQualified\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('prop'), false)\n    lu.assertEquals(candidate('xmlns'), false)\n    lu.assertEquals(candidate('xlink:type'), true)\n    lu.assertEquals(candidate('xlink:title'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_405193_getStatusWord", "language": "lua", "prompt": "-- Returns the status word from the status code. \nlocal function getStatusWord(status)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_405193_getStatusWord.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = getStatusWord\n    lu.assertEquals(candidate(1), 'ordered')\n    lu.assertEquals(candidate(0), 'wished')\n    lu.assertEquals(candidate(2), 'owned')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_405292_factorial", "language": "lua", "prompt": "-- This function calculates factorial of a number recursively.\n-- n! = n*(n-1)*(n-2)*...*2*1\n-- Parameters\n-- ----------\n-- num : uint64\n--     Input positive integer to calcuate factorial.\n-- Returns\n-- -------\n-- uint64\n--     Factorial of input positive integer.\nlocal function factorial(num)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_405292_factorial.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = factorial\n    lu.assertEquals(candidate(8), 40320)\n    lu.assertEquals(candidate(5), 120)\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(17), 355687428096000)\n    lu.assertEquals(candidate(4), 24)\n    lu.assertEquals(candidate(20), 2432902008176640000)\n    lu.assertEquals(candidate(11), 39916800)\n    lu.assertEquals(candidate(12), 479001600)\n    lu.assertEquals(candidate(10), 3628800)\n    lu.assertEquals(candidate(19), 121645100408832000)\n    lu.assertEquals(candidate(15), 1307674368000)\n    lu.assertEquals(candidate(13), 6227020800)\n    lu.assertEquals(candidate(9), 362880)\n    lu.assertEquals(candidate(18), 6402373705728000)\n    lu.assertEquals(candidate(3), 6)\n    lu.assertEquals(candidate(6), 720)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(14), 87178291200)\n    lu.assertEquals(candidate(7), 5040)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_405585_dms2dd", "language": "lua", "prompt": "-- http://en.proft.me/2015/09/20/converting-latitude-and-longitude-decimal-values-p/\n-- Args:\n--     degrees:\n--     minutes:\n--     seconds:\n--     direction:\n-- Returns:\nlocal function dms2dd(degrees, minutes, seconds, direction)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_405585_dms2dd.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = dms2dd\n    lu.assertEquals(candidate(40, 0, 0, 'N'), 40.0)\n    lu.assertEquals(candidate(41, 30, 30, 'N'), 41.50833333333333)\n    lu.assertEquals(candidate(31, 30, 30, 'W'), -31.508333333333333)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_406279_realign_shifted_streams", "language": "lua", "prompt": "-- Durations are shifted by 1, F0 by 2\n-- >>> tokens = [\"<s>\", \"t1\",  \"t2\", \"t3\", \"</s>\", \"x\", \"x\"]\n-- >>> durations = [\"<0>\", \"<0>\", \"d1\", \"d2\", \"d3\", \"<0>\", \"x\"]\n-- >>> F0s    = [\"<0>\", \"<0>\", \"<0>\", \"f1\", \"f2\", \"f3\", \"<0>\"]\n-- >>> shifts = [1,2]\n-- >>> realign_shifted_streams(tokens, durations, F0s, shifts)\n-- (['<s>', 't1', 't2', 't3', '</s>'], ['<0>', 'd1', 'd2', 'd3', '<0>'], ['<0>', 'f1', 'f2', 'f3', '<0>'])\nlocal function realign_shifted_streams(tokens, durations, F0s, shifts)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_406279_realign_shifted_streams.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = realign_shifted_streams\n    lu.assertEquals(candidate({'<s>', 't1', 't2', 't3', '</s>', 'x', 'x'}, {'<0>', '<0>', 'd1', 'd2', 'd3', '<0>', 'x'}, {'<0>', '<0>', '<0>', 'f1', 'f2', 'f3', '<0>'}, {1, 2}), {{'<s>', 't1', 't2', 't3', '</s>'}, {'<0>', 'd1', 'd2', 'd3', '<0>'}, {'<0>', 'f1', 'f2', 'f3', '<0>'}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_406838_wait_for_line", "language": "lua", "prompt": "-- Should the intepreter wait for another line of input or try to evaluate the\n-- current line as is.\nlocal function wait_for_line(input_string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_406838_wait_for_line.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = wait_for_line\n    lu.assertEquals(candidate('a = b = c = d = e = f'), false)\n    lu.assertEquals(candidate('(a = b = c) = (d = e = f)'), false)\n    lu.assertEquals(candidate('a + b * (c + d) + e'), false)\n    lu.assertEquals(candidate('a + b * (c + d) + e = f + g'), false)\n    lu.assertEquals(candidate('a = 1, b = 2;'), false)\n    lu.assertEquals(candidate('return 42;'), false)\n    lu.assertEquals(candidate('(a + b * (c + d)) + e = f + g'), false)\n    lu.assertEquals(candidate('(a + b) * (c + d) + e = f + g'), false)\n    lu.assertEquals(candidate('a = b = c'), false)\n    lu.assertEquals(candidate('let a = 1, b = 2;'), false)\n    lu.assertEquals(candidate('a + b * (c + d)'), false)\n    lu.assertEquals(candidate('a = b = c = d = e'), false)\n    lu.assertEquals(candidate('function my_func(a, b) { return a + b; }'), false)\n    lu.assertEquals(candidate('a = b = c = d'), false)\n    lu.assertEquals(candidate('a + b * (c + d) + e = f'), false)\n    lu.assertEquals(candidate('2 + 2;'), false)\n    lu.assertEquals(candidate('var a = 1, b = 2;'), false)\n    lu.assertEquals(candidate('a + ((b * c))'), false)\n    lu.assertEquals(candidate('a + (b * c)'), false)\n    lu.assertEquals(candidate('for (i = 0; i < 10; i++) { print(i); }'), false)\n    lu.assertEquals(candidate('print(1 + 1) && print(2 + 2)'), false)\n    lu.assertEquals(candidate('print(\"Hello, World!\");'), false)\n    lu.assertEquals(candidate('a + b * c'), false)\n    lu.assertEquals(candidate('my_func(1, 2);'), false)\n    lu.assertEquals(candidate('a = b = c = (d = e = f)'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_40712_generate_base_code", "language": "lua", "prompt": "-- Returns a base code, one of:\n-- A -- Naval Base and Scout Base/Outpost\n-- G -- Scout Base/Outpost and Pirate Base\n-- N -- Naval Base\n-- P -- Pirate Base\n-- S -- Scout Base/Outpost\nlocal function generate_base_code(naval_base, scout_base, pirate_base)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_40712_generate_base_code.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = generate_base_code\n    lu.assertEquals(candidate(true, false, true), 'N')\n    lu.assertEquals(candidate(true, true, false), 'A')\n    lu.assertEquals(candidate(true, true, true), 'A')\n    lu.assertEquals(candidate(true, false, false), 'N')\n    lu.assertEquals(candidate(false, false, false), ' ')\n    lu.assertEquals(candidate(false, true, false), 'S')\n    lu.assertEquals(candidate(false, true, true), 'G')\n    lu.assertEquals(candidate(false, false, true), 'P')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_408233_parse", "language": "lua", "prompt": "-- Parse URL query into correct SQL syntax.\n-- :param query: SQL query pulled from URL argument.\n-- :return: Parsed query converted to valid SQL syntax.\nlocal function parse(query)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_408233_parse.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse\n    lu.assertEquals(candidate(\"SELECT * FROM film WHERE length > 60 AND title LIKE '%n'\"), \"SELECT * FROM film WHERE length > 60 AND title LIKE '%n'\")\n    lu.assertEquals(candidate(\"SELECT * FROM film WHERE length > 60 AND title LIKE '%n' AND year = 2004\"), \"SELECT * FROM film WHERE length > 60 AND title LIKE '%n' AND year = 2004\")\n    lu.assertEquals(candidate('SELECT * FROM table_name WHERE column_name = value'), 'SELECT * FROM table_name WHERE column_name = value')\n    lu.assertEquals(candidate(\"SELECT * FROM table_name WHERE column_name LIKE '%value%'\"), \"SELECT * FROM table_name WHERE column_name LIKE '%value%'\")\n    lu.assertEquals(candidate('SELECT * FROM table_name WHERE column_name <= value'), 'SELECT * FROM table_name WHERE column_name <= value')\n    lu.assertEquals(candidate(\"SELECT * FROM table_name WHERE column_name NOT LIKE '%value%'\"), \"SELECT * FROM table_name WHERE column_name NOT LIKE '%value%'\")\n    lu.assertEquals(candidate('SELECT * FROM table_name WHERE column_name >= value'), 'SELECT * FROM table_name WHERE column_name >= value')\n    lu.assertEquals(candidate('SELECT * FROM table_name WHERE column_name!= value'), 'SELECT * FROM table_name WHERE column_name!= value')\n    lu.assertEquals(candidate(\"SELECT * FROM table_name WHERE column_name IN ('value1', 'value2')\"), \"SELECT * FROM table_name WHERE column_name IN ('value1', 'value2')\")\n    lu.assertEquals(candidate('SELECT * FROM table_name WHERE column_name < value'), 'SELECT * FROM table_name WHERE column_name < value')\n    lu.assertEquals(candidate('SELECT * FROM table_name WHERE column_name > value'), 'SELECT * FROM table_name WHERE column_name > value')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_409149_turnOff", "language": "lua", "prompt": "--     function to turn off lights with given coordinates from array\nlocal function turnOff(array, a2d)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_409149_turnOff.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = turnOff\n    lu.assertEquals(candidate({2, 1, 3, 1}, {{0, 0, 0, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}}), {{0, 0, 0, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_40937_extract_name", "language": "lua", "prompt": "-- extracts the module name.\n-- :param module_name:\n-- :return: <str> the module name without the version.\nlocal function extract_name(module_name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_40937_extract_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = extract_name\n    lu.assertEquals(candidate('baz_v3'), 'baz')\n    lu.assertEquals(candidate('foo_v2'), 'foo')\n    lu.assertEquals(candidate('foo'), 'foo')\n    lu.assertEquals(candidate('bar'), 'bar')\n    lu.assertEquals(candidate('baz'), 'baz')\n    lu.assertEquals(candidate('qux'), 'qux')\n    lu.assertEquals(candidate('bar_v1'), 'bar')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_409443_get_network_bits", "language": "lua", "prompt": "-- Returns number of network bits of given mask\n-- :param mask_binary: Subnet Mask in binary\n-- :return: Number of network bits\nlocal function get_network_bits(mask_binary)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_409443_get_network_bits.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_network_bits\n    lu.assertEquals(candidate('11111111111111111111111111111111'), 32)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_409453_fibonacci_by_index", "language": "lua", "prompt": "-- Get the value at the index of the Fibonacci series.\n-- Austin W. Milne @awbmilne  <austin.milne@uwaterloo.ca>\n-- Parameters\n-- ----------\n-- index: number\n--     The index of the Fibonacci series to return.\n-- Returns\n-- -------\n-- The value from the Fibonacci series at the given index.\nlocal function fibonacci_by_index(index)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_409453_fibonacci_by_index.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fibonacci_by_index\n    lu.assertEquals(candidate(2), 1)\n    lu.assertEquals(candidate(12), 144)\n    lu.assertEquals(candidate(9), 34)\n    lu.assertEquals(candidate(10), 55)\n    lu.assertEquals(candidate(13), 233)\n    lu.assertEquals(candidate(4), 3)\n    lu.assertEquals(candidate(11), 89)\n    lu.assertEquals(candidate(19), 4181)\n    lu.assertEquals(candidate(22), 17711)\n    lu.assertEquals(candidate(14), 377)\n    lu.assertEquals(candidate(16), 987)\n    lu.assertEquals(candidate(15), 610)\n    lu.assertEquals(candidate(6), 8)\n    lu.assertEquals(candidate(24), 46368)\n    lu.assertEquals(candidate(3), 2)\n    lu.assertEquals(candidate(17), 1597)\n    lu.assertEquals(candidate(23), 28657)\n    lu.assertEquals(candidate(18), 2584)\n    lu.assertEquals(candidate(20), 6765)\n    lu.assertEquals(candidate(21), 10946)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(7), 13)\n    lu.assertEquals(candidate(8), 21)\n    lu.assertEquals(candidate(5), 5)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_409856_MILLISECOND", "language": "lua", "prompt": "-- Returns the millisecond portion of a date as an integer between 0 and 999.\n-- See https://docs.mongodb.com/manual/reference/operator/aggregation/millisecond/\n-- for more details\n-- :param expression: expression or variable of a Date, a Timestamp, or an ObjectID\n-- :return: Aggregation operator\nlocal function MILLISECOND(expression)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_409856_MILLISECOND.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = MILLISECOND\n    lu.assertEquals(candidate(2017), {['$millisecond'] = 2017})\n    lu.assertEquals(candidate(1437400400000), {['$millisecond'] = 1437400400000})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_410378_tickDiff", "language": "lua", "prompt": "-- Returns the microsecond difference between two ticks.\n-- t1:= the earlier tick\n-- t2:= the later tick\n-- ...\n-- print(pigpio.tickDiff(4294967272, 12))\n-- 36\n-- ...\nlocal function tickDiff(t1, t2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_410378_tickDiff.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = tickDiff\n    lu.assertEquals(candidate(1, 2), 1)\n    lu.assertEquals(candidate(-1, 0), 1)\n    lu.assertEquals(candidate(1, 1), 0)\n    lu.assertEquals(candidate(0, 3), 3)\n    lu.assertEquals(candidate(123456, 123456), 0)\n    lu.assertEquals(candidate(123456, 123457), 1)\n    lu.assertEquals(candidate(0, 1), 1)\n    lu.assertEquals(candidate(4294967272, 12), 36)\n    lu.assertEquals(candidate(0, 0), 0)\n    lu.assertEquals(candidate(0, 2), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_41072_rename_candidate_hugo", "language": "lua", "prompt": "-- Renames a candidate name according to a renaming map.\nlocal function rename_candidate_hugo(candidate, renamings)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_41072_rename_candidate_hugo.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rename_candidate_hugo\n    lu.assertEquals(candidate('HLA-A*01:01:01:01', {['HLA-A*01:01:01:01'] = 'HLA-A*01:01:01:01_NewName'}), 'HLA-A*01:01:01:01_NewName')\n    lu.assertEquals(candidate('A.a.a.a.a', {['A'] = 'B'}), 'B.a.a.a.a')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_410947_arxiv_url_sanitizer", "language": "lua", "prompt": "-- as of now, just converts \n-- arxiv.org/pdf/ to arxiv.org/abs\nlocal function arxiv_url_sanitizer(url)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_410947_arxiv_url_sanitizer.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = arxiv_url_sanitizer\n    lu.assertEquals(candidate('http://www.arxiv.org/pdf/cond-mat/0712.1784.pdf'), 'http://www.arxiv.org/abs/cond-mat/0712.1784')\n    lu.assertEquals(candidate('https://arxiv.org/pdf/2004.09813v23.pdf'), 'https://arxiv.org/abs/2004.09813v23')\n    lu.assertEquals(candidate('https://arxiv.org/pdf/cond-mat/0712.1784.pdf'), 'https://arxiv.org/abs/cond-mat/0712.1784')\n    lu.assertEquals(candidate('https://arxiv.org/pdf/cond-mat/0712.1784v1.pdf'), 'https://arxiv.org/abs/cond-mat/0712.1784v1')\n    lu.assertEquals(candidate('https://arxiv.org/pdf/2004.09813v2.pdf'), 'https://arxiv.org/abs/2004.09813v2')\n    lu.assertEquals(candidate('https://arxiv.org/abs/2012.12345.pdf'), 'https://arxiv.org/abs/2012.12345')\n    lu.assertEquals(candidate('http://www.arxiv.org/pdf/cond-mat/0712.1784v1.pdf'), 'http://www.arxiv.org/abs/cond-mat/0712.1784v1')\n    lu.assertEquals(candidate('https://arxiv.org/abs/cond-mat/0712.1784'), 'https://arxiv.org/abs/cond-mat/0712.1784')\n    lu.assertEquals(candidate('https://arxiv.org/pdf/2004.09813.pdf'), 'https://arxiv.org/abs/2004.09813')\n    lu.assertEquals(candidate('https://arxiv.org/pdf/math.GT/0611008.pdf'), 'https://arxiv.org/abs/math.GT/0611008')\n    lu.assertEquals(candidate('http://arxiv.org/pdf/1702.06188'), 'http://arxiv.org/abs/1702.06188')\n    lu.assertEquals(candidate('http://arxiv.org/pdf/1702.06188.pdf'), 'http://arxiv.org/abs/1702.06188')\n    lu.assertEquals(candidate('https://arxiv.org/pdf/2012.12345.pdf'), 'https://arxiv.org/abs/2012.12345')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_411394_append_default_columns", "language": "lua", "prompt": "-- appends num string to a list as col_[index]\nlocal function append_default_columns(start, num)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_411394_append_default_columns.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = append_default_columns\n    lu.assertEquals(candidate(0, 1), {'col_1'})\n    lu.assertEquals(candidate(0, 2), {'col_1', 'col_2'})\n    lu.assertEquals(candidate(10, 0), {})\n    lu.assertEquals(candidate(0, 2), {'col_1', 'col_2'})\n    lu.assertEquals(candidate(3, 0), {})\n    lu.assertEquals(candidate(2, 5), {'col_3', 'col_4', 'col_5'})\n    lu.assertEquals(candidate(0, 0), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_411424__re_word_boundary", "language": "lua", "prompt": "-- Adds word boundary characters to the start and end of an\n-- expression to require that the match occur as a whole word,\n-- but do so respecting the fact that strings starting or ending\n-- with non-word characters will change word boundaries.\nlocal function _re_word_boundary(r)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_411424__re_word_boundary.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _re_word_boundary\n    lu.assertEquals(candidate('\\\\B'), '(^|\\\\W)\\\\B(\\\\W|$)')\n    lu.assertEquals(candidate('\\\\W+'), candidate('\\\\W+'))\n    lu.assertEquals(candidate('a?'), '(^|\\\\W)a?(\\\\W|$)')\n    lu.assertEquals(candidate('[a-zA-Z]'), '(^|\\\\W)[a-zA-Z](\\\\W|$)')\n    lu.assertEquals(candidate('a[b-]b'), '(^|\\\\W)a[b-]b(\\\\W|$)')\n    lu.assertEquals(candidate('a'), '(^|\\\\W)a(\\\\W|$)')\n    lu.assertEquals(candidate('[cat]'), '(^|\\\\W)[cat](\\\\W|$)')\n    lu.assertEquals(candidate('a[]b'), '(^|\\\\W)a[]b(\\\\W|$)')\n    lu.assertEquals(candidate('[abc]'), '(^|\\\\W)[abc](\\\\W|$)')\n    lu.assertEquals(candidate('[a]'), '(^|\\\\W)[a](\\\\W|$)')\n    lu.assertEquals(candidate('[\\\\d\\\\w]'), '(^|\\\\W)[\\\\d\\\\w](\\\\W|$)')\n    lu.assertEquals(candidate('[ab]'), '(^|\\\\W)[ab](\\\\W|$)')\n    lu.assertEquals(candidate('foo1'), '(^|\\\\W)foo1(\\\\W|$)')\n    lu.assertEquals(candidate('foo\\\\b'), '(^|\\\\W)foo\\\\b(\\\\W|$)')\n    lu.assertEquals(candidate('foo-bar'), '(^|\\\\W)foo-bar(\\\\W|$)')\n    lu.assertEquals(candidate('a[b-Xb-]b'), '(^|\\\\W)a[b-Xb-]b(\\\\W|$)')\n    lu.assertEquals(candidate('cat\\\\s+'), '(^|\\\\W)cat\\\\s+(\\\\W|$)')\n    lu.assertEquals(candidate('\\\\\\\\'), '(^|\\\\W)\\\\\\\\(\\\\W|$)')\n    lu.assertEquals(candidate('x'), '(^|\\\\W)x(\\\\W|$)')\n    lu.assertEquals(candidate('cat'), '(^|\\\\W)cat(\\\\W|$)')\n    lu.assertEquals(candidate('foo\\\\bfoo'), '(^|\\\\W)foo\\\\bfoo(\\\\W|$)')\n    lu.assertEquals(candidate('\\\\d'), '(^|\\\\W)\\\\d(\\\\W|$)')\n    lu.assertEquals(candidate('[^abc]'), '(^|\\\\W)[^abc](\\\\W|$)')\n    lu.assertEquals(candidate('\\\\w'), '(^|\\\\W)\\\\w(\\\\W|$)')\n    lu.assertEquals(candidate('cat\\\\|'), '(^|\\\\W)cat\\\\|(\\\\W|$)')\n    lu.assertEquals(candidate('a+b'), '(^|\\\\W)a+b(\\\\W|$)')\n    lu.assertEquals(candidate('.*'), '(^|\\\\W).*(\\\\W|$)')\n    lu.assertEquals(candidate('\\\\w+'), '(^|\\\\W)\\\\w+(\\\\W|$)')\n    lu.assertEquals(candidate('a\\\\sb'), '(^|\\\\W)a\\\\sb(\\\\W|$)')\n    lu.assertEquals(candidate('abc'), '(^|\\\\W)abc(\\\\W|$)')\n    lu.assertEquals(candidate('cat\\\\\\\\'), '(^|\\\\W)cat\\\\\\\\(\\\\W|$)')\n    lu.assertEquals(candidate('cat\\\\\\\\\\\\\\\\'), '(^|\\\\W)cat\\\\\\\\\\\\\\\\(\\\\W|$)')\n    lu.assertEquals(candidate('a\\\\b'), '(^|\\\\W)a\\\\b(\\\\W|$)')\n    lu.assertEquals(candidate('\\\\[cat\\\\]'), '(^|\\\\W)\\\\[cat\\\\](\\\\W|$)')\n    lu.assertEquals(candidate('a[\\\\s]b'), '(^|\\\\W)a[\\\\s]b(\\\\W|$)')\n    lu.assertEquals(candidate('1foo'), '(^|\\\\W)1foo(\\\\W|$)')\n    lu.assertEquals(candidate('(\\\\w+|\\\\\\\\)'), '(^|\\\\W)(\\\\w+|\\\\\\\\)(\\\\W|$)')\n    lu.assertEquals(candidate('foo'), '(^|\\\\W)foo(\\\\W|$)')\n    lu.assertEquals(candidate('[^ab]'), '(^|\\\\W)[^ab](\\\\W|$)')\n    lu.assertEquals(candidate('123'), '(^|\\\\W)123(\\\\W|$)')\n    lu.assertEquals(candidate('foo-bar-'), '(^|\\\\W)foo-bar-(\\\\W|$)')\n    lu.assertEquals(candidate('\\\\]'), '(^|\\\\W)\\\\](\\\\W|$)')\n    lu.assertEquals(candidate('\\\\['), '(^|\\\\W)\\\\[(\\\\W|$)')\n    lu.assertEquals(candidate('a[b-gB-G]b'), '(^|\\\\W)a[b-gB-G]b(\\\\W|$)')\n    lu.assertEquals(candidate('foo1bar'), '(^|\\\\W)foo1bar(\\\\W|$)')\n    lu.assertEquals(candidate('a*'), '(^|\\\\W)a*(\\\\W|$)')\n    lu.assertEquals(candidate('foo_bar1_'), '(^|\\\\W)foo_bar1_(\\\\W|$)')\n    lu.assertEquals(candidate('foo_bar1'), '(^|\\\\W)foo_bar1(\\\\W|$)')\n    lu.assertEquals(candidate('\\\\\\\\cat'), '(^|\\\\W)\\\\\\\\cat(\\\\W|$)')\n    lu.assertEquals(candidate('[^a]'), '(^|\\\\W)[^a](\\\\W|$)')\n    lu.assertEquals(candidate('\\\\W'), candidate('\\\\W'))\n    lu.assertEquals(candidate('a_b'), '(^|\\\\W)a_b(\\\\W|$)')\n    lu.assertEquals(candidate('\\\\d+'), '(^|\\\\W)\\\\d+(\\\\W|$)')\n    lu.assertEquals(candidate('\\\\W'), '(^|\\\\W)\\\\W(\\\\W|$)')\n    lu.assertEquals(candidate('foo-'), '(^|\\\\W)foo-(\\\\W|$)')\n    lu.assertEquals(candidate('foo_bar'), '(^|\\\\W)foo_bar(\\\\W|$)')\n    lu.assertEquals(candidate('\\\\b'), '(^|\\\\W)\\\\b(\\\\W|$)')\n    lu.assertEquals(candidate('!'), '(^|\\\\W)!(\\\\W|$)')\n    lu.assertEquals(candidate('\\\\w+'), candidate('\\\\w+'))\n    lu.assertEquals(candidate('foo-_bar'), '(^|\\\\W)foo-_bar(\\\\W|$)')\n    lu.assertEquals(candidate('a\\\\.b'), '(^|\\\\W)a\\\\.b(\\\\W|$)')\n    lu.assertEquals(candidate('a[^]b]'), '(^|\\\\W)a[^]b](\\\\W|$)')\n    lu.assertEquals(candidate('1foo_bar1'), '(^|\\\\W)1foo_bar1(\\\\W|$)')\n    lu.assertEquals(candidate('[a-zA-Z0-9_]'), '(^|\\\\W)[a-zA-Z0-9_](\\\\W|$)')\n    lu.assertEquals(candidate('the'), '(^|\\\\W)the(\\\\W|$)')\n    lu.assertEquals(candidate('1foo_bar'), '(^|\\\\W)1foo_bar(\\\\W|$)')\n    lu.assertEquals(candidate('[a-z]'), '(^|\\\\W)[a-z](\\\\W|$)')\n    lu.assertEquals(candidate('a.b'), '(^|\\\\W)a.b(\\\\W|$)')\n    lu.assertEquals(candidate('foo;bar'), '(^|\\\\W)foo;bar(\\\\W|$)')\n    lu.assertEquals(candidate('a[b-g]b'), '(^|\\\\W)a[b-g]b(\\\\W|$)')\n    lu.assertEquals(candidate('a/b'), '(^|\\\\W)a/b(\\\\W|$)')\n    lu.assertEquals(candidate('a[b-Za-y]b'), '(^|\\\\W)a[b-Za-y]b(\\\\W|$)')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_411437__prt_mode_from_unfolding", "language": "lua", "prompt": "--  Return 'fixed' or 'staggered' depending on unfolding flag \nlocal function _prt_mode_from_unfolding(unfolding)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_411437__prt_mode_from_unfolding.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _prt_mode_from_unfolding\n    lu.assertEquals(candidate(0), 'fixed')\n    lu.assertEquals(candidate(1), 'staggered')\n    lu.assertEquals(candidate(-1), 'staggered')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_411619_order_of_execution", "language": "lua", "prompt": "-- This one is linear time.\n-- :param count:\n-- :param k:\n-- :return:\nlocal function order_of_execution(count, k)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_411619_order_of_execution.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = order_of_execution\n    lu.assertEquals(candidate(3, 1), {1, 2, 3})\n    lu.assertEquals(candidate(2, 3), {1, 2})\n    lu.assertEquals(candidate(2, 1), {1, 2})\n    lu.assertEquals(candidate(5, 1), {1, 2, 3, 4, 5})\n    lu.assertEquals(candidate(6, 1), {1, 2, 3, 4, 5, 6})\n    lu.assertEquals(candidate(4, 1), {1, 2, 3, 4})\n    lu.assertEquals(candidate(1, 2), {1})\n    lu.assertEquals(candidate(10, 1), {1, 2, 3, 4, 5, 6, 7, 8, 9, 10})\n    lu.assertEquals(candidate(1, 3), {1})\n    lu.assertEquals(candidate(3, 3), {3, 1, 2})\n    lu.assertEquals(candidate(1, 1), {1})\n    lu.assertEquals(candidate(3, 2), {2, 1, 3})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_41197_contains_word", "language": "lua", "prompt": "--     Checks whether a string contains a certain word\nlocal function contains_word(s, w)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_41197_contains_word.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = contains_word\n    lu.assertEquals(candidate('This is a string with a word in it', 'word'), true)\n    lu.assertEquals(candidate('This is a string with a word in it', 'dog'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_41279_get_attrs", "language": "lua", "prompt": "-- Get foreground and background attributes.\nlocal function get_attrs(foreground, background, style)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_41279_get_attrs.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_attrs\n    lu.assertEquals(candidate(0, 0, 2), 2)\n    lu.assertEquals(candidate(0, 0, 1), 1)\n    lu.assertEquals(candidate(0, 0, 0), 0)\n    lu.assertEquals(candidate(0, 0, 0), 0)\n    lu.assertEquals(candidate(0, 0, 3), 3)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_413062_matrix_add", "language": "lua", "prompt": "-- Accepts two lists-of-lists of numbers and returns one\n-- list-of-lists with each of the corresponding numbers in the\n-- two given lists-of-lists added together.\n-- Example:\n-- >>> matrix1 = [[1, -2], [-3, 4]]\n-- >>> matrix2 = [[2, -1], [0, -1]]\n-- >>> add(matrix1, matrix2)\n-- [[3, -3], [-3, 3]]\n-- >>> matrix1 = [[1, -2, 3], [-4, 5, -6], [7, -8, 9]]\n-- >>> matrix2 = [[1, 1, 0], [1, -2, 3], [-2, 2, -2]]\n-- >>> add(matrix1, matrix2)\n-- [[2, -1, 3], [-3, 3, -3], [5, -6, 7]]\nlocal function matrix_add(list1, list2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_413062_matrix_add.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = matrix_add\n    lu.assertEquals(candidate({{1, -2, 3}, {-4, 5, -6}, {7, -8, 9}}, {{1, 1, 0}, {1, -2, 3}, {-2, 2, -2}}), {{2, -1, 3}, {-3, 3, -3}, {5, -6, 7}})\n    lu.assertEquals(candidate({{1, -2, 3}, {-4, 5, -6}, {7, -8, 9}}, {{1, 1, 0}, {1, -2, 3}, {-2, 2, -2}}), {{2, -1, 3}, {-3, 3, -3}, {5, -6, 7}})\n    lu.assertEquals(candidate({{1, -2}, {-3, 4}}, {{2, -1}, {0, -1}}), {{3, -3}, {-3, 3}})\n    lu.assertEquals(candidate({{1, 2, -3}, {4, -5, 6}}, {{-1, 1, 2}, {-1, 2, 3}, {4, 5, 6}}), {{0, 3, -1}, {3, -3, 9}})\n    lu.assertEquals(candidate({{1, -2}, {-3, 4}}, {{2, -1}, {0, -1}}), {{3, -3}, {-3, 3}})\n    lu.assertEquals(candidate({{1, -2}, {-3, 4}}, {{2, -1}, {0, -1}}), {{3, -3}, {-3, 3}})\n    lu.assertEquals(candidate({{1, 0, 1, 0}, {0, 1, 0, 1}, {1, 0, 1, 0}, {0, 1, 0, 1}}, {{1, 1, 1, 1}, {1, 1, 1, 1}, {1, 1, 1, 1}, {1, 1, 1, 1}}), {{2, 1, 2, 1}, {1, 2, 1, 2}, {2, 1, 2, 1}, {1, 2, 1, 2}})\n    lu.assertEquals(candidate({{1, -2, 3}, {-4, 5, -6}, {7, -8, 9}}, {{1, 1, 0}, {1, -2, 3}, {-2, 2, -2}}), {{2, -1, 3}, {-3, 3, -3}, {5, -6, 7}})\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}, {{-1, -2, -3}, {-4, -5, -6}, {-7, -8, -9}}), {{0, 0, 0}, {0, 0, 0}, {0, 0, 0}})\n    lu.assertEquals(candidate({{1, -2}, {-3, 4}}, {{2, -1}, {0, -1}}), {{3, -3}, {-3, 3}})\n    lu.assertEquals(candidate({{1, -2, 3}, {-4, 5, -6}, {7, -8, 9}}, {{1, 1, 0}, {1, -2, 3}, {-2, 2, -2}}), {{2, -1, 3}, {-3, 3, -3}, {5, -6, 7}})\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}, {{-1, -2, -3}, {-4, -5, -6}, {-7, -8, -9}}), {{0, 0, 0}, {0, 0, 0}, {0, 0, 0}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_413287_ConvertPrivateIpv6GoogleAccess", "language": "lua", "prompt": "-- Return PrivateIpv6GoogleAccess enum defined in mixer.\n-- Args:\n--   choice: Enum value of PrivateIpv6GoogleAccess defined in gcloud.\nlocal function ConvertPrivateIpv6GoogleAccess(choice)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_413287_ConvertPrivateIpv6GoogleAccess.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = ConvertPrivateIpv6GoogleAccess\n    lu.assertEquals(candidate('ENABLE_OUTBOUND_VM_ACCESS'), 'ENABLE_OUTBOUND_VM_ACCESS_TO_GOOGLE')\n    lu.assertEquals(candidate('DISABLE'), 'DISABLE_GOOGLE_ACCESS')\n    lu.assertEquals(candidate('ENABLE_BIDIRECTIONAL_ACCESS'), 'ENABLE_BIDIRECTIONAL_ACCESS_TO_GOOGLE')\n    lu.assertEquals(candidate('ENABLE_BIDIRECTIONAL_ACCESS'), 'ENABLE_BIDIRECTIONAL_ACCESS_TO_GOOGLE')\n    lu.assertEquals(candidate('ENABLE_OUTBOUND_VM_ACCESS'), 'ENABLE_OUTBOUND_VM_ACCESS_TO_GOOGLE')\n    lu.assertEquals(candidate('DISABLE'), 'DISABLE_GOOGLE_ACCESS')\n    lu.assertEquals(candidate(None), None)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_413434_song_decoder", "language": "lua", "prompt": "-- Return decoded song string\nlocal function song_decoder(song)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_413434_song_decoder.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = song_decoder\n    lu.assertEquals(candidate('AWUB'), 'A')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate(candidate('WUBWUBWUBWUBWUBAWUBBWUBC')), 'A B C')\n    lu.assertEquals(candidate(candidate('WUBAWUBBWUBCWUB')), 'A B C')\n    lu.assertEquals(candidate('AWUBWUBWUBBWUBWUBWUBC'), 'A B C')\n    lu.assertEquals(candidate(candidate('WUBAWUBBWUBC')), 'A B C')\n    lu.assertEquals(candidate(candidate('WUBWUBWUBWUBWUBAWUBBWUBCWUB')), 'A B C')\n    lu.assertEquals(candidate(candidate('WUBWUBWUBAWUBBWUBC')), 'A B C')\n    lu.assertEquals(candidate(candidate('WUBWUBWUBWUBWUBWUBWUBWUBWUBWUB')), '')\n    lu.assertEquals(candidate('AWUBWUBWUBBWUBWUBWUBC'), 'A B C')\n    lu.assertEquals(candidate(candidate('WUBWUBAWUBBWUBC')), 'A B C')\n    lu.assertEquals(candidate(candidate('WUBWUBWUBWUBWUBWUBAWUBBWUBC')), 'A B C')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('WUBAWUBBWUBCWUB'), 'A B C')\n    lu.assertEquals(candidate(candidate('WUBWUBWUBAWUBBWUBCWUBWUB')), 'A B C')\n    lu.assertEquals(candidate(candidate('WUBWUBWUBWUBWUBWUBWUBWUBWUB')), '')\n    lu.assertEquals(candidate('WUBAWUBBWUBCWUB'), 'A B C')\n    lu.assertEquals(candidate('WUBAWUB'), 'A')\n    lu.assertEquals(candidate('AWUBBWUBC'), 'A B C')\n    lu.assertEquals(candidate('WUBWUB'), '')\n    lu.assertEquals(candidate(candidate('AWUBBWUBC')), 'A B C')\n    lu.assertEquals(candidate(candidate('AWUBWUBWUBBWUBWUBWUBC')), 'A B C')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_41418_get_api_interfaces_name_by_type", "language": "lua", "prompt": "-- Extract interface names from Interfaces API response by type\n-- :param api_interfaces: Interfaces API response\n-- :param type_str: Type string to match\n-- :param key_name: Optional - Key name to use (default 'name')\n-- :return: List of Interface names matching type_str\nlocal function get_api_interfaces_name_by_type(api_interfaces, type_str, key_name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_41418_get_api_interfaces_name_by_type.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_api_interfaces_name_by_type\n    lu.assertEquals(candidate({{['name'] = 'Ethernet0', ['type'] = 'iana-if-type:ethernetCsmacd'}, {['name'] = 'Ethernet4', ['type'] = 'iana-if-type:ethernetCsmacd'}}, 'iana-if-type:ethernetCsmacd'), {'Ethernet0', 'Ethernet4'})\n    lu.assertEquals(candidate({{['name'] = 'Ethernet0', ['type'] = 'iana-if-type:ethernetCsmacd'}, {['name'] = 'Ethernet4', ['type'] = 'iana-if-type:ethernetCsmacd'}}, 'iana-if-type:ethernetCsmacd', 'name'), {'Ethernet0', 'Ethernet4'})\n    lu.assertEquals(candidate({{['name'] = 'Ethernet0', ['type'] = 'iana-if-type:ethernetCsmacd'}, {['name'] = 'Ethernet4', ['type'] = 'iana-if-type:ethernetCsmacd'}}, 'iana-if-type:ethernetCsmacd', 'type'), {'iana-if-type:ethernetCsmacd', 'iana-if-type:ethernetCsmacd'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_414823_clean_whitespace", "language": "lua", "prompt": "--     Remove any extra whitespace and line breaks as needed.\nlocal function clean_whitespace(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_414823_clean_whitespace.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = clean_whitespace\n    lu.assertEquals(candidate('one\\r\\r\\r\\ntwo'), 'one two')\n    lu.assertEquals(candidate('one\\r\\n\\t\\t\\ntwo'), 'one two')\n    lu.assertEquals(candidate('one\\n\\r\\n\\ntwo\\n'), 'one two')\n    lu.assertEquals(candidate('one\\ntwo'), 'one two')\n    lu.assertEquals(candidate('one\\t\\t\\r\\n\\r\\n\\n\\n\\ntwo\\r\\n'), 'one two')\n    lu.assertEquals(candidate(' '), '')\n    lu.assertEquals(candidate('one\\n\\r\\r\\n\\t\\t\\ntwo\\n\\t\\t'), 'one two')\n    lu.assertEquals(candidate('one\\r\\n\\n\\ntwo'), 'one two')\n    lu.assertEquals(candidate(' one '), 'one')\n    lu.assertEquals(candidate('one\\n\\r\\r\\ntwo'), 'one two')\n    lu.assertEquals(candidate('one '), 'one')\n    lu.assertEquals(candidate('  one  '), 'one')\n    lu.assertEquals(candidate(' one'), 'one')\n    lu.assertEquals(candidate('one'), 'one')\n    lu.assertEquals(candidate('one\\n\\ntwo\\n'), 'one two')\n    lu.assertEquals(candidate('one\\r\\n\\r\\r\\ntwo\\r\\n'), 'one two')\n    lu.assertEquals(candidate('one\\t\\t\\t\\ttwo'), 'one two')\n    lu.assertEquals(candidate('one\\n\\ntwo'), 'one two')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_415327_escape_bytes", "language": "lua", "prompt": "-- Escapes seven bytes to eight bytes.\n-- Args:\n--     value7_uint64be(int): Bytes as a 56-bit bigendian unsigned integer.\n-- Returns:\n--     int: Escaped bytes as a 64-bit bigendian unsigned integer.\nlocal function escape_bytes(value7_uint64be)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_415327_escape_bytes.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = escape_bytes\n    lu.assertEquals(candidate(72057594037927935), 18446744073709551615)\n    lu.assertEquals(candidate(0), 9259542123273814144)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_415365_chop_at", "language": "lua", "prompt": "-- Truncate string ``s`` at the first occurrence of ``sub``.\n-- If ``inclusive`` is true, truncate just after ``sub`` rather than at it.\n-- >>> chop_at(\"plutocratic brats\", \"rat\")\n-- 'plutoc'\n-- >>> chop_at(\"plutocratic brats\", \"rat\", True)\n-- 'plutocrat'\nlocal function chop_at(s, sub, inclusive)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_415365_chop_at.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = chop_at\n    lu.assertEquals(candidate('rat', 'bar'), 'rat')\n    lu.assertEquals(candidate('foo bar', 'bar'), 'foo ')\n    lu.assertEquals(candidate('plutocratic brats', 'bar', true), 'plutocratic brats')\n    lu.assertEquals(candidate('', 'rat', true), '')\n    lu.assertEquals(candidate('plutocratic brats', 'rat'), 'plutoc')\n    lu.assertEquals(candidate('rat', 'rat'), '')\n    lu.assertEquals(candidate('a', 'b'), 'a')\n    lu.assertEquals(candidate('abc', 'bc'), 'a')\n    lu.assertEquals(candidate('a', 'b'), 'a')\n    lu.assertEquals(candidate('abc', 'c'), 'ab')\n    lu.assertEquals(candidate('a', 'a'), '')\n    lu.assertEquals(candidate('', 'rat'), '')\n    lu.assertEquals(candidate('plutocratic brats', 'bar'), 'plutocratic brats')\n    lu.assertEquals(candidate('plutocratic brats', 'tat', true), 'plutocratic brats')\n    lu.assertEquals(candidate('rat', 'bar', true), 'rat')\n    lu.assertEquals(candidate('plutocratic brats', 'rat', true), 'plutocrat')\n    lu.assertEquals(candidate('plutocratic brats', 'rat'), 'plutoc')\n    lu.assertEquals(candidate('abc', 'ab'), '')\n    lu.assertEquals(candidate('a', 'b', true), 'a')\n    lu.assertEquals(candidate('a', 'a'), '')\n    lu.assertEquals(candidate('plutocratic brats', 'tat'), 'plutocratic brats')\n    lu.assertEquals(candidate('plutocratic brats', 'rat', true), 'plutocrat')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_415543_add_host", "language": "lua", "prompt": "-- Make the image path absolute for those served by the server.\nlocal function add_host(data, host)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_415543_add_host.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = add_host\n    lu.assertEquals(candidate({{['name'] = 'name1', ['image'] = 'img1'}, {['name'] = 'name2', ['image'] = 'img2'}}, 'localhost:8000'), {{['name'] = 'name1', ['image'] = 'http://localhost:8000/img1'}, {['name'] = 'name2', ['image'] = 'http://localhost:8000/img2'}})\n    lu.assertEquals(candidate({{['image'] = 'foo/bar.png'}, {['image'] = 'foo/baz.png'}}, 'example.com'), {{['image'] = 'http://example.com/foo/bar.png'}, {['image'] = 'http://example.com/foo/baz.png'}})\n    lu.assertEquals(candidate({{['name'] = 'name1', ['image'] = 'img1'}, {['name'] = 'name2', ['image'] = 'img2'}}, 'localhost:9000/api'), {{['name'] = 'name1', ['image'] = 'http://localhost:9000/api/img1'}, {['name'] = 'name2', ['image'] = 'http://localhost:9000/api/img2'}})\n    lu.assertEquals(candidate({{['image'] = 'foo/bar.png'}, {['image'] = 'foo/baz.png'}, {['image'] = 'qux/quux.png'}}, 'example.com'), {{['image'] = 'http://example.com/foo/bar.png'}, {['image'] = 'http://example.com/foo/baz.png'}, {['image'] = 'http://example.com/qux/quux.png'}})\n    lu.assertEquals(candidate({{['name'] = 'name1', ['image'] = 'img1'}, {['name'] = 'name2', ['image'] = 'img2'}}, 'localhost'), {{['name'] = 'name1', ['image'] = 'http://localhost/img1'}, {['name'] = 'name2', ['image'] = 'http://localhost/img2'}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_415824_color2rgba", "language": "lua", "prompt": "--  convert #RRGGBB[AA] to an (R, G, B, [A]) tuple \nlocal function color2rgba(colorstring)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_415824_color2rgba.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = color2rgba\n    lu.assertEquals(candidate('#0000ffcc'), 65484)\n    lu.assertEquals(candidate('#0000ff00'), 65280)\n    lu.assertEquals(candidate('#ff0000cc'), 4278190284)\n    lu.assertEquals(candidate('#00ff00cc'), 16711884)\n    lu.assertEquals(candidate('#00000000'), 0)\n    lu.assertEquals(candidate('#ff0000ff'), 4278190335)\n    lu.assertEquals(candidate('#00ff0000'), 16711680)\n    lu.assertEquals(candidate('#00ff00ff'), 16711935)\n    lu.assertEquals(candidate('#ff000000'), 4278190080)\n    lu.assertEquals(candidate('#0000ffff'), 65535)\n    lu.assertEquals(candidate('#000000ff'), 255)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_416641_init_method_normalizer", "language": "lua", "prompt": "-- Normalizes the name of an initialization method.\nlocal function init_method_normalizer(name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_416641_init_method_normalizer.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = init_method_normalizer\n    lu.assertEquals(candidate('kaimingnormal'), 'kaimingnormal')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_416669_is_counting_line_passed", "language": "lua", "prompt": "-- To check if the point passed the counting line by the x coord if it left/right or y coord if it bottom/top.\n-- :param point: the object location.\n-- :param counting_line: the coordinates list of the area.\n-- :param line_orientation: the string of the orientation of the line.need to be top, bottom, left, right.\n-- :return: True if the point passed the line , False if the point didnt pass the line.\nlocal function is_counting_line_passed(point, counting_line, line_orientation)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_416669_is_counting_line_passed.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_counting_line_passed\n    lu.assertEquals(candidate({0, 0}, {{1, 0}, {0, 0}}, 'right'), false)\n    lu.assertEquals(candidate({0, 0}, {{1, 0}, {0, 0}}, 'top'), false)\n    lu.assertEquals(candidate({0, 0}, {{0, 0}, {0, 1}}, 'left'), false)\n    lu.assertEquals(candidate({0, 0}, {{1, 0}, {0, 0}}, 'left'), true)\n    lu.assertEquals(candidate({0, 0}, {{0, 0}, {0, 1}}, 'top'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_4167_wrap", "language": "lua", "prompt": "-- :param x: a scalar\n-- :param m: minimum possible value in range\n-- :param M: maximum possible value in range\n-- Wraps ``x`` so m <= x <= M; but unlike ``bound()`` which\n-- truncates, ``wrap()`` wraps x around the coordinate system defined by m,M.\n-- For example, m = -180, M = 180 (degrees), x = 360 --> returns 0.\nlocal function wrap(x, m, M)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_4167_wrap.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = wrap\n    lu.assertEquals(candidate(180, -180, 180), 180)\n    lu.assertEquals(candidate(-10, 0, 100), 90)\n    lu.assertEquals(candidate(3, 1, 5), 3)\n    lu.assertEquals(candidate(181, -180, 180), -179)\n    lu.assertEquals(candidate(13, 10, 20), 13)\n    lu.assertEquals(candidate(-180, -180, 180), -180)\n    lu.assertEquals(candidate(0, 0, 100), 0)\n    lu.assertEquals(candidate(-10, -100, 0), -10)\n    lu.assertEquals(candidate(0, -2, 1), 0)\n    lu.assertEquals(candidate(0, -1, 1), 0)\n    lu.assertEquals(candidate(1, 1, 1), 1)\n    lu.assertEquals(candidate(2, 1, 3), 2)\n    lu.assertEquals(candidate(-100, 0, 100), 0)\n    lu.assertEquals(candidate(5, 1, 5), 5)\n    lu.assertEquals(candidate(0, -1, 5), 0)\n    lu.assertEquals(candidate(3, 1, 3), 3)\n    lu.assertEquals(candidate(3, -1, 0), 0)\n    lu.assertEquals(candidate(3, -2, -1), -1)\n    lu.assertEquals(candidate(0, -100, 0), 0)\n    lu.assertEquals(candidate(-100, 1, 3), 2)\n    lu.assertEquals(candidate(10, 0, 100), 10)\n    lu.assertEquals(candidate(100, 1, 3), 2)\n    lu.assertEquals(candidate(360, -180, 180), 0)\n    lu.assertEquals(candidate(3, 10, 20), 13)\n    lu.assertEquals(candidate(-181, -180, 180), 179)\n    lu.assertEquals(candidate(15, 10, 20), 15)\n    lu.assertEquals(candidate(-3, 0, 1), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_417404_even", "language": "lua", "prompt": "--     Returns 1 if x is even, 0 otherwise.\nlocal function even(x)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_417404_even.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = even\n    lu.assertEquals(candidate(3), 0)\n    lu.assertEquals(candidate(0), 1)\n    lu.assertEquals(candidate(-1), 0)\n    lu.assertEquals(candidate(4), 1)\n    lu.assertEquals(candidate(1), 0)\n    lu.assertEquals(candidate(2), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_417916_tokenize_grapheme_langid", "language": "lua", "prompt": "--     tokenizer the langid  of word (For multilingual GBERT)\nlocal function tokenize_grapheme_langid(enhanced_word)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_417916_tokenize_grapheme_langid.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = tokenize_grapheme_langid\n    lu.assertEquals(candidate('hello}'), {'hello}'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_418429_normpath", "language": "lua", "prompt": "-- Normalize path, eliminating double slashes, etc.\nlocal function normpath(path)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_418429_normpath.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = normpath\n    lu.assertEquals(candidate('foo/bar/..'), 'foo')\n    lu.assertEquals(candidate('/foo/bar/..'), '/foo')\n    lu.assertEquals(candidate('/foo/bar/../../'), '/')\n    lu.assertEquals(candidate('/../foo/bar/../../'), '/')\n    lu.assertEquals(candidate('/a/b/c/../..'), '/a')\n    lu.assertEquals(candidate('/a/b/c'), '/a/b/c')\n    lu.assertEquals(candidate('/a/b/../c'), '/a/c')\n    lu.assertEquals(candidate('\\\\foo\\\\bar'), '\\\\foo\\\\bar')\n    lu.assertEquals(candidate('/a/b//c'), '/a/b/c')\n    lu.assertEquals(candidate('foo'), 'foo')\n    lu.assertEquals(candidate('/'), '/')\n    lu.assertEquals(candidate('/../../../../a'), '/a')\n    lu.assertEquals(candidate('/a/b/c/../../..'), '/')\n    lu.assertEquals(candidate('/foo/bar/../..'), '/')\n    lu.assertEquals(candidate(''), '.')\n    lu.assertEquals(candidate('/a/b/c/../../../..'), '/')\n    lu.assertEquals(candidate('/a/b/c/../../../../..'), '/')\n    lu.assertEquals(candidate('/foo'), '/foo')\n    lu.assertEquals(candidate('/a/../b/c'), '/b/c')\n    lu.assertEquals(candidate('/a/./b/c'), '/a/b/c')\n    lu.assertEquals(candidate('/a/b/c/../../../../../..'), '/')\n    lu.assertEquals(candidate('/a/b/c/'), '/a/b/c')\n    lu.assertEquals(candidate('foo/bar'), 'foo/bar')\n    lu.assertEquals(candidate('a/b/c'), 'a/b/c')\n    lu.assertEquals(candidate('/../../../a'), '/a')\n    lu.assertEquals(candidate('a/b//c'), 'a/b/c')\n    lu.assertEquals(candidate('foo\\\\bar'), 'foo\\\\bar')\n    lu.assertEquals(candidate('/foo/bar'), '/foo/bar')\n    lu.assertEquals(candidate('/a/b/./c'), '/a/b/c')\n    lu.assertEquals(candidate('/../../a'), '/a')\n    lu.assertEquals(candidate('a/b/./c'), 'a/b/c')\n    lu.assertEquals(candidate('/../a'), '/a')\n    lu.assertEquals(candidate('/a/b/c/..'), '/a/b')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_418893_factorial_pythonic", "language": "lua", "prompt": "-- Factorial with reduce function (pythonic approach).\n-- Examples:\n--     >>> assert factorial_pythonic(0) == 1\n--     >>> assert factorial_pythonic(1) == 1\n--     >>> assert factorial_pythonic(2) == 2\n--     >>> assert factorial_pythonic(3) == 6\nlocal function factorial_pythonic(number)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_418893_factorial_pythonic.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = factorial_pythonic\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(3), 6)\n    lu.assertEquals(candidate(0), 1)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(10), 3628800)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_419117_filter_matching_fields", "language": "lua", "prompt": "-- return fields which are same as in other_fields list, ignoring the case\nlocal function filter_matching_fields(fields, other_fields)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_419117_filter_matching_fields.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = filter_matching_fields\n    lu.assertEquals(candidate({}, {'FOO', 'BAR'}), {})\n    lu.assertEquals(candidate({}, {}), {})\n    lu.assertEquals(candidate({'foo', 'bar', 'baz'}, {}), {})\n    lu.assertEquals(candidate({'aaa', 'bbb', 'ccc'}, {'aaa', 'bbb', 'ccc'}), {'aaa', 'bbb', 'ccc'})\n    lu.assertEquals(candidate({'foo', 'bar', 'baz'}, {'foo', 'baz'}), {'foo', 'baz'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_420357_fixIncorrectDateEncoding", "language": "lua", "prompt": "--     Fix date string to make it conform to ISO standard.\nlocal function fixIncorrectDateEncoding(Date)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_420357_fixIncorrectDateEncoding.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fixIncorrectDateEncoding\n    lu.assertEquals(candidate('2020-12-20'), '2020-12-20T00:00:00Z')\n    lu.assertEquals(candidate('2020-12-20T00:00:00Z'), '2020-12-20T00:00:00Z')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_421139_ctz_naive", "language": "lua", "prompt": "--     counting zeros starting at the LSB until a 1-bit is encountered\nlocal function ctz_naive(x, w)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_421139_ctz_naive.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = ctz_naive\n    lu.assertEquals(candidate(9), 0)\n    lu.assertEquals(candidate(3, 8), 0)\n    lu.assertEquals(candidate(8), 3)\n    lu.assertEquals(candidate(1), 0)\n    lu.assertEquals(candidate(3), 0)\n    lu.assertEquals(candidate(5), 0)\n    lu.assertEquals(candidate(11, 8), 0)\n    lu.assertEquals(candidate(10), 1)\n    lu.assertEquals(candidate(6, 8), 1)\n    lu.assertEquals(candidate(13), 0)\n    lu.assertEquals(candidate(12), 2)\n    lu.assertEquals(candidate(15), 0)\n    lu.assertEquals(candidate(262143), 0)\n    lu.assertEquals(candidate(7, 8), 0)\n    lu.assertEquals(candidate(5, 8), 0)\n    lu.assertEquals(candidate(8), 3)\n    lu.assertEquals(candidate(3), 0)\n    lu.assertEquals(candidate(1, 8), 0)\n    lu.assertEquals(candidate(7), 0)\n    lu.assertEquals(candidate(10, 8), 1)\n    lu.assertEquals(candidate(6), 1)\n    lu.assertEquals(candidate(9, 8), 0)\n    lu.assertEquals(candidate(7), 0)\n    lu.assertEquals(candidate(262142), 1)\n    lu.assertEquals(candidate(18708), 2)\n    lu.assertEquals(candidate(2, 8), 1)\n    lu.assertEquals(candidate(4, 8), 2)\n    lu.assertEquals(candidate(16), 4)\n    lu.assertEquals(candidate(13), 0)\n    lu.assertEquals(candidate(11), 0)\n    lu.assertEquals(candidate(11), 0)\n    lu.assertEquals(candidate(2), 1)\n    lu.assertEquals(candidate(5), 0)\n    lu.assertEquals(candidate(0), 16)\n    lu.assertEquals(candidate(14), 1)\n    lu.assertEquals(candidate(4), 2)\n    lu.assertEquals(candidate(2), 1)\n    lu.assertEquals(candidate(15), 0)\n    lu.assertEquals(candidate(10), 1)\n    lu.assertEquals(candidate(4), 2)\n    lu.assertEquals(candidate(1), 0)\n    lu.assertEquals(candidate(8, 8), 3)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_421307_get_file_type", "language": "lua", "prompt": "--     Determine file type by extracting suffix of file_name\nlocal function get_file_type(file_name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_421307_get_file_type.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_file_type\n    lu.assertEquals(candidate('test.gro.nc'), 'netcdf')\n    lu.assertEquals(candidate('myfile.pdb'), 'pdb')\n    lu.assertEquals(candidate('test.itp'), 'itp')\n    lu.assertEquals(candidate('a/b/c.cms'), 'mae')\n    lu.assertEquals(candidate('a/b/c.gro'), 'gro')\n    lu.assertEquals(candidate('x/y/z/a/b/c.d'), 'd')\n    lu.assertEquals(candidate('something.txt'), 'txt')\n    lu.assertEquals(candidate('test.gro'), 'gro')\n    lu.assertEquals(candidate('a/b/c.nc'), 'netcdf')\n    lu.assertEquals(candidate('myfile.mae'), 'mae')\n    lu.assertEquals(candidate('test.nc'), 'netcdf')\n    lu.assertEquals(candidate('a/b/c.prmtop'), 'parm7')\n    lu.assertEquals(candidate('test.pdb'), 'pdb')\n    lu.assertEquals(candidate('test.cms'), 'mae')\n    lu.assertEquals(candidate('a/b/c.d'), 'd')\n    lu.assertEquals(candidate('something.netcdf'), 'netcdf')\n    lu.assertEquals(candidate(None), None)\n    lu.assertEquals(candidate('myfile.cms'), 'mae')\n    lu.assertEquals(candidate('a/b/c.pdbx'), 'pdbx')\n    lu.assertEquals(candidate('a/b/c.pdb'), 'pdb')\n    lu.assertEquals(candidate('something.pdb'), 'pdb')\n    lu.assertEquals(candidate('something.nc'), 'netcdf')\n    lu.assertEquals(candidate('something.pdbx'), 'pdbx')\n    lu.assertEquals(candidate('something.mae'), 'mae')\n    lu.assertEquals(candidate('test.prmtop'), 'parm7')\n    lu.assertEquals(candidate('something.prmtop'), 'parm7')\n    lu.assertEquals(candidate('something.sdf'), 'sdf')\n    lu.assertEquals(candidate('test.top'), 'top')\n    lu.assertEquals(candidate('something.cms'), 'mae')\n    lu.assertEquals(candidate('test.cif'), 'pdbx')\n    lu.assertEquals(candidate('a/b/c.cif'), 'pdbx')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_421350_extract", "language": "lua", "prompt": "-- Return a tuple (uin, nick) from 'O11111111\tnickname'\nlocal function extract(line)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_421350_extract.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = extract\n    lu.assertEquals(candidate('O22222222\\tNickname:with:colons'), {'22222222', 'Nickname_with_colons'})\n    lu.assertEquals(candidate('O11111111\\tn/ickn:ame'), {'11111111', 'n_ickn_ame'})\n    lu.assertEquals(candidate('O11111111\\tNickname'), {'11111111', 'Nickname'})\n    lu.assertEquals(candidate('O11111111\\tnickname'), {'11111111', 'nickname'})\n    lu.assertEquals(candidate('O44444444\\tNickname/with:mixed/slashes:and:colons'), {'44444444', 'Nickname_with_mixed_slashes_and_colons'})\n    lu.assertEquals(candidate('O12345678\\tmy_cool_nickname'), {'12345678', 'my_cool_nickname'})\n    lu.assertEquals(candidate('O12345678\\tmy/cool/nickname'), {'12345678', 'my_cool_nickname'})\n    lu.assertEquals(candidate('O12345678\\tmy:cool:nickname'), {'12345678', 'my_cool_nickname'})\n    lu.assertEquals(candidate('O33333333\\tNickname/with/slashes'), {'33333333', 'Nickname_with_slashes'})\n    lu.assertEquals(candidate('O12345678\\tnick:name'), {'12345678', 'nick_name'})\n    lu.assertEquals(candidate('O11111111\\tnickname'), {'11111111', 'nickname'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_42140_get_train_valid_test_split_", "language": "lua", "prompt": "-- Get dataset splits from comma or '/' separated string list.\nlocal function get_train_valid_test_split_(splits_string, size)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_42140_get_train_valid_test_split_.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_train_valid_test_split_\n    lu.assertEquals(candidate('0.6,0.2,0.2', 10), {0, 6, 8, 10})\n    lu.assertEquals(candidate('0.6/0.2/0.2', 10), {0, 6, 8, 10})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_421692_convert_target_counters", "language": "lua", "prompt": "-- This function converts the FxxxGxxx xml format to the final format. E.g: F29G034 -> 29034,\n-- F08G069 -> 8069.\nlocal function convert_target_counters(x)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_421692_convert_target_counters.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = convert_target_counters\n    lu.assertEquals(candidate('F08G069'), '8069')\n    lu.assertEquals(candidate('F08G069'), '8069')\n    lu.assertEquals(candidate('F29G034'), '29034')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_421969_sum_scores", "language": "lua", "prompt": "-- Sums all the scores\nlocal function sum_scores(scores, query)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_421969_sum_scores.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sum_scores\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2}, 'a b'), 3)\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3}, 'a b c'), 6)\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2}, 'a b'), 3)\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3}, 'c a b'), 6)\n    lu.assertEquals(candidate({}, 'a'), 0)\n    lu.assertEquals(candidate({['a'] = 1}, 'a'), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_422550_solution", "language": "lua", "prompt": "-- Returns the first ten digits of the sum of the array elements.\n-- >>> import os\n-- >>> sum = 0\n-- >>> array = []\n-- >>> with open(os.path.dirname(__file__) + \"/num.txt\",\"r\") as f:\n-- ...     for line in f:\n-- ...         array.append(int(line))\n-- ...\n-- >>> solution(array)\n-- '5537376230'\nlocal function solution(array)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_422550_solution.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = solution\n    lu.assertEquals(candidate(list(range(1, 101))), '5050')\n    lu.assertEquals(candidate(list(range(1, 1001))), '500500')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_422804_charencode", "language": "lua", "prompt": "-- String.CharCode\nlocal function charencode(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_422804_charencode.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = charencode\n    lu.assertEquals(candidate('z'), '122')\n    lu.assertEquals(candidate('abcde'), '97,98,99,100,101')\n    lu.assertEquals(candidate('ABC'), '65,66,67')\n    lu.assertEquals(candidate('aA1'), '97,65,49')\n    lu.assertEquals(candidate('AaA1'), '65,97,65,49')\n    lu.assertEquals(candidate('AB'), '65,66')\n    lu.assertEquals(candidate('A1a'), '65,49,97')\n    lu.assertEquals(candidate('Aa1'), '65,97,49')\n    lu.assertEquals(candidate('Aa1A'), '65,97,49,65')\n    lu.assertEquals(candidate('abcdefghi'), '97,98,99,100,101,102,103,104,105')\n    lu.assertEquals(candidate('123'), '49,50,51')\n    lu.assertEquals(candidate('Hello'), '72,101,108,108,111')\n    lu.assertEquals(candidate('1a'), '49,97')\n    lu.assertEquals(candidate('Hello, World!'), '72,101,108,108,111,44,32,87,111,114,108,100,33')\n    lu.assertEquals(candidate('Aa'), '65,97')\n    lu.assertEquals(candidate('abc'), '97,98,99')\n    lu.assertEquals(candidate('1aA'), '49,97,65')\n    lu.assertEquals(candidate('abcdef'), '97,98,99,100,101,102')\n    lu.assertEquals(candidate('abc123'), '97,98,99,49,50,51')\n    lu.assertEquals(candidate('a'), '97')\n    lu.assertEquals(candidate('Z'), '90')\n    lu.assertEquals(candidate('ab'), '97,98')\n    lu.assertEquals(candidate('a'), '97')\n    lu.assertEquals(candidate('A1Aa'), '65,49,65,97')\n    lu.assertEquals(candidate('1A1a'), '49,65,49,97')\n    lu.assertEquals(candidate('a1'), '97,49')\n    lu.assertEquals(candidate('A'), '65')\n    lu.assertEquals(candidate(' '), '32')\n    lu.assertEquals(candidate('abc,def,ghi'), '97,98,99,44,100,101,102,44,103,104,105')\n    lu.assertEquals(candidate('a,b,c'), '97,44,98,44,99')\n    lu.assertEquals(candidate('aA'), '97,65')\n    lu.assertEquals(candidate('A1aA'), '65,49,97,65')\n    lu.assertEquals(candidate('1AaA'), '49,65,97,65')\n    lu.assertEquals(candidate('1Aa'), '49,65,97')\n    lu.assertEquals(candidate('abcd'), '97,98,99,100')\n    lu.assertEquals(candidate('A'), '65')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_422870_calc_bits", "language": "lua", "prompt": "-- Generates the string of where the bits of that property in a register live \n-- Parameters\n-- ----------\n-- offset : int,  \n-- size : int, \n-- Returns \n-- ----------\n-- ret_str : str, the string\nlocal function calc_bits(offset, size)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_422870_calc_bits.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = calc_bits\n    lu.assertEquals(candidate(16, 2), '[17:16]')\n    lu.assertEquals(candidate(15, 1), '[15]')\n    lu.assertEquals(candidate(0, 16), '[15:0]')\n    lu.assertEquals(candidate(0, 32), '[31:0]')\n    lu.assertEquals(candidate(16, 1), '[16]')\n    lu.assertEquals(candidate(4, 4), '[7:4]')\n    lu.assertEquals(candidate(1, 1), '[1]')\n    lu.assertEquals(candidate(0, 2), '[1:0]')\n    lu.assertEquals(candidate(0, 1), '[0]')\n    lu.assertEquals(candidate(0, 4), '[3:0]')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_423409_pretty_print", "language": "lua", "prompt": "--     We just print so it looks decent in a terminal\nlocal function pretty_print(parsed_file)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_423409_pretty_print.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = pretty_print\n    lu.assertEquals(candidate({['origpath'] = 'foo/bar', ['artifact'] = 'foo/bar.baz', ['uncommented_content'] = 'foobarbaz\\nfoobarbaz\\n'}), 'foo/bar (foo/bar.baz):\\n    foobarbaz\\n    foobarbaz')\n    lu.assertEquals(candidate({['origpath'] = 'foo/bar', ['artifact'] = 'foo/bar.baz', ['uncommented_content'] = 'foobarbaz\\n'}), 'foo/bar (foo/bar.baz):\\n    foobarbaz')\n    lu.assertEquals(candidate({['origpath'] = 'foo/bar', ['artifact'] = 'foo/bar.baz', ['uncommented_content'] = 'foobarbaz'}), 'foo/bar (foo/bar.baz):\\n    foobarbaz')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_423580__jinja2_filter_datetime", "language": "lua", "prompt": "--  Extract an excert of a post\nlocal function _jinja2_filter_datetime(data)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_423580__jinja2_filter_datetime.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _jinja2_filter_datetime\n    lu.assertEquals(candidate(\"Hello World! I'm a Pythonista!\"), \"Hello World! I'm a Pythonista!\")\n    lu.assertEquals(candidate('2019-01-01 10:00:00'), '2019-01-01 10:00:00')\n    lu.assertEquals(candidate('A long time ago in a galaxy far, far away...'), 'A long time ago in a galaxy far, far away...')\n    lu.assertEquals(candidate('2019-06-13 10:00:00.1234567890123456789'), '2019-06-13 10:00:00.1234567890123456789')\n    lu.assertEquals(candidate('2019-06-13 10:00:00.123456'), '2019-06-13 10:00:00.123456')\n    lu.assertEquals(candidate('Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.'), 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.')\n    lu.assertEquals(candidate('Hello World!'), 'Hello World!')\n    lu.assertEquals(candidate('2019-06-13 10:00:00'), '2019-06-13 10:00:00')\n    lu.assertEquals(candidate(\"Hello World! I'm a Pythonista! I'm a Pythonista! I'm a Pythonista! I'm a Pythonista! I'm a Pythonista!\"), \"Hello World! I'm a Pythonista! I'm a Pythonista! I'm a Pythonista! I'm a Pythonista! I'm a Pythonista!\")\n    lu.assertEquals(candidate('There was a time...'), 'There was a time...')\n    lu.assertEquals(candidate('Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.'), 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.')\n    lu.assertEquals(candidate('2019-06-13 10:00'), '2019-06-13 10:00')\n    lu.assertEquals(candidate(\"Hello World! I'm a Pythonista! I'm a Pythonista!\"), \"Hello World! I'm a Pythonista! I'm a Pythonista!\")\n    lu.assertEquals(candidate('2012-09-22T16:00:00+02:00'), '2012-09-22T16:00:00+02:00')\n    lu.assertEquals(candidate('Once upon a time...'), 'Once upon a time...')\n    lu.assertEquals(candidate('2019-06-13 10:00:00.123456789'), '2019-06-13 10:00:00.123456789')\n    lu.assertEquals(candidate(''), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_423776_yearmonthplusoffset", "language": "lua", "prompt": "--  calculate new year/month from year/month and offset \nlocal function yearmonthplusoffset(year, month, offset)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_423776_yearmonthplusoffset.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = yearmonthplusoffset\n    lu.assertEquals(candidate(2019, 12, 0), {2019, 12})\n    lu.assertEquals(candidate(2018, 1, 3), {2018, 4})\n    lu.assertEquals(candidate(2017, 1, 1), {2017, 2})\n    lu.assertEquals(candidate(2000, 12, 1), {2001, 1})\n    lu.assertEquals(candidate(2000, 1, 13), {2001, 2})\n    lu.assertEquals(candidate(2018, 1, 13), {2019, 2})\n    lu.assertEquals(candidate(2018, 1, 4), {2018, 5})\n    lu.assertEquals(candidate(2017, 1, -1), {2016, 12})\n    lu.assertEquals(candidate(2000, 1, -13), {1998, 12})\n    lu.assertEquals(candidate(2018, 1, 9), {2018, 10})\n    lu.assertEquals(candidate(2018, 1, 11), {2018, 12})\n    lu.assertEquals(candidate(2019, 12, 13), {2021, 1})\n    lu.assertEquals(candidate(2000, 12, 0), {2000, 12})\n    lu.assertEquals(candidate(2000, 12, 12), {2001, 12})\n    lu.assertEquals(candidate(2000, 1, 10), {2000, 11})\n    lu.assertEquals(candidate(2018, 1, 5), {2018, 6})\n    lu.assertEquals(candidate(2017, 1, 11), {2017, 12})\n    lu.assertEquals(candidate(2017, 1, 12), {2018, 1})\n    lu.assertEquals(candidate(2017, 1, 0), {2017, 1})\n    lu.assertEquals(candidate(2017, 1, 13), {2018, 2})\n    lu.assertEquals(candidate(2018, 1, 1), {2018, 2})\n    lu.assertEquals(candidate(2018, 1, 2), {2018, 3})\n    lu.assertEquals(candidate(2018, 1, 6), {2018, 7})\n    lu.assertEquals(candidate(2018, 1, 0), {2018, 1})\n    lu.assertEquals(candidate(2019, 12, -11), {2019, 1})\n    lu.assertEquals(candidate(2000, 1, -12), {1999, 1})\n    lu.assertEquals(candidate(2017, 1, -11), {2016, 2})\n    lu.assertEquals(candidate(2018, 1, 10), {2018, 11})\n    lu.assertEquals(candidate(2000, 1, 1), {2000, 2})\n    lu.assertEquals(candidate(2000, 1, 12), {2001, 1})\n    lu.assertEquals(candidate(2018, 1, 12), {2019, 1})\n    lu.assertEquals(candidate(2019, 12, -1), {2019, 11})\n    lu.assertEquals(candidate(2018, 1, 8), {2018, 9})\n    lu.assertEquals(candidate(2000, 1, 0), {2000, 1})\n    lu.assertEquals(candidate(2019, 12, 1), {2020, 1})\n    lu.assertEquals(candidate(2000, 12, 13), {2002, 1})\n    lu.assertEquals(candidate(2018, 1, 7), {2018, 8})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_424985_sanitize", "language": "lua", "prompt": "--     Removes backticks (code tag) and linebreaks from a message.\nlocal function sanitize(message)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_424985_sanitize.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sanitize\n    lu.assertEquals(candidate('`hello`'), 'hello')\n    lu.assertEquals(candidate('No backticks'), 'No backticks')\n    lu.assertEquals(candidate('hello'), 'hello')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('`'), '')\n    lu.assertEquals(candidate('\\n'), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_425289_compreso", "language": "lua", "prompt": "--     checks whether or not a number is between low and high\nlocal function compreso(num, low, high)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_425289_compreso.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = compreso\n    lu.assertEquals(candidate(10, 1, 5), false)\n    lu.assertEquals(candidate(10, 3, 10), true)\n    lu.assertEquals(candidate(3, 3, 6), true)\n    lu.assertEquals(candidate(-5, -3, 1), false)\n    lu.assertEquals(candidate(10, 10, 5), false)\n    lu.assertEquals(candidate(3, 3, 5), true)\n    lu.assertEquals(candidate(5, 3, 10), true)\n    lu.assertEquals(candidate(1, 1, 3), true)\n    lu.assertEquals(candidate(3, -3, 6), true)\n    lu.assertEquals(candidate(3, 1, 5), true)\n    lu.assertEquals(candidate(10, 10, 10), true)\n    lu.assertEquals(candidate(10, 3, 6), false)\n    lu.assertEquals(candidate(-5, -3, 6), false)\n    lu.assertEquals(candidate(5, 10, 10), false)\n    lu.assertEquals(candidate(1, 3, 6), false)\n    lu.assertEquals(candidate(1, 1, 5), true)\n    lu.assertEquals(candidate(1, 2, 3), false)\n    lu.assertEquals(candidate(10, 3, 5), false)\n    lu.assertEquals(candidate(10, -3, 6), false)\n    lu.assertEquals(candidate(2, 1, 3), true)\n    lu.assertEquals(candidate(3, 1, 3), true)\n    lu.assertEquals(candidate(10, -3, 1), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_425575_milli_2_readadble", "language": "lua", "prompt": "-- Function:  milli_2_readadble\n-- Description:  Converts milliseconds into days, hours, minutes and seconds.\n--     Returns values with appropriate tags.\n-- Arguments:\n--     (input) msecs -> Milliseconds.\nlocal function milli_2_readadble(msecs)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_425575_milli_2_readadble.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = milli_2_readadble\n    lu.assertEquals(candidate(86400000), '1 days 0 hours 0 minutes 0 seconds')\n    lu.assertEquals(candidate(0), '0 days 0 hours 0 minutes 0 seconds')\n    lu.assertEquals(candidate(86400001), '1 days 0 hours 0 minutes 0 seconds')\n    lu.assertEquals(candidate(172800000), '2 days 0 hours 0 minutes 0 seconds')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_425947_exactly", "language": "lua", "prompt": "--  Match the previous pattern exactly `length` times.\n-- >>> import superexpressive as se\n-- >>> se.exactly(4)\n-- '{4}'\n-- >>> import superexpressive as se\n-- >>> se.DIGIT + se.exactly(6)\n-- '\\\\d{6}'\nlocal function exactly(length)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_425947_exactly.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = exactly\n    lu.assertEquals(candidate(8), '{8}')\n    lu.assertEquals(candidate(7), '{7}')\n    lu.assertEquals(candidate(3), '{3}')\n    lu.assertEquals(candidate(110), '{110}')\n    lu.assertEquals(candidate(6), '{6}')\n    lu.assertEquals(candidate(1), '{1}')\n    lu.assertEquals(candidate(42), '{42}')\n    lu.assertEquals(candidate(10), '{10}')\n    lu.assertEquals(candidate(4), '{4}')\n    lu.assertEquals(candidate(1000000), '{1000000}')\n    lu.assertEquals(candidate(6), '{6}')\n    lu.assertEquals(candidate(1000), '{1000}')\n    lu.assertEquals(candidate(10), '{10}')\n    lu.assertEquals(candidate(4), '{4}')\n    lu.assertEquals(candidate(100), '{100}')\n    lu.assertEquals(candidate(100000), '{100000}')\n    lu.assertEquals(candidate(5), '{5}')\n    lu.assertEquals(candidate(9), '{9}')\n    lu.assertEquals(candidate(2), '{2}')\n    lu.assertEquals(candidate(3), '{3}')\n    lu.assertEquals(candidate(51), '{51}')\n    lu.assertEquals(candidate(30), '{30}')\n    lu.assertEquals(candidate(10000), '{10000}')\n    lu.assertEquals(candidate(222), '{222}')\n    lu.assertEquals(candidate(333), '{333}')\n    lu.assertEquals(candidate(1), '{1}')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_426317_HSVtoRGB", "language": "lua", "prompt": "-- Convert HSV values to RGB\n-- Algorithm is taken from https://www.cs.rit.edu/~ncs/color/t_convert.html\nlocal function HSVtoRGB(h, s, v)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_426317_HSVtoRGB.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = HSVtoRGB\n    lu.assertEquals(candidate(0, 0, 0), {0, 0, 0})\n    lu.assertEquals(candidate(120, 0, 0), {0, 0, 0})\n    lu.assertEquals(candidate(0, 0, 1), {255, 255, 255})\n    lu.assertEquals(candidate(0, 0, 0), {0, 0, 0})\n    lu.assertEquals(candidate(300, 1, 1), {255, 0, 255})\n    lu.assertEquals(candidate(60, 1, 1), {255, 255, 0})\n    lu.assertEquals(candidate(0, 1, 1), {255, 0, 0})\n    lu.assertEquals(candidate(0, 0, 1), {255, 255, 255})\n    lu.assertEquals(candidate(240, 0, 0), {0, 0, 0})\n    lu.assertEquals(candidate(0, 1, 1), {255, 0, 0})\n    lu.assertEquals(candidate(300, 1, 1), {255, 0, 255})\n    lu.assertEquals(candidate(120, 1, 1), {0, 255, 0})\n    lu.assertEquals(candidate(60, 1, 1), {255, 255, 0})\n    lu.assertEquals(candidate(120, 1, 1), {0, 255, 0})\n    lu.assertEquals(candidate(240, 1, 1), {0, 0, 255})\n    lu.assertEquals(candidate(180, 1, 1), {0, 255, 255})\n    lu.assertEquals(candidate(240, 1, 1), {0, 0, 255})\n    lu.assertEquals(candidate(180, 1, 1), {0, 255, 255})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_426643_remove_keys", "language": "lua", "prompt": "-- Gracefully remove keys from dict.\nlocal function remove_keys(dict_, seq)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_426643_remove_keys.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_keys\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3, ['d'] = 4}, {'a', 'b'}), {['c'] = 3, ['d'] = 4})\n    lu.assertEquals(candidate(dict(), {}), dict())\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3, ['d'] = 4}, {'a', 'b', 'c', 'd'}), {})\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3, ['d'] = 4, ['e'] = 5, ['f'] = 6}, {'d', 'c', 'b', 'a', 'e', 'f'}), {})\n    lu.assertEquals(candidate(dict(), {'a', 'b'}), dict())\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3, ['d'] = 4}, {'a', 'e'}), {['b'] = 2, ['c'] = 3, ['d'] = 4})\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3, ['d'] = 4}, {'d', 'c'}), {['a'] = 1, ['b'] = 2})\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3, ['d'] = 4}, {}), {['a'] = 1, ['b'] = 2, ['c'] = 3, ['d'] = 4})\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3, ['d'] = 4}, {'a', 'b'}), {['c'] = 3, ['d'] = 4})\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3, ['d'] = 4, ['e'] = 5, ['f'] = 6}, {'a', 'b', 'c', 'd', 'e', 'f'}), {})\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3, ['d'] = 4}, {'a', 'b', 'c'}), {['d'] = 4})\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3, ['d'] = 4}, {}), {['a'] = 1, ['b'] = 2, ['c'] = 3, ['d'] = 4})\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3, ['d'] = 4}, {'a', 'b', 'c'}), {['d'] = 4})\n    lu.assertEquals(candidate(dict(), {'a'}), dict())\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_426793_natMult3and5", "language": "lua", "prompt": "-- Find the sum of all the multiples of 3 or 5 below 'limit'\nlocal function natMult3and5(limit)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_426793_natMult3and5.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = natMult3and5\n    lu.assertEquals(candidate(100), 2318)\n    lu.assertEquals(candidate(10), 23)\n    lu.assertEquals(candidate(10), 23)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(1000), 233168)\n    lu.assertEquals(candidate(20), 78)\n    lu.assertEquals(candidate(1000), 233168)\n    lu.assertEquals(candidate(1), 0)\n    lu.assertEquals(candidate(20), 78)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_426978_validate_slice_int", "language": "lua", "prompt": "-- Ensure that the given integer makes sense as a slice entry, and move to\n-- a normalized form.\n-- Parameters\n-- ----------\n-- the_int : int\n-- bound : int\n-- include : bool\n-- Returns\n-- -------\n-- int\nlocal function validate_slice_int(the_int, bound, include)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_426978_validate_slice_int.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = validate_slice_int\n    lu.assertEquals(candidate(-5, 10), 5)\n    lu.assertEquals(candidate(-5, 10, true), 5)\n    lu.assertEquals(candidate(9, 10), 9)\n    lu.assertEquals(candidate(0, 10), 0)\n    lu.assertEquals(candidate(0, 100), 0)\n    lu.assertEquals(candidate(1, 10, true), 1)\n    lu.assertEquals(candidate(99, 100), 99)\n    lu.assertEquals(candidate(1, 10), 1)\n    lu.assertEquals(candidate(-50, 100), 50)\n    lu.assertEquals(candidate(-1, 10, true), 9)\n    lu.assertEquals(candidate(-1, 10), 9)\n    lu.assertEquals(candidate(-10, 10), 0)\n    lu.assertEquals(candidate(-1, 100), 99)\n    lu.assertEquals(candidate(5, 10, true), 5)\n    lu.assertEquals(candidate(0, 10, true), 0)\n    lu.assertEquals(candidate(-10, 10, true), 0)\n    lu.assertEquals(candidate(9, 10, true), 9)\n    lu.assertEquals(candidate(50, 100), 50)\n    lu.assertEquals(candidate(10, 10, false), 10)\n    lu.assertEquals(candidate(2, 10), 2)\n    lu.assertEquals(candidate(-100, 100), 0)\n    lu.assertEquals(candidate(5, 10), 5)\n    lu.assertEquals(candidate(-3, 10), 7)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_427698__num_starting_hashes", "language": "lua", "prompt": "-- Return the number of hashes (#) at the beginning of the line.\nlocal function _num_starting_hashes(line)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_427698__num_starting_hashes.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _num_starting_hashes\n    lu.assertEquals(candidate('hello, world! #'), 0)\n    lu.assertEquals(candidate('# hello, world!'), 1)\n    lu.assertEquals(candidate('# hello, world! #'), 1)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate(None), 0)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('##### hello, world! ###'), 5)\n    lu.assertEquals(candidate('hello, world!'), 0)\n    lu.assertEquals(candidate('one'), 0)\n    lu.assertEquals(candidate('##### hello, world! #'), 5)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_428261_file_names", "language": "lua", "prompt": "-- Return the linkname and filename for dotfile based on user input.\nlocal function file_names(inp_fname)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_428261_file_names.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = file_names\n    lu.assertEquals(candidate('.inp_fname'), {'.inp_fname', 'dot.inp_fname.symlink'})\n    lu.assertEquals(candidate(), {'.a', 'dot.a.symlink'})\n    lu.assertEquals(candidate(), {'.a', 'dot.a.symlink'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_428422_greeting", "language": "lua", "prompt": "--     Build the greeting message\nlocal function greeting(name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_428422_greeting.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = greeting\n    lu.assertEquals(candidate('William'), 'Hello, William!')\n    lu.assertEquals(candidate('Alexander'), 'Hello, Alexander!')\n    lu.assertEquals(candidate('Eric'), 'Hello, Eric!')\n    lu.assertEquals(candidate('Anne'), 'Hello, Anne!')\n    lu.assertEquals(candidate('John'), 'Hello, John!')\n    lu.assertEquals(candidate('Robert'), 'Hello, Robert!')\n    lu.assertEquals(candidate('World'), 'Hello, World!')\n    lu.assertEquals(candidate('Sarah'), 'Hello, Sarah!')\n    lu.assertEquals(candidate('Ryan'), 'Hello, Ryan!')\n    lu.assertEquals(candidate('Michael'), 'Hello, Michael!')\n    lu.assertEquals(candidate('Christopher'), 'Hello, Christopher!')\n    lu.assertEquals(candidate('Bryan'), 'Hello, Bryan!')\n    lu.assertEquals(candidate('Luis'), 'Hello, Luis!')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_429755_select_supporting_facts", "language": "lua", "prompt": "-- select supporting facts according to the provided thresholds\n-- :param scored_sfs: a list of (sentence_id, score)\n-- :param min_thresholds: a list of minimum scores for top ranked supporting facts:\n--        [min_score_for_top_ranked, min_score_for_second_ranked, min_score_for_others]\n-- :return: a list of sentence ids predicted as supporting facts\nlocal function select_supporting_facts(scored_sfs, min_thresholds)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_429755_select_supporting_facts.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = select_supporting_facts\n    lu.assertEquals(candidate({{0, 0.4}, {1, 0.5}, {2, 0.6}}, {0.6, 0.6}), {2})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_431077_check_for_take", "language": "lua", "prompt": "-- Helper Function that checks to see if clapperboard elements\n-- follows set of rules to be identified as a \"take\" element\n-- Parameters\n-- ----------\n-- string: String\n--     (The string thay will be checked\n-- Returns\n-- -------\n-- Boolean\n--     True if object follows set of rules\n--     False if not.\nlocal function check_for_take(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_431077_check_for_take.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = check_for_take\n    lu.assertEquals(candidate('23'), true)\n    lu.assertEquals(candidate('25'), true)\n    lu.assertEquals(candidate('1234567'), false)\n    lu.assertEquals(candidate('1234'), false)\n    lu.assertEquals(candidate('18'), true)\n    lu.assertEquals(candidate('123'), false)\n    lu.assertEquals(candidate('foo'), false)\n    lu.assertEquals(candidate('27'), true)\n    lu.assertEquals(candidate('12345678'), false)\n    lu.assertEquals(candidate('12345'), false)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('21'), true)\n    lu.assertEquals(candidate('28'), true)\n    lu.assertEquals(candidate('172'), false)\n    lu.assertEquals(candidate('123456'), false)\n    lu.assertEquals(candidate('1234567890'), false)\n    lu.assertEquals(candidate('a'), false)\n    lu.assertEquals(candidate('24'), true)\n    lu.assertEquals(candidate('22'), true)\n    lu.assertEquals(candidate('29'), true)\n    lu.assertEquals(candidate('123456789'), false)\n    lu.assertEquals(candidate('15'), true)\n    lu.assertEquals(candidate('16'), true)\n    lu.assertEquals(candidate('20'), true)\n    lu.assertEquals(candidate('19'), true)\n    lu.assertEquals(candidate('17'), true)\n    lu.assertEquals(candidate('11'), true)\n    lu.assertEquals(candidate('30'), false)\n    lu.assertEquals(candidate('26'), true)\n    lu.assertEquals(candidate('100'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_431116_replace", "language": "lua", "prompt": "-- If pattern in the template replaces it with subst.\n-- Returns str object template with replaced patterns. \nlocal function replace(template, pattern, subst)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_431116_replace.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = replace\n    lu.assertEquals(candidate('The quick brown fox jumps over the lazy dog', 'The', 'The'), 'The quick brown fox jumps over the lazy dog')\n    lu.assertEquals(candidate('a test', 'test', 'result'), 'a result')\n    lu.assertEquals(candidate('The quick brown fox jumps over the lazy dog', 'fox', 'fox'), 'The quick brown fox jumps over the lazy dog')\n    lu.assertEquals(candidate('The quick brown fox jumps over the lazy dog', 'lazy', 'fox'), 'The quick brown fox jumps over the fox dog')\n    lu.assertEquals(candidate(candidate('X', 'Y', 'Z'), 'Y', 'X'), 'X')\n    lu.assertEquals(candidate('The quick brown fox jumps over the lazy dog', 'dog', 'cat'), 'The quick brown fox jumps over the lazy cat')\n    lu.assertEquals(candidate('The quick brown fox jumps over the lazy dog', 'dog', 'fox'), 'The quick brown fox jumps over the lazy fox')\n    lu.assertEquals(candidate('The quick brown fox jumps over the lazy dog', 'fox', 'cat'), 'The quick brown cat jumps over the lazy dog')\n    lu.assertEquals(candidate(candidate('X', 'Y', 'Z'), 'Y', 'Z'), 'X')\n    lu.assertEquals(candidate('The quick brown fox jumps over the lazy dog', 'The', 'a'), 'a quick brown fox jumps over the lazy dog')\n    lu.assertEquals(candidate('The quick brown fox jumps over the lazy dog', 'The', 'lazy'), 'lazy quick brown fox jumps over the lazy dog')\n    lu.assertEquals(candidate(candidate('X', 'X', 'X'), 'X', 'Z'), 'Z')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_432490_splitStringIntoChunks", "language": "lua", "prompt": "--     Split string into chunks of defined size\nlocal function splitStringIntoChunks(string, length)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_432490_splitStringIntoChunks.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = splitStringIntoChunks\n    lu.assertEquals(candidate('abcdefghijklmn', 3), {'abc', 'def', 'ghi', 'jkl', 'mn'})\n    lu.assertEquals(candidate('abcdef'), {'abcdef'})\n    lu.assertEquals(candidate('abcdefghij'), {'abcdefghij'})\n    lu.assertEquals(candidate('abcdefg', 3), {'abc', 'def', 'g'})\n    lu.assertEquals(candidate('This is a test', 14), {'This is a test'})\n    lu.assertEquals(candidate('abcdefghij', 5), {'abcde', 'fghij'})\n    lu.assertEquals(candidate('ab', 1), {'a', 'b'})\n    lu.assertEquals(candidate('hello world!'), {'hello world!'})\n    lu.assertEquals(candidate('a', 1), {'a'})\n    lu.assertEquals(candidate('This is a test'), {'This is a test'})\n    lu.assertEquals(candidate('', 1), {''})\n    lu.assertEquals(candidate('abcdef', 2), {'ab', 'cd', 'ef'})\n    lu.assertEquals(candidate('abcdef', 3), {'abc', 'def'})\n    lu.assertEquals(candidate('a', 2), {'a'})\n    lu.assertEquals(candidate('abc'), {'abc'})\n    lu.assertEquals(candidate('ab', 2), {'ab'})\n    lu.assertEquals(candidate('abcdef', 2), {'ab', 'cd', 'ef'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_432816_get_base_out_of_iri", "language": "lua", "prompt": "-- Give an iri, returns an the ontology base name\n-- Args:\n--     iri\n-- Returns:\n--     str\nlocal function get_base_out_of_iri(iri)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_432816_get_base_out_of_iri.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_base_out_of_iri\n    lu.assertEquals(candidate('http://example.com#'), 'http://example.com')\n    lu.assertEquals(candidate('http://example.com/ontology#'), 'http://example.com/ontology')\n    lu.assertEquals(candidate('http://webprotege.stanford.edu/RDwpQ8vbi7HaApq8VoqJUXH#'), 'http://webprotege.stanford.edu/RDwpQ8vbi7HaApq8VoqJUXH')\n    lu.assertEquals(candidate('http://webprotege.stanford.edu/RDwpQ8vbi7HaApq8VoqJUXH#Human'), 'http://webprotege.stanford.edu/RDwpQ8vbi7HaApq8VoqJUXH')\n    lu.assertEquals(candidate('http://example.com/ontology/term'), 'http://example.com/ontology')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_433197_binaryalert_yara_match", "language": "lua", "prompt": "-- author:       Austin Byers (Airbnb CSIRT)\n-- description:  BinaryAlert found a binary matching a YARA rule\n-- reference:    https://binaryalert.io\nlocal function binaryalert_yara_match(rec)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_433197_binaryalert_yara_match.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = binaryalert_yara_match\n    lu.assertEquals(candidate({['NumMatchedRules'] = 1}), true)\n    lu.assertEquals(candidate({['NumMatchedRules'] = 0}), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_433253__fk", "language": "lua", "prompt": "-- Construct a dict key for a feature instance\nlocal function _fk(feature_name, channel, target)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_433253__fk.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _fk\n    lu.assertEquals(candidate('A', 'c1', 't1'), 'A::c1::t1')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_433350_addslashes", "language": "lua", "prompt": "-- Adds slashes before quotes. Useful for escaping strings in CSV, for\n-- example. Less useful for escaping JavaScript; use the ``escapejs``\n-- filter instead.\nlocal function addslashes(value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_433350_addslashes.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = addslashes\n    lu.assertEquals(candidate('and \" quotes'), 'and \\\\\" quotes')\n    lu.assertEquals(candidate('\"123'), '\\\\\"123')\n    lu.assertEquals(candidate(\"foo 'bar'\"), \"foo \\\\'bar\\\\'\")\n    lu.assertEquals(candidate('a\"b'), 'a\\\\\"b')\n    lu.assertEquals(candidate('\\\\\\\\'), '\\\\\\\\\\\\\\\\')\n    lu.assertEquals(candidate('\\\\r\\\\n'), '\\\\\\\\r\\\\\\\\n')\n    lu.assertEquals(candidate('slash /'), 'slash /')\n    lu.assertEquals(candidate('1\\\\2\\\\3'), '1\\\\\\\\2\\\\\\\\3')\n    lu.assertEquals(candidate('\\\\'), '\\\\\\\\')\n    lu.assertEquals(candidate(\"'\"), \"\\\\'\")\n    lu.assertEquals(candidate('\"foo\"'), '\\\\\"foo\\\\\"')\n    lu.assertEquals(candidate('This is a \"test\"'), 'This is a \\\\\"test\\\\\"')\n    lu.assertEquals(candidate('\\\\\\\\'), '\\\\\\\\\\\\\\\\')\n    lu.assertEquals(candidate('\"'), '\\\\\"')\n    lu.assertEquals(candidate('foo\\\\tbar\\\\n\\\\baz\\\\n'), 'foo\\\\\\\\tbar\\\\\\\\n\\\\\\\\baz\\\\\\\\n')\n    lu.assertEquals(candidate('123\"'), '123\\\\\"')\n    lu.assertEquals(candidate('foo \"bar\"'), 'foo \\\\\"bar\\\\\"')\n    lu.assertEquals(candidate('this is a \\\\ test'), 'this is a \\\\\\\\ test')\n    lu.assertEquals(candidate('test\\\\ntest'), 'test\\\\\\\\ntest')\n    lu.assertEquals(candidate('abc\"def'), 'abc\\\\\"def')\n    lu.assertEquals(candidate('This is a \"\"test\"\"'), 'This is a \\\\\"\\\\\"test\\\\\"\\\\\"')\n    lu.assertEquals(candidate('this is a \"test\"'), 'this is a \\\\\"test\\\\\"')\n    lu.assertEquals(candidate('\\\\\"'), '\\\\\\\\\\\\\"')\n    lu.assertEquals(candidate('123'), '123')\n    lu.assertEquals(candidate('this is a test'), 'this is a test')\n    lu.assertEquals(candidate(\"I'm a fan of yours, Johnny.\"), \"I\\\\'m a fan of yours, Johnny.\")\n    lu.assertEquals(candidate('this is \"a test\"'), 'this is \\\\\"a test\\\\\"')\n    lu.assertEquals(candidate('\\\\\\'\"'), '\\\\\\\\\\\\\\'\\\\\"')\n    lu.assertEquals(candidate(\"this is 'a test'\"), \"this is \\\\'a test\\\\'\")\n    lu.assertEquals(candidate('\\\\t'), '\\\\\\\\t')\n    lu.assertEquals(candidate(\"'foo'\"), \"\\\\'foo\\\\'\")\n    lu.assertEquals(candidate(\"\\\\'\"), \"\\\\\\\\\\\\'\")\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_433455_this_exist_not_null", "language": "lua", "prompt": "-- Check if parameter exists or not\nlocal function this_exist_not_null(param)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_433455_this_exist_not_null.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = this_exist_not_null\n    lu.assertEquals(candidate('not empty'), true)\n    lu.assertEquals(candidate(None), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_433810_megagcd", "language": "lua", "prompt": "-- needs in diophantic function\nlocal function megagcd(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_433810_megagcd.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = megagcd\n    lu.assertEquals(candidate(1, 1), {1, 0, 1})\n    lu.assertEquals(candidate(1234567890123456789, 1234567890123456789), {1234567890123456789, 0, 1})\n    lu.assertEquals(candidate(2, 1), {1, 0, 1})\n    lu.assertEquals(candidate(2, 4), {2, 1, 0})\n    lu.assertEquals(candidate(40, 120), {40, 1, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_433930_build_select", "language": "lua", "prompt": "-- Build a select request.\n-- Parameters\n-- ----------\n-- table : str\n--     Table where query will be directed.\n-- to_set: iterable\n--     The list of columns to select.\n-- where: iterable\n--     The list of conditions to constrain the query.\n-- Returns\n-- -------\n-- str\n--     Built query string.\nlocal function build_select(table, to_select, where)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_433930_build_select.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = build_select\n    lu.assertEquals(candidate('person', {'first_name', 'last_name'}), 'SELECT first_name, last_name FROM \"person\"')\n    lu.assertEquals(candidate('User', {'User.id', 'User.name'}), 'SELECT User.id, User.name FROM \"User\"')\n    lu.assertEquals(candidate('artists', {'name'}, {'genre', 'name'}), 'SELECT name FROM \"artists\" WHERE genre = :genre AND name = :name')\n    lu.assertEquals(candidate('person', {'first_name', 'last_name'}, {'first_name', 'last_name'}), 'SELECT first_name, last_name FROM \"person\" WHERE first_name = :first_name AND last_name = :last_name')\n    lu.assertEquals(candidate('artists', {'name'}, None), 'SELECT name FROM \"artists\"')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_434357_sample_width_to_string", "language": "lua", "prompt": "-- Convert sample width (bytes) to ALSA format string.\nlocal function sample_width_to_string(sample_width)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_434357_sample_width_to_string.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sample_width_to_string\n    lu.assertEquals(candidate(2), 's16')\n    lu.assertEquals(candidate(1), 's8')\n    lu.assertEquals(candidate(4), 's32')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_434952_register_dictionary", "language": "lua", "prompt": "-- creates the dictionary that can be used for registration\nlocal function register_dictionary(nickname, email, password, repeat_password)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_434952_register_dictionary.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = register_dictionary\n    lu.assertEquals(candidate('a', 'b', 'c', 'd'), {['nickname'] = 'a', ['email'] = 'b', ['password'] = 'c', ['repeat_password'] = 'd'})\n    lu.assertEquals(candidate('A', '<EMAIL>', 'password', 'password'), {['nickname'] = 'A', ['email'] = '<EMAIL>', ['password'] = 'password', ['repeat_password'] = 'password'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_435735_get_wsgi_header", "language": "lua", "prompt": "-- Returns a WSGI compliant HTTP header.\n-- See https://www.python.org/dev/peps/pep-3333/#environ-variables for\n-- information from the spec.\nlocal function get_wsgi_header(header)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_435735_get_wsgi_header.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_wsgi_header\n    lu.assertEquals(candidate('accept-charset'), 'HTTP_ACCEPT_CHARSET')\n    lu.assertEquals(candidate('dnt'), 'HTTP_DNT')\n    lu.assertEquals(candidate('content-type'), 'HTTP_CONTENT_TYPE')\n    lu.assertEquals(candidate('CoNtEnT-tyPe'), 'HTTP_CONTENT_TYPE')\n    lu.assertEquals(candidate('content-type'), 'HTTP_CONTENT_TYPE')\n    lu.assertEquals(candidate('content-md5'), 'HTTP_CONTENT_MD5')\n    lu.assertEquals(candidate('expect'), 'HTTP_EXPECT')\n    lu.assertEquals(candidate('user-agent'), 'HTTP_USER_AGENT')\n    lu.assertEquals(candidate('authorization'), 'HTTP_AUTHORIZATION')\n    lu.assertEquals(candidate('Host'), 'HTTP_HOST')\n    lu.assertEquals(candidate('if-none-match'), 'HTTP_IF_NONE_MATCH')\n    lu.assertEquals(candidate('content-TYPE'), 'HTTP_CONTENT_TYPE')\n    lu.assertEquals(candidate('content-length'), 'HTTP_CONTENT_LENGTH')\n    lu.assertEquals(candidate('CONTENT-type'), 'HTTP_CONTENT_TYPE')\n    lu.assertEquals(candidate('X-Some-Header-Here'), 'HTTP_X_SOME_HEADER_HERE')\n    lu.assertEquals(candidate('content-type'), candidate('CONTENT-TYPE'))\n    lu.assertEquals(candidate('X-Some-Header'), 'HTTP_X_SOME_HEADER')\n    lu.assertEquals(candidate('cookie'), 'HTTP_COOKIE')\n    lu.assertEquals(candidate('Content-TYPE'), 'HTTP_CONTENT_TYPE')\n    lu.assertEquals(candidate('x-forwarded-proto'), 'HTTP_X_FORWARDED_PROTO')\n    lu.assertEquals(candidate('upgrade-insecure-requests'), 'HTTP_UPGRADE_INSECURE_REQUESTS')\n    lu.assertEquals(candidate('accept-encoding'), 'HTTP_ACCEPT_ENCODING')\n    lu.assertEquals(candidate('accept-language'), 'HTTP_ACCEPT_LANGUAGE')\n    lu.assertEquals(candidate('host'), 'HTTP_HOST')\n    lu.assertEquals(candidate('connection'), 'HTTP_CONNECTION')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_436371__tbl_str_width", "language": "lua", "prompt": "-- Returns the width-argument for an html table cell using the width from\n-- the list of widths.\n-- Returns width=\"[some number]\" or the empty-string if no width is\n-- specified for this num\nlocal function _tbl_str_width(num, widths)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_436371__tbl_str_width.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _tbl_str_width\n    lu.assertEquals(candidate(3, {20, 30}), '')\n    lu.assertEquals(candidate(0, {10, 20}), ' width=\"10\"')\n    lu.assertEquals(candidate(0, {}), '')\n    lu.assertEquals(candidate(2, {}), '')\n    lu.assertEquals(candidate(3, {20, 30, 40}), '')\n    lu.assertEquals(candidate(0, {}), '')\n    lu.assertEquals(candidate(1000, {}), '')\n    lu.assertEquals(candidate(4, {1, 2, 3}), '')\n    lu.assertEquals(candidate(2, {10, 20}), '')\n    lu.assertEquals(candidate(3, {20}), '')\n    lu.assertEquals(candidate(2, {10}), '')\n    lu.assertEquals(candidate(0, {10}), ' width=\"10\"')\n    lu.assertEquals(candidate(1, {10, 20}), ' width=\"20\"')\n    lu.assertEquals(candidate(1, {}), '')\n    lu.assertEquals(candidate(1, {10}), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_436426_parse_slots", "language": "lua", "prompt": "-- Parse the list of slots.\n-- Cleans up spaces between items.\n-- Parameters\n-- ----------\n-- content: :class:`str`\n--     A string containing comma separated values.\n-- Returns\n-- -------\n-- :class:`str`:\n--     The slots string.\nlocal function parse_slots(content)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_436426_parse_slots.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_slots\n    lu.assertEquals(candidate('Slot1,Slot2,Slot3,Slot4,Slot5,Slot6,Slot7,Slot8'), 'Slot1,Slot2,Slot3,Slot4,Slot5,Slot6,Slot7,Slot8')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('Slot1,Slot2'), 'Slot1,Slot2')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_436791___equivalent_lists", "language": "lua", "prompt": "-- Return True if list1 and list2 contain the same items.\nlocal function __equivalent_lists(list1, list2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_436791___equivalent_lists.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = __equivalent_lists\n    lu.assertEquals(candidate(list({1, 2, 3, 4}), list({2, 4, 3, 1})), true)\n    lu.assertEquals(candidate(list({1, 2, 3, 4}), list({4, 3, 2, 1})), true)\n    lu.assertEquals(candidate(list({1}), list()), false)\n    lu.assertEquals(candidate(list({1, 2, 3}), list({1, 3, 4})), false)\n    lu.assertEquals(candidate(list({1, 2}), list({2, 1})), true)\n    lu.assertEquals(candidate(list({1, 2, 3, 4}), list({2, 4, 1, 3})), true)\n    lu.assertEquals(candidate(list({1, 2, 3, 4}), list({4, 3, 1, 2})), true)\n    lu.assertEquals(candidate(list({1, 2, 3}), list({2, 1, 3})), true)\n    lu.assertEquals(candidate(list({1}), list({1})), true)\n    lu.assertEquals(candidate(list({1, 2}), list({1, 3})), false)\n    lu.assertEquals(candidate(list({1, 2, 3}), list({3, 1, 2})), true)\n    lu.assertEquals(candidate(list(), list()), true)\n    lu.assertEquals(candidate(list({1, 2, 3, 4}), list({3, 4, 1, 2})), true)\n    lu.assertEquals(candidate(list({1, 2, 3}), list({1, 3, 2})), true)\n    lu.assertEquals(candidate(list({1, 2, 3, 4}), list({3, 4, 2, 1})), true)\n    lu.assertEquals(candidate(list({1}), list({2})), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_43689_detect_graphql", "language": "lua", "prompt": "local function detect_graphql(payload)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_43689_detect_graphql.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = detect_graphql\n    lu.assertEquals(candidate('this is some text'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_437285_valid", "language": "lua", "prompt": "-- Check if the coordinates are in bounds.\n-- :param x:\n-- :param y:\n-- :param n:\n-- :param m:\n-- :return:\nlocal function valid(x, y, n, m)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_437285_valid.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = valid\n    lu.assertEquals(candidate(0, 0, 3, 2), true)\n    lu.assertEquals(candidate(1, 3, 3, 3), false)\n    lu.assertEquals(candidate(2, 3, 3, 3), false)\n    lu.assertEquals(candidate(2, 2, 3, 3), true)\n    lu.assertEquals(candidate(0, 3, 3, 3), false)\n    lu.assertEquals(candidate(-1, 1, 3, 3), false)\n    lu.assertEquals(candidate(0, -1, 3, 3), false)\n    lu.assertEquals(candidate(-1, -1, 3, 2), false)\n    lu.assertEquals(candidate(3, 0, 3, 2), false)\n    lu.assertEquals(candidate(4, 4, 3, 3), false)\n    lu.assertEquals(candidate(2, 0, 3, 2), true)\n    lu.assertEquals(candidate(2, 1, 3, 3), true)\n    lu.assertEquals(candidate(2, 1, 3, 2), true)\n    lu.assertEquals(candidate(-1, 0, 3, 3), false)\n    lu.assertEquals(candidate(3, 1, 3, 3), false)\n    lu.assertEquals(candidate(3, 0, 3, 3), false)\n    lu.assertEquals(candidate(1, 1, 3, 3), true)\n    lu.assertEquals(candidate(3, 1, 3, 2), false)\n    lu.assertEquals(candidate(4, 3, 3, 2), false)\n    lu.assertEquals(candidate(1, 1, 3, 2), true)\n    lu.assertEquals(candidate(1, -1, 3, 3), false)\n    lu.assertEquals(candidate(0, 0, 3, 3), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_437295_get_max_key", "language": "lua", "prompt": "-- Return the key from the dict with the max value.\nlocal function get_max_key(d)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_437295_get_max_key.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_max_key\n    lu.assertEquals(candidate({['b'] = 2}), 'b')\n    lu.assertEquals(candidate({['a'] = 1}), 'a')\n    lu.assertEquals(candidate({['c'] = 3}), 'c')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_43748__is_summary", "language": "lua", "prompt": "-- Checks if the line is the summary line 'Found X errors in Y files (checked Z source files)'\nlocal function _is_summary(l)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_43748__is_summary.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _is_summary\n    lu.assertEquals(candidate('Found 3 errors in 2 files (checked 11 source files)\\nother line'), false)\n    lu.assertEquals(candidate('Found 3 errors in 2 files (checked 11 source files)\\n\\n'), false)\n    lu.assertEquals(candidate('Found 0 errors in 0 files (checked 24 source files)\\n'), true)\n    lu.assertEquals(candidate('Found 0 errors in 1 files (checked 5 source files)\\n'), true)\n    lu.assertEquals(candidate('Found 3 errors in 2 files (checked 11 source files)\\n'), true)\n    lu.assertEquals(candidate('Found 1 errors in 1 files (checked 1 source files)\\n'), true)\n    lu.assertEquals(candidate('Found 10 errors in 100 files (checked 1000 source files)\\n'), true)\n    lu.assertEquals(candidate('Found 1 error in 1 files (checked 10 source files)\\n'), true)\n    lu.assertEquals(candidate('Found 3 errors in 2 files (checked 11 source files\\n'), false)\n    lu.assertEquals(candidate('Found 1 errors in 1 files (checked 1 source files) \\n'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_437626_progessbar", "language": "lua", "prompt": "-- Builds progressbar\n-- Args:\n--     new: current progress\n--     tot: total length of the download\n-- Returns:\n--     progressbar as a string of length 20\nlocal function progessbar(new, tot)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_437626_progessbar.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = progessbar\n    lu.assertEquals(candidate(100, 100), '[====================] 100.0 %\\r')\n    lu.assertEquals(candidate(0, 100), '[--------------------] 0.0 %\\r')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_437635_get_str_bytes_length", "language": "lua", "prompt": "--     - source: https://stackoverflow.com/a/30686735/8445442\nlocal function get_str_bytes_length(value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_437635_get_str_bytes_length.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_str_bytes_length\n    lu.assertEquals(candidate('test'), 4)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('1234567890'), 10)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_437844_is_identity_matrix", "language": "lua", "prompt": "--     Returns True if the input matrix is an identity matrix, False otherwise.\nlocal function is_identity_matrix(L)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_437844_is_identity_matrix.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_identity_matrix\n    lu.assertEquals(candidate({{1, 0, 0, 0}, {0, 1, 0, 0}, {0, 0, 1, 0}, {0, 0, 0, 1}}), true)\n    lu.assertEquals(candidate({{1, 1, 1}, {0, 1, 0}, {0, 0, 1}}), false)\n    lu.assertEquals(candidate({{0, 1, 2, 3}, {4, 5, 6, 7}, {8, 9, 10, 11}, {12, 13, 14, 15}}), false)\n    lu.assertEquals(candidate({{1, 0, 0, 0}, {0, 1, 1, 0}, {0, 0, 1, 0}, {0, 0, 0, 1}}), false)\n    lu.assertEquals(candidate({{1, 0, 0, 0}, {0, 1, 0, 0}, {0, 0, 1, 0}, {0, 0, 0, 1}}), true)\n    lu.assertEquals(candidate({{1, 0, 0, 0}, {0, 1, 0, 0}, {0, 0, 0, 0}, {0, 0, 0, 1}}), false)\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}), false)\n    lu.assertEquals(candidate({{1, 0, 0, 0}, {0, 1, 0, 0}, {0, 0, 0, 1}, {0, 0, 1, 0}}), false)\n    lu.assertEquals(candidate({{1, 0, 0}, {0, 1, 0}, {0, 0, 1}}), true)\n    lu.assertEquals(candidate({{1, 0, 0, 0}, {0, 0, 0, 0}, {0, 0, 1, 0}, {0, 0, 0, 1}}), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_438500_pax_to_human_time", "language": "lua", "prompt": "-- Converts a pax time to a human-readable representation\nlocal function pax_to_human_time(num)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_438500_pax_to_human_time.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = pax_to_human_time\n    lu.assertEquals(candidate(1000000000000000000000), '1.000 T')\n    lu.assertEquals(candidate(1100000000), '1.100 s')\n    lu.assertEquals(candidate(1000000000000), '1.000 ks')\n    lu.assertEquals(candidate(999), '999.000 ns')\n    lu.assertEquals(candidate(1000), '1.000 us')\n    lu.assertEquals(candidate(999999), '999.999 us')\n    lu.assertEquals(candidate(10000), '10.000 us')\n    lu.assertEquals(candidate(123), '123.000 ns')\n    lu.assertEquals(candidate(1000000000), '1.000 s')\n    lu.assertEquals(candidate(100), '100.000 ns')\n    lu.assertEquals(candidate(12345), '12.345 us')\n    lu.assertEquals(candidate(1), '1.000 ns')\n    lu.assertEquals(candidate(12345), '12.345 us')\n    lu.assertEquals(candidate(10), '10.000 ns')\n    lu.assertEquals(candidate(1000000), '1.000 ms')\n    lu.assertEquals(candidate(1000000000000000000), '1.000 G')\n    lu.assertEquals(candidate(1000000000000000), '1.000 Ms')\n    lu.assertEquals(candidate(0), '0.000 ns')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_43932_area", "language": "lua", "prompt": "-- Area of a polygone\n-- :param p: list of the points taken in any orientation,\n--           p[0] can differ from p[-1]\n-- :returns: area\n-- :complexity: linear\nlocal function area(p)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_43932_area.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = area\n    lu.assertEquals(candidate({{0, 0}, {2, 0}, {0, 2}, {0, 0}}), 2)\n    lu.assertEquals(candidate({{0, 0}, {2, 0}, {2, 2}, {0, 2}}), 4)\n    lu.assertEquals(candidate({{0, 0}, {2, 0}, {2, 1}, {0, 1}}), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_439474_dms_to_dmm", "language": "lua", "prompt": "-- Converts degrees, minutes and decimal seconds to degrees and decimal minutes.\n-- Example: (41, 24, 12.2) -> (41, 24.2033)\n-- :param int d: degrees\n-- :param int m: minutes\n-- :param float s: decimal seconds\n-- :rtype: str\nlocal function dms_to_dmm(d, m, s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_439474_dms_to_dmm.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = dms_to_dmm\n    lu.assertEquals(candidate(-10, 0, 0), {-10, 0})\n    lu.assertEquals(candidate(41, 24, 0), {41, 24})\n    lu.assertEquals(candidate(10, 0, 0), {10, 0})\n    lu.assertEquals(candidate(0, 0, 0), {0, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_439518_fnSeconds_To_Hours", "language": "lua", "prompt": "-- Convert from seconds to hours, minutes and seconds.\n-- Date: 16 October 2016\n-- originally in AstroFunctions.py\nlocal function fnSeconds_To_Hours(time_period)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_439518_fnSeconds_To_Hours.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fnSeconds_To_Hours\n    lu.assertEquals(candidate(3600), {1, 0, 0})\n    lu.assertEquals(candidate(60), {0, 1, 0})\n    lu.assertEquals(candidate(0), {0, 0, 0})\n    lu.assertEquals(candidate(30), {0, 0, 30})\n    lu.assertEquals(candidate(90), {0, 1, 30})\n    lu.assertEquals(candidate(1), {0, 0, 1})\n    lu.assertEquals(candidate(0), {0, 0, 0})\n    lu.assertEquals(candidate(3600), {1, 0, 0})\n    lu.assertEquals(candidate(3723), {1, 2, 3})\n    lu.assertEquals(candidate(86400), {24, 0, 0})\n    lu.assertEquals(candidate(120), {0, 2, 0})\n    lu.assertEquals(candidate(1), {0, 0, 1})\n    lu.assertEquals(candidate(60), {0, 1, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_439784_containsDuplicate", "language": "lua", "prompt": "-- :type nums: List[int]\n-- :rtype: bool\nlocal function containsDuplicate(nums)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_439784_containsDuplicate.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = containsDuplicate\n    lu.assertEquals(candidate(list({1, 2, 3})), false)\n    lu.assertEquals(candidate({1, 2}), false)\n    lu.assertEquals(candidate({}), false)\n    lu.assertEquals(candidate(list({1, 2})), false)\n    lu.assertEquals(candidate(list()), false)\n    lu.assertEquals(candidate(list({1, 2, 3, 4})), false)\n    lu.assertEquals(candidate({1}), false)\n    lu.assertEquals(candidate({1, 2, 3}), false)\n    lu.assertEquals(candidate(list({1, 1, 1, 3, 3, 4, 3, 2, 4, 2})), true)\n    lu.assertEquals(candidate(list({1})), false)\n    lu.assertEquals(candidate({1, 2, 2}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_440003_map_range", "language": "lua", "prompt": "-- Map a value in one range to another.\nlocal function map_range(value, from_lower, from_upper, to_lower, to_upper)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_440003_map_range.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = map_range\n    lu.assertEquals(candidate(5, 1, 10, 10, 10), 10)\n    lu.assertEquals(candidate(5, 1, 10, 1, 1), 1)\n    lu.assertEquals(candidate(7, 1, 10, 1, 10), 7)\n    lu.assertEquals(candidate(10, 1, 10, 0, 1), 1)\n    lu.assertEquals(candidate(6, 0, 10, 100, 200), 160)\n    lu.assertEquals(candidate(5, 1, 10, 5, 5), 5)\n    lu.assertEquals(candidate(50, 0, 100, 0, 200), 100)\n    lu.assertEquals(candidate(0, 0, 10, 0, 100), 0)\n    lu.assertEquals(candidate(15, 0, 10, 100, 200), 200)\n    lu.assertEquals(candidate(7, 0, 10, 100, 200), 170)\n    lu.assertEquals(candidate(10, 0, 10, 100, 0), 0)\n    lu.assertEquals(candidate(5, 0, 10, 0, 100), 50)\n    lu.assertEquals(candidate(1, 1, 10, 1, 10), 1)\n    lu.assertEquals(candidate(13, 0, 10, 100, 200), 200)\n    lu.assertEquals(candidate(16, 0, 10, 100, 200), 200)\n    lu.assertEquals(candidate(10, 0, 10, 100, 200), 200)\n    lu.assertEquals(candidate(0, 0, 100, 0, 100), 0)\n    lu.assertEquals(candidate(11, 0, 10, 100, 200), 200)\n    lu.assertEquals(candidate(50, 0, 100, 0, 100), 50)\n    lu.assertEquals(candidate(10, 1, 10, 1, 10), 10)\n    lu.assertEquals(candidate(0, 1, 10, 1, 10), 1)\n    lu.assertEquals(candidate(10, 1, 10, 10, 20), 20)\n    lu.assertEquals(candidate(5, 0, 10, 100, 200), 150)\n    lu.assertEquals(candidate(6, 1, 10, 1, 10), 6)\n    lu.assertEquals(candidate(2, 10, 1, 100, 10), 10)\n    lu.assertEquals(candidate(12, 0, 10, 100, 200), 200)\n    lu.assertEquals(candidate(9, 1, 10, 1, 10), 9)\n    lu.assertEquals(candidate(-5, 0, 10, 0, 100), 0)\n    lu.assertEquals(candidate(100, 0, 100, 0, 100), 100)\n    lu.assertEquals(candidate(14, 0, 10, 100, 200), 200)\n    lu.assertEquals(candidate(0, 0, 100, -100, 100), -100)\n    lu.assertEquals(candidate(5, 1, 10, 1, 10), 5)\n    lu.assertEquals(candidate(10, 0, 10, 0, 100), 100)\n    lu.assertEquals(candidate(4, 1, 10, 1, 10), 4)\n    lu.assertEquals(candidate(10, 10, 1, 1, 100), 1)\n    lu.assertEquals(candidate(100, 0, 100, 0, 200), 200)\n    lu.assertEquals(candidate(10, 1, 10, 0, 100), 100)\n    lu.assertEquals(candidate(2, 1, 10, 1, 10), 2)\n    lu.assertEquals(candidate(0, 0, 100, 0, 200), 0)\n    lu.assertEquals(candidate(100, 0, 100, -200, -100), -100)\n    lu.assertEquals(candidate(4, 0, 10, 100, 200), 140)\n    lu.assertEquals(candidate(3, 1, 10, 1, 10), 3)\n    lu.assertEquals(candidate(9, 0, 10, 100, 200), 190)\n    lu.assertEquals(candidate(8, 1, 10, 1, 10), 8)\n    lu.assertEquals(candidate(50, 0, 100, 100, 200), 150)\n    lu.assertEquals(candidate(8, 0, 10, 100, 200), 180)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_44003_vmul", "language": "lua", "prompt": "-- Return element wise multiplication\nlocal function vmul(vec1, vec2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_44003_vmul.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = vmul\n    lu.assertEquals(candidate({1, -2, 3}, {1, 2, 3}), {1, -4, 9})\n    lu.assertEquals(candidate({1, 2, 3}, {1, 2, 3}), {1, 4, 9})\n    lu.assertEquals(candidate({1, 2, -3}, {1, 2, 3}), {1, 4, -9})\n    lu.assertEquals(candidate({1000, 2000, 3000}, {1, 2, 3}), {1000, 4000, 9000})\n    lu.assertEquals(candidate({-1, 2, 3}, {1, -2, 3}), {-1, -4, 9})\n    lu.assertEquals(candidate({1, 2, 3}, {10, 20, 30}), {10, 40, 90})\n    lu.assertEquals(candidate({2}, {2}), {4})\n    lu.assertEquals(candidate({3, 1, 5}, {1, 2, 0}), {3, 2, 0})\n    lu.assertEquals(candidate({-3, 0, 1}, {1, -1, 3}), {-3, 0, 3})\n    lu.assertEquals(candidate({1, 2, 3}, {1, 2, 3}), {1, 4, 9})\n    lu.assertEquals(candidate({1, 2, 3}, {-1, 2, -3}), {-1, 4, -9})\n    lu.assertEquals(candidate({1, 2, 3}, {100, 200, 300}), {100, 400, 900})\n    lu.assertEquals(candidate({1, 2, 3}, {1, 0, 3}), {1, 0, 9})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_440770_filter_python_file", "language": "lua", "prompt": "-- filter python files from simulation folder\nlocal function filter_python_file(files)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_440770_filter_python_file.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = filter_python_file\n    lu.assertEquals(candidate({'simulations/example.py', 'simulations/example_1.py', 'simulations/example_2.py'}), {'simulations/example.py', 'simulations/example_1.py', 'simulations/example_2.py'})\n    lu.assertEquals(candidate({'simulations/test_a.py', 'simulations/test_b.py', 'simulations/test_c.txt'}), {'simulations/test_a.py', 'simulations/test_b.py'})\n    lu.assertEquals(candidate({'simulations/file1.py', 'simulations/subdir/file2.py', 'file3.py', 'simulations/subdir/file4.pyc'}), {'simulations/file1.py', 'simulations/subdir/file2.py'})\n    lu.assertEquals(candidate({'simulations/file1.py', 'simulations/subdir/file2.py', 'file3.py'}), {'simulations/file1.py', 'simulations/subdir/file2.py'})\n    lu.assertEquals(candidate({'simulations/test_a.py', 'simulations/test_b.py'}), {'simulations/test_a.py', 'simulations/test_b.py'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_441120_get_method_color", "language": "lua", "prompt": "--     Return color given the method name.\nlocal function get_method_color(method)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_441120_get_method_color.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_method_color\n    lu.assertEquals(candidate('Random'), 'blue')\n    lu.assertEquals(candidate('SubSample'), 'rebeccapurple')\n    lu.assertEquals(candidate('BoostIn'), 'orange')\n    lu.assertEquals(candidate('Loss'), 'yellow')\n    lu.assertEquals(candidate('LOO'), 'red')\n    lu.assertEquals(candidate('TreeSim'), 'mediumseagreen')\n    lu.assertEquals(candidate('Target'), 'cyan')\n    lu.assertEquals(candidate('InputSim'), 'gray')\n    lu.assertEquals(candidate('LeafInfSP'), 'brown')\n    lu.assertEquals(candidate('TREX'), 'green')\n    lu.assertEquals(candidate('Minority'), 'cyan')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_441315_filter_func", "language": "lua", "prompt": "-- Given a list of bigrams from a review's text, returns true if the review is\n-- incentivized by using a lookup list\n-- :param bigrams: Bigrams from the review's text, lemmatized for better matching\n-- :return: True if the review is incentivized, False otherwise\nlocal function filter_func(bigrams)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_441315_filter_func.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = filter_func\n    lu.assertEquals(candidate({{'free', 'discount'}, {'free', 'exchange'}}), true)\n    lu.assertEquals(candidate({{'unbiased', 'view'}}), true)\n    lu.assertEquals(candidate({{'return', 'unbiased'}, {'review', 'sample'}}), true)\n    lu.assertEquals(candidate({{'opinion', 'state'}, {'opinion', 'own'}}), true)\n    lu.assertEquals(candidate({{'complimentary', 'copy'}, {'discount', 'exchange'}}), true)\n    lu.assertEquals(candidate({{'sample', 'product'}, {'sample', 'unbiased'}}), true)\n    lu.assertEquals(candidate({{'provide', 'exchange'}, {'provided', 'sample'}}), true)\n    lu.assertEquals(candidate({{'free', 'sample'}, {'free', 'unbiased'}}), true)\n    lu.assertEquals(candidate({{'honest', 'feedback'}, {'honest', 'unbiased'}}), true)\n    lu.assertEquals(candidate({{'receive', 'free'}, {'received', 'sample'}}), true)\n    lu.assertEquals(candidate({{'unbiased', 'review'}, {'unbiased', 'opinion'}}), true)\n    lu.assertEquals(candidate({{'sample', 'free'}, {'send', 'sample'}}), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_441869_is_candidate_word", "language": "lua", "prompt": "--     check a word is correct candidate word for identifying pronoun\nlocal function is_candidate_word(word)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_441869_is_candidate_word.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_candidate_word\n    lu.assertEquals(candidate('The Dog'), true)\n    lu.assertEquals(candidate('the cat'), true)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('the Cat'), true)\n    lu.assertEquals(candidate('the'), false)\n    lu.assertEquals(candidate('a'), false)\n    lu.assertEquals(candidate('cat'), true)\n    lu.assertEquals(candidate('apple'), true)\n    lu.assertEquals(candidate('The Cat'), true)\n    lu.assertEquals(candidate('The dog'), true)\n    lu.assertEquals(candidate('an'), false)\n    lu.assertEquals(candidate('The'), false)\n    lu.assertEquals(candidate('the Dog'), true)\n    lu.assertEquals(candidate('dog'), true)\n    lu.assertEquals(candidate(' '), false)\n    lu.assertEquals(candidate('banana'), true)\n    lu.assertEquals(candidate('the dog'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_441928_mtoft", "language": "lua", "prompt": "-- Convertie les meters en feets\n-- note: 12 [in] = 1 [ft] and 1 [in] = 25.4 [mm] and 1000 [mm] = 1 [m]\n-- :param m: length [m]\n-- :return ft: length [ft]\nlocal function mtoft(m)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_441928_mtoft.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = mtoft\n    lu.assertEquals(candidate(0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_442368_remove_leading_zeros", "language": "lua", "prompt": "-- >>> remove_leading_zeros(\"0033\")\n-- '33'\nlocal function remove_leading_zeros(numeric_string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_442368_remove_leading_zeros.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_leading_zeros\n    lu.assertEquals(candidate('000'), '')\n    lu.assertEquals(candidate('00'), '')\n    lu.assertEquals(candidate('1234'), '1234')\n    lu.assertEquals(candidate('0123'), '123')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_442462_count_leading_spaces", "language": "lua", "prompt": "-- Count the number of spaces in a string before any other character.\n-- :param string: input string\n-- :return: number of spaces\nlocal function count_leading_spaces(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_442462_count_leading_spaces.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = count_leading_spaces\n    lu.assertEquals(candidate('  hello  \\tworld'), 2)\n    lu.assertEquals(candidate('  hello'), 2)\n    lu.assertEquals(candidate('  hello'), 2)\n    lu.assertEquals(candidate('hello\\tworld'), 0)\n    lu.assertEquals(candidate('hello'), 0)\n    lu.assertEquals(candidate('  hello  '), 2)\n    lu.assertEquals(candidate('     hello     '), 5)\n    lu.assertEquals(candidate('  hello   world'), 2)\n    lu.assertEquals(candidate('  hello  '), 2)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('  hello world'), 2)\n    lu.assertEquals(candidate('hello   '), 0)\n    lu.assertEquals(candidate('This is a string without leading spaces.'), 0)\n    lu.assertEquals(candidate('    hello'), 4)\n    lu.assertEquals(candidate('    hello'), 4)\n    lu.assertEquals(candidate('hello'), 0)\n    lu.assertEquals(candidate('   hello'), 3)\n    lu.assertEquals(candidate('hello    '), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_442522_editDistance", "language": "lua", "prompt": "--  Calculate edit distance between 2 strings\n-- Args:\n--     s1: string 1\n--     s2: string 2\n-- Returns:\n--     Edit distance between s1 and s2\nlocal function editDistance(s1, s2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_442522_editDistance.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = editDistance\n    lu.assertEquals(candidate('aaab', 'aaa'), 1)\n    lu.assertEquals(candidate('aaac', 'aaa'), 1)\n    lu.assertEquals(candidate('aab', 'aaa'), 1)\n    lu.assertEquals(candidate('a', 'bb'), 2)\n    lu.assertEquals(candidate('aaa', 'aaa'), 0)\n    lu.assertEquals(candidate('a', 'a'), 0)\n    lu.assertEquals(candidate('', ''), 0)\n    lu.assertEquals(candidate('foo', 'fO0baR'), 4)\n    lu.assertEquals(candidate('aaa', 'aaab'), 1)\n    lu.assertEquals(candidate('a', 'ccc'), 3)\n    lu.assertEquals(candidate('ABC', 'ABC'), 0)\n    lu.assertEquals(candidate('bb', 'a'), 2)\n    lu.assertEquals(candidate('a', 'b'), 1)\n    lu.assertEquals(candidate('', 'a'), 1)\n    lu.assertEquals(candidate('foo', 'bar'), 3)\n    lu.assertEquals(candidate('b', 'a'), 1)\n    lu.assertEquals(candidate('aaa', 'aab'), 1)\n    lu.assertEquals(candidate('sunday', 'saturday'), 3)\n    lu.assertEquals(candidate('kitten', 'sitting'), 3)\n    lu.assertEquals(candidate('ccc', 'a'), 3)\n    lu.assertEquals(candidate('a', ''), 1)\n    lu.assertEquals(candidate('aaa', 'aaac'), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_442974_label_to_int", "language": "lua", "prompt": "-- Label to tensor\n-- :param label:\n-- :return:\nlocal function label_to_int(label)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_442974_label_to_int.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = label_to_int\n    lu.assertEquals(candidate('male'), 1)\n    lu.assertEquals(candidate('female'), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_443062_partition", "language": "lua", "prompt": "-- Returns: a list splitting s in two parts\n-- The 1st element of the list consists of all characters in even\n-- positions (starting at 0), while the 2nd element is the odd\n-- positions.\n-- Examples:\n--     partition('abcde') is ['ace','bd']\n--     partition('aabb') is ['ab', 'ab']\n-- Parameter s: the string to partition\n-- Precondition: s is a string\nlocal function partition(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_443062_partition.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = partition\n    lu.assertEquals(candidate('abcde'), {'ace', 'bd'})\n    lu.assertEquals(candidate('12345'), {'135', '24'})\n    lu.assertEquals(candidate('a'), {'a', ''})\n    lu.assertEquals(candidate(''), {'', ''})\n    lu.assertEquals(candidate('abcde'), {'ace', 'bd'})\n    lu.assertEquals(candidate(''), {'', ''})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_443442_column", "language": "lua", "prompt": "-- Gets column of matrix. \n-- INPUTS:     \n--     Matrix, Int of column to look at\n-- RETURNS:    \n--     Array of the column\nlocal function column(matrix, i)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_443442_column.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = column\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}}, 1), {2, 5})\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}}, 0), {1, 4})\n    lu.assertEquals(candidate({{1, 2, 3}, {4, 5, 6}}, 2), {3, 6})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_444222__get_num_to_fold", "language": "lua", "prompt": "-- Returns the number of gates to fold to achieve the desired (approximate)\n-- stretch factor.\n-- Args:\n--     stretch: Floating point value to stretch the circuit by.\n--     ngates: Number of gates in the circuit to stretch.\nlocal function _get_num_to_fold(stretch, ngates)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_444222__get_num_to_fold.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _get_num_to_fold\n    lu.assertEquals(candidate(1.0, 1), 0)\n    lu.assertEquals(candidate(3.5, 5), 6)\n    lu.assertEquals(candidate(3.0, 5), 5)\n    lu.assertEquals(candidate(1.5, 2), 0)\n    lu.assertEquals(candidate(2.0, 3), 2)\n    lu.assertEquals(candidate(1.0, 5), 0)\n    lu.assertEquals(candidate(2.0, 1000), 500)\n    lu.assertEquals(candidate(2.0, 100), 50)\n    lu.assertEquals(candidate(1.1, 10), 1)\n    lu.assertEquals(candidate(1.4, 12), 2)\n    lu.assertEquals(candidate(1.6, 12), 4)\n    lu.assertEquals(candidate(1.0, 100), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_444241_bin2int", "language": "lua", "prompt": "-- convert the binary (as string) to integer\nlocal function bin2int(bin)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_444241_bin2int.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = bin2int\n    lu.assertEquals(candidate('10111110011'), 1523)\n    lu.assertEquals(candidate('10101110'), 174)\n    lu.assertEquals(candidate('100101100101110111'), 153975)\n    lu.assertEquals(candidate('10101110010111'), 11159)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_444506_rename_dupe_cols", "language": "lua", "prompt": "-- Renames duplicate columns in order of occurrence.\n-- columns [0, 0, 0, 0]\n-- turn into [0, 1, 2, 3]\n-- columns [name10, name10, name10, name10]\n-- turn into [name10, name11, name12, name13]\n-- :param cols: iterable of columns\n-- :return: unique columns with digits incremented.\nlocal function rename_dupe_cols(cols)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_444506_rename_dupe_cols.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rename_dupe_cols\n    lu.assertEquals(candidate({'name10', 'name10', 'name10', 'name10', 'name10', 'name10'}), {'name10', 'name11', 'name12', 'name13', 'name14', 'name15'})\n    lu.assertEquals(candidate({'name1', 'name2', 'name3', 'name4', 'name5', 'name6', 'name7', 'name8'}), {'name1', 'name2', 'name3', 'name4', 'name5', 'name6', 'name7', 'name8'})\n    lu.assertEquals(candidate({'name1', 'name2', 'name3', 'name4', 'name5', 'name6', 'name7', 'name8', 'name9'}), {'name1', 'name2', 'name3', 'name4', 'name5', 'name6', 'name7', 'name8', 'name9'})\n    lu.assertEquals(candidate({'name10', 'name10', 'name10', 'name10'}), {'name10', 'name11', 'name12', 'name13'})\n    lu.assertEquals(candidate({'name10', 'name11', 'name12', 'name13', 'name14', 'name15'}), {'name10', 'name11', 'name12', 'name13', 'name14', 'name15'})\n    lu.assertEquals(candidate(list('abc')), list('abc'))\n    lu.assertEquals(candidate({'name1', 'name1', 'name1', 'name1', 'name1', 'name1', 'name1', 'name1'}), {'name1', 'name2', 'name3', 'name4', 'name5', 'name6', 'name7', 'name8'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_445003_add_trailing_slash", "language": "lua", "prompt": "-- Add trailing slash. \nlocal function add_trailing_slash(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_445003_add_trailing_slash.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = add_trailing_slash\n    lu.assertEquals(candidate('fiddle/'), 'fiddle/')\n    lu.assertEquals(candidate('eggplant/'), 'eggplant/')\n    lu.assertEquals(candidate('durian'), 'durian/')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_445676__format_time", "language": "lua", "prompt": "-- Defines how to format time in FunctionEvent\nlocal function _format_time(time_us)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_445676__format_time.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _format_time\n    lu.assertEquals(candidate(100), '100.000us')\n    lu.assertEquals(candidate(1000), '1.000ms')\n    lu.assertEquals(candidate(10000), '10.000ms')\n    lu.assertEquals(candidate(100000), '100.000ms')\n    lu.assertEquals(candidate(1000000), '1.000s')\n    lu.assertEquals(candidate(100000000), '100.000s')\n    lu.assertEquals(candidate(10000000), '10.000s')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_445722_org_add_payload", "language": "lua", "prompt": "-- Provide an organization payload for adding a member.\nlocal function org_add_payload(org_default_payload)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_445722_org_add_payload.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = org_add_payload\n    lu.assertEquals(candidate({['action'] = 'member_added'}), {['action'] = 'member_added'})\n    lu.assertEquals(candidate({['action'] = 'member_removed'}), {['action'] = 'member_added'})\n    lu.assertEquals(candidate({['action'] = 'member_removed'}), {['action'] = 'member_added'})\n    lu.assertEquals(candidate({['action'] = 'member_added'}), {['action'] = 'member_added'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_445953_dopant_site", "language": "lua", "prompt": "-- With the given VASP POSCAR file, determine the impurity location\n-- given the folder structure\n-- Inputs\n-- ------\n-- poscar:  File path for the relevant POSCAR file\n-- Outputs\n-- -------\n-- impurity type of the defect as defined by collaborators\nlocal function dopant_site(poscar)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_445953_dopant_site.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = dopant_site\n    lu.assertEquals(candidate('M_i_S_site/POSCAR'), 'M_i_S_site')\n    lu.assertEquals(candidate('M_i_Se_site/POSCAR'), 'M_i_Se_site')\n    lu.assertEquals(candidate('M_i_Cd_site/POSCAR'), 'M_i_Cd_site')\n    lu.assertEquals(candidate('M_Se/POSCAR'), 'M_Se')\n    lu.assertEquals(candidate('M_Cd/POSCAR'), 'M_Cd')\n    lu.assertEquals(candidate('M_i_other/POSCAR'), 'M_i_old')\n    lu.assertEquals(candidate('M_i_neutral_site/POSCAR'), 'M_i_old')\n    lu.assertEquals(candidate('M_Cd/POSCAR'), 'M_Cd')\n    lu.assertEquals(candidate('M_i_Te_site/POSCAR'), 'M_i_Te_site')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_446431_decolonize", "language": "lua", "prompt": "-- Remove the colon at the end of the word\n-- This will be used by the unique word of\n-- template class to sanitize attr accesses\nlocal function decolonize(val)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_446431_decolonize.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = decolonize\n    lu.assertEquals(candidate(str(400)), '400')\n    lu.assertEquals(candidate(str(1600)), '1600')\n    lu.assertEquals(candidate(str(2100)), '2100')\n    lu.assertEquals(candidate(str(1900)), '1900')\n    lu.assertEquals(candidate(str(1100)), '1100')\n    lu.assertEquals(candidate(str(200)), '200')\n    lu.assertEquals(candidate(str(600)), '600')\n    lu.assertEquals(candidate(str(800)), '800')\n    lu.assertEquals(candidate('Hello'), 'Hello')\n    lu.assertEquals(candidate(str(300)), '300')\n    lu.assertEquals(candidate('Hello '), 'Hello ')\n    lu.assertEquals(candidate(str(100)), '100')\n    lu.assertEquals(candidate(str(1000)), '1000')\n    lu.assertEquals(candidate(str(1400)), '1400')\n    lu.assertEquals(candidate(str(1500)), '1500')\n    lu.assertEquals(candidate(str(500)), '500')\n    lu.assertEquals(candidate(str(700)), '700')\n    lu.assertEquals(candidate(':foo'), 'foo')\n    lu.assertEquals(candidate('Hello :  '), 'Hello :  ')\n    lu.assertEquals(candidate('  '), '  ')\n    lu.assertEquals(candidate(':FOO'), 'FOO')\n    lu.assertEquals(candidate('Foo:'), 'Foo')\n    lu.assertEquals(candidate(str(2000)), '2000')\n    lu.assertEquals(candidate('FOO'), 'FOO')\n    lu.assertEquals(candidate(str(1800)), '1800')\n    lu.assertEquals(candidate(str(900)), '900')\n    lu.assertEquals(candidate('FOO:'), 'FOO')\n    lu.assertEquals(candidate(str(1200)), '1200')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('foo:'), 'foo')\n    lu.assertEquals(candidate(' '), ' ')\n    lu.assertEquals(candidate('foo'), 'foo')\n    lu.assertEquals(candidate(str(1700)), '1700')\n    lu.assertEquals(candidate(':Foo'), 'Foo')\n    lu.assertEquals(candidate('Foo'), 'Foo')\n    lu.assertEquals(candidate(str(1300)), '1300')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_446564__nipype_logging_config", "language": "lua", "prompt": "-- This Function takes in...\n-- :param wfrun: cachedir\n-- :return:\nlocal function _nipype_logging_config(cachedir)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_446564__nipype_logging_config.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _nipype_logging_config\n    lu.assertEquals(candidate('testdir'), {['workflow_level'] = 'INFO', ['filemanip_level'] = 'INFO', ['interface_level'] = 'INFO', ['log_directory'] = 'testdir'})\n    lu.assertEquals(candidate('foo'), {['workflow_level'] = 'INFO', ['filemanip_level'] = 'INFO', ['interface_level'] = 'INFO', ['log_directory'] = 'foo'})\n    lu.assertEquals(candidate('cachedir'), {['workflow_level'] = 'INFO', ['filemanip_level'] = 'INFO', ['interface_level'] = 'INFO', ['log_directory'] = 'cachedir'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_446882_sort_012", "language": "lua", "prompt": "-- Sort a list containing the integers 0, 1, and 2, in a single traversal\n-- :param input_list: list\n-- :return: list\nlocal function sort_012(input_list)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_446882_sort_012.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sort_012\n    lu.assertEquals(candidate({1, 0, 2}), {0, 1, 2})\n    lu.assertEquals(candidate({2, 0, 1}), {0, 1, 2})\n    lu.assertEquals(candidate({1, 2, 0}), {0, 1, 2})\n    lu.assertEquals(candidate({0, 2, 1}), {0, 1, 2})\n    lu.assertEquals(candidate({0, 0, 2}), {0, 0, 2})\n    lu.assertEquals(candidate({2, 2, 2}), {2, 2, 2})\n    lu.assertEquals(candidate({2, 1, 0}), {0, 1, 2})\n    lu.assertEquals(candidate({0, 0, 0}), {0, 0, 0})\n    lu.assertEquals(candidate({0, 1, 2}), {0, 1, 2})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_446968_format_markdown", "language": "lua", "prompt": "-- Format content with config parameters.\n-- Arguments:\n--     content {str} -- Unformatted content\n-- Returns:\n--     {str} -- Formatted content\nlocal function format_markdown(content, params)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_446968_format_markdown.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = format_markdown\n    lu.assertEquals(candidate('The following is a **{document}** document.', {['document'] = 'document'}), 'The following is a **document** document.')\n    lu.assertEquals(candidate('The following is a **markdown** document.', {['document'] = 'document'}), 'The following is a **markdown** document.')\n    lu.assertEquals(candidate('The following is a **{markdown}** document.', {}), 'The following is a **{markdown}** document.')\n    lu.assertEquals(candidate('The following is a **markdown** document.', {['document'] = 'document', ['markdown'] = '**markdown**'}), 'The following is a **markdown** document.')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_447141_distance_between_points", "language": "lua", "prompt": "-- Calculates the Distance between 2 points. (x^2 + y^2) ^ 0.5\n-- :param first_point: tuple of x and y value of point 1\n-- :param second_point: tuple of x and y value of point 2\n-- :return: Float value of the distance between the 2 points\n-- :rtype: float\nlocal function distance_between_points(first_point, second_point)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_447141_distance_between_points.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = distance_between_points\n    lu.assertEquals(candidate({0, 1}, {1, 0}), 1.4142135623730951)\n    lu.assertEquals(candidate({-1, 0}, {3, 0}), 4.0)\n    lu.assertEquals(candidate({0, 0}, {3, 4}), 5.0)\n    lu.assertEquals(candidate({0, 0}, {1, 1}), 1.4142135623730951)\n    lu.assertEquals(candidate({-1, -1}, {1, 1}), 2.8284271247461903)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_448228_ind_dict2list", "language": "lua", "prompt": "-- :param dic: dictionary form object ot index, starting from zero\n-- :return:\nlocal function ind_dict2list(dic)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_448228_ind_dict2list.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = ind_dict2list\n    lu.assertEquals(candidate({['x'] = 0, ['y'] = 1, ['z'] = 2}), {'x', 'y', 'z'})\n    lu.assertEquals(candidate(dict(zip(list('abcde'), range(5)))), list('abcde'))\n    lu.assertEquals(candidate(dict()), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_448750_simple_decompression", "language": "lua", "prompt": "-- Decompression for `simple_compression(string)`\nlocal function simple_decompression(compressed_string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_448750_simple_decompression.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = simple_decompression\n    lu.assertEquals(candidate('c3'), 'ccc')\n    lu.assertEquals(candidate('a4'), 'aaaa')\n    lu.assertEquals(candidate('b1'), 'b')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_448838_pad_diff", "language": "lua", "prompt": "--  Pads img_arr width or height < samples_size with zeros \nlocal function pad_diff(actual_height, actual_width, desired_height, desired_width)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_448838_pad_diff.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = pad_diff\n    lu.assertEquals(candidate(10, 10, 15, 15), {0, 0, 5, 5})\n    lu.assertEquals(candidate(2, 2, 4, 4), {0, 0, 2, 2})\n    lu.assertEquals(candidate(2, 2, 3, 3), {0, 0, 1, 1})\n    lu.assertEquals(candidate(100, 100, 100, 200), {0, 0, 100, 0})\n    lu.assertEquals(candidate(200, 300, 200, 300), {0, 0, 0, 0})\n    lu.assertEquals(candidate(100, 100, 200, 100), {0, 0, 0, 100})\n    lu.assertEquals(candidate(4, 6, 4, 6), {0, 0, 0, 0})\n    lu.assertEquals(candidate(1, 1, 3, 2), {0, 0, 1, 2})\n    lu.assertEquals(candidate(1, 1, 2, 2), {0, 0, 1, 1})\n    lu.assertEquals(candidate(100, 100, 100, 100), {0, 0, 0, 0})\n    lu.assertEquals(candidate(10, 10, 10, 10), {0, 0, 0, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_44905_calc_intersection", "language": "lua", "prompt": "-- Calculates the intersection of 2 rects\n-- Maths from https://es.wikipedia.org/wiki/Intersecci%C3%B3n_de_dos_rectas\n-- :param r1:\n-- :param r2:\n-- :return:\nlocal function calc_intersection(r1, r2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_44905_calc_intersection.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = calc_intersection\n    lu.assertEquals(candidate({{0, 0}, {0, 1}}, {{0, 0}, {1, 0}}), {0, 0})\n    lu.assertEquals(candidate({{0, 0}, {0, 1}}, {{-1, 0}, {1, 0}}), {0, 0})\n    lu.assertEquals(candidate({{1, 1}, {2, 2}}, {{-1, 1}, {1, 3}}), None)\n    lu.assertEquals(candidate({{1, 1}, {3, 3}}, {{1, 2}, {3, 2}}), {2, 2})\n    lu.assertEquals(candidate({{0, 0}, {0, 1}}, {{0, 0}, {1, 1}}), {0, 0})\n    lu.assertEquals(candidate({{0, 0}, {0, 1}}, {{-1, 1}, {1, 1}}), {0, 1})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_449923_get_as_clause_multicol", "language": "lua", "prompt": "-- get_as_clause will return tuple of column names of intermediate table c of postgresql query.\n-- :param columns_to_query_lst: columns for where clause.E.g [col1]\n-- :param update_param_list: new column names for columns to be updated.E.g [updatecol2,updatecol3]\n-- :return as_clause: string. E.g \"as c(col1,updatecol2,updatecol3)\"\nlocal function get_as_clause_multicol(columns_to_query_lst, update_param_list)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_449923_get_as_clause_multicol.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_as_clause_multicol\n    lu.assertEquals(candidate({'col1'}, {'updatecol2', 'updatecol3'}), 'as c(col1,updatecol2,updatecol3)')\n    lu.assertEquals(candidate({'col1', 'col2'}, {'updatecol2', 'updatecol3'}), 'as c(col1,col2,updatecol2,updatecol3)')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_450025_word_count", "language": "lua", "prompt": "--  The word-count of the given text. Goes through the string exactly\n-- once and has constant memory usage. Not super sophisticated though.\nlocal function word_count(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_450025_word_count.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = word_count\n    lu.assertEquals(candidate('a b c d e '), 5)\n    lu.assertEquals(candidate('a'), 1)\n    lu.assertEquals(candidate('\\nfoo'), 1)\n    lu.assertEquals(candidate('foo\\tbar'), 2)\n    lu.assertEquals(candidate('a b c d e f g h i j k l m n o p q r s t u v w x y z'), 26)\n    lu.assertEquals(candidate('a b'), 2)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('a b c d e f g'), 7)\n    lu.assertEquals(candidate('foo\\n  \\n  bar'), 2)\n    lu.assertEquals(candidate('foo  bar  baz'), 3)\n    lu.assertEquals(candidate('foo bar baz quux'), 4)\n    lu.assertEquals(candidate('foo\\rbar'), 2)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('foo '), 1)\n    lu.assertEquals(candidate('\\n\\n\\n\\n\\n'), 0)\n    lu.assertEquals(candidate('foo\\n'), 1)\n    lu.assertEquals(candidate(None), 0)\n    lu.assertEquals(candidate('a b c d e'), 5)\n    lu.assertEquals(candidate('a'), 1)\n    lu.assertEquals(candidate('\\n'), 0)\n    lu.assertEquals(candidate('a b c d e f '), 6)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('Hello  World!'), 2)\n    lu.assertEquals(candidate('a b c d e f g h '), 8)\n    lu.assertEquals(candidate('foo \\n bar \\n baz'), 3)\n    lu.assertEquals(candidate('\\t\\n\\n\\n\\t\\t'), 0)\n    lu.assertEquals(candidate('a b c'), 3)\n    lu.assertEquals(candidate('a b c d e f g '), 7)\n    lu.assertEquals(candidate('foo\\n  bar'), 2)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('foo\\n\\nbar'), 2)\n    lu.assertEquals(candidate('foo\\tbar\\tbaz?'), 3)\n    lu.assertEquals(candidate(' foo'), 1)\n    lu.assertEquals(candidate('a b c d e f g h'), 8)\n    lu.assertEquals(candidate('foo\\nbar\\nbaz'), 3)\n    lu.assertEquals(candidate('a b c d e f g h i '), 9)\n    lu.assertEquals(candidate('foo'), 1)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('foo bar baz'), 3)\n    lu.assertEquals(candidate('a b c d'), 4)\n    lu.assertEquals(candidate('a b c d e f g h i'), 9)\n    lu.assertEquals(candidate('foo  \\t\\tbar'), 2)\n    lu.assertEquals(candidate('foo\\nbar'), 2)\n    lu.assertEquals(candidate(' a b  c '), 3)\n    lu.assertEquals(candidate('a b c d e f'), 6)\n    lu.assertEquals(candidate('foo bar'), 2)\n    lu.assertEquals(candidate('foo\\tbar\\tbaz'), 3)\n    lu.assertEquals(candidate('a b c d '), 4)\n    lu.assertEquals(candidate('foo'), 1)\n    lu.assertEquals(candidate('Hello\\n\\nWorld!'), 2)\n    lu.assertEquals(candidate('Hello World!'), 2)\n    lu.assertEquals(candidate('  '), 0)\n    lu.assertEquals(candidate('  foo'), 1)\n    lu.assertEquals(candidate('foo\\t\\tbar'), 2)\n    lu.assertEquals(candidate('foo   bar  \\t\\n  baz'), 3)\n    lu.assertEquals(candidate('Hello\\tWorld!'), 2)\n    lu.assertEquals(candidate('foo bar baz'), 3)\n    lu.assertEquals(candidate(' a b '), 2)\n    lu.assertEquals(candidate('a b'), 2)\n    lu.assertEquals(candidate('foo\\r\\nbar'), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_45007_process_value", "language": "lua", "prompt": "-- Returns a processed value for an environment variable.\nlocal function process_value(value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_45007_process_value.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = process_value\n    lu.assertEquals(candidate('\"a\"'), 'a')\n    lu.assertEquals(candidate('\"a'), '\"a')\n    lu.assertEquals(candidate('\"a\"b'), '\"a\"b')\n    lu.assertEquals(candidate('a'), 'a')\n    lu.assertEquals(candidate('\"a b\"'), 'a b')\n    lu.assertEquals(candidate('\"a\"'), 'a')\n    lu.assertEquals(candidate('a\"b\"'), 'a\"b\"')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('a\"'), 'a\"')\n    lu.assertEquals(candidate('a\"b'), 'a\"b')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_450178_startWithArabic", "language": "lua", "prompt": "--     this function return true if the given string starts with am Arabic numeral\nlocal function startWithArabic(Instr)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_450178_startWithArabic.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = startWithArabic\n    lu.assertEquals(candidate('1999'), true)\n    lu.assertEquals(candidate('12345'), true)\n    lu.assertEquals(candidate('7'), true)\n    lu.assertEquals(candidate('1'), true)\n    lu.assertEquals(candidate('123'), true)\n    lu.assertEquals(candidate('8'), true)\n    lu.assertEquals(candidate('10000000'), true)\n    lu.assertEquals(candidate('999'), true)\n    lu.assertEquals(candidate('7000'), true)\n    lu.assertEquals(candidate('x'), false)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('0'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_450346_search_escape", "language": "lua", "prompt": "-- Escape URLs such that preexisting { and } are handled properly.\n-- Will obviously trash a properly-formatted qutebrowser URL.\nlocal function search_escape(url)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_450346_search_escape.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = search_escape\n    lu.assertEquals(candidate('http://example.com/?q=a}b'), 'http://example.com/?q=a}}b')\n    lu.assertEquals(candidate('some/url/with/{special characters}'), 'some/url/with/{{special characters}}')\n    lu.assertEquals(candidate('some/url/with/no/{characters}'), 'some/url/with/no/{{characters}}')\n    lu.assertEquals(candidate('some/url/with/no/special/characters'), 'some/url/with/no/special/characters')\n    lu.assertEquals(candidate('https://duckduckgo.com/?q=foo+bar&t=h_'), 'https://duckduckgo.com/?q=foo+bar&t=h_')\n    lu.assertEquals(candidate('http://example.com/?q=a{'), 'http://example.com/?q=a{{')\n    lu.assertEquals(candidate('http://example.com/?q=}'), 'http://example.com/?q=}}')\n    lu.assertEquals(candidate('http://example.com/?q=a}'), 'http://example.com/?q=a}}')\n    lu.assertEquals(candidate('https://duckduckgo.com/?q=foo+bar&t=h_'), 'https://duckduckgo.com/?q=foo+bar&t=h_')\n    lu.assertEquals(candidate('http://example.com/?q=a}b}'), 'http://example.com/?q=a}}b}}')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_450375_get_y_indicator_variable_index", "language": "lua", "prompt": "-- Map the i,j indices to the sequential indicator variable index\n-- for the y_{ij} variable.\n-- This is basically the (2-dimensional) 'array equation' (as per\n-- row-major arrays in C for example).\n-- Note that for MiniSat+, the variables are juist indexed sequentially\n-- and we are mapping the y_{ij} to y_r for 0 <= r < m*n variables.\n-- This function gets the sequential index for a y_{ij} variable.\n-- Parameters:\n--     i, j   - indices for y indicator variable\n--     m - order of tableau a (0 <= i,k < m)\n--     n - order of tableau b (0 <= j,l < n)\n-- Return value:\n--     index r of indicator variable y_{r} corresponding to y_{ij}\nlocal function get_y_indicator_variable_index(i, j, m, n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_450375_get_y_indicator_variable_index.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_y_indicator_variable_index\n    lu.assertEquals(candidate(0, 0, 0, 0), 0)\n    lu.assertEquals(candidate(1, 1, 2, 2), 3)\n    lu.assertEquals(candidate(0, 3, 5, 6), 3)\n    lu.assertEquals(candidate(0, 0, 5, 6), 0)\n    lu.assertEquals(candidate(0, 1, 1, 2), 1)\n    lu.assertEquals(candidate(0, 0, 1, 1), 0)\n    lu.assertEquals(candidate(0, 2, 5, 6), 2)\n    lu.assertEquals(candidate(1, 0, 1, 1), 1)\n    lu.assertEquals(candidate(0, 0, 3, 4), 0)\n    lu.assertEquals(candidate(1, 0, 2, 1), 1)\n    lu.assertEquals(candidate(0, 0, 1, 2), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_450502_default", "language": "lua", "prompt": "--     Return default if no input_str, otherwise stripped input_str.\nlocal function default(input_str, name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_450502_default.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = default\n    lu.assertEquals(candidate('', 'name'), 'name')\n    lu.assertEquals(candidate('abc', None), 'abc')\n    lu.assertEquals(candidate('  hi  ', 'candidate'), 'hi')\n    lu.assertEquals(candidate(None, 'name'), 'name')\n    lu.assertEquals(candidate('  ', None), '')\n    lu.assertEquals(candidate('  abc  ', None), 'abc')\n    lu.assertEquals(candidate(None, None), None)\n    lu.assertEquals(candidate(None, 'bob'), 'bob')\n    lu.assertEquals(candidate('1', None), '1')\n    lu.assertEquals(candidate('  bob  ', 'bob'), 'bob')\n    lu.assertEquals(candidate('name', 'name'), 'name')\n    lu.assertEquals(candidate('\\t   \\t', 'candidate'), '')\n    lu.assertEquals(candidate('   str   ', 'candidate'), 'str')\n    lu.assertEquals(candidate('bob', 'bob'), 'bob')\n    lu.assertEquals(candidate('  ', 'bob'), '')\n    lu.assertEquals(candidate(None, 'candidate'), 'candidate')\n    lu.assertEquals(candidate('\\n\\n', 'candidate'), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_451058_est_palindrome3", "language": "lua", "prompt": "--  ... cf. ci-dessus ...\nlocal function est_palindrome3(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_451058_est_palindrome3.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = est_palindrome3\n    lu.assertEquals(candidate('abb'), false)\n    lu.assertEquals(candidate('aabaa'), true)\n    lu.assertEquals(candidate('abbbbbbbbbbba'), true)\n    lu.assertEquals(candidate('abbaabb'), false)\n    lu.assertEquals(candidate('abbbbba'), true)\n    lu.assertEquals(candidate('0'), true)\n    lu.assertEquals(candidate('toto0'), false)\n    lu.assertEquals(candidate('abbbbbbbaa'), false)\n    lu.assertEquals(candidate('abbbaabb'), false)\n    lu.assertEquals(candidate('abbaabba'), true)\n    lu.assertEquals(candidate(''), true)\n    lu.assertEquals(candidate('aba'), true)\n    lu.assertEquals(candidate('00'), true)\n    lu.assertEquals(candidate('abbba'), true)\n    lu.assertEquals(candidate('ab'), false)\n    lu.assertEquals(candidate('abbbbbbba'), true)\n    lu.assertEquals(candidate('bab'), true)\n    lu.assertEquals(candidate('abba'), true)\n    lu.assertEquals(candidate('a'), true)\n    lu.assertEquals(candidate('abbab'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_451156_dhash_hamming_distance", "language": "lua", "prompt": "-- Calculate the hamming distance between two dhash values\n-- :param dhash1: str, the dhash of an image returned by `calculate_dhash`\n-- :param dhash2: str, the dhash of an image returned by `calculate_dhash`\n-- :return: int, the hamming distance between two dhash values\nlocal function dhash_hamming_distance(dhash1, dhash2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_451156_dhash_hamming_distance.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = dhash_hamming_distance\n    lu.assertEquals(candidate('1234567890abcdef1234567890abcdef', '1234567890abcdef1234567890abcdef'), 0)\n    lu.assertEquals(candidate('1234567890abcdef1234567890abcdee', '1234567890abcdef1234567890abcdee'), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_451382_findimagenumber", "language": "lua", "prompt": "-- find the number for each image file\nlocal function findimagenumber(filename)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_451382_findimagenumber.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = findimagenumber\n    lu.assertEquals(candidate('Data/OBSDATE0001.jpg'), 1)\n    lu.assertEquals(candidate('Data/OBSDATE0010.jpg'), 10)\n    lu.assertEquals(candidate('OBSDATE0001.fits'), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_451777__rescale_score_by_abs", "language": "lua", "prompt": "-- Normalizes an attribution score to the range [0., 1.], where a score\n-- score of 0. is mapped to 0.5.\n-- :param score: An attribution score\n-- :param max_score: The maximum possible attribution score\n-- :param min_score: The minimum possible attribution score\n-- :return: The normalized score\nlocal function _rescale_score_by_abs(score, max_score, min_score)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_451777__rescale_score_by_abs.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _rescale_score_by_abs\n    lu.assertEquals(candidate(0, 1, 0), 0.5)\n    lu.assertEquals(candidate(-1, 0, 0), 0.5)\n    lu.assertEquals(candidate(1.0, 1.0, -1.0), 1.0)\n    lu.assertEquals(candidate(0, 0, 0), 0.5)\n    lu.assertEquals(candidate(1, 1, 0), 1)\n    lu.assertEquals(candidate(1.0, 1.0, 0.0), 1.0)\n    lu.assertEquals(candidate(0.0, 1.0, -1.0), 0.5)\n    lu.assertEquals(candidate(0.0, 0.0, 0.0), 0.5)\n    lu.assertEquals(candidate(0, 1e-05, 0), 0.5)\n    lu.assertEquals(candidate(0, 0, -1), 0.5)\n    lu.assertEquals(candidate(-1.0, 1.0, 0.0), 0.0)\n    lu.assertEquals(candidate(-1.0, 1.0, -1.0), 0.0)\n    lu.assertEquals(candidate(0.0, 1.0, 0.0), 0.5)\n    lu.assertEquals(candidate(0, 0, 1), 0.5)\n    lu.assertEquals(candidate(0, 0, 0), 0.5)\n    lu.assertEquals(candidate(1, 0, 0), 0.5)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_451986_update_dependencies", "language": "lua", "prompt": "-- Update the source package's existing dependencies.\n-- When a user passes additional dependencies from the command line,\n-- these dependencies will be added to the source package's existing dependencies.\n-- If the dependencies passed from the command line are existing dependencies,\n-- these existing dependencies are overwritten.\n-- Positional arguments:\n-- new_dependencies (List[str]) -- the dependencies passed from the command line\n-- existing_dependencies (List[str]) -- the dependencies found in the source\n--     package's index.json file\nlocal function update_dependencies(new_dependencies, existing_dependencies)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_451986_update_dependencies.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = update_dependencies\n    lu.assertEquals(candidate({'test', 'tests', 'testing'}, {}), {'test', 'tests', 'testing'})\n    lu.assertEquals(candidate({'foo', 'bar', 'baz'}, {}), {'foo', 'bar', 'baz'})\n    lu.assertEquals(candidate({}, {'foo', 'bar', 'baz'}), {'foo', 'bar', 'baz'})\n    lu.assertEquals(candidate({'test', 'tests', 'testing'}, {'test'}), {'test', 'tests', 'testing'})\n    lu.assertEquals(candidate({'foo 4.5.6'}, {'hello 1.2.3', 'goodbye 3.2.1', 'foo 4.5.6'}), {'hello 1.2.3', 'goodbye 3.2.1', 'foo 4.5.6'})\n    lu.assertEquals(candidate({}, {}), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_452069_convertBoolean", "language": "lua", "prompt": "-- Convert Python bool to JS boolean.\n-- Args:\n--     value (bool): True/False\nlocal function convertBoolean(value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_452069_convertBoolean.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = convertBoolean\n    lu.assertEquals(candidate(false), 'false')\n    lu.assertEquals(candidate(true), 'true')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_452718_hash_generator", "language": "lua", "prompt": "-- Generate hash for tokens in 'tokens' using 'token_to_id'.\n-- Args:\n--     token_to_id: dict. A dictionary which maps each token to a unique ID.\n--     tokens: list(str). A list of tokens.\n-- Returns:\n--     int. Hash value generated for tokens in 'tokens' using 'token_to_id'.\nlocal function hash_generator(token_to_id, tokens)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_452718_hash_generator.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = hash_generator\n    lu.assertEquals(candidate(dict(zip('abcdefghijklmnopqrstuvwxyz', range(26))), 'a'), 0)\n    lu.assertEquals(candidate(dict(zip('abc', range(5))), 'a'), 0)\n    lu.assertEquals(candidate(dict(zip('abc', range(3))), 'a'), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_45275_RPL_ADMINEMAIL", "language": "lua", "prompt": "--  Reply Code 259 \nlocal function RPL_ADMINEMAIL(sender, receipient, message)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_45275_RPL_ADMINEMAIL.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = RPL_ADMINEMAIL\n    lu.assertEquals(candidate('foo', 'bar', 'baz'), '<foo>: baz')\n    lu.assertEquals(candidate('foo', 'bar', 'baz'), '<foo>: baz')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_453163_piece_placed", "language": "lua", "prompt": "-- This function determines the piece played.\n-- It takes the coordinates of the piece, the player number, and the board.\n-- The pieces are zeros or ones and the function returns the piece on the board based on the number.\nlocal function piece_placed(x, y, player, board)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_453163_piece_placed.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = piece_placed\n    lu.assertEquals(candidate(1, 1, 1, {{0, 0, 0}, {0, 0, 0}, {0, 0, 0}}), {{0, 0, 0}, {0, 2, 0}, {0, 0, 0}})\n    lu.assertEquals(candidate(0, 0, 0, {{0, 0, 0}, {0, 0, 0}, {0, 0, 0}}), {{1, 0, 0}, {0, 0, 0}, {0, 0, 0}})\n    lu.assertEquals(candidate(1, 1, 1, {{1, 0, 0}, {0, 0, 1}, {0, 0, 0}}), {{1, 0, 0}, {0, 2, 1}, {0, 0, 0}})\n    lu.assertEquals(candidate(0, 0, 0, {{0, 0, 0, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}}), {{1, 0, 0, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_453517_do_math", "language": "lua", "prompt": "-- Helper function that performs computation between two numbers.\nlocal function do_math(a, b, operator)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_453517_do_math.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = do_math\n    lu.assertEquals(candidate(1, 3, '*'), 3)\n    lu.assertEquals(candidate(2, 4, '*'), 8)\n    lu.assertEquals(candidate(1, 2, '*'), 2)\n    lu.assertEquals(candidate(1, 1, '/'), 1)\n    lu.assertEquals(candidate(1, 1, '+'), 2)\n    lu.assertEquals(candidate(1, 3, '-'), 2)\n    lu.assertEquals(candidate(1, 1, '*'), 1)\n    lu.assertEquals(candidate(2, 4, '-'), 2)\n    lu.assertEquals(candidate(1, 2, '+'), 3)\n    lu.assertEquals(candidate(1, 1, '-'), 0)\n    lu.assertEquals(candidate(2, 3, '+'), 5)\n    lu.assertEquals(candidate(2, 4, '/'), 2)\n    lu.assertEquals(candidate(2, 4, '+'), 6)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_453870_get_version", "language": "lua", "prompt": "-- Generate a PEP386  compliant version\n-- Stolen from django.utils.version.get_version\n-- :param v tuple: A five part tuple indicating the version\n-- :returns str: Compliant version\nlocal function get_version(v)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_453870_get_version.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_version\n    lu.assertEquals(candidate({1, 2, 3, 'beta', 1}), '1.2.3b1')\n    lu.assertEquals(candidate({1, 0, 1, 'alpha', 0}), '1.0.1a0')\n    lu.assertEquals(candidate({0, 1, 0, 'rc', 100}), '0.1c100')\n    lu.assertEquals(candidate({1, 2, 0, 'beta', 11}), '1.2b11')\n    lu.assertEquals(candidate({1, 2, 0, 'final', 0}), '1.2')\n    lu.assertEquals(candidate({0, 1, 0, 'rc', 0}), '0.1c0')\n    lu.assertEquals(candidate({0, 1, 0, 'rc', 10}), '0.1c10')\n    lu.assertEquals(candidate({1, 1, 0, 'final', 0}), '1.1')\n    lu.assertEquals(candidate({1, 2, 0, 'rc', 1}), '1.2c1')\n    lu.assertEquals(candidate({1, 2, 0, 'alpha', 2}), '1.2a2')\n    lu.assertEquals(candidate({0, 1, 1, 'final', 0}), '0.1.1')\n    lu.assertEquals(candidate({1, 0, 1, 'beta', 0}), '1.0.1b0')\n    lu.assertEquals(candidate({1, 1, 0, 'alpha', 1}), '1.1a1')\n    lu.assertEquals(candidate({1, 2, 0, 'beta', 2}), '1.2b2')\n    lu.assertEquals(candidate({0, 1, 0, 'rc', 1}), '0.1c1')\n    lu.assertEquals(candidate({1, 0, 1, 'rc', 0}), '1.0.1c0')\n    lu.assertEquals(candidate({1, 0, 0, 'final', 0}), '1.0')\n    lu.assertEquals(candidate({0, 1, 0, 'final', 1}), '0.1')\n    lu.assertEquals(candidate({1, 2, 1, 'final', 11}), '1.2.1')\n    lu.assertEquals(candidate({1, 2, 0, 'alpha', 0}), '1.2a0')\n    lu.assertEquals(candidate({0, 1, 0, 'beta', 0}), '0.1b0')\n    lu.assertEquals(candidate({1, 1, 0, 'beta', 3}), '1.1b3')\n    lu.assertEquals(candidate({0, 1, 0, 'final', 100}), '0.1')\n    lu.assertEquals(candidate({1, 1, 0, 'rc', 3}), '1.1c3')\n    lu.assertEquals(candidate({0, 1, 1, 'beta', 2}), '0.1.1b2')\n    lu.assertEquals(candidate({1, 2, 0, 'alpha', 11}), '1.2a11')\n    lu.assertEquals(candidate({2, 1, 0, 'final', 0}), '2.1')\n    lu.assertEquals(candidate({0, 1, 0, 'final', 10}), '0.1')\n    lu.assertEquals(candidate({0, 1, 0, 'alpha', 0}), '0.1a0')\n    lu.assertEquals(candidate({0, 1, 0, 'rc', 1000}), '0.1c1000')\n    lu.assertEquals(candidate({1, 0, 1, 'final', 0}), '1.0.1')\n    lu.assertEquals(candidate({2, 1, 1, 'final', 0}), '2.1.1')\n    lu.assertEquals(candidate({1, 2, 1, 'final', 0}), '1.2.1')\n    lu.assertEquals(candidate({1, 2, 0, 'rc', 11}), '1.2c11')\n    lu.assertEquals(candidate({0, 1, 0, 'final', 0}), '0.1')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_454038_norm_mac", "language": "lua", "prompt": "-- Normalize a MAC Address from the pypowervm format to the neutron format.\n-- That means that the format will be converted to lower case and will have\n-- colons added.\n-- :param mac: A pypowervm mac address.  E.g. 1234567890AB\n-- :returns: A mac that matches the standard neutron format.\n--           E.g. 12:34:56:78:90:ab\nlocal function norm_mac(mac)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_454038_norm_mac.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = norm_mac\n    lu.assertEquals(candidate('1234567890AB'), '12:34:56:78:90:ab')\n    lu.assertEquals(candidate('1234567890AB'), '12:34:56:78:90:ab')\n    lu.assertEquals(candidate('1234:5678:90AB'), '12:34:56:78:90:ab')\n    lu.assertEquals(candidate('1234567890ab'), '12:34:56:78:90:ab')\n    lu.assertEquals(candidate('1234567890AB'), '12:34:56:78:90:ab')\n    lu.assertEquals(candidate('1234567890AB'), '12:34:56:78:90:ab')\n    lu.assertEquals(candidate('1234567890ab'), '12:34:56:78:90:ab')\n    lu.assertEquals(candidate('000000000000'), '00:00:00:00:00:00')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_454515_contains_common_item_2", "language": "lua", "prompt": "-- loop through first array and create dictionary object where the keys are the items in the array\n-- loop through the second array and check if item in second array exists in the created dictionary\nlocal function contains_common_item_2(arr1, arr2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_454515_contains_common_item_2.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = contains_common_item_2\n    lu.assertEquals(candidate({'apples', 'carrots', 'pears'}, {'oranges', 'bananas', 'apples'}), true)\n    lu.assertEquals(candidate({'a', 'b', 'c', 'd'}, {'a', 'y', 'x'}), true)\n    lu.assertEquals(candidate({}, {'z', 'y', 'x'}), false)\n    lu.assertEquals(candidate({'a', 'b', 'c', 'd'}, {'x', 'y', 'z'}), false)\n    lu.assertEquals(candidate({'a', 'b', 'c', 'd'}, {}), false)\n    lu.assertEquals(candidate({'a', 'b', 'c', 'd'}, {'b', 'c', 'd'}), true)\n    lu.assertEquals(candidate({'b', 'a', 'c', 'd'}, {'z', 'y', 'x'}), false)\n    lu.assertEquals(candidate({}, {}), false)\n    lu.assertEquals(candidate({'a', 'b', 'c', 'd'}, {'z', 'y', 'x'}), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_454709_port_to_ip_mapping", "language": "lua", "prompt": "--     A user defined mapping port_id (kni) to ipv4.\nlocal function port_to_ip_mapping(index)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_454709_port_to_ip_mapping.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = port_to_ip_mapping\n    lu.assertEquals(candidate(0), {['vEth0_0'] = '192.167.10.1'})\n    lu.assertEquals(candidate(2), {['vEth0_2'] = '192.167.10.3'})\n    lu.assertEquals(candidate(3), {['vEth0_3'] = '192.167.10.4'})\n    lu.assertEquals(candidate(3), {['vEth0_3'] = '192.167.10.4'})\n    lu.assertEquals(candidate(7), {['vEth0_7'] = '192.167.10.8'})\n    lu.assertEquals(candidate(5), {['vEth0_5'] = '192.167.10.6'})\n    lu.assertEquals(candidate(5), {['vEth0_5'] = '192.167.10.6'})\n    lu.assertEquals(candidate(1), {['vEth0_1'] = '192.167.10.2'})\n    lu.assertEquals(candidate(4), {['vEth0_4'] = '192.167.10.5'})\n    lu.assertEquals(candidate(6), {['vEth0_6'] = '192.167.10.7'})\n    lu.assertEquals(candidate(1), {['vEth0_1'] = '192.167.10.2'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_455809__handle_sort_key", "language": "lua", "prompt": "-- Generate sort keys according to the passed in sort key from user.\n-- :param model_name: Database model name be query.(alarm, meter, etc.)\n-- :param sort_key: sort key passed from user.\n-- return: sort keys list\nlocal function _handle_sort_key(model_name, sort_key)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_455809__handle_sort_key.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _handle_sort_key\n    lu.assertEquals(candidate('alarm', 'name'), {'name', 'user_id', 'project_id'})\n    lu.assertEquals(candidate('meter', 'user_id'), {'user_id', 'project_id'})\n    lu.assertEquals(candidate('meter', 'user_id'), {'user_id', 'project_id'})\n    lu.assertEquals(candidate('resource', None), {'user_id', 'project_id', 'timestamp'})\n    lu.assertEquals(candidate('meter', 'user_id'), {'user_id', 'project_id'})\n    lu.assertEquals(candidate('resource', 'user_id'), {'user_id', 'project_id', 'timestamp'})\n    lu.assertEquals(candidate('meter', None), {'user_id', 'project_id'})\n    lu.assertEquals(candidate('alarm', 'name'), {'name', 'user_id', 'project_id'})\n    lu.assertEquals(candidate('resource', 'user_id'), {'user_id', 'project_id', 'timestamp'})\n    lu.assertEquals(candidate('alarm', None), {'name', 'user_id', 'project_id'})\n    lu.assertEquals(candidate('resource', None), {'user_id', 'project_id', 'timestamp'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_45618_nearest_square", "language": "lua", "prompt": "-- Function to calculate nearest square of any number.\n-- Args: \n--     num (int): Any integer\n-- Returns: \n--     Int: Nearest Square of num\nlocal function nearest_square(num)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_45618_nearest_square.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = nearest_square\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(2), 1)\n    lu.assertEquals(candidate(5), 4)\n    lu.assertEquals(candidate(3), 1)\n    lu.assertEquals(candidate(17), 16)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_456370_path_inside_dir", "language": "lua", "prompt": "-- Returns True if the specified @path is inside @directory,\n-- performing component-wide comparison. Otherwise returns False.\nlocal function path_inside_dir(path, directory)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_456370_path_inside_dir.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = path_inside_dir\n    lu.assertEquals(candidate('foo/bar/baz', 'foo'), true)\n    lu.assertEquals(candidate('some/path', ''), true)\n    lu.assertEquals(candidate('foo/bar', 'foo\\\\bar\\\\baz\\\\quux'), false)\n    lu.assertEquals(candidate('some/path/', 'other/path'), false)\n    lu.assertEquals(candidate('some/path', 'other/path'), false)\n    lu.assertEquals(candidate('/a/b/c/d/e', '/a/b/c'), true)\n    lu.assertEquals(candidate('foo\\\\bar', 'foo\\\\bar\\\\baz'), false)\n    lu.assertEquals(candidate('foo/bar', 'foo/bar/baz'), false)\n    lu.assertEquals(candidate('foo\\\\bar', 'foo\\\\bar'), false)\n    lu.assertEquals(candidate('some/path/', 'other/directory'), false)\n    lu.assertEquals(candidate('foo\\\\bar', 'foo\\\\bar\\\\baz\\\\quux'), false)\n    lu.assertEquals(candidate('foo\\\\bar', 'foo/bar/baz/quux'), false)\n    lu.assertEquals(candidate('some/path', 'some/path/path'), false)\n    lu.assertEquals(candidate('some/path', 'some/path/'), false)\n    lu.assertEquals(candidate('foo/bar', 'foo/bar'), false)\n    lu.assertEquals(candidate('some/path/', ''), true)\n    lu.assertEquals(candidate('foo/bar', 'foo'), true)\n    lu.assertEquals(candidate('', 'some/path'), false)\n    lu.assertEquals(candidate('foo/bar', 'foo\\\\bar\\\\baz'), false)\n    lu.assertEquals(candidate('some/path', 'some/directory/path'), false)\n    lu.assertEquals(candidate('foo/bar', 'foo/bar/baz/quux'), false)\n    lu.assertEquals(candidate('foo\\\\bar', 'foo/bar/baz'), false)\n    lu.assertEquals(candidate('some/path', 'other/directory'), false)\n    lu.assertEquals(candidate('', ''), false)\n    lu.assertEquals(candidate('/a/b/c/d/e', '/a/b/c/'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_45640_num_digits", "language": "lua", "prompt": "-- Returns number of digits in an integer.\n-- :param number: Integer\n-- :return: Number of digits\nlocal function num_digits(number)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_45640_num_digits.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = num_digits\n    lu.assertEquals(candidate(3), 1)\n    lu.assertEquals(candidate(223100), 6)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(1000), 4)\n    lu.assertEquals(candidate(0), 1)\n    lu.assertEquals(candidate(23), 2)\n    lu.assertEquals(candidate(123), 3)\n    lu.assertEquals(candidate(12345), 5)\n    lu.assertEquals(candidate(99999999), 8)\n    lu.assertEquals(candidate(1234567890), 10)\n    lu.assertEquals(candidate(223), 3)\n    lu.assertEquals(candidate(123456), 6)\n    lu.assertEquals(candidate(999999), 6)\n    lu.assertEquals(candidate(10), 2)\n    lu.assertEquals(candidate(9999), 4)\n    lu.assertEquals(candidate(22310), 5)\n    lu.assertEquals(candidate(2231), 4)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_457283_unf_gas_density_kgm3", "language": "lua", "prompt": "-- Equation for gas density\n-- :param t_K: temperature\n-- :param p_MPaa: pressure\n-- :param gamma_gas: specific gas density by air\n-- :param z: z-factor\n-- :return: gas density\nlocal function unf_gas_density_kgm3(t_K, p_MPaa, gamma_gas, z)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_457283_unf_gas_density_kgm3.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = unf_gas_density_kgm3\n    lu.assertEquals(candidate(293.15, 101325, 0, 0.5), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_457405_count_tilings", "language": "lua", "prompt": "-- Returns the number of unique ways to tile a row of length n >= 1.\nlocal function count_tilings(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_457405_count_tilings.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = count_tilings\n    lu.assertEquals(candidate(4), 8)\n    lu.assertEquals(candidate(5), 15)\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(1), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_458323_parse_boolean", "language": "lua", "prompt": "-- Returns boolean representation of argument.\nlocal function parse_boolean(arg)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_458323_parse_boolean.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_boolean\n    lu.assertEquals(candidate(0), false)\n    lu.assertEquals(candidate('TRUE'), true)\n    lu.assertEquals(candidate('true'), true)\n    lu.assertEquals(candidate('True'), true)\n    lu.assertEquals(candidate(false), false)\n    lu.assertEquals(candidate('true'), true)\n    lu.assertEquals(candidate('FALSE'), false)\n    lu.assertEquals(candidate('false'), false)\n    lu.assertEquals(candidate('TRUE'), true)\n    lu.assertEquals(candidate('True'), true)\n    lu.assertEquals(candidate('False'), false)\n    lu.assertEquals(candidate('FALSE'), false)\n    lu.assertEquals(candidate('false'), false)\n    lu.assertEquals(candidate('0'), false)\n    lu.assertEquals(candidate(true), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_45854_check_fields_to_join", "language": "lua", "prompt": "-- Check which fields have been passed to be joined\nlocal function check_fields_to_join(fields_to_join)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_45854_check_fields_to_join.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = check_fields_to_join\n    lu.assertEquals(candidate({'oa', 'lad', 'gor'}), {true, true, true})\n    lu.assertEquals(candidate({'oa', 'lad'}), {true, true, false})\n    lu.assertEquals(candidate({'oa', 'gor'}), {true, false, true})\n    lu.assertEquals(candidate({'lad', 'gor'}), {false, true, true})\n    lu.assertEquals(candidate({}), {false, false, false})\n    lu.assertEquals(candidate({'lad'}), {false, true, false})\n    lu.assertEquals(candidate({'oa'}), {true, false, false})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_458724_pageHeader", "language": "lua", "prompt": "-- *Generate a pageHeader - TBS style*\n-- **Key Arguments:**\n--     - ``headline`` -- the headline text\n--     - ``tagline`` -- the tagline text for below the headline\n-- **Return:**\n--     - ``pageHeader`` -- the pageHeader\nlocal function pageHeader(headline, tagline)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_458724_pageHeader.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = pageHeader\n    lu.assertEquals(candidate('headline', 'tagline'), '\\n        <div class=\"page-header\" id=\"  \">\\n            <h1>headline<br><small>tagline</small></h1>\\n        </div>')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_46021_gauss_sum", "language": "lua", "prompt": "--  Computes the gaussian sum for an input number. \nlocal function gauss_sum(number)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_46021_gauss_sum.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = gauss_sum\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(10), 55)\n    lu.assertEquals(candidate(6), 21)\n    lu.assertEquals(candidate(20), 210)\n    lu.assertEquals(candidate(2), 3)\n    lu.assertEquals(candidate(7), 28)\n    lu.assertEquals(candidate(5), 15)\n    lu.assertEquals(candidate(2), 3)\n    lu.assertEquals(candidate(4), 10)\n    lu.assertEquals(candidate(3), 6)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_46688_get_variable_sites", "language": "lua", "prompt": "-- Get a list of sites where data[index] are stored\nlocal function get_variable_sites(index)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_46688_get_variable_sites.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_variable_sites\n    lu.assertEquals(candidate(21), {2})\n    lu.assertEquals(candidate(25), {6})\n    lu.assertEquals(candidate(19), {10})\n    lu.assertEquals(candidate(1), {2})\n    lu.assertEquals(candidate(23), {4})\n    lu.assertEquals(candidate(7), {8})\n    lu.assertEquals(candidate(15), {6})\n    lu.assertEquals(candidate(3), {4})\n    lu.assertEquals(candidate(17), {8})\n    lu.assertEquals(candidate(11), {2})\n    lu.assertEquals(candidate(5), {6})\n    lu.assertEquals(candidate(9), {10})\n    lu.assertEquals(candidate(13), {4})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_4747_create_url", "language": "lua", "prompt": "-- Method which creates new url from base url\n-- :param url: base url\n-- :param data: data to append to base url\n-- :return: new url\nlocal function create_url(url, data)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_4747_create_url.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = create_url\n    lu.assertEquals(candidate('http://example.com', 'test'), 'http://example.com/test')\n    lu.assertEquals(candidate('http://www.codewars.com', 'users/mattC'), 'http://www.codewars.com/users/mattC')\n    lu.assertEquals(candidate('https://www.reddit.com/r/dailyprogrammer/comments/2ofb7m/20140926_challenge_177_easy_morse_code', 'upvote'), 'https://www.reddit.com/r/dailyprogrammer/comments/2ofb7m/20140926_challenge_177_easy_morse_code/upvote')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_49061_format32BitHexStr", "language": "lua", "prompt": "-- format the given string which represents a valid 32-bit hexadecimal number.\n-- prefix \"0x\" will be added and will replace any valid prefix.\n-- alphabetic letter will be formatted into upper case.\n-- \"0\" will be used to fill the hexadecimal number if this number is represented as less than 8-letter.\n-- Exmaple usage:\n-- input: 0Xff  -> output:0x000000FF\n-- input: Ab -> output: 0x000000AB\n-- input 0xAf -> output: 0x000000AF\n-- :param hexStr:  a valid string representing a 32-bit hexadecimal number\n-- :return: a formatted string representing 32-bit hexadecimal number as described\nlocal function format32BitHexStr(hexStr)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_49061_format32BitHexStr.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = format32BitHexStr\n    lu.assertEquals(candidate('0xAF'), '0x000000AF')\n    lu.assertEquals(candidate('0xAB'), '0x000000AB')\n    lu.assertEquals(candidate('0XAB'), '0x000000AB')\n    lu.assertEquals(candidate('aB'), '0x000000AB')\n    lu.assertEquals(candidate('AB'), '0x000000AB')\n    lu.assertEquals(candidate('0XFF'), '0x000000FF')\n    lu.assertEquals(candidate('FF'), '0x000000FF')\n    lu.assertEquals(candidate('AF'), '0x000000AF')\n    lu.assertEquals(candidate('0xFF'), '0x000000FF')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_5015_SEARCH", "language": "lua", "prompt": "-- Returns the position at which a string is first found within text, ignoring case.\n-- Find is case-sensitive. The returned position is 1 if within_text starts with find_text.\n-- Start_num specifies the character at which to start the search, defaulting to 1 (the first\n-- character of within_text).\n-- If find_text is not found, or start_num is invalid, raises ValueError.\n-- >>> SEARCH(\"e\", \"Statements\", 6)\n-- 7\n-- >>> SEARCH(\"margin\", \"Profit Margin\")\n-- 8\n-- >>> SEARCH(\" \", \"Profit Margin\")\n-- 7\n-- >>> SEARCH('\"', 'The \"boss\" is here.')\n-- 5\n-- >>> SEARCH(\"gle\", \"Google\")\n-- 4\n-- >>> SEARCH(\"GLE\", \"Google\")\n-- 4\nlocal function SEARCH(find_text, within_text, start_num)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_5015_SEARCH.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = SEARCH\n    lu.assertEquals(candidate(' ', 'Profit Margin'), 7)\n    lu.assertEquals(candidate('GLE', 'Google'), 4)\n    lu.assertEquals(candidate('e', 'Statements', 6), 7)\n    lu.assertEquals(candidate('\"', 'The \"boss\" is here.'), 5)\n    lu.assertEquals(candidate('e', 'Statements', 6), 7)\n    lu.assertEquals(candidate('\"', 'The \"boss\" is here.'), 5)\n    lu.assertEquals(candidate('gle', 'Google'), 4)\n    lu.assertEquals(candidate('margin', 'Profit Margin'), 8)\n    lu.assertEquals(candidate(' ', 'Profit Margin'), 7)\n    lu.assertEquals(candidate('gle', 'Google'), 4)\n    lu.assertEquals(candidate('e', 'Statements', 6), 7)\n    lu.assertEquals(candidate('margin', 'Profit Margin'), 8)\n    lu.assertEquals(candidate('GLE', 'Google'), 4)\n    lu.assertEquals(candidate('g', 'Google', 4), 4)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_50398_task2", "language": "lua", "prompt": "--     Second task that depends on the output of the first task.\nlocal function task2(arg1)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_50398_task2.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = task2\n    lu.assertEquals(candidate(102), {true, {'arg1', 'arg2', 'arg3'}})\n    lu.assertEquals(candidate(104), {true, {'arg1', 'arg2', 'arg3'}})\n    lu.assertEquals(candidate(105), {true, {'arg1', 'arg2', 'arg3'}})\n    lu.assertEquals(candidate(101), {true, {'arg1', 'arg2', 'arg3'}})\n    lu.assertEquals(candidate(1), {true, {'arg1', 'arg2', 'arg3'}})\n    lu.assertEquals(candidate(3), {true, {'arg1', 'arg2', 'arg3'}})\n    lu.assertEquals(candidate(103), {true, {'arg1', 'arg2', 'arg3'}})\n    lu.assertEquals(candidate(2), {true, {'arg1', 'arg2', 'arg3'}})\n    lu.assertEquals(candidate(4), {true, {'arg1', 'arg2', 'arg3'}})\n    lu.assertEquals(candidate(5), {true, {'arg1', 'arg2', 'arg3'}})\n    lu.assertEquals(candidate(109), {true, {'arg1', 'arg2', 'arg3'}})\n    lu.assertEquals(candidate(108), {true, {'arg1', 'arg2', 'arg3'}})\n    lu.assertEquals(candidate(100), {true, {'arg1', 'arg2', 'arg3'}})\n    lu.assertEquals(candidate(107), {true, {'arg1', 'arg2', 'arg3'}})\n    lu.assertEquals(candidate(106), {true, {'arg1', 'arg2', 'arg3'}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_50616_suffixed_file_name", "language": "lua", "prompt": "--  Returns file path with appended string (preserving file type)\n-- :param file_path: (string) either relative or absolute path of file\n-- :param suffix_string: (string) string to append to the original file name\n-- :return: (string) suffixed file path\n-- example:\n--     append_path(\"foo.html.bar.html\", \"_BAZ\")\n--     >>> \"foo.html.bar.html_BAZ.html\"\nlocal function suffixed_file_name(file_path, suffix_string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_50616_suffixed_file_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = suffixed_file_name\n    lu.assertEquals(candidate('foo.html', ''), 'foo.html')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_50913__normalize_block_name", "language": "lua", "prompt": "-- Implements Unicode name normalization for block names.\n-- Removes white space, '-', '_' and forces lower case.\nlocal function _normalize_block_name(block_name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_50913__normalize_block_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _normalize_block_name\n    lu.assertEquals(candidate('A B C'), 'abc')\n    lu.assertEquals(candidate('Block_Name_ '), 'blockname')\n    lu.assertEquals(candidate('block-name'), 'blockname')\n    lu.assertEquals(candidate('foo bar'), 'foobar')\n    lu.assertEquals(candidate('foo\\nbar'), 'foobar')\n    lu.assertEquals(candidate('ABC_DEF'), 'abcdef')\n    lu.assertEquals(candidate('foo'), 'foo')\n    lu.assertEquals(candidate('foo-bar'), 'foobar')\n    lu.assertEquals(candidate('block name\\n\\r\\t'), 'blockname')\n    lu.assertEquals(candidate('\\t\\n\\rfoo-bar'), 'foobar')\n    lu.assertEquals(candidate('ABC-DEF'), 'abcdef')\n    lu.assertEquals(candidate('foo\\tbar'), 'foobar')\n    lu.assertEquals(candidate('Block-Name\\n\\r\\t'), 'blockname')\n    lu.assertEquals(candidate('Block_Name-'), 'blockname')\n    lu.assertEquals(candidate('A  B  C'), 'abc')\n    lu.assertEquals(candidate('A-B-C'), 'abc')\n    lu.assertEquals(candidate('Block_Name_'), 'blockname')\n    lu.assertEquals(candidate('block_name'), 'blockname')\n    lu.assertEquals(candidate('foo_bar'), 'foobar')\n    lu.assertEquals(candidate('A_B_C'), 'abc')\n    lu.assertEquals(candidate('Block-Name \\n\\r\\t'), 'blockname')\n    lu.assertEquals(candidate('ABC  DEF'), 'abcdef')\n    lu.assertEquals(candidate('  block-name \\n\\n\\t'), 'blockname')\n    lu.assertEquals(candidate('block name\\t'), 'blockname')\n    lu.assertEquals(candidate('blockname'), 'blockname')\n    lu.assertEquals(candidate('ABC'), 'abc')\n    lu.assertEquals(candidate('foo-bar_1'), 'foobar1')\n    lu.assertEquals(candidate('Block_Name'), 'blockname')\n    lu.assertEquals(candidate('foo-1_bar'), 'foo1bar')\n    lu.assertEquals(candidate('foo-bar-1'), 'foobar1')\n    lu.assertEquals(candidate('o-ya'), 'oya')\n    lu.assertEquals(candidate('block-name\\r\\n\\t'), 'blockname')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_51126_get_tag_line", "language": "lua", "prompt": "-- Get the revision hash for the tag matching the given project revision in\n-- the given lines containing revision hashes. Uses the given array of tag\n-- prefix strings if provided. For example, given an array of tag prefixes\n-- [\"checker-framework-\", \"checkers-\"] and project revision \"2.0.0\", the\n-- tags named \"checker-framework-2.0.0\" and \"checkers-2.0.0\" are sought.\nlocal function get_tag_line(lines, revision, tag_prefixes)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_51126_get_tag_line.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_tag_line\n    lu.assertEquals(candidate({'checkers-2.1.5', 'checkers-2.1.6'}, '2.1.5', {'checker-framework-', 'checkers-'}), 'checkers-2.1.5')\n    lu.assertEquals(candidate({'checker-framework-1.0.0', 'checker-framework-1.0.1'}, '1.0.1', {'checker-framework-'}), 'checker-framework-1.0.1')\n    lu.assertEquals(candidate({'checkers-2.1.6', 'checkers-2.1.5'}, '2.1.6', {'checker-framework-', 'checkers-'}), 'checkers-2.1.6')\n    lu.assertEquals(candidate({'checker-framework-2.0.0', 'checker-framework-2.0.1'}, '2.0.1', {'checker-framework-'}), 'checker-framework-2.0.1')\n    lu.assertEquals(candidate({'a', 'b', 'c'}, 'd', {'e', 'f'}), None)\n    lu.assertEquals(candidate({'checker-framework-2.0.0', 'checker-framework-2.0.1', 'checker-framework-2.0.2'}, '2.0.2', {'checker-framework-', 'checkers-'}), 'checker-framework-2.0.2')\n    lu.assertEquals(candidate({'checker-framework-2.1.10', 'checker-framework-2.1.11', 'checker-framework-2.2.0'}, '2.2.0', {'checker-framework-', 'checkers-'}), 'checker-framework-2.2.0')\n    lu.assertEquals(candidate({'checker-framework-2.0.0', 'checker-framework-2.0.1', 'checker-framework-2.0.2'}, '2.0.2', {}), None)\n    lu.assertEquals(candidate({'checker-framework-2.1.10', 'checker-framework-2.1.11', 'checker-framework-2.2.0'}, '2.2.0', {'checker-framework-'}), 'checker-framework-2.2.0')\n    lu.assertEquals(candidate({'checkers-2.1.5', 'checkers-2.1.6'}, '2.1.6', {'checker-framework-', 'checkers-'}), 'checkers-2.1.6')\n    lu.assertEquals(candidate({'checker-framework-2.1.6', 'checker-framework-2.1.5'}, '2.1.6', {'checker-framework-', 'checkers-'}), 'checker-framework-2.1.6')\n    lu.assertEquals(candidate({'checker-framework-2.0.0', 'checker-framework-2.0.1'}, '2.0.1', {'checkers-'}), None)\n    lu.assertEquals(candidate({'checkers-2.1.6', 'checkers-2.1.5'}, '2.1.5', {'checker-framework-', 'checkers-'}), 'checkers-2.1.5')\n    lu.assertEquals(candidate({'checker-framework-2.0.0', 'checker-framework-2.0.1', 'checker-framework-2.0.2'}, '2.0.2', {'checker-framework-'}), 'checker-framework-2.0.2')\n    lu.assertEquals(candidate({'checker-framework-2.1.6', 'checker-framework-2.1.5'}, '2.1.5', {'checker-framework-', 'checkers-'}), 'checker-framework-2.1.5')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_51134_extract_class_label", "language": "lua", "prompt": "--     arg:\n-- filename: string, e.g.\n-- 'images/001.Black_footed_Albatross/Black_footed_Albatross_0001_2950163169.jpg'\n--     return:\n-- A class label as integer, e.g. 1\nlocal function extract_class_label(filename)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_51134_extract_class_label.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = extract_class_label\n    lu.assertEquals(candidate('images/002.Laysan_Albatross/Laysan_Albatross_0004_2950165039.jpg'), 2)\n    lu.assertEquals(candidate('images/007.Parakeet_Auklet/Parakeet_Auklet_0002_2950163991.jpg'), 7)\n    lu.assertEquals(candidate('images/001.Black_footed_Albatross/Black_footed_Albatross_0001_2950163169.jpg'), 1)\n    lu.assertEquals(candidate('images/003.Sooty_Albatross/Sooty_Albatross_0005_2950164871.jpg'), 3)\n    lu.assertEquals(candidate('images/006.Least_Auklet/Least_Auklet_0001_2950163844.jpg'), 6)\n    lu.assertEquals(candidate('images/004.Groove_billed_Ani/Groove_billed_Ani_0001_2950166344.jpg'), 4)\n    lu.assertEquals(candidate('images/005.Crested_Auklet/Crested_Auklet_0005_2950164507.jpg'), 5)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_51820_getcardinals", "language": "lua", "prompt": "-- Get lats and longs to mark on map\n-- :param minv:\n-- :type minv: float\n-- :param maxv:\n-- :type maxv: float\n-- :param stepv:\n-- :type stepv: int\n-- :return:\n-- :rtype: list\nlocal function getcardinals(minv, maxv, stepv)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_51820_getcardinals.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = getcardinals\n    lu.assertEquals(candidate(-5, 5, 1), {-5, -4, -3, -2, -1, 0, 1, 2, 3, 4})\n    lu.assertEquals(candidate(0, 360, 360), {0})\n    lu.assertEquals(candidate(1, 5, 1), {1, 2, 3, 4})\n    lu.assertEquals(candidate(0, 100, 20), {0, 20, 40, 60, 80})\n    lu.assertEquals(candidate(2, 9, 2), {2, 4, 6, 8})\n    lu.assertEquals(candidate(0, 360, 90), {0, 90, 180, 270})\n    lu.assertEquals(candidate(0, 10, 6), {0, 6})\n    lu.assertEquals(candidate(1, 10, 1), {1, 2, 3, 4, 5, 6, 7, 8, 9})\n    lu.assertEquals(candidate(10, 100, 10), {10, 20, 30, 40, 50, 60, 70, 80, 90})\n    lu.assertEquals(candidate(0, 10, 1), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9})\n    lu.assertEquals(candidate(0, 5, 2), {0, 2, 4})\n    lu.assertEquals(candidate(0, 5, 3), {0, 3})\n    lu.assertEquals(candidate(0, 10, 2), {0, 2, 4, 6, 8})\n    lu.assertEquals(candidate(0, 5, 1), {0, 1, 2, 3, 4})\n    lu.assertEquals(candidate(10, 100, 200), {})\n    lu.assertEquals(candidate(20, 100, 10), {20, 30, 40, 50, 60, 70, 80, 90})\n    lu.assertEquals(candidate(360, 0, 360), {})\n    lu.assertEquals(candidate(0, 10, 5), {0, 5})\n    lu.assertEquals(candidate(0, 10, 4), {0, 4, 8})\n    lu.assertEquals(candidate(10, 100, 100), {})\n    lu.assertEquals(candidate(0, 5, 4), {0, 4})\n    lu.assertEquals(candidate(0, 10, 3), {0, 3, 6, 9})\n    lu.assertEquals(candidate(1, 11, 1), {1, 2, 3, 4, 5, 6, 7, 8, 9, 10})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_51944_validate_stdout", "language": "lua", "prompt": "-- :param stdout:\n-- :return: true if stdout does not indicate test failure\nlocal function validate_stdout(stdout)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_51944_validate_stdout.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = validate_stdout\n    lu.assertEquals(candidate('Hello World'), true)\n    lu.assertEquals(candidate('Hello!!!PANIC!!! World'), false)\n    lu.assertEquals(candidate('Hello!!!PANIC!!!'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_52012_sqlite3_column_affinity", "language": "lua", "prompt": "-- Return the sqlite3 column affinity corresponding to a type string.\nlocal function sqlite3_column_affinity(column_type)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_52012_sqlite3_column_affinity.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sqlite3_column_affinity\n    lu.assertEquals(candidate('BLOB(12)'), 'NONE')\n    lu.assertEquals(candidate('VARCHAR(12)'), 'TEXT')\n    lu.assertEquals(candidate('CHARACTER VARYING'), 'TEXT')\n    lu.assertEquals(candidate('CHARACTER VARYING(12)'), 'TEXT')\n    lu.assertEquals(candidate('not a number'), 'NUMERIC')\n    lu.assertEquals(candidate('blob(12)'), 'NONE')\n    lu.assertEquals(candidate('DOUBLE'), 'REAL')\n    lu.assertEquals(candidate('DOUBLE(12)'), 'REAL')\n    lu.assertEquals(candidate('CHARACTER'), 'TEXT')\n    lu.assertEquals(candidate('CHARACTER(12)'), 'TEXT')\n    lu.assertEquals(candidate('text'), 'TEXT')\n    lu.assertEquals(candidate('TEXT'), 'TEXT')\n    lu.assertEquals(candidate('DOUBLE PRECISION(12)'), 'REAL')\n    lu.assertEquals(candidate(str('1234567890123456789012345678901234567890')), 'NUMERIC')\n    lu.assertEquals(candidate('REAL'), 'REAL')\n    lu.assertEquals(candidate('CLOB'), 'TEXT')\n    lu.assertEquals(candidate(str(-1234567890123456789012345678901234567890)), 'NUMERIC')\n    lu.assertEquals(candidate('Int'), 'INTEGER')\n    lu.assertEquals(candidate(str('-1234567890123456789012345678901234567890')), 'NUMERIC')\n    lu.assertEquals(candidate('BLOB'), 'NONE')\n    lu.assertEquals(candidate('FLOAT'), 'REAL')\n    lu.assertEquals(candidate('CHAR(12)'), 'TEXT')\n    lu.assertEquals(candidate('CLOB(12)'), 'TEXT')\n    lu.assertEquals(candidate('FLOAT(12)'), 'REAL')\n    lu.assertEquals(candidate(str(1234567890123456789012345678901234567890)), 'NUMERIC')\n    lu.assertEquals(candidate('VARCHAR'), 'TEXT')\n    lu.assertEquals(candidate('DOUBLE PRECISION'), 'REAL')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_5259_without_end_slash", "language": "lua", "prompt": "-- Makes sure there is no end slash at the end of a url.\nlocal function without_end_slash(url)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_5259_without_end_slash.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = without_end_slash\n    lu.assertEquals(candidate('www.python.org/books'), 'www.python.org/books')\n    lu.assertEquals(candidate('http://python.org/'), 'http://python.org')\n    lu.assertEquals(candidate('http://www.hackerrank.com/challenges/nested-list/'), 'http://www.hackerrank.com/challenges/nested-list')\n    lu.assertEquals(candidate('http://python.org/books'), 'http://python.org/books')\n    lu.assertEquals(candidate('http://www.python.org/'), 'http://www.python.org')\n    lu.assertEquals(candidate('python.org/books'), 'python.org/books')\n    lu.assertEquals(candidate('www.python.org/'), 'www.python.org')\n    lu.assertEquals(candidate('python.org/books/'), 'python.org/books')\n    lu.assertEquals(candidate('http://python.org'), 'http://python.org')\n    lu.assertEquals(candidate('http://www.python.org/books'), 'http://www.python.org/books')\n    lu.assertEquals(candidate('www.python.org'), 'www.python.org')\n    lu.assertEquals(candidate('http://www.python.org/books/'), 'http://www.python.org/books')\n    lu.assertEquals(candidate('python.org/'), 'python.org')\n    lu.assertEquals(candidate('http://www.python.org'), 'http://www.python.org')\n    lu.assertEquals(candidate('www.python.org/books/'), 'www.python.org/books')\n    lu.assertEquals(candidate('http://python.org/books/'), 'http://python.org/books')\n    lu.assertEquals(candidate('http://www.hackerrank.com/challenges/nested-list'), 'http://www.hackerrank.com/challenges/nested-list')\n    lu.assertEquals(candidate('python.org'), 'python.org')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_52634__clear_data", "language": "lua", "prompt": "-- Check and clear data\nlocal function _clear_data(data, need_fields_tuple)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_52634__clear_data.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _clear_data\n    lu.assertEquals(candidate({['A'] = 1, ['B'] = 2, ['C'] = 3}, {'A', 'C'}), {['A'] = 1, ['C'] = 3})\n    lu.assertEquals(candidate({['A'] = 1, ['B'] = 2, ['C'] = 3}, {'A', 'B'}), {['A'] = 1, ['B'] = 2})\n    lu.assertEquals(candidate({['A'] = 1, ['B'] = 2, ['C'] = 3}, {}), {})\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3}, {'a', 'b'}), {['a'] = 1, ['b'] = 2})\n    lu.assertEquals(candidate({['A'] = 1, ['B'] = 2, ['C'] = 3}, {'C', 'B'}), {['C'] = 3, ['B'] = 2})\n    lu.assertEquals(candidate({['a'] = 1, ['b'] = 2, ['c'] = 3}, {}), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_52943_Hubble", "language": "lua", "prompt": "--  LCDM AP parameter auxiliary function \nlocal function Hubble(Om, z)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_52943_Hubble.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = Hubble\n    lu.assertEquals(candidate(1, 0), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_5314_int_to_float", "language": "lua", "prompt": "-- Converts a uniformly random [[64-bit computing|64-bit]]\n-- integer to uniformly random floating point number on interval <math>[0, 1)</math>.\nlocal function int_to_float(value)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_5314_int_to_float.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = int_to_float\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(18446744073709551615), 0.9999999999999999)\n    lu.assertEquals(candidate(-1), 0.9999999999999999)\n    lu.assertEquals(candidate(0), 0.0)\n    lu.assertEquals(candidate(0), 0.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_54360_has_seven", "language": "lua", "prompt": "-- Returns True if at least one of the digits of k is a 7, False otherwise.\n-- >>> has_seven(3)\n-- False\n-- >>> has_seven(7)\n-- True\n-- >>> has_seven(2734)\n-- True\n-- >>> has_seven(2634)\n-- False\n-- >>> has_seven(734)\n-- True\n-- >>> has_seven(7777)\n-- True\n-- >>> from construct_check import check\n-- >>> check(HW_SOURCE_FILE, 'has_seven',\n-- ...       ['Assign', 'AugAssign'])\n-- True\nlocal function has_seven(k)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_54360_has_seven.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = has_seven\n    lu.assertEquals(candidate(7), true)\n    lu.assertEquals(candidate(734), true)\n    lu.assertEquals(candidate(11235813), false)\n    lu.assertEquals(candidate(2734), true)\n    lu.assertEquals(candidate(3), false)\n    lu.assertEquals(candidate(7777), true)\n    lu.assertEquals(candidate(1234), false)\n    lu.assertEquals(candidate(300000000), false)\n    lu.assertEquals(candidate(2634), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_5448_POS", "language": "lua", "prompt": "-- Returns 'F' if position indicator is present. The AllSportCG sends a * in a specific position to indicate which\n-- team has posession, and this changes that character to an 'F'. Using font Mattbats, F is a football.\nlocal function POS(POSInt)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_5448_POS.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = POS\n    lu.assertEquals(candidate(24), '')\n    lu.assertEquals(candidate(29), '')\n    lu.assertEquals(candidate(14), '')\n    lu.assertEquals(candidate(21), '')\n    lu.assertEquals(candidate(20), '')\n    lu.assertEquals(candidate(42), 'F')\n    lu.assertEquals(candidate(0), '')\n    lu.assertEquals(candidate(13), '')\n    lu.assertEquals(candidate(19), '')\n    lu.assertEquals(candidate(7), '')\n    lu.assertEquals(candidate(25), '')\n    lu.assertEquals(candidate(27), '')\n    lu.assertEquals(candidate(34), '')\n    lu.assertEquals(candidate(), 'F')\n    lu.assertEquals(candidate(39), '')\n    lu.assertEquals(candidate(28), '')\n    lu.assertEquals(candidate(5), '')\n    lu.assertEquals(candidate(37), '')\n    lu.assertEquals(candidate(2), '')\n    lu.assertEquals(candidate(11), '')\n    lu.assertEquals(candidate(12), '')\n    lu.assertEquals(candidate(18), '')\n    lu.assertEquals(candidate(41), '')\n    lu.assertEquals(candidate(23), '')\n    lu.assertEquals(candidate(40), '')\n    lu.assertEquals(candidate(4), '')\n    lu.assertEquals(candidate(3), '')\n    lu.assertEquals(candidate(36), '')\n    lu.assertEquals(candidate(43), '')\n    lu.assertEquals(candidate(17), '')\n    lu.assertEquals(candidate(30), '')\n    lu.assertEquals(candidate(9), '')\n    lu.assertEquals(candidate(), '')\n    lu.assertEquals(candidate(32), '')\n    lu.assertEquals(candidate(42), 'F')\n    lu.assertEquals(candidate(10), '')\n    lu.assertEquals(candidate(35), '')\n    lu.assertEquals(candidate(38), '')\n    lu.assertEquals(candidate(16), '')\n    lu.assertEquals(candidate(22), '')\n    lu.assertEquals(candidate(1), '')\n    lu.assertEquals(candidate(6), '')\n    lu.assertEquals(candidate(26), '')\n    lu.assertEquals(candidate(8), '')\n    lu.assertEquals(candidate(31), '')\n    lu.assertEquals(candidate(15), '')\n    lu.assertEquals(candidate(33), '')\n    lu.assertEquals(candidate(3), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_55281_get_name_from_selector", "language": "lua", "prompt": "--     A basic method to get the name from a name selector.\nlocal function get_name_from_selector(selector)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_55281_get_name_from_selector.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_name_from_selector\n    lu.assertEquals(candidate('name=x'), 'x')\n    lu.assertEquals(candidate('&'), '')\n    lu.assertEquals(candidate('x'), 'x')\n    lu.assertEquals(candidate('&x'), 'x')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_55787_get_custom_kickstart_name", "language": "lua", "prompt": "-- This function is to generate a name for the custom kickstart file based on the type of OS and server serial number\n-- Arguments:\n--     os_type {string}              -- Type of the opertaing system - RHEL\n--     server_serial_number {string} -- Server serial number\n-- Returns:\n--     string -- custom kickstart filename\nlocal function get_custom_kickstart_name(os_type, server_serial_number)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_55787_get_custom_kickstart_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_custom_kickstart_name\n    lu.assertEquals(candidate('RHEL', '8888888888'), 'RHEL8888888888_ks.cfg')\n    lu.assertEquals(candidate('RHEL', '123456'), 'RHEL123456_ks.cfg')\n    lu.assertEquals(candidate('RHEL', 'C2251756072'), 'RHELC2251756072_ks.cfg')\n    lu.assertEquals(candidate('RHEL', '7777777777'), 'RHEL7777777777_ks.cfg')\n    lu.assertEquals(candidate('RHEL', 'C2251756072'), 'RHELC2251756072_ks.cfg')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_56082_drop_role", "language": "lua", "prompt": "-- Helper method to construct SQL: drop role.\nlocal function drop_role(role)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_56082_drop_role.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = drop_role\n    lu.assertEquals(candidate(), 'DROP ROLE IF EXISTS my_role;')\n    lu.assertEquals(candidate('a'), 'DROP ROLE IF EXISTS a;')\n    lu.assertEquals(candidate('my_role'), 'DROP ROLE IF EXISTS my_role;')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_56324_dice_roll", "language": "lua", "prompt": "--  Dice roll as number of rolls (eg 6) or as num and sides (2x6)\nlocal function dice_roll(arg)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_56324_dice_roll.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = dice_roll\n    lu.assertEquals(candidate('1x-2'), None)\n    lu.assertEquals(candidate('x5y6'), None)\n    lu.assertEquals(candidate('5x10'), {5, 10})\n    lu.assertEquals(candidate('5x6 3'), None)\n    lu.assertEquals(candidate('5 6'), None)\n    lu.assertEquals(candidate('6'), {6, 6})\n    lu.assertEquals(candidate('5x6x3x9x8'), None)\n    lu.assertEquals(candidate('x5x6'), None)\n    lu.assertEquals(candidate('2x0'), None)\n    lu.assertEquals(candidate(' '), None)\n    lu.assertEquals(candidate('5y6x'), None)\n    lu.assertEquals(candidate('4x6'), {4, 6})\n    lu.assertEquals(candidate('18x20'), {18, 20})\n    lu.assertEquals(candidate('x4'), None)\n    lu.assertEquals(candidate('5x6x3'), None)\n    lu.assertEquals(candidate('5x12'), {5, 12})\n    lu.assertEquals(candidate('0x1'), None)\n    lu.assertEquals(candidate('5x6y3'), None)\n    lu.assertEquals(candidate('-1x2'), None)\n    lu.assertEquals(candidate('1x1'), {1, 1})\n    lu.assertEquals(candidate('2x4'), {2, 4})\n    lu.assertEquals(candidate('\\n'), None)\n    lu.assertEquals(candidate('1x0'), None)\n    lu.assertEquals(candidate('5y6'), None)\n    lu.assertEquals(candidate('2'), {2, 6})\n    lu.assertEquals(candidate('2x'), None)\n    lu.assertEquals(candidate(''), None)\n    lu.assertEquals(candidate('\\t'), None)\n    lu.assertEquals(candidate('0x0'), None)\n    lu.assertEquals(candidate('2x6'), {2, 6})\n    lu.assertEquals(candidate('3x6'), {3, 6})\n    lu.assertEquals(candidate('5x6x3x9'), None)\n    lu.assertEquals(candidate('1x2'), {1, 2})\n    lu.assertEquals(candidate('5x6x'), None)\n    lu.assertEquals(candidate('-1x-2'), None)\n    lu.assertEquals(candidate('1x10'), {1, 10})\n    lu.assertEquals(candidate('5y6x3'), None)\n    lu.assertEquals(candidate('5x6'), {5, 6})\n    lu.assertEquals(candidate('5x6y'), None)\n    lu.assertEquals(candidate('1x100'), {1, 100})\n    lu.assertEquals(candidate('x5x6y'), None)\n    lu.assertEquals(candidate('10x4'), {10, 4})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_56391_charCodeAt", "language": "lua", "prompt": "-- Returns the Unicode value of the character at the specified location.\n-- @param - index The zero-based index of the desired character.\n-- If there is no character at the specified index, NaN is returned.\n-- This was added for compatibility with python\nlocal function charCodeAt(src, pos)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_56391_charCodeAt.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = charCodeAt\n    lu.assertEquals(candidate('', 0), None)\n    lu.assertEquals(candidate('abc', -2), 98)\n    lu.assertEquals(candidate('abc', -3), 97)\n    lu.assertEquals(candidate('', -1), None)\n    lu.assertEquals(candidate('hello world', 21), None)\n    lu.assertEquals(candidate('abc', 3), None)\n    lu.assertEquals(candidate('abc', 3), None)\n    lu.assertEquals(candidate('abc', 1), 98)\n    lu.assertEquals(candidate('hello world', 1), 101)\n    lu.assertEquals(candidate('abc', 0), 97)\n    lu.assertEquals(candidate('abc', -4), None)\n    lu.assertEquals(candidate('abc', 2), 99)\n    lu.assertEquals(candidate('hello world', 2), 108)\n    lu.assertEquals(candidate('\ud83d\ude0a\ud83d\udc0d', 3), None)\n    lu.assertEquals(candidate('abc', 2), 99)\n    lu.assertEquals(candidate('\ud83d\ude0a\ud83d\udc0d', -4), None)\n    lu.assertEquals(candidate('abc', 0), 97)\n    lu.assertEquals(candidate('abc', 1), 98)\n    lu.assertEquals(candidate('', 2), None)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_56448_filter", "language": "lua", "prompt": "--  Filters a plain text and makes it acceptable for docbook \nlocal function filter(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_56448_filter.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = filter\n    lu.assertEquals(candidate('abc'), 'abc')\n    lu.assertEquals(candidate('<><>'), '&lt;&gt;&lt;&gt;')\n    lu.assertEquals(candidate('>'), '&gt;')\n    lu.assertEquals(candidate('<>'), '&lt;&gt;')\n    lu.assertEquals(candidate('foo'), 'foo')\n    lu.assertEquals(candidate('<Hello world>'), '&lt;Hello world&gt;')\n    lu.assertEquals(candidate('<'), '&lt;')\n    lu.assertEquals(candidate('a < b'), 'a &lt; b')\n    lu.assertEquals(candidate(None), '')\n    lu.assertEquals(candidate('this is plain text'), 'this is plain text')\n    lu.assertEquals(candidate('Hello world!'), 'Hello world!')\n    lu.assertEquals(candidate('><'), '&gt;&lt;')\n    lu.assertEquals(candidate('a'), 'a')\n    lu.assertEquals(candidate(''), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_56655_bool_to_string", "language": "lua", "prompt": "-- Convert a boolean type to string.\n-- Args:\n--     b (bool): A Boolean.\n-- Raises:\n--     TypeError\n-- Returns:\n--     str: String representation of a bool type.\nlocal function bool_to_string(b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_56655_bool_to_string.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = bool_to_string\n    lu.assertEquals(candidate(bool(false)), candidate(false))\n    lu.assertEquals(candidate(bool(true)), candidate(true))\n    lu.assertEquals(candidate(true), 'true')\n    lu.assertEquals(candidate(false), 'false')\n    lu.assertEquals(candidate(true), candidate(bool(true)))\n    lu.assertEquals(candidate(bool(false)), 'false')\n    lu.assertEquals(candidate(false), candidate(bool(false)))\n    lu.assertEquals(candidate(bool(true)), 'true')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_56738_sum_of_powers", "language": "lua", "prompt": "-- Sums each number raised to power\n-- Ex: sum_of_powers([2, 3, 4], 2) = 2^2 + 3^2 + 4^2 = 29\nlocal function sum_of_powers(numbers, power)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_56738_sum_of_powers.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sum_of_powers\n    lu.assertEquals(candidate({1, 2, 3}, 3), 36)\n    lu.assertEquals(candidate({2, 3, 4}, 2), 29)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_56766_factorial", "language": "lua", "prompt": "-- Returns the factorial of the number, the product of all positive integers smaller or equal to the number.\n-- By convention an empty product is considered 1, meaning factorial(0) will return 1.\n-- :param k: A positive integer\n-- :return: The factorial of that integer\nlocal function factorial(k)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_56766_factorial.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = factorial\n    lu.assertEquals(candidate(17), 355687428096000)\n    lu.assertEquals(candidate(9), 362880)\n    lu.assertEquals(candidate(20), 2432902008176640000)\n    lu.assertEquals(candidate(5), 120)\n    lu.assertEquals(candidate(11), 39916800)\n    lu.assertEquals(candidate(14), 87178291200)\n    lu.assertEquals(candidate(10), 3628800)\n    lu.assertEquals(candidate(0), 1)\n    lu.assertEquals(candidate(12), 479001600)\n    lu.assertEquals(candidate(8), 40320)\n    lu.assertEquals(candidate(13), 6227020800)\n    lu.assertEquals(candidate(15), 1307674368000)\n    lu.assertEquals(candidate(6), 720)\n    lu.assertEquals(candidate(18), 6402373705728000)\n    lu.assertEquals(candidate(4), 24)\n    lu.assertEquals(candidate(3), 6)\n    lu.assertEquals(candidate(16), 20922789888000)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(7), 5040)\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(19), 121645100408832000)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_57139_build_type_flag", "language": "lua", "prompt": "-- returns flags specific to the build type (Debug, Release, etc.)\n-- (-s, -g, /Zi, etc.)\nlocal function build_type_flag(compiler, build_type)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_57139_build_type_flag.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = build_type_flag\n    lu.assertEquals(candidate('Visual Studio', 'Release'), '')\n    lu.assertEquals(candidate('Visual Studio', 'Debug'), '-Zi')\n    lu.assertEquals(candidate('foo', 'RelWithDebInfo'), '')\n    lu.assertEquals(candidate(None, 'Release'), '')\n    lu.assertEquals(candidate(None, 'Release'), '')\n    lu.assertEquals(candidate('Visual Studio', 'RelWithDebInfo'), '')\n    lu.assertEquals(candidate('Visual Studio', None), '')\n    lu.assertEquals(candidate('foo', None), '')\n    lu.assertEquals(candidate('foo', 'Release'), '')\n    lu.assertEquals(candidate(None, 'RelWithDebInfo'), '')\n    lu.assertEquals(candidate(None, 'Debug'), '')\n    lu.assertEquals(candidate(None, None), '')\n    lu.assertEquals(candidate('Visual Studio', 'Debug'), '-Zi')\n    lu.assertEquals(candidate('Visual Studio', None), '')\n    lu.assertEquals(candidate('gcc', 'Debug'), '-g')\n    lu.assertEquals(candidate('gcc', None), '')\n    lu.assertEquals(candidate('gcc', 'Release'), '-s')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_57161_remove_cdata_tags_from_every_node", "language": "lua", "prompt": "-- [removes a CDATA tag from every node in the document] \nlocal function remove_cdata_tags_from_every_node(content)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_57161_remove_cdata_tags_from_every_node.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_cdata_tags_from_every_node\n    lu.assertEquals(candidate('<![CDATA[this is a cdata]]>'), '<this is a cdata>')\n    lu.assertEquals(candidate('this is not a cdata'), 'this is not a cdata')\n    lu.assertEquals(candidate('<div>Hi there</div>'), '<div>Hi there</div>')\n    lu.assertEquals(candidate('I am not a CDATA tag!'), 'I am not a CDATA tag!')\n    lu.assertEquals(candidate('<a><b><![CDATA[this is a cdata]]></b></a>'), '<a><b><this is a cdata></b></a>')\n    lu.assertEquals(candidate('<a><b><![CDATA[this is not a cdata]]></b><![CDATA[so this one too]]></a>'), '<a><b><this is not a cdata></b><so this one too></a>')\n    lu.assertEquals(candidate('<![CDATA[this is not a cdata]]><![CDATA[so this one too]]>'), '<this is not a cdata><so this one too>')\n    lu.assertEquals(candidate(''), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_57396_convert_case", "language": "lua", "prompt": "--     Given a string in snake case, conver to CamelCase\nlocal function convert_case(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_57396_convert_case.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = convert_case\n    lu.assertEquals(candidate('this_is_snake_case'), 'ThisIsSnakeCase')\n    lu.assertEquals(candidate('James'), 'James')\n    lu.assertEquals(candidate('sally_brown'), 'SallyBrown')\n    lu.assertEquals(candidate('this_is_snake_case_too'), 'ThisIsSnakeCaseToo')\n    lu.assertEquals(candidate('Sally_Brown'), 'SallyBrown')\n    lu.assertEquals(candidate('sAlly_bRoWn'), 'SallyBrown')\n    lu.assertEquals(candidate('this__is__snake__case_too'), 'ThisIsSnakeCaseToo')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_57398_correct_sentence", "language": "lua", "prompt": "-- returns a corrected sentence which starts with a capital letter\n-- and ends with a dot.\nlocal function correct_sentence(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_57398_correct_sentence.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = correct_sentence\n    lu.assertEquals(candidate('hello world.'), 'Hello world.')\n    lu.assertEquals(candidate('hello world'), 'Hello world.')\n    lu.assertEquals(candidate('hello world.'), 'Hello world.')\n    lu.assertEquals(candidate('hello world'), 'Hello world.')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_58289_api_repo_url", "language": "lua", "prompt": "-- With the supplied organization name, constructs a GitHub API URL\n-- :param org_name: GitHub organization name\n-- :return: URL to GitHub API to query org's repos\nlocal function api_repo_url(org_name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_58289_api_repo_url.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = api_repo_url\n    lu.assertEquals(candidate('github'), 'https://api.github.com/orgs/github/repos')\n    lu.assertEquals(candidate('org2'), 'https://api.github.com/orgs/org2/repos')\n    lu.assertEquals(candidate('google'), 'https://api.github.com/orgs/google/repos')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_5841__root_sort_key", "language": "lua", "prompt": "-- Allow root comparison when sorting.\n-- Args:\n--     root (str or re.Pattern): Root.\n-- Returns:\n--     str: Comparable root string.\nlocal function _root_sort_key(root)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_5841__root_sort_key.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _root_sort_key\n    lu.assertEquals(candidate('^/a/b/?$'), '^/a/b/?$')\n    lu.assertEquals(candidate('^/foo/bar/baz/quux/a[b]c.*$'), '^/foo/bar/baz/quux/a[b]c.*$')\n    lu.assertEquals(candidate('^/foo/bar/baz/quux/a[b]c.*'), '^/foo/bar/baz/quux/a[b]c.*')\n    lu.assertEquals(candidate('.*'), '.*')\n    lu.assertEquals(candidate('foo'), 'foo')\n    lu.assertEquals(candidate('/?$'), '/?$')\n    lu.assertEquals(candidate('^/$'), '^/$')\n    lu.assertEquals(candidate('^/foo/bar/baz/quux/.*'), '^/foo/bar/baz/quux/.*')\n    lu.assertEquals(candidate('root_2'), 'root_2')\n    lu.assertEquals(candidate('^/foo/bar/baz/quux$'), '^/foo/bar/baz/quux$')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_59500_lr_schedule_adam", "language": "lua", "prompt": "-- Learning Rate Schedule\n-- # Arguments\n--     epoch (int): The number of epochs\n-- # Returns\n--     lr (float32): learning rate\nlocal function lr_schedule_adam(epoch)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_59500_lr_schedule_adam.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = lr_schedule_adam\n    lu.assertEquals(candidate(100), 0.001)\n    lu.assertEquals(candidate(400), 1e-05)\n    lu.assertEquals(candidate(200), 0.0005)\n    lu.assertEquals(candidate(10), 0.001)\n    lu.assertEquals(candidate(0), 0.001)\n    lu.assertEquals(candidate(50), 0.001)\n    lu.assertEquals(candidate(50), 0.001)\n    lu.assertEquals(candidate(200), 0.0005)\n    lu.assertEquals(candidate(149), 0.0005)\n    lu.assertEquals(candidate(0), 0.001)\n    lu.assertEquals(candidate(151), 0.0005)\n    lu.assertEquals(candidate(99), 0.001)\n    lu.assertEquals(candidate(49), 0.001)\n    lu.assertEquals(candidate(150), 0.0005)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_60112_set_to_dm_limits", "language": "lua", "prompt": "-- Check that the values for piston, tip, and tilt are not exceeding the hardware\n-- limit and reset to limit if limit is exceeded. These limits are the same as what\n-- the IrisAO GUI has set.\n-- :param ppt_list: list, of tuples existing of piston, tip, tilt, values for each\n--                  segment in a pupil, in DM units\n-- :param limit: float, in DM units. Default = 5.\n-- :return: list of tuples of the piston, tip, tilt values in DM units for each segment listed\n--          such that none of the values exceed the limit\nlocal function set_to_dm_limits(ptt_list, limit)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_60112_set_to_dm_limits.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = set_to_dm_limits\n    lu.assertEquals(candidate({{0.2, 0.5, 0.3, 1000.0}, {0.5, 0.5, 0.3, 0.1}, {0.4, 0.5, 0.3, 0.1}}), {{0.2, 0.5, 0.3, 5.0}, {0.5, 0.5, 0.3, 0.1}, {0.4, 0.5, 0.3, 0.1}})\n    lu.assertEquals(candidate({{0.2, 0.5, 0.3, 0.2}, {0.5, 0.5, 0.3, 0.1}, {0.4, 0.5, 0.3, 0.1}}), {{0.2, 0.5, 0.3, 0.2}, {0.5, 0.5, 0.3, 0.1}, {0.4, 0.5, 0.3, 0.1}})\n    lu.assertEquals(candidate({{0.2, 0.5, 0.3, 0.2}, {0.5, 0.5, 0.3, 0.1}, {0.4, 0.5, 0.3, 0.1}}, 1.0), {{0.2, 0.5, 0.3, 0.2}, {0.5, 0.5, 0.3, 0.1}, {0.4, 0.5, 0.3, 0.1}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_60491_prime_factors", "language": "lua", "prompt": "-- Compute the prime factors of the given number\n-- :param n: Number you want to compute the prime factors (intger)\n-- :return: Prime factors of the given number (list of integer)\nlocal function prime_factors(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_60491_prime_factors.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = prime_factors\n    lu.assertEquals(candidate(15), {3, 5})\n    lu.assertEquals(candidate(21), {3, 7})\n    lu.assertEquals(candidate(4), {2, 2})\n    lu.assertEquals(candidate(6), {2, 3})\n    lu.assertEquals(candidate(19), {19})\n    lu.assertEquals(candidate(13), {13})\n    lu.assertEquals(candidate(12), {2, 2, 3})\n    lu.assertEquals(candidate(26), {2, 13})\n    lu.assertEquals(candidate(3), {3})\n    lu.assertEquals(candidate(8), {2, 2, 2})\n    lu.assertEquals(candidate(10), {2, 5})\n    lu.assertEquals(candidate(0), {})\n    lu.assertEquals(candidate(2), {2})\n    lu.assertEquals(candidate(24), {2, 2, 2, 3})\n    lu.assertEquals(candidate(18), {2, 3, 3})\n    lu.assertEquals(candidate(1), {})\n    lu.assertEquals(candidate(16), {2, 2, 2, 2})\n    lu.assertEquals(candidate(20), {2, 2, 5})\n    lu.assertEquals(candidate(23), {23})\n    lu.assertEquals(candidate(14), {2, 7})\n    lu.assertEquals(candidate(22), {2, 11})\n    lu.assertEquals(candidate(11), {11})\n    lu.assertEquals(candidate(9), {3, 3})\n    lu.assertEquals(candidate(25), {5, 5})\n    lu.assertEquals(candidate(5), {5})\n    lu.assertEquals(candidate(17), {17})\n    lu.assertEquals(candidate(7), {7})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_6077_get_index_str", "language": "lua", "prompt": "-- To convert an int 'i' to a string.\n-- Parameters\n-- ----------\n-- n : int\n--     Order to put 0 if necessary.\n-- i : int\n--     The number to convert.\n-- Returns\n-- -------\n-- res : str\n--     The number as a string.\n-- Examples\n-- --------\n-- ```python\n--     getIndexStr(100,15)\n-- ```\n-- Out:\n-- ```\n--     '015'\n-- ```\nlocal function get_index_str(n, i)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_6077_get_index_str.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_index_str\n    lu.assertEquals(candidate(10, 1), '01')\n    lu.assertEquals(candidate(100, 100), '100')\n    lu.assertEquals(candidate(10, 10), '10')\n    lu.assertEquals(candidate(10, 0), '00')\n    lu.assertEquals(candidate(100, 0), '000')\n    lu.assertEquals(candidate(10, 9), '09')\n    lu.assertEquals(candidate(10, 10), '10')\n    lu.assertEquals(candidate(1, 1), str(1))\n    lu.assertEquals(candidate(20, 10), '10')\n    lu.assertEquals(candidate(100, 15), '015')\n    lu.assertEquals(candidate(100, 99), '099')\n    lu.assertEquals(candidate(0, 0), '0')\n    lu.assertEquals(candidate(10, 2), '02')\n    lu.assertEquals(candidate(10, 10), '10')\n    lu.assertEquals(candidate(1, 0), '0')\n    lu.assertEquals(candidate(100, 15), '015')\n    lu.assertEquals(candidate(1, 1), '1')\n    lu.assertEquals(candidate(100, 15), '015')\n    lu.assertEquals(candidate(1, 1), '1')\n    lu.assertEquals(candidate(100, 10), '010')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_61119__topo_to_sphere", "language": "lua", "prompt": "-- Convert 2D topo coordinates to spherical.\nlocal function _topo_to_sphere(theta, radius)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_61119__topo_to_sphere.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _topo_to_sphere\n    lu.assertEquals(candidate(0.0, 0.5), {0.0, 0.0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_6150__dof", "language": "lua", "prompt": "-- Returns the degrees of freedom for the chi-2 distribution from the mean and\n-- variance of the uncertainty model, as reported in equation 5.5 of Al Atik\n-- (2015)\nlocal function _dof(mean_tau, sd_tau2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_6150__dof.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _dof\n    lu.assertEquals(candidate(), candidate(0.1, 0.001))\n    lu.assertEquals(candidate(1.0, 1.0), 2.0)\n    lu.assertEquals(candidate(1.0, 1.0), 2.0)\n    lu.assertEquals(candidate(0.1), candidate(0.1, 0.001))\n    lu.assertEquals(candidate(2.0, 8.0), 0.5)\n    lu.assertEquals(candidate(1.0, 2.0), 0.5)\n    lu.assertEquals(candidate(2.0, 2.0), 8.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_61922_http_verifier", "language": "lua", "prompt": "-- verifies if the url starts with\n-- http:// or https://. If not, http://\n-- is put in the start of url\n-- :param url: url to be verified\n-- :return: url with http://\nlocal function http_verifier(url)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_61922_http_verifier.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = http_verifier\n    lu.assertEquals(candidate('http://www.codewars.com'), 'http://www.codewars.com')\n    lu.assertEquals(candidate('http://www.codewars.com/users/GiacomoSorbi?ref=codewars'), 'http://www.codewars.com/users/GiacomoSorbi?ref=codewars')\n    lu.assertEquals(candidate('http://foo.bar'), 'http://foo.bar')\n    lu.assertEquals(candidate('http://www.codewars.com/users/GiacomoSorbi?ref=codewars&foo=bar'), 'http://www.codewars.com/users/GiacomoSorbi?ref=codewars&foo=bar')\n    lu.assertEquals(candidate('http://google.com'), 'http://google.com')\n    lu.assertEquals(candidate('http://www.codewars.com/users/GiacomoSorbi?ref=other'), 'http://www.codewars.com/users/GiacomoSorbi?ref=other')\n    lu.assertEquals(candidate('https://www.foo.bar'), 'https://www.foo.bar')\n    lu.assertEquals(candidate('https://youtube.com'), 'https://youtube.com')\n    lu.assertEquals(candidate('http://www.python.org/'), 'http://www.python.org/')\n    lu.assertEquals(candidate('codewars.com'), 'http://codewars.com')\n    lu.assertEquals(candidate('www.foo.bar'), 'http://www.foo.bar')\n    lu.assertEquals(candidate('https://foo.bar'), 'https://foo.bar')\n    lu.assertEquals(candidate('www.codewars.com'), 'http://www.codewars.com')\n    lu.assertEquals(candidate('http://www.codewars.com/users/GiacomoSorbi?ref=mycodewars'), 'http://www.codewars.com/users/GiacomoSorbi?ref=mycodewars')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_61942_write_var_length", "language": "lua", "prompt": "--  Take a numerical value, and convert it to a 7-bit packed string\n-- with high bit of each byte set as a flag to indicate to the reader that\n-- the value that follows in the following byte is to be consumed as well.\nlocal function write_var_length(var)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_61942_write_var_length.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = write_var_length\n    lu.assertEquals(candidate(23), '\\x17')\n    lu.assertEquals(candidate(1), '\\x01')\n    lu.assertEquals(candidate(127), '\\x7f')\n    lu.assertEquals(candidate(268435455), '\u00ff\u00ff\u00ff\\x7f')\n    lu.assertEquals(candidate(16384), '\\x81\\x80\\x00')\n    lu.assertEquals(candidate(16383), '\u00ff\\x7f')\n    lu.assertEquals(candidate(268435456), '\\x81\\x80\\x80\\x80\\x00')\n    lu.assertEquals(candidate(0), '\\x00')\n    lu.assertEquals(candidate(128), '\\x81\\x00')\n    lu.assertEquals(candidate(0), '\\x00')\n    lu.assertEquals(candidate(127), chr(127))\n    lu.assertEquals(candidate(2097151), '\u00ff\u00ff\\x7f')\n    lu.assertEquals(candidate(1), '\\x01')\n    lu.assertEquals(candidate(127), '\\x7f')\n    lu.assertEquals(candidate(2097152), '\\x81\\x80\\x80\\x00')\n    lu.assertEquals(candidate(1), chr(1))\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_62278_fibonacci", "language": "lua", "prompt": "-- Returns the n-th number in the Fibonacci sequence.\n-- Parameters\n-- ----------\n-- n: int\n--    The n-th number in the Fibonacci sequence.\nlocal function fibonacci(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_62278_fibonacci.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fibonacci\n    lu.assertEquals(candidate(12), 144)\n    lu.assertEquals(candidate(18), 2584)\n    lu.assertEquals(candidate(2), 1)\n    lu.assertEquals(candidate(19), 4181)\n    lu.assertEquals(candidate(8), 21)\n    lu.assertEquals(candidate(7), 13)\n    lu.assertEquals(candidate(22), 17711)\n    lu.assertEquals(candidate(25), 75025)\n    lu.assertEquals(candidate(14), 377)\n    lu.assertEquals(candidate(15), 610)\n    lu.assertEquals(candidate(21), 10946)\n    lu.assertEquals(candidate(13), 233)\n    lu.assertEquals(candidate(11), 89)\n    lu.assertEquals(candidate(26), 121393)\n    lu.assertEquals(candidate(24), 46368)\n    lu.assertEquals(candidate(6), 8)\n    lu.assertEquals(candidate(9), 34)\n    lu.assertEquals(candidate(1), 1)\n    lu.assertEquals(candidate(20), 6765)\n    lu.assertEquals(candidate(3), 2)\n    lu.assertEquals(candidate(27), 196418)\n    lu.assertEquals(candidate(30), 832040)\n    lu.assertEquals(candidate(17), 1597)\n    lu.assertEquals(candidate(29), 514229)\n    lu.assertEquals(candidate(28), 317811)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(5), 5)\n    lu.assertEquals(candidate(4), 3)\n    lu.assertEquals(candidate(23), 28657)\n    lu.assertEquals(candidate(16), 987)\n    lu.assertEquals(candidate(10), 55)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_62303_genSubparts", "language": "lua", "prompt": "-- Partition a string into all possible two parts, e.g.\n-- given \"abcd\", generate [(\"a\", \"bcd\"), (\"ab\", \"cd\"), (\"abc\", \"d\")]\n-- For string of length 1, return empty list\nlocal function genSubparts(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_62303_genSubparts.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = genSubparts\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('abcd'), {{'a', 'bcd'}, {'ab', 'cd'}, {'abc', 'd'}})\n    lu.assertEquals(candidate('abcd'), {{'a', 'bcd'}, {'ab', 'cd'}, {'abc', 'd'}})\n    lu.assertEquals(candidate('abcd'), {{'a', 'bcd'}, {'ab', 'cd'}, {'abc', 'd'}})\n    lu.assertEquals(candidate('abc'), {{'a', 'bc'}, {'ab', 'c'}})\n    lu.assertEquals(candidate('abcd'), {{'a', 'bcd'}, {'ab', 'cd'}, {'abc', 'd'}})\n    lu.assertEquals(candidate('a'), {})\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('abcd'), {{'a', 'bcd'}, {'ab', 'cd'}, {'abc', 'd'}})\n    lu.assertEquals(candidate('ab'), {{'a', 'b'}})\n    lu.assertEquals(candidate('abcd'), {{'a', 'bcd'}, {'ab', 'cd'}, {'abc', 'd'}})\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('abc'), {{'a', 'bc'}, {'ab', 'c'}})\n    lu.assertEquals(candidate('a'), {})\n    lu.assertEquals(candidate('ab'), {{'a', 'b'}})\n    lu.assertEquals(candidate('abc'), {{'a', 'bc'}, {'ab', 'c'}})\n    lu.assertEquals(candidate('abc'), {{'a', 'bc'}, {'ab', 'c'}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_63573_check_bounds", "language": "lua", "prompt": "-- Limit voltage.\n-- Voltage limits are 45 (1.1%) and 4055 (99.0%) of a 4095 max.\n-- Valve calibrated so that at 45 (1.1%) it's fully shutoff.\nlocal function check_bounds(volts)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_63573_check_bounds.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = check_bounds\n    lu.assertEquals(candidate(500), 500)\n    lu.assertEquals(candidate(4046), 4046)\n    lu.assertEquals(candidate(4037), 4037)\n    lu.assertEquals(candidate(4033), 4033)\n    lu.assertEquals(candidate(4055), 4055)\n    lu.assertEquals(candidate(4044), 4044)\n    lu.assertEquals(candidate(4048), 4048)\n    lu.assertEquals(candidate(4034), 4034)\n    lu.assertEquals(candidate(4056), 4055)\n    lu.assertEquals(candidate(45), 45)\n    lu.assertEquals(candidate(4050), 4050)\n    lu.assertEquals(candidate(0), 45)\n    lu.assertEquals(candidate(4041), 4041)\n    lu.assertEquals(candidate(4054), 4054)\n    lu.assertEquals(candidate(4045), 4045)\n    lu.assertEquals(candidate(1), 45)\n    lu.assertEquals(candidate(4047), 4047)\n    lu.assertEquals(candidate(4049), 4049)\n    lu.assertEquals(candidate(4042), 4042)\n    lu.assertEquals(candidate(4040), 4040)\n    lu.assertEquals(candidate(3000), 3000)\n    lu.assertEquals(candidate(4035), 4035)\n    lu.assertEquals(candidate(4095), 4055)\n    lu.assertEquals(candidate(4039), 4039)\n    lu.assertEquals(candidate(4036), 4036)\n    lu.assertEquals(candidate(4096), 4055)\n    lu.assertEquals(candidate(4038), 4038)\n    lu.assertEquals(candidate(4043), 4043)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_63833_multiline_test", "language": "lua", "prompt": "-- test if the current line is a multiline with \"=\" at the end\n-- :param line: 'O1 3 -0.01453 1.66590 0.10966 11.00 0.05 ='\n-- :type line: string\n-- >>> line = 'C1    1    0.278062    0.552051    0.832431    11.00000    0.02895    0.02285 ='\n-- >>> multiline_test(line)\n-- True\n-- >>> line = 'C1    1    0.278062    0.552051    0.832431    11.00000    0.05 '\n-- >>> multiline_test(line)\n-- False\nlocal function multiline_test(line)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_63833_multiline_test.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = multiline_test\n    lu.assertEquals(candidate('O1 3 -0.01453 1.66590 0.10966 11.00 0.05 ='), true)\n    lu.assertEquals(candidate('O1 3 -0.01453 1.66590 0.10966 11.00 0.05 '), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_64387_cleanForIRI", "language": "lua", "prompt": "-- Cleans a string to be suitable for use as an IRI (punctation we dont want is removed)\nlocal function cleanForIRI(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_64387_cleanForIRI.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = cleanForIRI\n    lu.assertEquals(candidate('123 456'), '123456')\n    lu.assertEquals(candidate('123'), '123')\n    lu.assertEquals(candidate('hello world!'), 'helloworld')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_65087_trim_lost_U", "language": "lua", "prompt": "--  test for lost U at the 3' end of the PCR primer sequence \nlocal function trim_lost_U(seq_F, qual_F, LOSTUSEQS)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_65087_trim_lost_U.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = trim_lost_U\n    lu.assertEquals(candidate('AACC', 'DEB', {'AACC'}), {'', ''})\n    lu.assertEquals(candidate('AACC', 'DEB', {'AACC', 'ACTA'}), {'', ''})\n    lu.assertEquals(candidate('CGT', 'DEB', {'AACT'}), {'CGT', 'DEB'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_65211_findDuplicate", "language": "lua", "prompt": "-- :type nums: List[int]\n-- :rtype: int\nlocal function findDuplicate(nums)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_65211_findDuplicate.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = findDuplicate\n    lu.assertEquals(candidate({1, 1, 2}), 1)\n    lu.assertEquals(candidate({1, 3, 4, 2, 2}), 2)\n    lu.assertEquals(candidate({1, 1}), 1)\n    lu.assertEquals(candidate({1, 1, 2, 2, 3, 3, 4, 4}), 1)\n    lu.assertEquals(candidate({3, 1, 3, 4, 2}), 3)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_65436_remove_min_line", "language": "lua", "prompt": "-- Soustraction des min par ligne\nlocal function remove_min_line(matrix, list_min_line)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_65436_remove_min_line.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_min_line\n    lu.assertEquals(candidate({{4, 1, 4, 4}, {4, 4, 1, 4}, {4, 4, 4, 1}}, {1, 1, 1}), {{3, 0, 3, 3}, {3, 3, 0, 3}, {3, 3, 3, 0}})\n    lu.assertEquals(candidate({{1, 2, 3, 4}}, {1}), {{0, 1, 2, 3}})\n    lu.assertEquals(candidate({{2, 2, 2}, {5, 5, 5}}, {2, 2, 2}), {{0, 0, 0}, {3, 3, 3}})\n    lu.assertEquals(candidate({{3, 4, 5, 6, 7, 8, 9, 0}}, {1, 2, 3, 4}), {{2, 3, 4, 5, 6, 7, 8, -1}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_65809_misencode", "language": "lua", "prompt": "-- Take a properly represented text, encode into win1250 and decode\n-- back into latin2 (iso-8859-2) so it could be encoded back as such over the wire.\n-- Has to be used when querying database for data stored by original application,\n-- represented by MisencodedChar/TextField.\nlocal function misencode(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_65809_misencode.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = misencode\n    lu.assertEquals(candidate('abc'), 'abc')\n    lu.assertEquals(candidate('\u017b'), '\u017b')\n    lu.assertEquals(candidate('x'), 'x')\n    lu.assertEquals(candidate('\u0119\u0142'), '\u0119\u0142')\n    lu.assertEquals(candidate('\u0119'), '\u0119')\n    lu.assertEquals(candidate('a'), 'a')\n    lu.assertEquals(candidate('x\\n\\r\\t a'), 'x\\n\\r\\t a')\n    lu.assertEquals(candidate('x\\n\\r\\t'), 'x\\n\\r\\t')\n    lu.assertEquals(candidate('x '), 'x ')\n    lu.assertEquals(candidate('abcd'), 'abcd')\n    lu.assertEquals(candidate('\u00f3'), '\u00f3')\n    lu.assertEquals(candidate('\u0142\u0119'), '\u0142\u0119')\n    lu.assertEquals(candidate('\u017c'), '\u017c')\n    lu.assertEquals(candidate(' '), ' ')\n    lu.assertEquals(candidate('x\\ta'), 'x\\ta')\n    lu.assertEquals(candidate('\u0118'), '\u0118')\n    lu.assertEquals(candidate('\u0142'), '\u0142')\n    lu.assertEquals(candidate('ab'), 'ab')\n    lu.assertEquals(candidate('\u0142'), '\u0142')\n    lu.assertEquals(candidate('\u0119'), '\u0119')\n    lu.assertEquals(candidate('x\\na'), 'x\\na')\n    lu.assertEquals(candidate('\u0141'), '\u0141')\n    lu.assertEquals(candidate('x\\n\\r a\\n'), 'x\\n\\r a\\n')\n    lu.assertEquals(candidate('x a'), 'x a')\n    lu.assertEquals(candidate('x\\r\\na'), 'x\\r\\na')\n    lu.assertEquals(candidate('x\\n\\r'), 'x\\n\\r')\n    lu.assertEquals(candidate('x\\n\\r\\t\\na'), 'x\\n\\r\\t\\na')\n    lu.assertEquals(candidate('\u00d3'), '\u00d3')\n    lu.assertEquals(candidate('\u0119'), '\u0119')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('ab\u010d'), 'ab\u010d')\n    lu.assertEquals(candidate('x\\n\\ra\\n'), 'x\\n\\ra\\n')\n    lu.assertEquals(candidate('\u0143'), '\u0143')\n    lu.assertEquals(candidate('\u0144'), '\u0144')\n    lu.assertEquals(candidate('x\\n\\ra'), 'x\\n\\ra')\n    lu.assertEquals(candidate('x\\n\\r a'), 'x\\n\\r a')\n    lu.assertEquals(candidate('\u0118'), '\u0118')\n    lu.assertEquals(candidate('ab\u010d'), 'ab\u010d')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_66931___validate_float_fields", "language": "lua", "prompt": "-- Validate float values from a dictionary.\n-- Parameters\n-- ----------\n-- value : float\n--     Value to be validated.\n-- error_msg : str\n--     Error message for an invalid value.\n-- Returns\n-- -------\n-- float\n--     Validated value.\n-- Raises\n-- ------\n-- TypeError\n--     Raised when the value is not valid (namely, when it is data that cannot be cast to float).\nlocal function __validate_float_fields(value, error_msg)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_66931___validate_float_fields.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = __validate_float_fields\n    lu.assertEquals(candidate(-273.15, ''), -273.15)\n    lu.assertEquals(candidate(0, ''), 0)\n    lu.assertEquals(candidate('1', 'Should be valid.'), 1.0)\n    lu.assertEquals(candidate(1.0, 'Error: Invalid value'), 1.0)\n    lu.assertEquals(candidate(1, 'Input value cannot be cast to float.'), 1.0)\n    lu.assertEquals(candidate(float('inf'), ''), float('inf'))\n    lu.assertEquals(candidate(10, 'Input value is not a float.'), 10.0)\n    lu.assertEquals(candidate('1', 'Error: Invalid value'), 1.0)\n    lu.assertEquals(candidate(1.0, 'Input value cannot be cast to float.'), 1.0)\n    lu.assertEquals(candidate(1, 'Error: Invalid value'), 1.0)\n    lu.assertEquals(candidate(-10, ''), -10)\n    lu.assertEquals(candidate(10.0, 'Input value is not a float.'), 10.0)\n    lu.assertEquals(candidate(1, ''), 1)\n    lu.assertEquals(candidate(-1, 'Input value cannot be cast to float.'), -1.0)\n    lu.assertEquals(candidate(-1.0, 'Input value cannot be cast to float.'), -1.0)\n    lu.assertEquals(candidate(3.14159, ''), 3.14159)\n    lu.assertEquals(candidate(1.0, 'Should be valid.'), 1.0)\n    lu.assertEquals(candidate('1.0', 'Should be valid.'), 1.0)\n    lu.assertEquals(candidate(0, 'Input value cannot be cast to float.'), 0.0)\n    lu.assertEquals(candidate(0.0, 'Input value cannot be cast to float.'), 0.0)\n    lu.assertEquals(candidate(1, 'Should be valid.'), 1.0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_67171_remove_unencodable", "language": "lua", "prompt": "-- :type str_: str\n-- :param str_: string to remove unencodable character\n-- :return: string removed unencodable character\nlocal function remove_unencodable(str_)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_67171_remove_unencodable.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = remove_unencodable\n    lu.assertEquals(candidate('\u201cHe said, \u201cLet us go to the movies tonight\u201d\u201d'), '\u201cHe said, \u201cLet us go to the movies tonight\u201d\u201d')\n    lu.assertEquals(candidate('The British Beatles were an English rock band formed in London in 1960 by <NAME>, <NAME> and <NAME>'), 'The British Beatles were an English rock band formed in London in 1960 by <NAME>, <NAME> and <NAME>')\n    lu.assertEquals(candidate('The American actress and author, <NAME>, is perhaps best known for her role as <NAME> in the 1994 film, Selma.'), 'The American actress and author, <NAME>, is perhaps best known for her role as <NAME> in the 1994 film, Selma.')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_6730_char_to_bool", "language": "lua", "prompt": "-- Transform character (J/N) to Bool.\nlocal function char_to_bool(letter)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_6730_char_to_bool.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = char_to_bool\n    lu.assertEquals(candidate('j'), true)\n    lu.assertEquals(candidate('N'), false)\n    lu.assertEquals(candidate('J'), true)\n    lu.assertEquals(candidate('n'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_67323_is_belong_train_set", "language": "lua", "prompt": "--     Args:\n-- fname: string, file name without dir path\n--     Returns:\n-- boolean\nlocal function is_belong_train_set(fname)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_67323_is_belong_train_set.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_belong_train_set\n    lu.assertEquals(candidate('2_2_1.txt'), true)\n    lu.assertEquals(candidate('3_1_1.txt'), false)\n    lu.assertEquals(candidate('2_1_1.txt'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_67419_get_index_of_char", "language": "lua", "prompt": "-- Returns all indices of all appearances of char in str\n-- :param file_name:\n-- :param char:\n-- :return:\nlocal function get_index_of_char(my_string, char)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_67419_get_index_of_char.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_index_of_char\n    lu.assertEquals(candidate('123123123', '2'), {1, 4, 7})\n    lu.assertEquals(candidate('abcdefg', 'z'), {})\n    lu.assertEquals(candidate('123123123', '1'), {0, 3, 6})\n    lu.assertEquals(candidate('abc\\nabc', '\\n'), {3})\n    lu.assertEquals(candidate('', ''), {})\n    lu.assertEquals(candidate('abcdef', 'z'), {})\n    lu.assertEquals(candidate('123123123', 'x'), {})\n    lu.assertEquals(candidate('a1b2c3', 'x'), {})\n    lu.assertEquals(candidate('abcdefg', 'd'), {3})\n    lu.assertEquals(candidate('abc', 'd'), {})\n    lu.assertEquals(candidate('1abc2', 'd'), {})\n    lu.assertEquals(candidate('abcabc', 'z'), {})\n    lu.assertEquals(candidate('abc', 'c'), {2})\n    lu.assertEquals(candidate('abc', 'c'), {2})\n    lu.assertEquals(candidate('abcdefg', 'a'), {0})\n    lu.assertEquals(candidate('a1b2c3', '1'), {1})\n    lu.assertEquals(candidate('aaaaaaaaaa', 'a'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9})\n    lu.assertEquals(candidate('abc', 'b'), {1})\n    lu.assertEquals(candidate('1abc2', 'b'), {2})\n    lu.assertEquals(candidate('123123123', '3'), {2, 5, 8})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_67437_check_dead", "language": "lua", "prompt": "-- Method to check if either player is dead\n-- :param left_hp: Hit points of priority player\n-- :param right_hp: Hit points of right player\n-- :return: True if somebody is dead, else False\nlocal function check_dead(left_hp, right_hp)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_67437_check_dead.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = check_dead\n    lu.assertEquals(candidate(-1, 1), true)\n    lu.assertEquals(candidate(0, 5), true)\n    lu.assertEquals(candidate(1, 1), false)\n    lu.assertEquals(candidate(0, 0), true)\n    lu.assertEquals(candidate(1, 0), true)\n    lu.assertEquals(candidate(5, 0), true)\n    lu.assertEquals(candidate(1, -1), true)\n    lu.assertEquals(candidate(0, 1), true)\n    lu.assertEquals(candidate(5, 5), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_67598_strip_str", "language": "lua", "prompt": "-- Strip string.\nlocal function strip_str(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_67598_strip_str.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = strip_str\n    lu.assertEquals(candidate(candidate(candidate('  a  '))), candidate('  a  '))\n    lu.assertEquals(candidate('  '), '')\n    lu.assertEquals(candidate(\"Hello'World\"), \"Hello'World\")\n    lu.assertEquals(candidate('Hello World!    '), 'Hello World!')\n    lu.assertEquals(candidate('    Hello World!'), 'Hello World!')\n    lu.assertEquals(candidate('Hello \" World'), 'Hello \" World')\n    lu.assertEquals(candidate('  hello  world  '), 'hello  world')\n    lu.assertEquals(candidate(\"'hello  world'\"), 'hello  world')\n    lu.assertEquals(candidate(' Hello World'), 'Hello World')\n    lu.assertEquals(candidate(candidate(candidate(\"' a '\"))), candidate(\"' a '\"))\n    lu.assertEquals(candidate('\"hello  world\"'), 'hello  world')\n    lu.assertEquals(candidate(\"'hello'\"), 'hello')\n    lu.assertEquals(candidate(\"  'hello'  'world'  \"), \"'hello'  'world'\")\n    lu.assertEquals(candidate('hi'), 'hi')\n    lu.assertEquals(candidate('Hello World'), 'Hello World')\n    lu.assertEquals(candidate(\"Hello 'World\"), \"Hello 'World\")\n    lu.assertEquals(candidate('Hello World!'), 'Hello World!')\n    lu.assertEquals(candidate('Hello \" World!'), 'Hello \" World!')\n    lu.assertEquals(candidate(\"Hello'World! \"), \"Hello'World!\")\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('  hi  '), 'hi')\n    lu.assertEquals(candidate('    Hello World!    '), 'Hello World!')\n    lu.assertEquals(candidate('hi'), 'hi')\n    lu.assertEquals(candidate('Hello World '), 'Hello World')\n    lu.assertEquals(candidate('Hello\" World'), 'Hello\" World')\n    lu.assertEquals(candidate('  \"hello\"  \"world\"  '), '\"hello\"  \"world\"')\n    lu.assertEquals(candidate(\"Hello'World\"), \"Hello'World\")\n    lu.assertEquals(candidate('\"hello\"'), 'hello')\n    lu.assertEquals(candidate(' Hello World '), 'Hello World')\n    lu.assertEquals(candidate(\"''\"), '')\n    lu.assertEquals(candidate('\"\"'), '')\n    lu.assertEquals(candidate(\"Hello' World\"), \"Hello' World\")\n    lu.assertEquals(candidate('  hello  '), 'hello')\n    lu.assertEquals(candidate('  \"hello\"  \\'world\\'  '), '\"hello\"  \\'world\\'')\n    lu.assertEquals(candidate('hello'), 'hello')\n    lu.assertEquals(candidate('Hello World!'), 'Hello World!')\n    lu.assertEquals(candidate('Hello\"World'), 'Hello\"World')\n    lu.assertEquals(candidate(candidate(candidate('\" a \"'))), candidate('\" a \"'))\n    lu.assertEquals(candidate('Hello \"World'), 'Hello \"World')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_68506_fib", "language": "lua", "prompt": "--  Calculate the nth digit of Fibonacci\n-- 0 1 1 2 3 5 8 13 21 34 ... \nlocal function fib(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_68506_fib.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fib\n    lu.assertEquals(candidate(2), 1)\n    lu.assertEquals(candidate(0), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_68615_is_even", "language": "lua", "prompt": "-- Check if a number is even.\nlocal function is_even(number)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_68615_is_even.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_even\n    lu.assertEquals(candidate(5), false)\n    lu.assertEquals(candidate(0), true)\n    lu.assertEquals(candidate(4), true)\n    lu.assertEquals(candidate(1), false)\n    lu.assertEquals(candidate(2), true)\n    lu.assertEquals(candidate(10), true)\n    lu.assertEquals(candidate(3), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_68774_extract", "language": "lua", "prompt": "-- Extract label from transition.\nlocal function extract(token)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_68774_extract.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = extract\n    lu.assertEquals(candidate(\"'bc'\"), 'bc')\n    lu.assertEquals(candidate(\"''\"), '')\n    lu.assertEquals(candidate('[a]'), 'a')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate(\"'a'\"), 'a')\n    lu.assertEquals(candidate('a'), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_68849_removeElement", "language": "lua", "prompt": "-- :type nums: List[int]\n-- :type val: int\n-- :rtype: int\nlocal function removeElement(nums, val)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_68849_removeElement.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = removeElement\n    lu.assertEquals(candidate({0, 1, 2, 2, 3, 0, 4, 2}, 2), 5)\n    lu.assertEquals(candidate({1, 2, 3, 3}, 3), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_69513_comma_counter", "language": "lua", "prompt": "-- :param field:\n-- :return:\nlocal function comma_counter(field)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_69513_comma_counter.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = comma_counter\n    lu.assertEquals(candidate('a,b,c,d,e'), 4)\n    lu.assertEquals(candidate('hello,,world'), 2)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('hello'), 0)\n    lu.assertEquals(candidate('hello,world'), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_69832_strip_all", "language": "lua", "prompt": "--  Strips leading and trailing whitespace from all strings in a list.\n-- Args:\n--     lst (list of str): The list of strings to strip.\n-- Returns:\n--     list of str: The list of stripped strings.\nlocal function strip_all(lst)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_69832_strip_all.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = strip_all\n    lu.assertEquals(candidate({' \\r\\n one \\r\\n', ' two \\r\\n', ' three \\r\\n'}), {'one', 'two', 'three'})\n    lu.assertEquals(candidate({'  ', '', '  hello  ', '  world', '  ', '', '  '}), {'', '', 'hello', 'world', '', '', ''})\n    lu.assertEquals(candidate({'    one   ', '   two  ', '  three'}), {'one', 'two', 'three'})\n    lu.assertEquals(candidate({'', '', ''}), {'', '', ''})\n    lu.assertEquals(candidate({'one', ' two', ' three'}), {'one', 'two', 'three'})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({'     Hello,     World!     ', 'Hello, World!'}), {'Hello,     World!', 'Hello, World!'})\n    lu.assertEquals(candidate({'hello', 'world'}), {'hello', 'world'})\n    lu.assertEquals(candidate({'', 'hello  ', '  world'}), {'', 'hello', 'world'})\n    lu.assertEquals(candidate({' \\n one\\n', ' two \\n', ' three \\n'}), {'one', 'two', 'three'})\n    lu.assertEquals(candidate({' one ', ' two ', ' three'}), {'one', 'two', 'three'})\n    lu.assertEquals(candidate({'  ', '  ', '  '}), {'', '', ''})\n    lu.assertEquals(candidate({'  hello  ', 'world', ''}), {'hello', 'world', ''})\n    lu.assertEquals(candidate({'one', '', 'two', 'three'}), {'one', '', 'two', 'three'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_70041_format_timedelta", "language": "lua", "prompt": "-- Returns a formatted message that is displayed whenever a command wants to display a duration\nlocal function format_timedelta(seconds)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_70041_format_timedelta.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = format_timedelta\n    lu.assertEquals(candidate(3661), '1h 1m')\n    lu.assertEquals(candidate(0), '0h 0m')\n    lu.assertEquals(candidate(7200), '2h 0m')\n    lu.assertEquals(candidate(86399), '23h 59m')\n    lu.assertEquals(candidate(3600), '1h 0m')\n    lu.assertEquals(candidate(60), '0h 1m')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_71150_max_divisible", "language": "lua", "prompt": "-- Keep dividing(a/b) till it's divisible(a % b == 0)\n-- e.g.\n-- Input: a = 300; b = 2\n-- Output: 75\n-- :param a:\n-- :param b:\n-- :return:\nlocal function max_divisible(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_71150_max_divisible.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = max_divisible\n    lu.assertEquals(candidate(100, 4), 25)\n    lu.assertEquals(candidate(24, 4), 6)\n    lu.assertEquals(candidate(300, 100), 3)\n    lu.assertEquals(candidate(15, 3), 5)\n    lu.assertEquals(candidate(100, 25), 4)\n    lu.assertEquals(candidate(300, 2), 75)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_72364_get_xi_from_ARPS_simulation", "language": "lua", "prompt": "-- Extract xi from full name of ARPS files\nlocal function get_xi_from_ARPS_simulation(simulation)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_72364_get_xi_from_ARPS_simulation.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_xi_from_ARPS_simulation\n    lu.assertEquals(candidate('wind_N2000_dx0.05_xi00001_sigma0.001_small'), '00001')\n    lu.assertEquals(candidate('wind_N1000_dx0.05_xi00100_sigma0.001_small'), '00100')\n    lu.assertEquals(candidate('topo_N100_dx0.02_xi00100_sigma0.001_small'), '00100')\n    lu.assertEquals(candidate('topo_N100_dx0.02_xi00200_sigma0.001_small'), '00200')\n    lu.assertEquals(candidate('topo_N100_dx0.02_xi00300_sigma0.001_small'), '00300')\n    lu.assertEquals(candidate('wind_N2000_dx0.05_xi00300_sigma0.001_small'), '00300')\n    lu.assertEquals(candidate('wind_N2000_dx0.05_xi00200_sigma0.001_small'), '00200')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_72597_plurality", "language": "lua", "prompt": "-- Return, for input dict d mapping vids to (real) counts, vid with largest count.\n-- (Tie-breaking done arbitrarily here.)\nlocal function plurality(d)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_72597_plurality.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = plurality\n    lu.assertEquals(candidate({[1] = 10}), 1)\n    lu.assertEquals(candidate(dict({{0, 1}, {1, 2}, {2, 1}, {3, 1}, {4, 1}, {5, 1}})), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_72678_f", "language": "lua", "prompt": "--         Defining Function\nlocal function f(x)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_72678_f.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = f\n    lu.assertEquals(candidate(0), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_73015_init_loop_state", "language": "lua", "prompt": "-- Initialize the file row counter, the file counter,\n-- and the list representing file data.\n-- Janky, I know, but this needed to be done in 2 spots.\nlocal function init_loop_state(file_counter)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_73015_init_loop_state.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = init_loop_state\n    lu.assertEquals(candidate(0), {0, 1, {{'Date', 'Weight (lb)', 'Fat mass (lb)'}}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_73332__make_even", "language": "lua", "prompt": "-- Return largest even integer less than or equal to `n`.\nlocal function _make_even(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_73332__make_even.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _make_even\n    lu.assertEquals(candidate(29), 28)\n    lu.assertEquals(candidate(0), 0)\n    lu.assertEquals(candidate(10), 10)\n    lu.assertEquals(candidate(8), 8)\n    lu.assertEquals(candidate(11), 10)\n    lu.assertEquals(candidate(13), 12)\n    lu.assertEquals(candidate(5), 4)\n    lu.assertEquals(candidate(24), 24)\n    lu.assertEquals(candidate(21), 20)\n    lu.assertEquals(candidate(15), 14)\n    lu.assertEquals(candidate(22), 22)\n    lu.assertEquals(candidate(30), 30)\n    lu.assertEquals(candidate(32), 32)\n    lu.assertEquals(candidate(6), 6)\n    lu.assertEquals(candidate(23), 22)\n    lu.assertEquals(candidate(17), 16)\n    lu.assertEquals(candidate(20), 20)\n    lu.assertEquals(candidate(19), 18)\n    lu.assertEquals(candidate(16), 16)\n    lu.assertEquals(candidate(1), 0)\n    lu.assertEquals(candidate(2), 2)\n    lu.assertEquals(candidate(3), 2)\n    lu.assertEquals(candidate(25), 24)\n    lu.assertEquals(candidate(14), 14)\n    lu.assertEquals(candidate(7), 6)\n    lu.assertEquals(candidate(4), 4)\n    lu.assertEquals(candidate(18), 18)\n    lu.assertEquals(candidate(12), 12)\n    lu.assertEquals(candidate(28), 28)\n    lu.assertEquals(candidate(4), candidate(candidate(4)))\n    lu.assertEquals(candidate(31), 30)\n    lu.assertEquals(candidate(9), 8)\n    lu.assertEquals(candidate(27), 26)\n    lu.assertEquals(candidate(26), 26)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_73550__desktop_escape", "language": "lua", "prompt": "-- Escape a filepath for use in a .desktop file\nlocal function _desktop_escape(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_73550__desktop_escape.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _desktop_escape\n    lu.assertEquals(candidate('\\\\v'), '\\\\\\\\v')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('\\\\\\\\s'), '\\\\\\\\\\\\\\\\s')\n    lu.assertEquals(candidate('C:\\\\Users\\\\foo\\\\Desktop\\\\bar'), 'C:\\\\\\\\Users\\\\\\\\foo\\\\\\\\Desktop\\\\\\\\bar')\n    lu.assertEquals(candidate('abc'), 'abc')\n    lu.assertEquals(candidate('\\\\\\\\\\\\a'), '\\\\\\\\\\\\\\\\\\\\\\\\a')\n    lu.assertEquals(candidate('\\\\\\\\\\\\s'), '\\\\\\\\\\\\\\\\\\\\\\\\s')\n    lu.assertEquals(candidate('\\\\\\\\\\\\0'), '\\\\\\\\\\\\\\\\\\\\\\\\0')\n    lu.assertEquals(candidate('\\\\\\\\a'), '\\\\\\\\\\\\\\\\a')\n    lu.assertEquals(candidate('C:\\\\Users\\\\foo\\\\Desktop\\\\tab\\\\t'), 'C:\\\\\\\\Users\\\\\\\\foo\\\\\\\\Desktop\\\\\\\\tab\\\\\\\\t')\n    lu.assertEquals(candidate('abcde'), 'abcde')\n    lu.assertEquals(candidate('\\\\s'), '\\\\\\\\s')\n    lu.assertEquals(candidate('C:\\\\Users\\\\foo\\\\Desktop\\\\newline\\\\n'), 'C:\\\\\\\\Users\\\\\\\\foo\\\\\\\\Desktop\\\\\\\\newline\\\\\\\\n')\n    lu.assertEquals(candidate('C:\\\\Users\\\\foo\\\\Desktop\\\\backslash\\\\backslash'), 'C:\\\\\\\\Users\\\\\\\\foo\\\\\\\\Desktop\\\\\\\\backslash\\\\\\\\backslash')\n    lu.assertEquals(candidate('\\\\\\\\f'), '\\\\\\\\\\\\\\\\f')\n    lu.assertEquals(candidate('\\\\\\\\\\\\f'), '\\\\\\\\\\\\\\\\\\\\\\\\f')\n    lu.assertEquals(candidate('\\\\\\\\\\\\v'), '\\\\\\\\\\\\\\\\\\\\\\\\v')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('\\\\\\\\v'), '\\\\\\\\\\\\\\\\v')\n    lu.assertEquals(candidate('a'), 'a')\n    lu.assertEquals(candidate('\\\\0'), '\\\\\\\\0')\n    lu.assertEquals(candidate('\\\\\\\\0'), '\\\\\\\\\\\\\\\\0')\n    lu.assertEquals(candidate('ab'), 'ab')\n    lu.assertEquals(candidate('\\\\f'), '\\\\\\\\f')\n    lu.assertEquals(candidate('\\\\a'), '\\\\\\\\a')\n    lu.assertEquals(candidate('abcd'), 'abcd')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_73986_manhattan_distance", "language": "lua", "prompt": "--  It is the sum of absolute values of differences in the point 1's x and y coordinates and the\n-- point 2's x and y coordinates respectively \nlocal function manhattan_distance(point1_x, point1_y, point2_x, point2_y)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_73986_manhattan_distance.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = manhattan_distance\n    lu.assertEquals(candidate(1, 1, 0, 0), 2)\n    lu.assertEquals(candidate(0, 0, -3, -4), 7)\n    lu.assertEquals(candidate(-2, -2, -4, -4), 4)\n    lu.assertEquals(candidate(10, 10, 0, 0), 20)\n    lu.assertEquals(candidate(0, 0, -10, 10), 20)\n    lu.assertEquals(candidate(1, 1, 3, 4), 5)\n    lu.assertEquals(candidate(1, 1, 1, 1), 0)\n    lu.assertEquals(candidate(0, 0, 10, -10), 20)\n    lu.assertEquals(candidate(0, 0, 10, 10), 20)\n    lu.assertEquals(candidate(3, -4, 0, 0), 7)\n    lu.assertEquals(candidate(0, 0, 0, 0), 0)\n    lu.assertEquals(candidate(0, 0, 3, 4), 7)\n    lu.assertEquals(candidate(1, 2, 3, 4), 4)\n    lu.assertEquals(candidate(-3, 4, 0, 0), 7)\n    lu.assertEquals(candidate(-1, -1, -1, -1), 0)\n    lu.assertEquals(candidate(0, 0, -10, -10), 20)\n    lu.assertEquals(candidate(-10, 10, 0, 0), 20)\n    lu.assertEquals(candidate(2, 2, 2, 2), 0)\n    lu.assertEquals(candidate(-10, -10, 0, 0), 20)\n    lu.assertEquals(candidate(1, 1, 2, 2), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_74366_to_unicode_repr", "language": "lua", "prompt": "--  helpful in situations where browser/app may recognize Unicode encoding\n-- in the \u0b8e type syntax but not actual unicode glyph/code-point\nlocal function to_unicode_repr(_letter)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_74366_to_unicode_repr.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = to_unicode_repr\n    lu.assertEquals(candidate('\u0b8e\u0b8e'), \"u'\\\\u0b8e\\\\u0b8e'\")\n    lu.assertEquals(candidate('\u0905\u0906\u0907\u0908\u0909\u090a'), \"u'\\\\u0905\\\\u0906\\\\u0907\\\\u0908\\\\u0909\\\\u090a'\")\n    lu.assertEquals(candidate(''), \"u''\")\n    lu.assertEquals(candidate('\u0b8e\u0b8e\u0b8e'), \"u'\\\\u0b8e\\\\u0b8e\\\\u0b8e'\")\n    lu.assertEquals(candidate('\u0b8e'), \"u'\\\\u0b8e'\")\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_76381_str_list", "language": "lua", "prompt": "-- convert string to list\nlocal function str_list(input_Str)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_76381_str_list.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = str_list\n    lu.assertEquals(candidate('0 0 1 1 2 3 5 8'), {0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 5.0, 8.0})\n    lu.assertEquals(candidate('1.0 2.0 3.0'), {1.0, 2.0, 3.0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_77434_get_str_ip", "language": "lua", "prompt": "--     turns a list of 4 integers into IP address format.\nlocal function get_str_ip(list_ip)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_77434_get_str_ip.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_str_ip\n    lu.assertEquals(candidate({192, 168, 1, 0}), '192.168.1.0')\n    lu.assertEquals(candidate({10, 0, 1, 0}), '10.0.1.0')\n    lu.assertEquals(candidate({10, 0, 0, 1}), '10.0.0.1')\n    lu.assertEquals(candidate({192, 168, 0, 1}), '192.168.0.1')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_77523_get_prefix", "language": "lua", "prompt": "-- @Description:\n-- get the prefix of a url\n-- to form the sub-level url\n-- ---------\n-- @Param:\n-- url:str\n-- -------\n-- @Returns:\n-- a substr end where '/' last time appears\n-- -------\nlocal function get_prefix(url)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_77523_get_prefix.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_prefix\n    lu.assertEquals(candidate('http://github.com/'), 'http://github.com/')\n    lu.assertEquals(candidate('http://github.com/this_is_a_test.py/this_is_another_test.py/'), 'http://github.com/this_is_a_test.py/this_is_another_test.py/')\n    lu.assertEquals(candidate('http://www.example.com/some/path/'), 'http://www.example.com/some/path/')\n    lu.assertEquals(candidate('https://www.coursera.org/api/onDemandProgrammingScripting'), 'https://www.coursera.org/api/')\n    lu.assertEquals(candidate('http://data.pr4e.org/data/animals.txt'), 'http://data.pr4e.org/data/')\n    lu.assertEquals(candidate('http://github.com/this_is_a_test.py'), 'http://github.com/')\n    lu.assertEquals(candidate('http://172.16.31.10/data.php'), 'http://172.16.31.10/')\n    lu.assertEquals(candidate('http://github.com/this_is_a_test.py/this_is_another_test.py/?some_variable=some_value'), 'http://github.com/this_is_a_test.py/this_is_another_test.py/')\n    lu.assertEquals(candidate('https://www.coursera.org/api/onDemandProgrammingScripting?a=1&b=2'), 'https://www.coursera.org/api/')\n    lu.assertEquals(candidate('http://www.example.com/'), 'http://www.example.com/')\n    lu.assertEquals(candidate('https://www.coursera.org/api/onDemandProgrammingScripting?a=1'), 'https://www.coursera.org/api/')\n    lu.assertEquals(candidate('http://www.example.com/some/path'), 'http://www.example.com/some/')\n    lu.assertEquals(candidate('http://github.com/this_is_a_test.py/this_is_another_test.py/?some_variable=some_value&other_variable=other_value'), 'http://github.com/this_is_a_test.py/this_is_another_test.py/')\n    lu.assertEquals(candidate('http://data.pr4e.org/data/intro-short.txt'), 'http://data.pr4e.org/data/')\n    lu.assertEquals(candidate('http://data.pr4e.org/intro-short.txt'), 'http://data.pr4e.org/')\n    lu.assertEquals(candidate('github.com'), '')\n    lu.assertEquals(candidate('http://172.16.31.10/data.php'), 'http://172.16.31.10/')\n    lu.assertEquals(candidate('http://stackoverflow.com/questions/tagged/python'), 'http://stackoverflow.com/questions/tagged/')\n    lu.assertEquals(candidate('http://github.com/this_is_a_test.py/this_is_another_test.py'), 'http://github.com/this_is_a_test.py/')\n    lu.assertEquals(candidate('http://coursera.org/api/onDemandProgrammingScripting'), 'http://coursera.org/api/')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_77581_has_no_trailing_zeroes", "language": "lua", "prompt": "-- True if string has no trailing zeroes, False otherwise.\n-- PARAMETERS:\n--     string : str\n-- RETURNS: bool\nlocal function has_no_trailing_zeroes(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_77581_has_no_trailing_zeroes.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = has_no_trailing_zeroes\n    lu.assertEquals(candidate('040'), false)\n    lu.assertEquals(candidate('4'), true)\n    lu.assertEquals(candidate('40'), true)\n    lu.assertEquals(candidate('0'), true)\n    lu.assertEquals(candidate('0400'), false)\n    lu.assertEquals(candidate('400'), true)\n    lu.assertEquals(candidate('000'), false)\n    lu.assertEquals(candidate('04'), false)\n    lu.assertEquals(candidate('00'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_77664_sumDigits", "language": "lua", "prompt": "--  Assumes s is a string\n-- Returns the sum of the decimal digits in s\n-- For example, if s is 'a2b3c' it returns 5\nlocal function sumDigits(s)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_77664_sumDigits.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sumDigits\n    lu.assertEquals(candidate('a2b3c'), 5)\n    lu.assertEquals(candidate('a2b3c0'), 5)\n    lu.assertEquals(candidate('1 2 3 4'), 10)\n    lu.assertEquals(candidate('a2b3c'), 5)\n    lu.assertEquals(candidate('a2b3c1'), 6)\n    lu.assertEquals(candidate('12 34'), 10)\n    lu.assertEquals(candidate('a2b3c'), 5)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('987654321'), 45)\n    lu.assertEquals(candidate('1'), 1)\n    lu.assertEquals(candidate('a'), 0)\n    lu.assertEquals(candidate('1234'), 10)\n    lu.assertEquals(candidate('xyz'), 0)\n    lu.assertEquals(candidate('0123456789'), 45)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('123'), 6)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_7831_mixed_radix_to_base_10", "language": "lua", "prompt": "-- Convert the `mixed radix`_ integer with digits `x` and bases `b` to base 10.\n-- Args:\n--     x (list): a list of digits ordered by increasing place values\n--     b (list): a list of bases corresponding to the digits\n-- Examples:\n--     Generally, the base 10 representation of the mixed radix number :math:`x_n\\ldots x_1` where :math:`x_i` is a digit in place value :math:`i` with base :math:`b_i` is\n--     .. math::\n--         \\sum_{i=1}^nx_i\\prod_{j=i+1}^nb_j = x_n + b_nx_{n-1} + b_nb_{n-1}x_{n-2} + \\cdots + b_n\\cdots b_2x_1\n--     Convert 111 with bases :math:`(b_1,b_2,b_3)=(2,3,4)` to base 10:\n--     >>> from fem.discrete.combinatorics import mixed_radix_to_base_10\n--     >>> mixed_radix_to_base_10([1,1,1], [2,3,4])\n--     17\n-- .. _mixed radix:\n--     https://en.wikipedia.org/wiki/Mixed_radix\nlocal function mixed_radix_to_base_10(x, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_7831_mixed_radix_to_base_10.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = mixed_radix_to_base_10\n    lu.assertEquals(candidate({1, 1, 1}, {2, 3, 4}), 17)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_79249_removeDuplicateChars", "language": "lua", "prompt": "-- assumes a-string is a string\n-- returns a string, a_string with any duplicate characters removed\nlocal function removeDuplicateChars(a_string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_79249_removeDuplicateChars.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = removeDuplicateChars\n    lu.assertEquals(candidate('aaabbbccc'), 'abc')\n    lu.assertEquals(candidate('aabbcde'), 'abcde')\n    lu.assertEquals(candidate('abcde'), 'abcde')\n    lu.assertEquals(candidate('aaaaaa'), 'a')\n    lu.assertEquals(candidate('aabbcdef'), 'abcdef')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_79326_fix_forts", "language": "lua", "prompt": "--  Changes Ft. -> Fort.\nlocal function fix_forts(report_city)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_79326_fix_forts.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fix_forts\n    lu.assertEquals(candidate('Ft. Myers, Missouri  '), 'Fort Myers, Missouri  ')\n    lu.assertEquals(candidate('Ft. Myers'), 'Fort Myers')\n    lu.assertEquals(candidate('Ft. Myers  '), 'Fort Myers  ')\n    lu.assertEquals(candidate('Ft.  Myers '), 'Fort  Myers ')\n    lu.assertEquals(candidate('Ft. Myers, Missouri'), 'Fort Myers, Missouri')\n    lu.assertEquals(candidate('Ft.  Myers, Missouri '), 'Fort  Myers, Missouri ')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_79846_failed", "language": "lua", "prompt": "-- Simply attaches a failed marker to a message\n-- :param message: The message\n-- :return: String\nlocal function failed(message)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_79846_failed.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = failed\n    lu.assertEquals(candidate('test'), 'Failed: test')\n    lu.assertEquals(candidate('2'), 'Failed: 2')\n    lu.assertEquals(candidate('Message'), 'Failed: Message')\n    lu.assertEquals(candidate('This test passed!'), 'Failed: This test passed!')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_80983_get_color", "language": "lua", "prompt": "--  Valid matplotlib colors. Could be used to automatically pick colors.\n-- :param n:   an integer\n-- :return:    a valid matploglib color string\nlocal function get_color(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_80983_get_color.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_color\n    lu.assertEquals(candidate(23), 'w')\n    lu.assertEquals(candidate(5), candidate(13))\n    lu.assertEquals(candidate(17), 'g')\n    lu.assertEquals(candidate(3), 'c')\n    lu.assertEquals(candidate(31), 'w')\n    lu.assertEquals(candidate(1), candidate(17))\n    lu.assertEquals(candidate(3), candidate(11))\n    lu.assertEquals(candidate(2), candidate(10))\n    lu.assertEquals(candidate(-1), 'w')\n    lu.assertEquals(candidate(7), 'w')\n    lu.assertEquals(candidate(4), candidate(20))\n    lu.assertEquals(candidate(13), 'y')\n    lu.assertEquals(candidate(9), 'g')\n    lu.assertEquals(candidate(20), 'm')\n    lu.assertEquals(candidate(25), 'g')\n    lu.assertEquals(candidate(4), 'm')\n    lu.assertEquals(candidate(4), candidate(12))\n    lu.assertEquals(candidate(7), candidate(15))\n    lu.assertEquals(candidate(0), candidate(16))\n    lu.assertEquals(candidate(16), 'b')\n    lu.assertEquals(candidate(24), 'b')\n    lu.assertEquals(candidate(6), 'k')\n    lu.assertEquals(candidate(6), candidate(14))\n    lu.assertEquals(candidate(1), candidate(9))\n    lu.assertEquals(candidate(5), candidate(21))\n    lu.assertEquals(candidate(5), 'y')\n    lu.assertEquals(candidate(12), 'm')\n    lu.assertEquals(candidate(21), 'y')\n    lu.assertEquals(candidate(14), 'k')\n    lu.assertEquals(candidate(30), 'k')\n    lu.assertEquals(candidate(2), candidate(18))\n    lu.assertEquals(candidate(22), 'k')\n    lu.assertEquals(candidate(7), candidate(23))\n    lu.assertEquals(candidate(10), 'r')\n    lu.assertEquals(candidate(1), 'g')\n    lu.assertEquals(candidate(8), 'b')\n    lu.assertEquals(candidate(3), candidate(19))\n    lu.assertEquals(candidate(27), 'c')\n    lu.assertEquals(candidate(0), 'b')\n    lu.assertEquals(candidate(29), 'y')\n    lu.assertEquals(candidate(15), 'w')\n    lu.assertEquals(candidate(19), 'c')\n    lu.assertEquals(candidate(26), 'r')\n    lu.assertEquals(candidate(2), 'r')\n    lu.assertEquals(candidate(28), 'm')\n    lu.assertEquals(candidate(0), candidate(8))\n    lu.assertEquals(candidate(18), 'r')\n    lu.assertEquals(candidate(11), 'c')\n    lu.assertEquals(candidate(6), candidate(22))\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_82442_get_params", "language": "lua", "prompt": "-- Turn arguments leftovers into service params.\nlocal function get_params(leftovers)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_82442_get_params.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_params\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({'--param1', '--param2', 'b'}), {})\n    lu.assertEquals(candidate({'--param1', 'a', '--param2', 'b', 'c'}), {})\n    lu.assertEquals(candidate({'--foo=1', '--bar=2', '--baz', 'baz=3'}), {['foo'] = '1', ['bar'] = '2', ['baz'] = true, ['baz'] = '3'})\n    lu.assertEquals(candidate({'--foo=1', '--bar=2', 'baz=3'}), {['foo'] = '1', ['bar'] = '2', ['baz'] = '3'})\n    lu.assertEquals(candidate({'--foo=1', '--bar=2'}), {['foo'] = '1', ['bar'] = '2'})\n    lu.assertEquals(candidate({'--foo=1', '--bar=2', '--baz', '--baz=3'}), {['foo'] = '1', ['bar'] = '2', ['baz'] = true, ['baz'] = '3'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_82529_filter_file_paths_by_extension", "language": "lua", "prompt": "-- Filters out file paths that do not have an appropriate extension.\n-- :param file_paths: list of file path strings\n-- :param ext: valid extension\nlocal function filter_file_paths_by_extension(file_paths, ext)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_82529_filter_file_paths_by_extension.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = filter_file_paths_by_extension\n    lu.assertEquals(candidate({'a.csv', 'b.csv', 'c.csv', 'd.txt', 'e.txt', 'f.json', 'g.csv'}, '  '), {})\n    lu.assertEquals(candidate({}), {})\n    lu.assertEquals(candidate({'my_file_0.csv'}), {'my_file_0.csv'})\n    lu.assertEquals(candidate({'a.csv', 'b.csv', 'c.csv', 'd.txt', 'e.txt', 'f.json', 'g.csv'}, 'csvx'), {})\n    lu.assertEquals(candidate({'my_file_0.csv', 'my_file_1.csv', 'my_file_2.csv', 'my_file_3.txt', 'my_file_4.png'}), {'my_file_0.csv', 'my_file_1.csv', 'my_file_2.csv'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_82780_is_bidirectional_conversion", "language": "lua", "prompt": "-- Check that two unicode value are also a mapping value of each other.\n-- :param letter_id: An integer, representing the unicode code point of the character.\n-- :param other_case_mapping: Comparable case mapping table which possible contains\n--                            the return direction of the conversion.\n-- :return: True, if it's a reverible conversion, false otherwise.\nlocal function is_bidirectional_conversion(letter_id, letter_case, reverse_letter_case)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_82780_is_bidirectional_conversion.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_bidirectional_conversion\n    lu.assertEquals(candidate(65, {[65] = 'A'}, {[66] = 'B'}), false)\n    lu.assertEquals(candidate(65, {[65] = 'a', [66] = 'B'}, {[66] = 'b'}), false)\n    lu.assertEquals(candidate(65, {[65] = 'a'}, {[66] = 'B'}), false)\n    lu.assertEquals(candidate(65, {[65] = 'A'}, {[97] = 'B'}), false)\n    lu.assertEquals(candidate(223, {[223] = 'ss'}, {[83] = 'S'}), false)\n    lu.assertEquals(candidate(65, {[65] = 'A'}, {[66] = 'a'}), false)\n    lu.assertEquals(candidate(65, {[65] = 'A'}, {[65] = 'a'}), false)\n    lu.assertEquals(candidate(65, {[65] = 'a'}, {[65] = 'a'}), false)\n    lu.assertEquals(candidate(65, {[65] = 'A'}, {[97] = 'A'}), false)\n    lu.assertEquals(candidate(65, {[65] = 'A'}, {[98] = 'a'}), false)\n    lu.assertEquals(candidate(65, {[65] = 'A'}, {[98] = 'B'}), false)\n    lu.assertEquals(candidate(97, {[65] = 'A'}, {[65] = 'A'}), false)\n    lu.assertEquals(candidate(65, {[65] = 'A', [66] = 'B'}, {[66] = 'b'}), false)\n    lu.assertEquals(candidate(98, {[66] = 'B'}, {[66] = 'B'}), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_8290_dot", "language": "lua", "prompt": "-- v and u are vectors. v and u -> list\nlocal function dot(v, u)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_8290_dot.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = dot\n    lu.assertEquals(candidate({1, 2}, {3, 4}), 11)\n    lu.assertEquals(candidate(), 11)\n    lu.assertEquals(candidate(), 5)\n    lu.assertEquals(candidate({-1, 2}, {3, 4}), 5)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_8323__get_text_alignment", "language": "lua", "prompt": "-- Get the horizontal and vertical text alignment keywords for text placed at the end of a line segment from point1 to point2\n-- args:\n--     point1 - x,y pair\n--     point2 - x,y pair\n-- returns:\n--     ha - horizontal alignment string\n--     va - vertical alignment string\nlocal function _get_text_alignment(point1, point2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_8323__get_text_alignment.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _get_text_alignment\n    lu.assertEquals(candidate({0, 0}, {1, 1}), {'left', 'bottom'})\n    lu.assertEquals(candidate({-1, -1}, {1, 1}), {'left', 'bottom'})\n    lu.assertEquals(candidate({0, 0}, {-1, -1}), {'right', 'top'})\n    lu.assertEquals(candidate({1, 1}, {-1, -1}), {'right', 'top'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_83484_getRefId", "language": "lua", "prompt": "--     Get the reference ID for a reference name\nlocal function getRefId(refs, refname)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_83484_getRefId.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = getRefId\n    lu.assertEquals(candidate({'A', 'B', 'C'}, 'A'), 0)\n    lu.assertEquals(candidate({'A', 'B', 'C'}, 'I'), -1)\n    lu.assertEquals(candidate(list('GATTACA'), 'GG'), -1)\n    lu.assertEquals(candidate(list('GATTACA'), 'A'), 1)\n    lu.assertEquals(candidate({'A', 'B', 'C'}, 'E'), -1)\n    lu.assertEquals(candidate(list('GATTACA'), 'GATAA'), -1)\n    lu.assertEquals(candidate({'A', 'B', 'C'}, 'D'), -1)\n    lu.assertEquals(candidate({'A', 'B', 'C'}, 'F'), -1)\n    lu.assertEquals(candidate({'A', 'B', 'C'}, 'L'), -1)\n    lu.assertEquals(candidate({'A', 'B', 'C'}, 'K'), -1)\n    lu.assertEquals(candidate({'A', 'B', 'C'}, 'J'), -1)\n    lu.assertEquals(candidate({'A', 'B', 'C'}, 'G'), -1)\n    lu.assertEquals(candidate({'A', 'B', 'C'}, 'A'), 0)\n    lu.assertEquals(candidate({'A', 'B', 'C'}, 'D'), -1)\n    lu.assertEquals(candidate({'A', 'B', 'C'}, 'H'), -1)\n    lu.assertEquals(candidate({'A', 'B', 'C'}, 'C'), 2)\n    lu.assertEquals(candidate({'A', 'B', 'C'}, 'C'), 2)\n    lu.assertEquals(candidate({'A', 'B', 'C'}, 'B'), 1)\n    lu.assertEquals(candidate(list('GATTACA'), 'G'), 0)\n    lu.assertEquals(candidate({'A', 'B', 'C'}, 'B'), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_83818_solution2", "language": "lua", "prompt": "-- given an index i, sort  the array such that elements less then i appear before i\n-- then element at i, then all items that are larger\nlocal function solution2(n, i)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_83818_solution2.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = solution2\n    lu.assertEquals(candidate({1, 4, 3, 2, 6}, 0), {1, 4, 3, 2, 6})\n    lu.assertEquals(candidate({1, 4, 3, 2, 6}, 1), {1, 3, 2, 4, 6})\n    lu.assertEquals(candidate({1, 2, 5, 3, 4}, 2), {1, 2, 3, 4, 5})\n    lu.assertEquals(candidate(list(range(10)), 5), list(range(10)))\n    lu.assertEquals(candidate({1, 4, 3, 2, 6}, 2), {1, 2, 3, 4, 6})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5}, 4), {1, 2, 3, 4, 5})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_84115_solution1", "language": "lua", "prompt": "-- Solves the first part of the challenge\nlocal function solution1(inp)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_84115_solution1.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = solution1\n    lu.assertEquals(candidate('1721\\n979\\n366\\n299\\n675\\n1456'), 514579)\n    lu.assertEquals(candidate('\\n1721\\n979\\n366\\n299\\n675\\n1456\\n'), 514579)\n    lu.assertEquals(candidate('1721\\n    979\\n    366\\n    299\\n    675\\n    1456'), 514579)\n    lu.assertEquals(candidate('\\n1721\\n979\\n366\\n299\\n675\\n1456\\n'), 514579)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_84207_isize", "language": "lua", "prompt": "-- Get a readable size from a number of bytes.\nlocal function isize(n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_84207_isize.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = isize\n    lu.assertEquals(candidate(1023), '1023 B')\n    lu.assertEquals(candidate(1024), '1.00 KB')\n    lu.assertEquals(candidate(1025), '1.00 KB')\n    lu.assertEquals(candidate(1), '1 B')\n    lu.assertEquals(candidate(0), '0 B')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_84583_min_abs_mod", "language": "lua", "prompt": "--     This function returns absolute minimum modulo of a over b.\nlocal function min_abs_mod(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_84583_min_abs_mod.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = min_abs_mod\n    lu.assertEquals(candidate(10, 10), 0)\n    lu.assertEquals(candidate(-1, 1), 0)\n    lu.assertEquals(candidate(3, 10), 3)\n    lu.assertEquals(candidate(3, -5), -2)\n    lu.assertEquals(candidate(1, 1), 0)\n    lu.assertEquals(candidate(-15, 5), 0)\n    lu.assertEquals(candidate(-3, 5), 2)\n    lu.assertEquals(candidate(10, 5), 0)\n    lu.assertEquals(candidate(8, 6), 2)\n    lu.assertEquals(candidate(3, 3), 0)\n    lu.assertEquals(candidate(-2, 2), 0)\n    lu.assertEquals(candidate(10, 3), 1)\n    lu.assertEquals(candidate(2, -2), 0)\n    lu.assertEquals(candidate(2, 2), 0)\n    lu.assertEquals(candidate(2, -1), 0)\n    lu.assertEquals(candidate(7, 6), 1)\n    lu.assertEquals(candidate(8, 8), 0)\n    lu.assertEquals(candidate(5, 5), 0)\n    lu.assertEquals(candidate(-2, -1), 0)\n    lu.assertEquals(candidate(4, 4), 0)\n    lu.assertEquals(candidate(-10, 5), 0)\n    lu.assertEquals(candidate(1, 5), 1)\n    lu.assertEquals(candidate(2, 1), 0)\n    lu.assertEquals(candidate(-1, -2), -1)\n    lu.assertEquals(candidate(-2, 1), 0)\n    lu.assertEquals(candidate(6, 6), 0)\n    lu.assertEquals(candidate(0, 1), 0)\n    lu.assertEquals(candidate(1, -1), 0)\n    lu.assertEquals(candidate(7, 5), 2)\n    lu.assertEquals(candidate(-2, -2), 0)\n    lu.assertEquals(candidate(0, 5), 0)\n    lu.assertEquals(candidate(10, 7), 3)\n    lu.assertEquals(candidate(4, 3), 1)\n    lu.assertEquals(candidate(8, 4), 0)\n    lu.assertEquals(candidate(-1, -1), 0)\n    lu.assertEquals(candidate(-1, 2), 1)\n    lu.assertEquals(candidate(1, 3), 1)\n    lu.assertEquals(candidate(2, 5), 2)\n    lu.assertEquals(candidate(4, 2), 0)\n    lu.assertEquals(candidate(-5, 5), 0)\n    lu.assertEquals(candidate(7, 7), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_84972_parse_hex", "language": "lua", "prompt": "--  Helper function for RA and Dec parsing, takes hex string, returns list of floats.\n-- Not normally called directly by user. TESTS OK 2020-10-24.\n--     :param hex_string: string in either full hex (\"12:34:56.7777\" or \"12 34 56.7777\"),\n--        or degrees (\"234.55\")\n--     :return: list of strings representing floats (hours:min:sec or deg:arcmin:arcsec).\nlocal function parse_hex(hex_string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_84972_parse_hex.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_hex\n    lu.assertEquals(candidate('234.55'), {'234.55'})\n    lu.assertEquals(candidate('123456.777'), {'123456.777'})\n    lu.assertEquals(candidate('12:34:56.7777'), candidate('12 34 56.7777'))\n    lu.assertEquals(candidate('23:45:12.456'), {'23', '45', '12.456'})\n    lu.assertEquals(candidate('-23:45:12.456'), {'-23', '45', '12.456'})\n    lu.assertEquals(candidate('12 34 56.7777'), {'12', '34', '56.7777'})\n    lu.assertEquals(candidate('12 34 56.777 78 90 11.111'), {'12', '34', '56.777', '78', '90', '11.111'})\n    lu.assertEquals(candidate('-234.5555'), {'-234.5555'})\n    lu.assertEquals(candidate('12:34:56'), {'12', '34', '56'})\n    lu.assertEquals(candidate('12 34 56.7777'), {'12', '34', '56.7777'})\n    lu.assertEquals(candidate('12 34 56.777'), {'12', '34', '56.777'})\n    lu.assertEquals(candidate('12:34:56.7777'), {'12', '34', '56.7777'})\n    lu.assertEquals(candidate('12:34:56.777'), {'12', '34', '56.777'})\n    lu.assertEquals(candidate('234.5555'), {'234.5555'})\n    lu.assertEquals(candidate('12 34 56'), {'12', '34', '56'})\n    lu.assertEquals(candidate('12:34:56'), {'12', '34', '56'})\n    lu.assertEquals(candidate('12:34:56.7777'), {'12', '34', '56.7777'})\n    lu.assertEquals(candidate('12 34 56'), {'12', '34', '56'})\n    lu.assertEquals(candidate('234.55'), {'234.55'})\n    lu.assertEquals(candidate('234.55 24.12'), {'234.55', '24.12'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_854_arg_return_greetings", "language": "lua", "prompt": "-- This is greeting function with arguments and return greeting message\n-- :param name:\n-- :return:\nlocal function arg_return_greetings(name)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_854_arg_return_greetings.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = arg_return_greetings\n    lu.assertEquals(candidate('Bob'), 'hello Bob')\n    lu.assertEquals(candidate('Milton'), 'hello Milton')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_85909_validate_training_proportion_input", "language": "lua", "prompt": "-- Validates the training proportion input\n-- :param input: The training proportion before parsing\n-- :return: The training proportion after parsing\nlocal function validate_training_proportion_input(input)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_85909_validate_training_proportion_input.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = validate_training_proportion_input\n    lu.assertEquals(candidate(0.1), 0.1)\n    lu.assertEquals(candidate(), 0.3)\n    lu.assertEquals(candidate(0.2), 0.2)\n    lu.assertEquals(candidate(0.3), 0.3)\n    lu.assertEquals(candidate('1'), 1)\n    lu.assertEquals(candidate(1), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_86450_matrix_n_by_n_determinant", "language": "lua", "prompt": "-- find the determinant of a n by n matrix\nlocal function matrix_n_by_n_determinant(nb_rows, nb_cols, matrix)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_86450_matrix_n_by_n_determinant.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = matrix_n_by_n_determinant\n    lu.assertEquals(candidate(1, 2, {{1, 2}}), 1)\n    lu.assertEquals(candidate(1, 1, {{5}}), 5)\n    lu.assertEquals(candidate(4, 4, {{1, 2, 3, 4}, {5, 6, 7, 8}, {9, 10, 11, 12}, {13, 14, 15, 16}}), 0)\n    lu.assertEquals(candidate(1, 1, {{1}}), 1)\n    lu.assertEquals(candidate(1, 1, {{2}}), 2)\n    lu.assertEquals(candidate(2, 2, {{2, 3}, {4, 5}}), -2)\n    lu.assertEquals(candidate(1, 3, {{1, 2, 3}}), 1)\n    lu.assertEquals(candidate(2, 2, {{1, 2}, {3, 4}}), -2)\n    lu.assertEquals(candidate(3, 3, {{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_86590_horizontal_index", "language": "lua", "prompt": "--  Compute the array index using horizontal-display logic \nlocal function horizontal_index(ncols, row, col)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_86590_horizontal_index.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = horizontal_index\n    lu.assertEquals(candidate(2, 1, 1), 1)\n    lu.assertEquals(candidate(2, 1, 2), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_86759_parse_codesys", "language": "lua", "prompt": "-- Operating System: Nucleus PLUS\n-- Operating System Details: Nucleus PLUS version unknown\n-- Product: 3S-Smart Software Solutions\nlocal function parse_codesys(info)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_86759_parse_codesys.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_codesys\n    lu.assertEquals(candidate('Operating System: Nucleus PLUS\\nOperating System Details: Nucleus PLUS version unknown\\nProduct: 3S-Smart Software Solutions\\n'), {['Operating System'] = 'Nucleus PLUS', ['Operating System Details'] = 'Nucleus PLUS version unknown', ['Product'] = '3S-Smart Software Solutions'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_86814_polynomial_decay_learning_rate", "language": "lua", "prompt": "-- Manual implementation of polynomial decay for learning rate\n-- :param step: which step we're on\n-- :param learning_rate_start: learning rate for epoch 0\n-- :param learning_rate_final: learning rate for epoch decay_steps\n-- :param decay_steps: epoch at which learning rate stops changing\n-- :param power: exponent\n-- :return:\nlocal function polynomial_decay_learning_rate(step, learning_rate_start, learning_rate_final, decay_steps, power)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_86814_polynomial_decay_learning_rate.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = polynomial_decay_learning_rate\n    lu.assertEquals(candidate(25, 1.0, 0.0, 25, 1.0), 0.0)\n    lu.assertEquals(candidate(50, 1.0, 0.0, 25, 1.0), 0.0)\n    lu.assertEquals(candidate(0, 1.0, 0.0, 25, 1.0), 1.0)\n    lu.assertEquals(candidate(10, 0.1, 0.5, 1, 2.0), 0.5)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_87160_steps_cancel_out", "language": "lua", "prompt": "-- >>> steps_cancel_out(None, \"U\")\n-- False\n-- >>> steps_cancel_out(\"U\", \"U'\")\n-- True\n-- >>> steps_cancel_out(\"U'\", \"U\")\n-- True\n-- >>> steps_cancel_out(\"U2\", \"U2\")\n-- True\n-- >>> steps_cancel_out(\"U\", \"U\")\n-- False\nlocal function steps_cancel_out(prev_step, step)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_87160_steps_cancel_out.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = steps_cancel_out\n    lu.assertEquals(candidate('U2', 'U2'), true)\n    lu.assertEquals(candidate('U', 'U2'), false)\n    lu.assertEquals(candidate('U2', 'U'), false)\n    lu.assertEquals(candidate(\"U'\", 'U'), true)\n    lu.assertEquals(candidate('U', \"U'\"), true)\n    lu.assertEquals(candidate('U', 'U'), false)\n    lu.assertEquals(candidate(None, 'U'), false)\n    lu.assertEquals(candidate('U2', 'D2'), false)\n    lu.assertEquals(candidate(\"U'\", 'U2'), false)\n    lu.assertEquals(candidate('U2', \"U'\"), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_87271_longestPalindrome", "language": "lua", "prompt": "--     Finds the longest instance of a palindrome in a string\nlocal function longestPalindrome(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_87271_longestPalindrome.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = longestPalindrome\n    lu.assertEquals(candidate('a'), 'a')\n    lu.assertEquals(candidate('abcba'), 'abcba')\n    lu.assertEquals(candidate('aa'), 'aa')\n    lu.assertEquals(candidate('abba'), 'abba')\n    lu.assertEquals(candidate('abababa'), 'abababa')\n    lu.assertEquals(candidate('racecar'), 'racecar')\n    lu.assertEquals(candidate('bananas'), 'anana')\n    lu.assertEquals(candidate('aba'), 'aba')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_87596_delimiter_check", "language": "lua", "prompt": "-- Determines what delimiter is used in given text file.\n-- Parameters:\n--         -line: str\n--                 line from text file\n-- Returns:\n--         -delim: str\n--                 delimiter used in text file\n-- Notes:\n-- Recognizes only \",\", \"\t\", and \":\" delimiters.\nlocal function delimiter_check(line)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_87596_delimiter_check.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = delimiter_check\n    lu.assertEquals(candidate('a,b,c'), ',')\n    lu.assertEquals(candidate('a\\tb\\tc'), '\\t')\n    lu.assertEquals(candidate('a:b:c'), ':')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_87843_create_fixed_income_regex", "language": "lua", "prompt": "-- Creates a regular expression pattern to match the fixed income symbology.\n-- To create the regular expression patter, the function uses the fact that within the\n-- ICE consolidated feed, all the fixed income instruments are identified by the root\n-- symbol ( a unique mnemonic based on the exchange ticker or the ISIN, where no exchange\n-- ticker is available), prefixed with the type and the optional session indicator. In\n-- addition to this minimal symbology setup, fixed income symbols can present optional\n-- elements such as the \"dirty bond\" marker and the sub-market indicator.\n-- The function only requires the root symbol, prefixed with the type and the optional\n-- session indicator, to generate a regular expression pattern, and takes care to\n-- autonomously extend the pattern to match as well all the optional components of the\n-- symbol.\n-- Parameters\n-- ----------\n-- input_symbol: str\n--     A fixed income symbol consisting of the root symbol prefixed with the type\n--     identifier (B) and optional session indicator.\n-- Returns\n-- -------\n-- str\n--     The regular expression pattern that matches the input symbol as well as all the\n--     optional components.\nlocal function create_fixed_income_regex(input_symbol)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_87843_create_fixed_income_regex.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = create_fixed_income_regex\n    lu.assertEquals(candidate('B\\\\d{1,10}'), '\\\\bB\\\\d{1,10}\\\\b\\\\\\\\{0,1}D{0,1}@{0,1}[a-zA-Z0-9]{1,10}')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_87844_min_value", "language": "lua", "prompt": "--  Compute min of a pair of two ints. \nlocal function min_value(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_87844_min_value.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = min_value\n    lu.assertEquals(candidate(3, 5), 3)\n    lu.assertEquals(candidate(2, 1), 1)\n    lu.assertEquals(candidate(0, -2), -2)\n    lu.assertEquals(candidate(-1, -2), -2)\n    lu.assertEquals(candidate(2, 3), 2)\n    lu.assertEquals(candidate(3, 4), 3)\n    lu.assertEquals(candidate(3, 1), 1)\n    lu.assertEquals(candidate(100, 1), 1)\n    lu.assertEquals(candidate(2, 2), 2)\n    lu.assertEquals(candidate(1, 100), 1)\n    lu.assertEquals(candidate(0, 0), 0)\n    lu.assertEquals(candidate(1, 1), 1)\n    lu.assertEquals(candidate(1, 3), 1)\n    lu.assertEquals(candidate(3, 3), 3)\n    lu.assertEquals(candidate(5, 3), 3)\n    lu.assertEquals(candidate(1, 2), 1)\n    lu.assertEquals(candidate(3, 2), 2)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_88209_location", "language": "lua", "prompt": "-- Function to format location\nlocal function location(loc)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_88209_location.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = location\n    lu.assertEquals(candidate('40.780831,-73.965339, 150 ft'), {['parsed'] = '40.780831,-73.965339, 150 ft', ['string'] = '40.780831,-73.965339, 150 ft'})\n    lu.assertEquals(candidate('E'), {['parsed'] = 'E', ['string'] = 'E'})\n    lu.assertEquals(candidate('F'), {['parsed'] = 'F', ['string'] = 'F'})\n    lu.assertEquals(candidate('H'), {['parsed'] = 'H', ['string'] = 'H'})\n    lu.assertEquals(candidate('D'), {['parsed'] = 'D', ['string'] = 'D'})\n    lu.assertEquals(candidate('New York, NY'), {['parsed'] = 'New York, NY', ['string'] = 'New York, NY'})\n    lu.assertEquals(candidate('somewhere'), {['parsed'] = 'somewhere', ['string'] = 'somewhere'})\n    lu.assertEquals(candidate('G'), {['parsed'] = 'G', ['string'] = 'G'})\n    lu.assertEquals(candidate('742 Evergreen Terrace'), {['parsed'] = '742 Evergreen Terrace', ['string'] = '742 Evergreen Terrace'})\n    lu.assertEquals(candidate('New York City'), {['parsed'] = 'New York City', ['string'] = 'New York City'})\n    lu.assertEquals(candidate('Q'), {['parsed'] = 'Q', ['string'] = 'Q'})\n    lu.assertEquals(candidate('New York'), {['parsed'] = 'New York', ['string'] = 'New York'})\n    lu.assertEquals(candidate('L'), {['parsed'] = 'L', ['string'] = 'L'})\n    lu.assertEquals(candidate('CaliforniA, Irvine'), {['parsed'] = 'CaliforniA, Irvine', ['string'] = 'CaliforniA, Irvine'})\n    lu.assertEquals(candidate('P'), {['parsed'] = 'P', ['string'] = 'P'})\n    lu.assertEquals(candidate('M'), {['parsed'] = 'M', ['string'] = 'M'})\n    lu.assertEquals(candidate('A'), {['parsed'] = 'A', ['string'] = 'A'})\n    lu.assertEquals(candidate('UCLA'), {['parsed'] = 'UCLA', ['string'] = 'UCLA'})\n    lu.assertEquals(candidate('University of California, Irvine'), {['parsed'] = 'University of California, Irvine', ['string'] = 'University of California, Irvine'})\n    lu.assertEquals(candidate('R'), {['parsed'] = 'R', ['string'] = 'R'})\n    lu.assertEquals(candidate('40.780831, -73.965339'), {['parsed'] = '40.780831, -73.965339', ['string'] = '40.780831, -73.965339'})\n    lu.assertEquals(candidate('NYC'), {['parsed'] = 'NYC', ['string'] = 'NYC'})\n    lu.assertEquals(candidate('C'), {['parsed'] = 'C', ['string'] = 'C'})\n    lu.assertEquals(candidate('40.780831,-73.965339'), {['parsed'] = '40.780831,-73.965339', ['string'] = '40.780831,-73.965339'})\n    lu.assertEquals(candidate('San Diego State University'), {['parsed'] = 'San Diego State University', ['string'] = 'San Diego State University'})\n    lu.assertEquals(candidate('O'), {['parsed'] = 'O', ['string'] = 'O'})\n    lu.assertEquals(candidate(''), {['parsed'] = '', ['string'] = ''})\n    lu.assertEquals(candidate('J'), {['parsed'] = 'J', ['string'] = 'J'})\n    lu.assertEquals(candidate('K'), {['parsed'] = 'K', ['string'] = 'K'})\n    lu.assertEquals(candidate('University of California, San Diego'), {['parsed'] = 'University of California, San Diego', ['string'] = 'University of California, San Diego'})\n    lu.assertEquals(candidate('N'), {['parsed'] = 'N', ['string'] = 'N'})\n    lu.assertEquals(candidate('None'), {['parsed'] = 'None', ['string'] = 'N/A'})\n    lu.assertEquals(candidate('New York State University'), {['parsed'] = 'New York State University', ['string'] = 'New York State University'})\n    lu.assertEquals(candidate('I'), {['parsed'] = 'I', ['string'] = 'I'})\n    lu.assertEquals(candidate('B'), {['parsed'] = 'B', ['string'] = 'B'})\n    lu.assertEquals(candidate('New York State'), {['parsed'] = 'New York State', ['string'] = 'New York State'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_8834_count_digit", "language": "lua", "prompt": "-- Return how many times digit appears in n.\n-- >>> count_digit(55055, 5)\n-- 4\n-- >>> count_digit(1231421, 1)\n-- 3\n-- >>> count_digit(12, 3)\n-- 0\nlocal function count_digit(n, digit)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_8834_count_digit.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = count_digit\n    lu.assertEquals(candidate(55055, 5), 4)\n    lu.assertEquals(candidate(12345, 6), 0)\n    lu.assertEquals(candidate(1234, 2), 1)\n    lu.assertEquals(candidate(1234, 3), 1)\n    lu.assertEquals(candidate(1231421, 1), 3)\n    lu.assertEquals(candidate(12, 3), 0)\n    lu.assertEquals(candidate(1231421, 0), 0)\n    lu.assertEquals(candidate(1234, 5), 0)\n    lu.assertEquals(candidate(1231421, 5), 0)\n    lu.assertEquals(candidate(1234, 4), 1)\n    lu.assertEquals(candidate(1234, 1), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_89299_get_pkg_vendor_name", "language": "lua", "prompt": "-- Method to extract vendor and name information from package. If vendor information is not available\n-- package url is used to extract the package registry provider such as pypi, maven\nlocal function get_pkg_vendor_name(pkg)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_89299_get_pkg_vendor_name.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = get_pkg_vendor_name\n    lu.assertEquals(candidate({['purl'] = 'pkg:pypi/pip', ['type'] = 'pypi', ['name'] = 'pip', ['version'] = '20.3.4', ['scope'] = 'dependencies'}), {'pypi', 'pip'})\n    lu.assertEquals(candidate({['purl'] = 'pkg:pypi/pip@20.3.4', ['type'] = 'pypi', ['name'] = 'pip', ['version'] = '20.3.4', ['scope'] = 'dependencies'}), {'pypi', 'pip'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_8962_is_catalog_record_owner", "language": "lua", "prompt": "-- Does user_id own catalog_record.\n-- :param catalog_record:\n-- :param user_id:\n-- :return:\nlocal function is_catalog_record_owner(catalog_record, user_id)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_8962_is_catalog_record_owner.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_catalog_record_owner\n    lu.assertEquals(candidate({['metadata_provider_user'] = 'a', ['owner'] = 'b'}, 'a'), true)\n    lu.assertEquals(candidate({['metadata_provider_user'] = 'a', ['owner'] = 'a'}, 'b'), false)\n    lu.assertEquals(candidate({['metadata_provider_user'] = 'a', ['owner'] = 'b'}, None), false)\n    lu.assertEquals(candidate({['metadata_provider_user'] = 'a', ['owner'] = 'a'}, None), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_89762_maxSatisfied", "language": "lua", "prompt": "-- :type customers: List[int]\n-- :type grumpy: List[int]\n-- :type X: int\n-- :rtype: int\nlocal function maxSatisfied(customers, grumpy, X)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_89762_maxSatisfied.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = maxSatisfied\n    lu.assertEquals(candidate({0, 0}, {0, 0}, 1), 0)\n    lu.assertEquals(candidate({1, 0, 1, 2, 1, 1, 7, 5}, {0, 1, 0, 1, 0, 1, 0, 1}, 3), 16)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_90472_conv_ls", "language": "lua", "prompt": "-- convert a number in a list of integers\nlocal function conv_ls(N)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_90472_conv_ls.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = conv_ls\n    lu.assertEquals(candidate(5), {5})\n    lu.assertEquals(candidate(7), {7})\n    lu.assertEquals(candidate(256), {2, 5, 6})\n    lu.assertEquals(candidate(123456789), {1, 2, 3, 4, 5, 6, 7, 8, 9})\n    lu.assertEquals(candidate(12345), {1, 2, 3, 4, 5})\n    lu.assertEquals(candidate(2), {2})\n    lu.assertEquals(candidate(9), {9})\n    lu.assertEquals(candidate(1), {1})\n    lu.assertEquals(candidate(19), {1, 9})\n    lu.assertEquals(candidate(123), {1, 2, 3})\n    lu.assertEquals(candidate(21), {2, 1})\n    lu.assertEquals(candidate(100), {1, 0, 0})\n    lu.assertEquals(candidate(12345), {1, 2, 3, 4, 5})\n    lu.assertEquals(candidate(23), {2, 3})\n    lu.assertEquals(candidate(253), {2, 5, 3})\n    lu.assertEquals(candidate(20), {2, 0})\n    lu.assertEquals(candidate(0), {0})\n    lu.assertEquals(candidate(32), {3, 2})\n    lu.assertEquals(candidate(13), {1, 3})\n    lu.assertEquals(candidate(11), {1, 1})\n    lu.assertEquals(candidate(18), {1, 8})\n    lu.assertEquals(candidate(1000), {1, 0, 0, 0})\n    lu.assertEquals(candidate(1234567), {1, 2, 3, 4, 5, 6, 7})\n    lu.assertEquals(candidate(12), {1, 2})\n    lu.assertEquals(candidate(123456), {1, 2, 3, 4, 5, 6})\n    lu.assertEquals(candidate(17), {1, 7})\n    lu.assertEquals(candidate(24), {2, 4})\n    lu.assertEquals(candidate(111), {1, 1, 1})\n    lu.assertEquals(candidate(8), {8})\n    lu.assertEquals(candidate(1234), {1, 2, 3, 4})\n    lu.assertEquals(candidate(22), {2, 2})\n    lu.assertEquals(candidate(26), {2, 6})\n    lu.assertEquals(candidate(4), {4})\n    lu.assertEquals(candidate(15), {1, 5})\n    lu.assertEquals(candidate(25), {2, 5})\n    lu.assertEquals(candidate(6), {6})\n    lu.assertEquals(candidate(257), {2, 5, 7})\n    lu.assertEquals(candidate(3), {3})\n    lu.assertEquals(candidate(10), {1, 0})\n    lu.assertEquals(candidate(16), {1, 6})\n    lu.assertEquals(candidate(14), {1, 4})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_9048_upto", "language": "lua", "prompt": "--  return all the text up to the limit string \nlocal function upto(limit, text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_9048_upto.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = upto\n    lu.assertEquals(candidate(' ', 'Python is the best choice to start learning'), 'Python')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_90538_rev", "language": "lua", "prompt": "-- >>> rev([20, 13, 8, 19, 19, 4, 18, 19, 8, 18, 1, 4, 19, 19, 4, 17])\n-- 'unittestisbetter'\nlocal function rev(l)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_90538_rev.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rev\n    lu.assertEquals(candidate(list('')), '')\n    lu.assertEquals(candidate({20, 13, 8, 19, 19, 4, 18, 19, 8, 18, 1, 4, 19, 19, 4, 17}), 'unittestisbetter')\n    lu.assertEquals(candidate({}), '')\n    lu.assertEquals(candidate({20, 13, 8, 19, 19, 4, 18, 19, 8, 18, 1, 4, 19, 19, 4, 17}), 'unittestisbetter')\n    lu.assertEquals(candidate({20, 13, 8, 19, 19, 4, 18, 19, 8, 18, 1, 4, 19, 19, 4, 17}), 'unittestisbetter')\n    lu.assertEquals(candidate({20, 13, 8, 19, 19, 4, 18, 19, 8, 18, 1, 4, 19, 19, 4, 17}), 'unittestisbetter')\n    lu.assertEquals(candidate({20, 13, 8, 19, 19, 4, 18, 19, 8, 18, 1, 4, 19, 19, 4, 17}), 'unittestisbetter')\n    lu.assertEquals(candidate(list(range(20))), 'abcdefghijklmnopqrst')\n    lu.assertEquals(candidate(list(map(ord, ''))), '')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_90563_smallest_difference", "language": "lua", "prompt": "-- Finds smallest angle between two bearings\n-- :param value1:\n-- :param value2:\n-- :return:\nlocal function smallest_difference(value1, value2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_90563_smallest_difference.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = smallest_difference\n    lu.assertEquals(candidate(10, 10), 0)\n    lu.assertEquals(candidate(-5, 5), 10)\n    lu.assertEquals(candidate(30, 35), 5)\n    lu.assertEquals(candidate(290, 270), 20)\n    lu.assertEquals(candidate(270, 270), 0)\n    lu.assertEquals(candidate(30, 50), 20)\n    lu.assertEquals(candidate(0, 360), 0)\n    lu.assertEquals(candidate(20, 35), 15)\n    lu.assertEquals(candidate(30, 30), 0)\n    lu.assertEquals(candidate(35, 20), 15)\n    lu.assertEquals(candidate(-10, 10), 20)\n    lu.assertEquals(candidate(35, 30), 5)\n    lu.assertEquals(candidate(20, 50), 30)\n    lu.assertEquals(candidate(15, 45), 30)\n    lu.assertEquals(candidate(-5, 25), 30)\n    lu.assertEquals(candidate(270, 360), 90)\n    lu.assertEquals(candidate(270, 290), 20)\n    lu.assertEquals(candidate(10, 20), 10)\n    lu.assertEquals(candidate(25, -5), 30)\n    lu.assertEquals(candidate(350, 360), 10)\n    lu.assertEquals(candidate(350, 355), 5)\n    lu.assertEquals(candidate(350, 350), 0)\n    lu.assertEquals(candidate(10, 30), 20)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_90785_dist_point", "language": "lua", "prompt": "-- Computes the distance square between a point and a line\n-- inputs:\n--   - point : (x,y)\n--   - line  : (slope, intercept)      \nlocal function dist_point(point, line)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_90785_dist_point.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = dist_point\n    lu.assertEquals(candidate({1, 2}, {1, 3}), 4)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_91158_count_leading_empty_lines", "language": "lua", "prompt": "-- Count the number of leading empty cells.\nlocal function count_leading_empty_lines(cell)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_91158_count_leading_empty_lines.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = count_leading_empty_lines\n    lu.assertEquals(candidate('Hello world!'), 0)\n    lu.assertEquals(candidate('\\n# This is a comment\\n# This is another comment\\nhello\\nworld\\n'), 1)\n    lu.assertEquals(candidate('hello world'), 0)\n    lu.assertEquals(candidate('\\n\\nhello\\nworld\\n'), 2)\n    lu.assertEquals(candidate('The first line is not empty'), 0)\n    lu.assertEquals(candidate('    \\n    '), 2)\n    lu.assertEquals(candidate('    Hello, world!\\n    '), 0)\n    lu.assertEquals(candidate('\\nA long cell with leading empty lines\\n\\n'), 1)\n    lu.assertEquals(candidate('\\n# This is a comment\\nhello\\nworld\\n'), 1)\n    lu.assertEquals(candidate('\\n\\n'), 2)\n    lu.assertEquals(candidate('This cell contains one line of text.'), 0)\n    lu.assertEquals(candidate('    \\n    \\n    '), 3)\n    lu.assertEquals(candidate(\"def func():\\n    print('Hi')\\n\"), 0)\n    lu.assertEquals(candidate('\\n\\n\\nhello\\nworld\\n'), 3)\n    lu.assertEquals(candidate('text'), 0)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('\\n\\nhello\\nworld\\n'), 2)\n    lu.assertEquals(candidate('\\n\\n\\ntext'), 3)\n    lu.assertEquals(candidate('\\n\\n# This is a comment\\nhello\\nworld\\n'), 2)\n    lu.assertEquals(candidate('hello\\nworld\\n'), 0)\n    lu.assertEquals(candidate('\\n\\n\\n'), 3)\n    lu.assertEquals(candidate('\\n\\n\\n   \\ntext'), 4)\n    lu.assertEquals(candidate('\\nhello\\nworld\\n'), 1)\n    lu.assertEquals(candidate('   '), 1)\n    lu.assertEquals(candidate('\\n\\n    '), 3)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('\\n'), 1)\n    lu.assertEquals(candidate(''), 0)\n    lu.assertEquals(candidate('hello world'), 0)\n    lu.assertEquals(candidate('\\n\\n\\nhello\\nworld\\n'), 3)\n    lu.assertEquals(candidate('\\nA long cell with leading empty lines\\n\\n \\n\\n\\n\\n \\n\\n\\n'), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_91177_calc_mi", "language": "lua", "prompt": "-- Calculate migration index (MI).\n-- For the right hip, MI = (lat acetabulum - lat head) / (med head - lat head)\n-- For the left hip first need to multiple each point by -1.\n-- Args:\n--     med_head_x: x coordinate of medial head\n--     lat_head_x: x coordinate of lateral head\n--     lat_acetabulum_x: x coordinate of lateral acetabulum\n--     side: side of hip from which points come (i.e., 'right' or 'left')\n-- Raise:\n--     ValueError if side not in ['right', 'left']\n-- Returns:\n--     Migration index in interval [0,1]\nlocal function calc_mi(med_head_x, lat_head_x, lat_acetabulum_x, side)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_91177_calc_mi.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = calc_mi\n    lu.assertEquals(candidate(2, 1, 2, 'right'), 1)\n    lu.assertEquals(candidate(2, 1, 1, 'right'), 0)\n    lu.assertEquals(candidate(2, 1, 2, 'left'), 1)\n    lu.assertEquals(candidate(1, 0, 0, 'right'), 0)\n    lu.assertEquals(candidate(100, 0, 0, 'left'), 0)\n    lu.assertEquals(candidate(0, 1, 0, 'left'), 1)\n    lu.assertEquals(candidate(1, 0, 0, 'left'), 0)\n    lu.assertEquals(candidate(2, 1, 1, 'left'), 0)\n    lu.assertEquals(candidate(100, 0, 0, 'right'), 0)\n    lu.assertEquals(candidate(0, 1, 0, 'right'), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_91262_password_rule_2", "language": "lua", "prompt": "-- Check if going from left to right, the digits never decrease; they only ever increase or\n-- stay the same (like 111123 or 135679).\n-- :param password: str\n-- :return: bool\nlocal function password_rule_2(password)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_91262_password_rule_2.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = password_rule_2\n    lu.assertEquals(candidate('111122'), true)\n    lu.assertEquals(candidate('1'), true)\n    lu.assertEquals(candidate('333'), true)\n    lu.assertEquals(candidate('223450'), false)\n    lu.assertEquals(candidate('123456'), true)\n    lu.assertEquals(candidate('4444'), true)\n    lu.assertEquals(candidate('111123'), true)\n    lu.assertEquals(candidate(''), false)\n    lu.assertEquals(candidate('22'), true)\n    lu.assertEquals(candidate('666666'), true)\n    lu.assertEquals(candidate('111111'), true)\n    lu.assertEquals(candidate('999999999'), true)\n    lu.assertEquals(candidate(None), false)\n    lu.assertEquals(candidate('55555'), true)\n    lu.assertEquals(candidate('88888888'), true)\n    lu.assertEquals(candidate('135679'), true)\n    lu.assertEquals(candidate('7777777'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_91318_decapitalize", "language": "lua", "prompt": "-- This method will be used to lower case the first character of SQS\n-- message attributes being received by Lambda to resolve inconsistencies.\n-- Issue outlined here: https://github.com/boto/boto3/issues/2582\nlocal function decapitalize(key)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_91318_decapitalize.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = decapitalize\n    lu.assertEquals(candidate('Foo'), 'foo')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('foo'), 'foo')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_91803_is_valid_square_input", "language": "lua", "prompt": "-- Checks if an entry square value is a valid input to the sudoku\n-- :param text: Str\n-- :return: True if valid, False if not\nlocal function is_valid_square_input(text)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_91803_is_valid_square_input.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = is_valid_square_input\n    lu.assertEquals(candidate('a'), false)\n    lu.assertEquals(candidate('abc'), false)\n    lu.assertEquals(candidate('1'), true)\n    lu.assertEquals(candidate('-1'), false)\n    lu.assertEquals(candidate('1.0'), false)\n    lu.assertEquals(candidate('11'), false)\n    lu.assertEquals(candidate('10'), false)\n    lu.assertEquals(candidate(' '), false)\n    lu.assertEquals(candidate('2'), true)\n    lu.assertEquals(candidate('9'), true)\n    lu.assertEquals(candidate('00000'), false)\n    lu.assertEquals(candidate('3'), true)\n    lu.assertEquals(candidate(''), true)\n    lu.assertEquals(candidate('100'), false)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_92093_format_makehelp", "language": "lua", "prompt": "--     return \"{target}:\t{detail}\"\nlocal function format_makehelp(target, detail)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_92093_format_makehelp.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = format_makehelp\n    lu.assertEquals(candidate('all', 'This target builds the following targets: clean, debug, release, and test.'), 'all:\\tThis target builds the following targets: clean, debug, release, and test.')\n    lu.assertEquals(candidate('debug', 'Build with debug symbols'), 'debug:\\tBuild with debug symbols')\n    lu.assertEquals(candidate('clean', 'Removes the build directory'), 'clean:\\tRemoves the build directory')\n    lu.assertEquals(candidate('release-test', 'Build release binary, run unit tests'), 'release-test:\\tBuild release binary, run unit tests')\n    lu.assertEquals(candidate('target', 'detail'), 'target:\\tdetail')\n    lu.assertEquals(candidate('run', 'Runs the program'), 'run:\\tRuns the program')\n    lu.assertEquals(candidate('test', 'this is a test'), 'test:\\tthis is a test')\n    lu.assertEquals(candidate('clean', 'Remove all build artifacts'), 'clean:\\tRemove all build artifacts')\n    lu.assertEquals(candidate('debug-test', 'Build debug binary, run unit tests'), 'debug-test:\\tBuild debug binary, run unit tests')\n    lu.assertEquals(candidate('test', 'Run all tests'), 'test:\\tRun all tests')\n    lu.assertEquals(candidate('release', 'Build without debug symbols'), 'release:\\tBuild without debug symbols')\n    lu.assertEquals(candidate('clean-debug', 'Remove all debug build artifacts'), 'clean-debug:\\tRemove all debug build artifacts')\n    lu.assertEquals(candidate('target', 'detail'), 'target:\\tdetail')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_92403__list_product", "language": "lua", "prompt": "-- Computes product of all elements in a list.\nlocal function _list_product(num_list)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_92403__list_product.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _list_product\n    lu.assertEquals(candidate({}), 1)\n    lu.assertEquals(candidate(list(range(1, 10))), 362880)\n    lu.assertEquals(candidate(list(range(1, 11))), 3628800)\n    lu.assertEquals(candidate(list(range(1, 21))), 2432902008176640000)\n    lu.assertEquals(candidate(list(range(1, 6))), 120)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_92626_gcd", "language": "lua", "prompt": "-- (int, int) -> int\n-- Uses Euclid's method to compute the greatest common factor\n-- (greatest common divisor) of two integers, <m> and <n>\n-- Returns greatest common factor (gcd) of the two integers\nlocal function gcd(m, n)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_92626_gcd.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = gcd\n    lu.assertEquals(candidate(12, 6), 6)\n    lu.assertEquals(candidate(12, 24), 12)\n    lu.assertEquals(candidate(2, 12), 2)\n    lu.assertEquals(candidate(9, 6), 3)\n    lu.assertEquals(candidate(10, 100), 10)\n    lu.assertEquals(candidate(5, 15), 5)\n    lu.assertEquals(candidate(4, 2), 2)\n    lu.assertEquals(candidate(8, 2), 2)\n    lu.assertEquals(candidate(56, 110), 2)\n    lu.assertEquals(candidate(18, 12), 6)\n    lu.assertEquals(candidate(15, 5), 5)\n    lu.assertEquals(candidate(1024, 1024), 1024)\n    lu.assertEquals(candidate(36, 6), 6)\n    lu.assertEquals(candidate(12, 3), 3)\n    lu.assertEquals(candidate(36, 24), 12)\n    lu.assertEquals(candidate(5, 0), 5)\n    lu.assertEquals(candidate(12, 18), 6)\n    lu.assertEquals(candidate(19, 3), 1)\n    lu.assertEquals(candidate(3, 12), 3)\n    lu.assertEquals(candidate(6, 36), 6)\n    lu.assertEquals(candidate(0, 5), 5)\n    lu.assertEquals(candidate(20, 15), 5)\n    lu.assertEquals(candidate(6, 9), 3)\n    lu.assertEquals(candidate(), 10)\n    lu.assertEquals(candidate(6, 12), 6)\n    lu.assertEquals(candidate(30, 10), 10)\n    lu.assertEquals(candidate(12, 12), 12)\n    lu.assertEquals(candidate(2, 4), 2)\n    lu.assertEquals(candidate(0, 2), 2)\n    lu.assertEquals(candidate(0, 0), 0)\n    lu.assertEquals(candidate(6, 18), 6)\n    lu.assertEquals(candidate(24, 36), 12)\n    lu.assertEquals(candidate(12, 2), 2)\n    lu.assertEquals(candidate(2, 0), 2)\n    lu.assertEquals(candidate(2, 8), 2)\n    lu.assertEquals(candidate(12, 0), 12)\n    lu.assertEquals(candidate(2, 10), 2)\n    lu.assertEquals(candidate(18, 6), 6)\n    lu.assertEquals(candidate(1, 1), 1)\n    lu.assertEquals(candidate(1000, 10), 10)\n    lu.assertEquals(candidate(3, 4), 1)\n    lu.assertEquals(candidate(10, 2), 2)\n    lu.assertEquals(candidate(1000, 10000), 1000)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_9273_clean_text_simple", "language": "lua", "prompt": "-- Remove all \u0019 from the string formatted with simple colors:\n-- \u00198\nlocal function clean_text_simple(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_9273_clean_text_simple.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = clean_text_simple\n    lu.assertEquals(candidate('This \\x191is\\x193 \\x199just\\x193 some\\x193 \\x199text.\\x193'), 'This is just some text.')\n    lu.assertEquals(candidate('This is just some text.'), 'This is just some text.')\n    lu.assertEquals(candidate('\\x190Red\\x198 \\x190Green\\x198 \\x190Blue\\x198 \\x190Yellow\\x198'), 'Red Green Blue Yellow')\n    lu.assertEquals(candidate('\\\\x198\\\\x1913'), '\\\\x198\\\\x1913')\n    lu.assertEquals(candidate('\\\\x198\\\\x198\\\\x19888'), '\\\\x198\\\\x198\\\\x19888')\n    lu.assertEquals(candidate('This \\x199is\\x193 \\x199just\\x193 some\\x193 \\x191text.\\x193'), 'This is just some text.')\n    lu.assertEquals(candidate('\\x194Red\\x198 \\x194Green\\x198 \\x194Blue\\x198 \\x194Yellow\\x198'), 'Red Green Blue Yellow')\n    lu.assertEquals(candidate('\\\\x198888'), '\\\\x198888')\n    lu.assertEquals(candidate('\\\\x1913\\\\x198888'), '\\\\x1913\\\\x198888')\n    lu.assertEquals(candidate('\\\\x198'), '\\\\x198')\n    lu.assertEquals(candidate('\\x194Red\\x198 \\x190Green\\x198 \\x192Blue\\x198 \\x191Yellow\\x198'), 'Red Green Blue Yellow')\n    lu.assertEquals(candidate('\\\\x1988\\\\x1988\\\\x1988'), '\\\\x1988\\\\x1988\\\\x1988')\n    lu.assertEquals(candidate('\\x194Red\\x198 \\x191Green\\x198 \\x192Blue\\x198 \\x193Yellow\\x198'), 'Red Green Blue Yellow')\n    lu.assertEquals(candidate('This \\x191is\\x193 \\x199just\\x193 some\\x193 \\x191text.\\x193'), 'This is just some text.')\n    lu.assertEquals(candidate('\\\\x198\\\\x198\\\\x198'), '\\\\x198\\\\x198\\\\x198')\n    lu.assertEquals(candidate('This \\x199is\\x193 \\x199just\\x193 some\\x193 text.\\x193'), 'This is just some text.')\n    lu.assertEquals(candidate('\\x191Red\\x198 \\x191Green\\x198 \\x191Blue\\x198 \\x191Yellow\\x198'), 'Red Green Blue Yellow')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_92801_parse_hl_lines", "language": "lua", "prompt": "-- Support our syntax for emphasizing certain lines of code.\n-- expr should be like '1 2' to emphasize lines 1 and 2 of a code block.\n-- Returns a list of ints, the line numbers to emphasize.\nlocal function parse_hl_lines(expr)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_92801_parse_hl_lines.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_hl_lines\n    lu.assertEquals(candidate('10 '), {10})\n    lu.assertEquals(candidate(' 10'), {10})\n    lu.assertEquals(candidate(' 1'), {1})\n    lu.assertEquals(candidate('1'), {1})\n    lu.assertEquals(candidate(' 10 11 '), {10, 11})\n    lu.assertEquals(candidate('10 11 12 13 '), {10, 11, 12, 13})\n    lu.assertEquals(candidate(' '), {})\n    lu.assertEquals(candidate('10 11'), {10, 11})\n    lu.assertEquals(candidate('1 2'), {1, 2})\n    lu.assertEquals(candidate('1'), {1})\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('10 11 a'), {})\n    lu.assertEquals(candidate(''), {})\n    lu.assertEquals(candidate('10'), {10})\n    lu.assertEquals(candidate('   '), {})\n    lu.assertEquals(candidate('10 11 '), {10, 11})\n    lu.assertEquals(candidate(None), {})\n    lu.assertEquals(candidate('10 11 12 13'), {10, 11, 12, 13})\n    lu.assertEquals(candidate(' 10 11 12 13 '), {10, 11, 12, 13})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_92907_distance", "language": "lua", "prompt": "--  Manthatten distance \nlocal function distance(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_92907_distance.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = distance\n    lu.assertEquals(candidate({0, 0}, {0, 0}), 0)\n    lu.assertEquals(candidate({-1, 1}, {1, 1}), 2)\n    lu.assertEquals(candidate({1, 1}, {-1, 1}), 2)\n    lu.assertEquals(candidate({1, 1}, {1, 1}), 0)\n    lu.assertEquals(candidate({0, 0}, {0, 1}), 1)\n    lu.assertEquals(candidate({0, 0}, {0, 0}), 0)\n    lu.assertEquals(candidate({1, 1}, {1, -1}), 2)\n    lu.assertEquals(candidate({1, 1}, {2, 2}), 2)\n    lu.assertEquals(candidate({1, 1}, {1, 2}), 1)\n    lu.assertEquals(candidate({1, 1}, {2, 1}), 1)\n    lu.assertEquals(candidate({1, 1}, {1, 1}), 0)\n    lu.assertEquals(candidate({0, 0}, {1, 1}), 2)\n    lu.assertEquals(candidate({1, 1}, {0, 0}), 2)\n    lu.assertEquals(candidate({3, 4}, {3, 4}), 0)\n    lu.assertEquals(candidate({0, 0}, {1, 0}), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_92983_areStringsEqual", "language": "lua", "prompt": "--     Returns if two strings are the same, disregarding cases.\nlocal function areStringsEqual(a, b)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_92983_areStringsEqual.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = areStringsEqual\n    lu.assertEquals(candidate('t', 'test'), false)\n    lu.assertEquals(candidate('TEST', 'test'), true)\n    lu.assertEquals(candidate('test', 'test'), true)\n    lu.assertEquals(candidate('TeSt', 'test'), true)\n    lu.assertEquals(candidate('Hello', 'hello'), true)\n    lu.assertEquals(candidate('Hello', 'world'), false)\n    lu.assertEquals(candidate('', ''), true)\n    lu.assertEquals(candidate('TESt', 'test'), true)\n    lu.assertEquals(candidate('Hello', 'Hello'), true)\n    lu.assertEquals(candidate('tESt', 'test'), true)\n    lu.assertEquals(candidate('test', 'other'), false)\n    lu.assertEquals(candidate('te', 'test'), false)\n    lu.assertEquals(candidate('test', 'TEST'), true)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_93087_binary_search", "language": "lua", "prompt": "-- Apply binary search to find either a \"start\" or \"end\" of a particular number\n-- >>> binary_search([2, 3, 3, 3, 4], 3, 'start')\n-- 1\n-- >>> binary_search([2, 3, 3, 3, 4], 3, 'end')\n-- 3\n-- >>> binary_search([2, 3, 3, 3, 4], 5, 'start')\n-- -1\n-- >>> binary_search([2, 3, 3, 3, 4], 5, 'end')\n-- -1\n-- >>> binary_search([2, 3, 3, 3, 5], 4, 'start')\n-- -1\nlocal function binary_search(array, k, pos)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_93087_binary_search.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = binary_search\n    lu.assertEquals(candidate({2, 3, 3, 3, 5}, 4, 'start'), -1)\n    lu.assertEquals(candidate({2, 3, 3, 3, 4}, 5, 'start'), -1)\n    lu.assertEquals(candidate({2, 3, 3, 3, 4}, 3, 'start'), 1)\n    lu.assertEquals(candidate({2, 3, 3, 3, 4}, 3, 'end'), 3)\n    lu.assertEquals(candidate({2, 3, 3, 3, 4}, 5, 'end'), -1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_93501_parse_line_contents", "language": "lua", "prompt": "-- Extract the sigma, gamma, lambda and m from the line:\n-- just read until we get something looking like a float and then store the first three of them\nlocal function parse_line_contents(line)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_93501_parse_line_contents.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_line_contents\n    lu.assertEquals(candidate('sigma: 1.0 gamma: 1.0 lambda: 1 m: 1'), {1.0, 1.0, 1.0})\n    lu.assertEquals(candidate('0.00000000 0.0 0.0'), {0.0, 0.0, 0.0})\n    lu.assertEquals(candidate('lambda: 1 m: 1 sigma: 1 gamma: 1'), {1.0, 1.0, 1.0})\n    lu.assertEquals(candidate('sigma: 1.0 gamma: 1.0 lambda: 1.0 m: 1'), {1.0, 1.0, 1.0})\n    lu.assertEquals(candidate('0.307228 0.010438 12.869096 0.0000000'), {0.307228, 0.010438, 12.869096})\n    lu.assertEquals(candidate('0.307228 0.010438 12.869096'), {0.307228, 0.010438, 12.869096})\n    lu.assertEquals(candidate('1.234567890 2345.678901 3.456789012'), {1.23456789, 2345.678901, 3.456789012})\n    lu.assertEquals(candidate('123.4567890 2.345678901 3.456789012'), {123.456789, 2.345678901, 3.456789012})\n    lu.assertEquals(candidate('0.0 0.1 0.0'), {0.0, 0.1, 0.0})\n    lu.assertEquals(candidate('1.234567890 2.345678901 3.456789012'), {1.23456789, 2.345678901, 3.456789012})\n    lu.assertEquals(candidate('0.0 0.0 0.0'), {0.0, 0.0, 0.0})\n    lu.assertEquals(candidate('123456.7890 2.345678901 3.456789012'), {123456.789, 2.345678901, 3.456789012})\n    lu.assertEquals(candidate('0.307228 0.010438 12.869096 0.0000000'), {0.307228, 0.010438, 12.869096})\n    lu.assertEquals(candidate('0.05 0.0 0.0'), {0.05, 0.0, 0.0})\n    lu.assertEquals(candidate('0.5 0.0 0.0'), {0.5, 0.0, 0.0})\n    lu.assertEquals(candidate('0.00 0.0 0.0'), {0.0, 0.0, 0.0})\n    lu.assertEquals(candidate('0.0 0.0 0.2'), {0.0, 0.0, 0.2})\n    lu.assertEquals(candidate('sigma: 1.0 gamma: 1.0 m: 1 lambda: 1'), {1.0, 1.0, 1.0})\n    lu.assertEquals(candidate('sigma: 1.0 lambda: 1 m: 1 gamma: 1'), {1.0, 1.0, 1.0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_93912_selection_to_string", "language": "lua", "prompt": "-- Convert dictionary of coordinates to a string for labels.\n-- Parameters\n-- ----------\n-- selection : dict[Any] -> Any\n-- Returns\n-- -------\n-- str\n--     key1: value1, key2: value2, ...\nlocal function selection_to_string(selection)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_93912_selection_to_string.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = selection_to_string\n    lu.assertEquals(candidate(dict()), '')\n    lu.assertEquals(candidate({[1] = 2, [3] = 4, [5] = 6, [7] = 8}), '2, 4, 6, 8')\n    lu.assertEquals(candidate({[1] = 2, [3] = 4}), '2, 4')\n    lu.assertEquals(candidate({[1] = 2}), '2')\n    lu.assertEquals(candidate({[1] = 2, [3] = 4, [5] = 6}), '2, 4, 6')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_94083_rotate_key", "language": "lua", "prompt": "-- This function is used to adjust the byte position in the temp_key, the bytes of the temp_key are shifted over one\n-- bytes to the left.\n-- :param temp_key: A 4 bytes value, only accept numeric object.\n-- :return: A new 4 bytes value.\nlocal function rotate_key(temp_key)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_94083_rotate_key.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = rotate_key\n    lu.assertEquals(candidate(65536), {1, 0, 0, 0})\n    lu.assertEquals(candidate(0), {0, 0, 0, 0})\n    lu.assertEquals(candidate(0), {0, 0, 0, 0})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_94301_fmt_jsdoc_union", "language": "lua", "prompt": "--     Returns a JSDoc union of the given type strings.\nlocal function fmt_jsdoc_union(type_strings)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_94301_fmt_jsdoc_union.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = fmt_jsdoc_union\n    lu.assertEquals(candidate({'(string|number)', '(boolean|number)'}), '((string|number)|(boolean|number))')\n    lu.assertEquals(candidate({'Number', 'boolean', 'String', 'undefined', 'void'}), '(Number|boolean|String|undefined|void)')\n    lu.assertEquals(candidate({'String'}), 'String')\n    lu.assertEquals(candidate({'number', 'undefined'}), '(number|undefined)')\n    lu.assertEquals(candidate({''}), '')\n    lu.assertEquals(candidate({'Number', 'boolean'}), '(Number|boolean)')\n    lu.assertEquals(candidate({'string', 'null'}), '(string|null)')\n    lu.assertEquals(candidate({'String', 'Number', 'Boolean'}), '(String|Number|Boolean)')\n    lu.assertEquals(candidate({'null', 'number'}), '(null|number)')\n    lu.assertEquals(candidate({'String', 'Number'}), '(String|Number)')\n    lu.assertEquals(candidate({'number', 'undefined', 'string', 'null'}), '(number|undefined|string|null)')\n    lu.assertEquals(candidate({'Number', 'Boolean', 'String', 'Array', 'Object', 'Function'}), '(Number|Boolean|String|Array|Object|Function)')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_94317_str_to_list", "language": "lua", "prompt": "-- remove [] and whitespace, then create list of integers to return\nlocal function str_to_list(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_94317_str_to_list.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = str_to_list\n    lu.assertEquals(candidate('[1, 2, 3, 4]'), {1, 2, 3, 4})\n    lu.assertEquals(candidate('[1,2,3,4]'), {1, 2, 3, 4})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_94524__create_mux_ranges", "language": "lua", "prompt": "-- Create a list of ranges based on a list of single values.\n-- Example:\n--     Input:  [1, 2, 3, 5,      7, 8, 9]\n--     Output: [[1, 3], [5, 5], [7, 9]]\nlocal function _create_mux_ranges(multiplexer_ids)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_94524__create_mux_ranges.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = _create_mux_ranges\n    lu.assertEquals(candidate({1, 2, 3, 5, 7, 8, 9}), {{1, 3}, {5, 5}, {7, 9}})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5}), {{1, 5}})\n    lu.assertEquals(candidate({1, 2}), {{1, 2}})\n    lu.assertEquals(candidate({1, 2, 3, 4, 6, 7, 8, 9, 10}), {{1, 4}, {6, 10}})\n    lu.assertEquals(candidate({1, 2, 3}), {{1, 3}})\n    lu.assertEquals(candidate(list(range(10))), {{0, 9}})\n    lu.assertEquals(candidate({1, 2, 3, 5, 7, 8, 9}), {{1, 3}, {5, 5}, {7, 9}})\n    lu.assertEquals(candidate({1, 3, 5, 7, 9}), {{1, 1}, {3, 3}, {5, 5}, {7, 7}, {9, 9}})\n    lu.assertEquals(candidate({2, 3}), {{2, 3}})\n    lu.assertEquals(candidate({1, 2, 4, 6, 8}), {{1, 2}, {4, 4}, {6, 6}, {8, 8}})\n    lu.assertEquals(candidate({2, 4, 6, 8}), {{2, 2}, {4, 4}, {6, 6}, {8, 8}})\n    lu.assertEquals(candidate(list(range(2, 10))), {{2, 9}})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13}), {{1, 10}, {12, 13}})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6, 7, 8, 9}), {{1, 9}})\n    lu.assertEquals(candidate({1, 2, 3, 4}), {{1, 4}})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6, 7}), {{1, 7}})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6, 7, 8}), {{1, 8}})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6, 7, 8, 9, 10}), {{1, 10}})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6}), {{1, 6}})\n    lu.assertEquals(candidate({1, 2, 3, 5, 7, 8, 9}), {{1, 3}, {5, 5}, {7, 9}})\n    lu.assertEquals(candidate({1, 2, 3, 4, 5, 6, 7, 8, 9}), {{1, 9}})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_94584_contar_palabra", "language": "lua", "prompt": "-- Cuenta cuantas veces se repite una palabra en una cadena de\n-- texto.\n-- :param linea: Cadena de texto.\n-- :linea type: str\n-- :param palabra: Palabra a buscar.\n-- :palabra type: str\n-- :return: Cuantas veces se repite la palabra en la cadena.\n-- :rtype: int\nlocal function contar_palabra(linea, palabra)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_94584_contar_palabra.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = contar_palabra\n    lu.assertEquals(candidate('la casa de papelera es de papel', 'de'), 2)\n    lu.assertEquals(candidate('Caminando por el camino de la victoria', 'camino'), 1)\n    lu.assertEquals(candidate('la casa de papelera es de papel', 'casa'), 1)\n    lu.assertEquals(candidate('Caminando por el camino de la victoria', 'de'), 1)\n    lu.assertEquals(candidate('Caminando por el camino de la victoria', 'victoria'), 1)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_94731_url_to_id", "language": "lua", "prompt": "--  Takes a tweet url and returns its id \nlocal function url_to_id(url)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_94731_url_to_id.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = url_to_id\n    lu.assertEquals(candidate('https://twitter.com/nasa/status/668083631563360256/'), 668083631563360256)\n    lu.assertEquals(candidate('https://twitter.com/GOP/status/883987787058900992'), 883987787058900992)\n    lu.assertEquals(candidate('https://twitter.com/Interior/status/1365679211592238592'), 1365679211592238592)\n    lu.assertEquals(candidate('http://twitter.com/realDonaldTrump/status/883891012282360832'), 883891012282360832)\n    lu.assertEquals(candidate('http://twitter.com/TheDemocrats/status/883891832571059712'), 883891832571059712)\n    lu.assertEquals(candidate('http://twitter.com/ThePSF/status/293380700514344496'), 293380700514344496)\n    lu.assertEquals(candidate('https://twitter.com/dog_rates/status/457937231478969344'), 457937231478969344)\n    lu.assertEquals(candidate('https://twitter.com/Interior/status/108076710113857283'), 108076710113857283)\n    lu.assertEquals(candidate('https://twitter.com/dog_rates/status/1234567890123456789'), 1234567890123456789)\n    lu.assertEquals(candidate('https://twitter.com/dog_rates/status/881533559209541120'), 881533559209541120)\n    lu.assertEquals(candidate('https://twitter.com/nasa/status/668083631563360256'), 668083631563360256)\n    lu.assertEquals(candidate('https://twitter.com/dog_rates/status/1456963204405214725'), 1456963204405214725)\n    lu.assertEquals(candidate('https://twitter.com/dog_rates/status/1228908675299224064'), 1228908675299224064)\n    lu.assertEquals(candidate('https://twitter.com/ThePSF/status/293380700514344496'), 293380700514344496)\n    lu.assertEquals(candidate('https://twitter.com/Interior/status/1278747526441191425/'), 1278747526441191425)\n    lu.assertEquals(candidate('https://twitter.com/dog_rates/status/1000000000000000000000'), 1000000000000000000000)\n    lu.assertEquals(candidate('https://twitter.com/Interior/status/108076710113857282'), 108076710113857282)\n    lu.assertEquals(candidate('https://twitter.com/dog_rates/status/1000000000000000000'), 1000000000000000000)\n    lu.assertEquals(candidate('https://twitter.com/dog_rates/status/1322712625669947906'), 1322712625669947906)\n    lu.assertEquals(candidate('https://twitter.com/dog_rates/status/1204125929760247808'), 1204125929760247808)\n    lu.assertEquals(candidate('https://twitter.com/ThePSF/status/1204844046511772737'), 1204844046511772737)\n    lu.assertEquals(candidate('https://twitter.com/Interior/status/1278747526441191425'), 1278747526441191425)\n    lu.assertEquals(candidate('https://twitter.com/Interior/status/1278747526441191425/?s=20#fragment'), 1278747526441191425)\n    lu.assertEquals(candidate('https://twitter.com/Interior/status/108076710113857286'), 108076710113857286)\n    lu.assertEquals(candidate('https://twitter.com/realDonaldTrump/status/883907451037186050'), 883907451037186050)\n    lu.assertEquals(candidate('https://twitter.com/Interior/status/108076710113857284'), 108076710113857284)\n    lu.assertEquals(candidate('https://twitter.com/realDonaldTrump/status/883907451037186051'), 883907451037186051)\n    lu.assertEquals(candidate('https://twitter.com/Interior/status/1278747526441191425/?s=20'), 1278747526441191425)\n    lu.assertEquals(candidate('https://twitter.com/realDonaldTrump/status/883907451037186052'), 883907451037186052)\n    lu.assertEquals(candidate('https://twitter.com/ThePSF/status/1204844046511772737'), 1204844046511772737)\n    lu.assertEquals(candidate('https://twitter.com/dog_rates/status/1360580986549242368'), 1360580986549242368)\n    lu.assertEquals(candidate('https://twitter.com/Interior/status/108076710113857281'), 108076710113857281)\n    lu.assertEquals(candidate('https://twitter.com/dog_rates/status/690096206448278528'), 690096206448278528)\n    lu.assertEquals(candidate('https://twitter.com/dog_rates/status/0000000000000000000'), 0)\n    lu.assertEquals(candidate('https://twitter.com/dog_rates/status/889479840728144384'), 889479840728144384)\n    lu.assertEquals(candidate('https://twitter.com/dog_rates/status/761015783402666496'), 761015783402666496)\n    lu.assertEquals(candidate('https://twitter.com/dog_rates/status/9999999999999999999'), 9999999999999999999)\n    lu.assertEquals(candidate('https://twitter.com/dog_rates/status/1234567890123456789'), 1234567890123456789)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_95589_parse_export_env", "language": "lua", "prompt": "-- Parse environment variables to a dictionary.\n-- Exmple:\n--     env_vars = parse_export_env(job.attr_export_env_to_job)\n--     primary_file = env_vars['PAS_PRIMARY_FILE']\n-- Args:\n--     env: Environment variables.\n-- Returns:\n--     Pairs of the name and value of environment variables.\nlocal function parse_export_env(env)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_95589_parse_export_env.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = parse_export_env\n    lu.assertEquals(candidate('PAS_ENVIRONMENT=1,PAS_PRIMARY_FILE=1,PAS_CONTEXT_ID=1'), {['PAS_ENVIRONMENT'] = '1', ['PAS_PRIMARY_FILE'] = '1', ['PAS_CONTEXT_ID'] = '1'})\n    lu.assertEquals(candidate('PAS_PRIMARY_FILE='), {['PAS_PRIMARY_FILE'] = ''})\n    lu.assertEquals(candidate('PAS_ENVIRONMENT=,PAS_PRIMARY_FILE=,PAS_CONTEXT_ID='), {['PAS_ENVIRONMENT'] = '', ['PAS_PRIMARY_FILE'] = '', ['PAS_CONTEXT_ID'] = ''})\n    lu.assertEquals(candidate('PAS_PRIMARY_FILE=primary_file'), {['PAS_PRIMARY_FILE'] = 'primary_file'})\n    lu.assertEquals(candidate('A=1,B=2,C='), {['A'] = '1', ['B'] = '2', ['C'] = ''})\n    lu.assertEquals(candidate('A=1,B=2,C=3'), {['A'] = '1', ['B'] = '2', ['C'] = '3'})\n    lu.assertEquals(candidate('PAS_PRIMARY_FILE=primary_file1,PAS_PRIMARY_FILE=primary_file2'), {['PAS_PRIMARY_FILE'] = 'primary_file2'})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_957_sparse_add", "language": "lua", "prompt": "-- dict, dict -> dict\n-- Returns a new dictionary that is the sum of the other two.\n-- >>>sparse_add(sv1, sv2)\n-- {0: 5, 1: 6, 2: 9}\nlocal function sparse_add(sv1, sv2)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_957_sparse_add.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = sparse_add\n    lu.assertEquals(candidate({[1] = 2, [3] = 3}, {}), {[1] = 2, [3] = 3})\n    lu.assertEquals(candidate({}, {[1] = 2, [3] = 3}), {[1] = 2, [3] = 3})\n    lu.assertEquals(candidate({[0] = 1, [1] = 2, [2] = 3, [4] = 1}, {[0] = 1, [1] = 2, [2] = 3}), {[0] = 2, [1] = 4, [2] = 6, [4] = 1})\n    lu.assertEquals(candidate({[1] = 2, [3] = 3}, {[1] = 4}), {[1] = 6, [3] = 3})\n    lu.assertEquals(candidate({}, {[0] = 1, [1] = 2, [2] = 3}), {[0] = 1, [1] = 2, [2] = 3})\n    lu.assertEquals(candidate({[0] = 1, [1] = 2, [3] = 3}, {[0] = 1, [1] = 2, [2] = 3}), {[0] = 2, [1] = 4, [2] = 3, [3] = 3})\n    lu.assertEquals(candidate({[0] = 1, [2] = 3}, {[0] = 1, [1] = 2, [2] = 3}), {[0] = 2, [1] = 2, [2] = 6})\n    lu.assertEquals(candidate({[1] = 2, [3] = 3}, {[3] = 4, [5] = 6}), {[1] = 2, [3] = 7, [5] = 6})\n    lu.assertEquals(candidate({}, {}), {})\n    lu.assertEquals(candidate({[0] = 1, [1] = 2, [2] = 3}, {}), {[0] = 1, [1] = 2, [2] = 3})\n    lu.assertEquals(candidate({}, {}), {})\n    lu.assertEquals(candidate({[1] = 2, [3] = 3}, {[4] = 5}), {[1] = 2, [3] = 3, [4] = 5})\n    lu.assertEquals(candidate({}, {[0] = 100}), {[0] = 100})\n    lu.assertEquals(candidate({[0] = 100}, {}), {[0] = 100})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_96148_index_from_weekday", "language": "lua", "prompt": "-- Returns a numeric index for day of week based on name of day\n-- :param weekday: Name of day (e.g. 'Sunday', 'Monday', etc.)\n-- :return: numeric index\nlocal function index_from_weekday(weekday)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_96148_index_from_weekday.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = index_from_weekday\n    lu.assertEquals(candidate('Sunday'), 0)\n    lu.assertEquals(candidate('Thursday'), 4)\n    lu.assertEquals(candidate('Saturday'), 6)\n    lu.assertEquals(candidate('Wednesday'), 3)\n    lu.assertEquals(candidate('Monday'), 1)\n    lu.assertEquals(candidate('Tuesday'), 2)\n    lu.assertEquals(candidate('Friday'), 5)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_96726_reverse_transform_params", "language": "lua", "prompt": "-- Merge input parameter key and value into one-line string\n-- Args:\n--     params_in (list): Python list of output params e.g.\n--     {\n--         \"ParameterKey\": \"principal_role\",\n--         \"ParameterValue\": \"$[alfred_ssm_/org/primary/service_catalog/\n--         principal/role_arn]\"\n--     }\n-- Return:\n--     params_out (dict): Python dict of input params e.g.\n--     {\n--         \"principal_role\": \"$[alfred_ssm_/org/primary/service_catalog/\n--         principal/role_arn]\"\n--     }\nlocal function reverse_transform_params(params_in)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_96726_reverse_transform_params.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = reverse_transform_params\n    lu.assertEquals(candidate({{['ParameterKey'] = 'principal_role', ['ParameterValue'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]'}, {['ParameterKey'] = 'role_arn', ['ParameterValue'] = '$[alfred_ssm_/org/primary/service_catalog/deployer/role_arn]'}}), {['principal_role'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]', ['role_arn'] = '$[alfred_ssm_/org/primary/service_catalog/deployer/role_arn]'})\n    lu.assertEquals(candidate({{['ParameterKey'] = 'principal_role', ['ParameterValue'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]'}}), {['principal_role'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]'})\n    lu.assertEquals(candidate({{['ParameterKey'] = 'principal_role', ['ParameterValue'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]'}, {['ParameterKey'] = 'data_bucket', ['ParameterValue'] = '$[alfred_ssm_/org/primary/data_lake/bucket]'}}), {['principal_role'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]', ['data_bucket'] = '$[alfred_ssm_/org/primary/data_lake/bucket]'})\n    lu.assertEquals(candidate({{['ParameterKey'] = 'principal_role', ['ParameterValue'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]'}}), {['principal_role'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]'})\n    lu.assertEquals(candidate({{['ParameterKey'] = 'empty', ['ParameterValue'] = ''}}), {['empty'] = ''})\n    lu.assertEquals(candidate({{['ParameterKey'] = 'principal_role', ['ParameterValue'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]'}, {['ParameterKey'] = 'data_bucket', ['ParameterValue'] = '$[alfred_ssm_/org/primary/data_lake/bucket]'}, {['ParameterKey'] = 'data_bucket', ['ParameterValue'] = '$[alfred_ssm_/org/primary/data_lake/bucket]'}}), {['principal_role'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]', ['data_bucket'] = '$[alfred_ssm_/org/primary/data_lake/bucket]'})\n    lu.assertEquals(candidate({{['ParameterKey'] = 'principal_role', ['ParameterValue'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]'}, {['ParameterKey'] = 'role_name', ['ParameterValue'] = '$[alfred_ssm_/org/primary/service_catalog/cross_account_access_role/name]'}}), {['principal_role'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]', ['role_name'] = '$[alfred_ssm_/org/primary/service_catalog/cross_account_access_role/name]'})\n    lu.assertEquals(candidate({{['ParameterKey'] = 'principal_role', ['ParameterValue'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]'}, {['ParameterKey'] = 'vpc_cidr', ['ParameterValue'] = '$[alfred_ssm_/org/primary/service_catalog/network/vpc/vpc_cidr]'}}), {['principal_role'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]', ['vpc_cidr'] = '$[alfred_ssm_/org/primary/service_catalog/network/vpc/vpc_cidr]'})\n    lu.assertEquals(candidate({{['ParameterKey'] = 'principal_role', ['ParameterValue'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]'}, {['ParameterKey'] = 'another_role', ['ParameterValue'] = '$[alfred_ssm_/org/primary/service_catalog/another_role_arn]'}}), {['principal_role'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]', ['another_role'] = '$[alfred_ssm_/org/primary/service_catalog/another_role_arn]'})\n    lu.assertEquals(candidate({{['ParameterKey'] = 'principal_role', ['ParameterValue'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]'}}), {['principal_role'] = '$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]'})\n    lu.assertEquals(candidate({}), {})\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_97036_string_lower", "language": "lua", "prompt": "-- **string_lower(string)** -> return the lowercase value of the string\n-- * string: (string) string to lower case.\n-- <code>\n--    Example:\n--        string_lower('Linux')\n--    Returns:\n--        'linux'\n-- </code>\nlocal function string_lower(string)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_97036_string_lower.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = string_lower\n    lu.assertEquals(candidate('A'), 'a')\n    lu.assertEquals(candidate('\u00a1'), '\u00a1')\n    lu.assertEquals(candidate('\u00bf'), '\u00bf')\n    lu.assertEquals(candidate('LINUX1234'), 'linux1234')\n    lu.assertEquals(candidate('`~-_=+[]{}\\\\|;:\\'\",<.>/?'), '`~-_=+[]{}\\\\|;:\\'\",<.>/?')\n    lu.assertEquals(candidate('z'), 'z')\n    lu.assertEquals(candidate('Linux1234'), 'linux1234')\n    lu.assertEquals(candidate('LiNuX'), 'linux')\n    lu.assertEquals(candidate('LInux'), 'linux')\n    lu.assertEquals(candidate('!@#$%^&*()'), '!@#$%^&*()')\n    lu.assertEquals(candidate('linux'), 'linux')\n    lu.assertEquals(candidate('\u01dd'), '\u01dd')\n    lu.assertEquals(candidate('Linux'), 'linux')\n    lu.assertEquals(candidate('Z'), 'z')\n    lu.assertEquals(candidate('\u0137'), '\u0137')\n    lu.assertEquals(candidate(''), '')\n    lu.assertEquals(candidate('lInuX'), 'linux')\n    lu.assertEquals(candidate('\u0133'), '\u0133')\n    lu.assertEquals(candidate('LinUxB'), 'linuxb')\n    lu.assertEquals(candidate('\u0135'), '\u0135')\n    lu.assertEquals(candidate('a'), 'a')\n    lu.assertEquals(candidate('linuxB'), 'linuxb')\n    lu.assertEquals(candidate('LinUxB!'), 'linuxb!')\n    lu.assertEquals(candidate('0123456789'), '0123456789')\n    lu.assertEquals(candidate('Linux!'), 'linux!')\n    lu.assertEquals(candidate('\u0138'), '\u0138')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_9742_convert_to_camel", "language": "lua", "prompt": "-- Convert snake case (foo_bar_bat) to camel case (fooBarBat).\n-- This is not pythonic, but needed for certain situations\nlocal function convert_to_camel(data)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_9742_convert_to_camel.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = convert_to_camel\n    lu.assertEquals(candidate('foo_bar_bat'), 'fooBarBat')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_98079_eq_11_dimensionless_hrr_rectangular", "language": "lua", "prompt": "-- Equation 11 in Section 8.3.2.2 PD 7974-1:2019 calculates dimensionless for rectangular fire source.\n-- :param Q_dot_kW: in kW, fire heat release rate.\n-- :param rho_0: in kg/m^3, density of ambient air.\n-- :param c_p_0_kJ_kg_K: in kJ/kg/K, specific heat capacity of ambient air.\n-- :param T_0: in K, ambient air temperature.\n-- :param g: in m/s^2, acceleration due to gravity.\n-- :param L_A: in m, rectangular shape dimension's shorter edge.\n-- :param L_B: in m, rectangular shape dimension's longer edge.\n-- :return Q_dot_star_rect: dimensionless, dimensionless heat release rate\nlocal function eq_11_dimensionless_hrr_rectangular(Q_dot_kW, rho_0, c_p_0_kJ_kg_K, T_0, g, L_A, L_B)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_98079_eq_11_dimensionless_hrr_rectangular.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = eq_11_dimensionless_hrr_rectangular\n    lu.assertEquals(candidate(0, 1, 1, 273.15, 9.807, 2, 2), 0)\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
{"name": "HumanEval_99617_unindent", "language": "lua", "prompt": "-- eat leading space in front of lines based on the smallest one\nlocal function unindent(str)\n", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_99617_unindent.py", "prompt_terminology": "verbatim", "tests": "lu = require('luaunit')\n\nfunction test_humaneval()\nlocal candidate = unindent\n    lu.assertEquals(candidate('\\n    line1\\n    line2\\n    line3\\n    line4\\n    '), '\\nline1\\nline2\\nline3\\nline4\\n')\n    lu.assertEquals(candidate('    This is a\\n    multi-line\\n    string\\n    '), 'This is a\\nmulti-line\\nstring\\n')\n    lu.assertEquals(candidate('\\n    line1\\n\\n    line2\\n\\n    line3\\n    line4\\n    '), '\\nline1\\n\\nline2\\n\\nline3\\nline4\\n')\n    lu.assertEquals(candidate('\\n\\n    line1\\n      line2\\n    line3\\n    line4\\n    '), '\\n\\nline1\\n  line2\\nline3\\nline4\\n')\n    lu.assertEquals(candidate('    This is a\\n    multi-line\\n    string\\n\\n    this is also part of the string\\n\\n        it has a nested indentation\\n    '), 'This is a\\nmulti-line\\nstring\\n\\nthis is also part of the string\\n\\n    it has a nested indentation\\n')\n    lu.assertEquals(candidate('\\n    line1\\n      line2\\n    line3\\n    line4\\n    '), '\\nline1\\n  line2\\nline3\\nline4\\n')\n    lu.assertEquals(candidate('    This is a\\n    multi-line\\n    string\\n\\n    this is also part of the string\\n    '), 'This is a\\nmulti-line\\nstring\\n\\nthis is also part of the string\\n')\nend\n\nos.exit(lu.LuaUnit.run())", "stop_tokens": ["\nlocal", "\nfunction", "\n--", "\n\n"]}
