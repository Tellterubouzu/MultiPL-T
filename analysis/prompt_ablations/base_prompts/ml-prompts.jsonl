{"name": "HumanEval_100473_bit_ceil", "language": "ml", "prompt": "(**Calculate the smallest power of 2 not smaller than n.\n*)\nlet bit_ceil (n : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_100473_bit_ceil.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = bit_ceil in\n  (assert ((candidate 28) = 32));\n  (assert ((candidate 10) = 16));\n  (assert ((candidate 8) = 8));\n  (assert ((candidate 13) = 16));\n  (assert ((candidate 31) = 32));\n  (assert ((candidate 22) = 32));\n  (assert ((candidate 7) = 8));\n  (assert ((candidate 20) = 32));\n  (assert ((candidate 26) = 32));\n  (assert ((candidate 12) = 16));\n  (assert ((candidate 3) = 4));\n  (assert ((candidate 19) = 32));\n  (assert ((candidate 16) = 16));\n  (assert ((candidate 23) = 32));\n  (assert ((candidate 4) = 4));\n  (assert ((candidate 9) = 16));\n  (assert ((candidate 17) = 32));\n  (assert ((candidate 24) = 32));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 0) = 1));\n  (assert ((candidate 15) = 16));\n  (assert ((candidate 27) = 32));\n  (assert ((candidate 25) = 32));\n  (assert ((candidate 11) = 16));\n  (assert ((candidate 6) = 8));\n  (assert ((candidate 14) = 16));\n  (assert ((candidate 5) = 8));\n  (assert ((candidate 30) = 32));\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 21) = 32));\n  (assert ((candidate 18) = 32));\n  (assert ((candidate 29) = 32));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_100527_ell2ang", "language": "ml", "prompt": "(**Convert the given ell(s) to its analogous angular scale(s) in arcmins.\nReturn the angular scale(s) in arcmins corresponding to the Fourier mode \nell(s).\nParameters\n----------\nell: value, array of values\n * The ell mode(s).\nReturns\n-------\na: float, array of floats\n * The angular scale(s) corresponding to ell.\n*)\nlet ell2ang (ell : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_100527_ell2ang.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = ell2ang in\n  (assert ((candidate 1) = 10800));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_101579_about_me", "language": "ml", "prompt": "(**Return the most important thing about a person.\nParameters\n----------\nyour_name\n * A string indicating the name of the person.\n*)\nlet about_me (your_name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_101579_about_me.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = about_me in\n  (assert ((candidate \"Jose\") = \"The wise Jose loves Python.\"));\n  (assert ((candidate \"<NAME>\") = \"The wise <NAME> loves Python.\"));\n  (assert ((candidate \"Peter\") = \"The wise Peter loves Python.\"));\n  (assert ((candidate \"Donald\") = \"The wise Donald loves Python.\"));\n  (assert ((candidate \"Bob\") = \"The wise Bob loves Python.\"));\n  (assert ((candidate \"Bernhard\") = \"The wise Bernhard loves Python.\"));\n  (assert ((candidate \"Abraham\") = \"The wise Abraham loves Python.\"));\n  (assert ((candidate \"Bob\") = \"The wise Bob loves Python.\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_101630_maybe_quote", "language": "ml", "prompt": "(**Enclose the string argument in single quotes if it looks like it needs it.\nSpaces and quotes will trigger; single quotes in the argument are escaped.\nThis is only used to compose the --print output so need only satisfy shlex.\n*)\nlet maybe_quote (s : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_101630_maybe_quote.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = maybe_quote in\n  (assert ((candidate \"foo bar\") = \"'foo bar'\"));\n  (assert ((candidate \"x\") = \"x\"));\n  (assert ((candidate \"fo\\\"o\") = \"'fo\\\\\"o'\"));\n  (assert ((candidate \"a\\tb\") = \"'a\\\\tb'\"));\n  (assert ((candidate \"fo\"o\") = \"'fo\"o'\"));\n  (assert ((candidate \"Hello World!\") = \"'Hello World!'\"));\n  (assert ((candidate \"a   b\") = \"'a   b'\"));\n  (assert ((candidate \"a\") = \"a\"));\n  (assert ((candidate \"ab c\\\") = \"'ab c\\\\'\"));\n  (assert ((candidate \"Hello World?\") = \"'Hello World?'\"));\n  (assert ((candidate \"fo\\\\o\") = \"'fo\\\\\\\\o'\"));\n  (assert ((candidate \"\\\") = \"'\\\\'\"));\n  (assert ((candidate \"a\\nb\\tc\") = \"'a\\\\nb\\\\tc'\"));\n  (assert ((candidate \"foo bar\") = \"'foo bar'\"));\n  (assert ((candidate \" x\") = \"' x'\"));\n  (assert ((candidate \"fo o\") = \"'fo o'\"));\n  (assert ((candidate \"Hello World?\") = \"'Hello World?'\"));\n  (assert ((candidate \"fo\\\\\\o\") = \"'fo\\\\\\\\\\\\o'\"));\n  (assert ((candidate \"ab c\") = \"'ab c'\"));\n  (assert ((candidate \"a\\nb\") = \"'a\\\\nb'\"));\n  (assert ((candidate \"x \") = \"'x '\"));\n  (assert ((candidate \"a  b\") = \"'a  b'\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"\"\") = \"'\"'\"));\n  (assert ((candidate \"foo\") = \"foo\"));\n  (assert ((candidate \"Hello \"World\"!\") = \"'Hello \"World\"!'\"));\n  (assert ((candidate \"Hello World!\") = \"'Hello World!'\"));\n  (assert ((candidate \"a b\") = \"'a b'\"));\n  (assert ((candidate \"hello\") = \"hello\"));\n  (assert ((candidate \"abc\") = \"abc\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_101962_is_categorical", "language": "ml", "prompt": "(**Checks whether the variable type for the\nvariable of interest is categorical.\n*)\nlet is_categorical (var_type : string option) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_101962_is_categorical.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_categorical in\n  (assert ((candidate Some(None)) = false));\n  (assert ((candidate Some(\"string\")) = false));\n  (assert ((candidate Some(\"date\")) = false));\n  (assert ((candidate Some(\"number\")) = false));\n  (assert ((candidate Some(\"categorical\")) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_10216_split3", "language": "ml", "prompt": "(**Split text in 3 parts: before pat1, between, and after pat2.\n*)\nlet split3 (text : string) (pat1 : string) (pat2 : string) :  string * string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_10216_split3.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = split3 in\n  (assert ((candidate \"a:b:c\" \":\" \":\") = (\"a\", \"b\", \"c\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_10218_parts", "language": "ml", "prompt": "(**https://stackoverflow.com/a/52698110\n*)\nlet parts (a : int) (b : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_10218_parts.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parts in\n  (assert ((candidate 0 4) = [0; 0; 0; 0]));\n  (assert ((candidate 3 2) = [2; 1]));\n  (assert ((candidate 11 2) = [6; 5]));\n  (assert ((candidate 10 1) = [10]));\n  (assert ((candidate 4 2) = [2; 2]));\n  (assert ((candidate 0 10) = [0; 0; 0; 0; 0; 0; 0; 0; 0; 0]));\n  (assert ((candidate 4 3) = [2; 1; 1]));\n  (assert ((candidate 10 3) = [4; 3; 3]));\n  (assert ((candidate 5 3) = [2; 2; 1]));\n  (assert ((candidate 0 2) = [0; 0]));\n  (assert ((candidate 2 3) = [1; 1; 0]));\n  (assert ((candidate 0 1) = [0]));\n  (assert ((candidate 1 1) = [1]));\n  (assert ((candidate 2 2) = [1; 1]));\n  (assert ((candidate 10 2) = [5; 5]));\n  (assert ((candidate 4 1) = [4]));\n  (assert ((candidate 6 3) = [2; 2; 2]));\n  (assert ((candidate 1 4) = [1; 0; 0; 0]));\n  (assert ((candidate 1 2) = [1; 0]));\n  (assert ((candidate 1 3) = [1; 0; 0]));\n  (assert ((candidate 3 1) = [3]));\n  (assert ((candidate 5 1) = [5]));\n  (assert ((candidate 100 10) = [10; 10; 10; 10; 10; 10; 10; 10; 10; 10]));\n  (assert ((candidate 99 10) = [10; 10; 10; 10; 10; 10; 10; 10; 10; 9]));\n  (assert ((candidate 0 3) = [0; 0; 0]));\n  (assert ((candidate 2 1) = [2]));\n  (assert ((candidate 3 3) = [1; 1; 1]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_102630_get_last_step_id", "language": "ml", "prompt": "(**Returns the id of the last step in |steps|.\n*)\nlet get_last_step_id (steps : (string, string) list list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_102630_get_last_step_id.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_last_step_id in\n  (assert ((candidate [[(\"id\", \"s1\")]; [(\"id\", \"s2\")]; [(\"id\", \"s3\")]]) = \"s3\"));\n  (assert ((candidate [[(\"id\", \"s1\")]]) = \"s1\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_102704_bit_length", "language": "ml", "prompt": "(**Measure the length of the number in bits.\n:param num: The number to measure.\n:return:    The minimal amount of bits needed to represent the number.\n*)\nlet bit_length (num : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_102704_bit_length.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = bit_length in\n  (assert ((candidate 6) = 3));\n  (assert ((candidate 281474976710656) = 49));\n  (assert ((candidate 27) = 5));\n  (assert ((candidate 255) = 8));\n  (assert ((candidate 8) = 4));\n  (assert ((candidate 65535) = 16));\n  (assert ((candidate 13) = 4));\n  (assert ((candidate 12) = 4));\n  (assert ((candidate 14) = 4));\n  (assert ((candidate 128) = 8));\n  (assert ((candidate 5) = 3));\n  (assert ((candidate 11) = 4));\n  (assert ((candidate 30) = 5));\n  (assert ((candidate 281474976710655) = 48));\n  (assert ((candidate 1099511627775) = 40));\n  (assert ((candidate 0) = 1));\n  (assert ((candidate 256) = 9));\n  (assert ((candidate 7) = 3));\n  (assert ((candidate 1023) = 10));\n  (assert ((candidate 23) = 5));\n  (assert ((candidate 15) = 4));\n  (assert ((candidate 4294967297) = 33));\n  (assert ((candidate 9) = 4));\n  (assert ((candidate 29) = 5));\n  (assert ((candidate 4294967295) = 32));\n  (assert ((candidate 1099511627776) = 41));\n  (assert ((candidate 28) = 5));\n  (assert ((candidate 16777216) = 25));\n  (assert ((candidate 16) = 5));\n  (assert ((candidate 17) = 5));\n  (assert ((candidate 10) = 4));\n  (assert ((candidate 20) = 5));\n  (assert ((candidate 32) = 6));\n  (assert ((candidate 25) = 5));\n  (assert ((candidate 22) = 5));\n  (assert ((candidate 1099511627777) = 41));\n  (assert ((candidate 21) = 5));\n  (assert ((candidate 31) = 5));\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 1024) = 11));\n  (assert ((candidate 19) = 5));\n  (assert ((candidate 18) = 5));\n  (assert ((candidate 127) = 7));\n  (assert ((candidate 1025) = 11));\n  (assert ((candidate 65536) = 17));\n  (assert ((candidate 3) = 2));\n  (assert ((candidate 33) = 6));\n  (assert ((candidate 24) = 5));\n  (assert ((candidate 16777215) = 24));\n  (assert ((candidate 4) = 3));\n  (assert ((candidate 16777217) = 25));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 26) = 5));\n  (assert ((candidate 4294967296) = 33));\n  (assert ((candidate 65537) = 17));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_103381_get_cindex", "language": "ml", "prompt": "(********NOTE; CAUTION******\nThis code is from the original repository of \"DeepDTA; Bioinformatics\"\nNow the get_cindex is invalid (order dependent of given pairs).\nWe will use lifelines.utils for\n*)\nlet get_cindex (Y : int list) (P : int list) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_103381_get_cindex.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_cindex in\n  (assert ((candidate [1; 0; 0; 0; 1; 1; 0; 0] [1; 0; 0; 0; 1; 1; 0; 0]) = 1.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_103969_split_compound", "language": "ml", "prompt": "(**Split a possibly compound format string into segments.\n>>> split_compound('bold_underline_bright_blue_on_red')\n['bold', 'underline', 'bright_blue', 'on_red']\n*)\nlet split_compound (compound : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_103969_split_compound.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = split_compound in\n  (assert ((candidate \"foo_bar\") = [\"foo\"; \"bar\"]));\n  (assert ((candidate \"bold_underline_bright_blue_on_red\") = [\"bold\"; \"underline\"; \"bright_blue\"; \"on_red\"]));\n  (assert ((candidate \"bold_underline\") = [\"bold\"; \"underline\"]));\n  (assert ((candidate \"underline_bright_blue_on_red\") = [\"underline\"; \"bright_blue\"; \"on_red\"]));\n  (assert ((candidate \"bold\") = [\"bold\"]));\n  (assert ((candidate \"underline_on_red\") = [\"underline\"; \"on_red\"]));\n  (assert ((candidate \"bold_underline_bright_blue_on_red\") = [\"bold\"; \"underline\"; \"bright_blue\"; \"on_red\"]));\n  (assert ((candidate \"bold_underline_bright_green\") = [\"bold\"; \"underline\"; \"bright_green\"]));\n  (assert ((candidate \"on_red\") = [\"on_red\"]));\n  (assert ((candidate \"underline\") = [\"underline\"]));\n  (assert ((candidate \"foo_on_bar\") = [\"foo\"; \"on_bar\"]));\n  (assert ((candidate \"on_green\") = [\"on_green\"]));\n  (assert ((candidate \"foo_bar_baz\") = [\"foo\"; \"bar\"; \"baz\"]));\n  (assert ((candidate \"foo\") = [\"foo\"]));\n  (assert ((candidate \"bold\") = [\"bold\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_104481_compliment", "language": "ml", "prompt": "(**[finds the complimentary strand of dna \"pattern\"]\nArgs:\n * pattern ([string]): [dna strand of which compliment is found]\nReturns:\n * [string]: [compliment of dna pattern: A -> T, G -> C, T -> A, C -> G]\n*)\nlet compliment (pattern : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_104481_compliment.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = compliment in\n  (assert ((candidate \"T\") = \"A\"));\n  (assert ((candidate \"A\") = \"T\"));\n  (assert ((candidate \"C\") = \"G\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"G\") = \"C\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_104902__escape", "language": "ml", "prompt": "(**Basic html escaping.\n*)\nlet _escape (txt : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_104902__escape.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _escape in\n  (assert ((candidate \"&\") = \"&amp;\"));\n  (assert ((candidate \"hello\") = \"hello\"));\n  (assert ((candidate \"foo<bar>\") = \"foo&lt;bar&gt;\"));\n  (assert ((candidate \"<html>\") = \"&lt;html&gt;\"));\n  (assert ((candidate \"<world>hello&\") = \"&lt;world&gt;hello&amp;\"));\n  (assert ((candidate \"<&>\") = \"&lt;&amp;&gt;\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"world\") = \"world\"));\n  (assert ((candidate \"<hello>\") = \"&lt;hello&gt;\"));\n  (assert ((candidate \"<hello/>\") = \"&lt;hello/&gt;\"));\n  (assert ((candidate \"<html>\") = \"&lt;html&gt;\"));\n  (assert ((candidate \"&<hello/>\") = \"&amp;&lt;hello/&gt;\"));\n  (assert ((candidate \"&<hello>\") = \"&amp;&lt;hello&gt;\"));\n  (assert ((candidate \"<world/>\") = \"&lt;world/&gt;\"));\n  (assert ((candidate \"&<world>hello\") = \"&amp;&lt;world&gt;hello\"));\n  (assert ((candidate \"foo<bar/>\") = \"foo&lt;bar/&gt;\"));\n  (assert ((candidate \"hello\") = \"hello\"));\n  (assert ((candidate \"hello\") = \"hello\"));\n  (assert ((candidate \"&<world/>\") = \"&amp;&lt;world/&gt;\"));\n  (assert ((candidate \"<hello>world&\") = \"&lt;hello&gt;world&amp;\"));\n  (assert ((candidate \">\") = \"&gt;\"));\n  (assert ((candidate \"<\") = \"&lt;\"));\n  (assert ((candidate \"&<world>\") = \"&amp;&lt;world&gt;\"));\n  (assert ((candidate \"&<>\") = \"&amp;&lt;&gt;\"));\n  (assert ((candidate \"&<hello>world\") = \"&amp;&lt;hello&gt;world\"));\n  (assert ((candidate \"<world>\") = \"&lt;world&gt;\"));\n  (assert ((candidate \"&<>\") = \"&amp;&lt;&gt;\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_105314_user_match", "language": "ml", "prompt": "(**Return True if this is the user we are looking for.\nCompares a user structure from a Gerrit record to a username (or email\naddress). All users match if the username is None.\n*)\nlet user_match (user : (string, string) list) (username : string option) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_105314_user_match.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = user_match in\n  (assert ((candidate [(\"username\", \"foo\")] Some(\"bar\")) = false));\n  (assert ((candidate [(\"username\", \"foo\")] Some(\"foo\")) = true));\n  (assert ((candidate [(\"email\", \"<EMAIL>\")] Some(\"<EMAIL>\")) = false));\n  (assert ((candidate [(\"username\", \"foo\"); (\"email\", \"<EMAIL>\")] Some(\"bar\")) = false));\n  (assert ((candidate [(\"username\", \"foo\"); (\"email\", \"<EMAIL>\")] Some(\"foo\")) = true));\n  (assert ((candidate [(\"username\", \"foo\"); (\"email\", \"<EMAIL>\")] Some(\"<EMAIL>\")) = false));\n  (assert ((candidate [(\"username\", \"foo\")] Some(None)) = true));\n  (assert ((candidate [(\"username\", \"alice\")] Some(\"bob\")) = false));\n  (assert ((candidate [(\"username\", \"alice\")] Some(None)) = true));\n  (assert ((candidate [(\"username\", \"alice\")] Some(\"alice\")) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_105342_get_month", "language": "ml", "prompt": "(**convert from a month string to a month integer.\n*)\nlet get_month (month : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_105342_get_month.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_month in\n  (assert ((candidate \"Nov\") = 11));\n  (assert ((candidate \"Jan\") = 1));\n  (assert ((candidate \"Jun\") = 6));\n  (assert ((candidate \"Sep\") = 9));\n  (assert ((candidate \"Oct\") = 10));\n  (assert ((candidate \"Apr\") = 4));\n  (assert ((candidate \"Mar\") = 3));\n  (assert ((candidate \"Feb\") = 2));\n  (assert ((candidate \"Aug\") = 8));\n  (assert ((candidate \"Dec\") = 12));\n  (assert ((candidate \"Jul\") = 7));\n  (assert ((candidate \"May\") = 5));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_105509_normalize_case", "language": "ml", "prompt": "(**Convert `text' to lower case.\n*)\nlet normalize_case (text : string option) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_105509_normalize_case.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = normalize_case in\n  (assert ((candidate Some(\"Hi there!\")) = \"hi there!\"));\n  (assert ((candidate Some(\"a b C\")) = \"a b c\"));\n  (assert ((candidate Some(\"1 2 3 4 5\")) = \"1 2 3 4 5\"));\n  (assert ((candidate Some(\"THAT\")) = \"that\"));\n  (assert ((candidate Some(\"none\")) = \"none\"));\n  (assert ((candidate Some(\"12345\")) = \"12345\"));\n  (assert ((candidate Some(\"I like pie.\")) = \"i like pie.\"));\n  (assert ((candidate Some(\"Hello world!\")) = \"hello world!\"));\n  (assert ((candidate Some(\"None\")) = \"none\"));\n  (assert ((candidate Some(\"abc\")) = \"abc\"));\n  (assert ((candidate Some(\"this\")) = \"this\"));\n  (assert ((candidate Some(None)) = \"none\"));\n  (assert ((candidate Some(\"AbC\")) = \"abc\"));\n  (assert ((candidate Some(\"hi there!\")) = \"hi there!\"));\n  (assert ((candidate Some(\"\")) = \"\"));\n  (assert ((candidate Some(\"Hey You!\")) = \"hey you!\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_105531_bisect_right", "language": "ml", "prompt": "(**Locates the first element in a sorted array that is larger than a given value.\nIt has the same interface as https://docs.python.org/3/library/bisect.html#bisect.bisect_right .\n:param sorted_collection: some ascending sorted collection with comparable items\n:param item: item to bisect\n:param lo: lowest index to consider (as in sorted_collection[lo:hi])\n:param hi: past the highest index to consider (as in sorted_collection[lo:hi])\n:return: index i such that all values in sorted_collection[lo:i] are <= item and all values in sorted_collection[i:hi] are > item.\nExamples:\n>>> bisect_right([0, 5, 7, 10, 15], 0)\n1\n>>> bisect_right([0, 5, 7, 10, 15], 15)\n5\n>>> bisect_right([0, 5, 7, 10, 15], 6)\n2\n>>> bisect_right([0, 5, 7, 10, 15], 15, 1, 3)\n3\n>>> bisect_right([0, 5, 7, 10, 15], 6, 2)\n2\n*)\nlet bisect_right (sorted_collection : int list) (item : int) (lo : int) (hi : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_105531_bisect_right.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = bisect_right in\n  (assert ((candidate [0; 5; 7; 10; 15] 6 2) = 2));\n  (assert ((candidate [0; 5; 7; 10; 15] 15 1 3) = 3));\n  (assert ((candidate [0; 5; 7; 10; 15] 0) = 1));\n  (assert ((candidate [0; 5; 7; 10; 15] 15 1 3) = 3));\n  (assert ((candidate [0; 5; 7; 10; 15] 15 3) = 5));\n  (assert ((candidate [0; 5; 7; 10; 15] 15) = 5));\n  (assert ((candidate [0; 5; 7; 10; 15] 0) = 1));\n  (assert ((candidate [0; 5; 7; 10; 15] 6) = 2));\n  (assert ((candidate [0; 5; 7; 10; 15] 6) = 2));\n  (assert ((candidate [0; 5; 7; 10; 15] 15) = 5));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_105585_concat_key_value", "language": "ml", "prompt": "(**concat keys and values of dict containing strings elements\ninto a list\nParameters\n----------\nstr_dict: dict\n * dict to process\n * {key1: value1, key2: value2}\nReturns\n-------\nlist\n * ['key1 value1', 'key2 value2']\n*)\nlet concat_key_value (str_dict : (string, string) list) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_105585_concat_key_value.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = concat_key_value in\n  (assert ((candidate []) = []));\n  (assert ((candidate [(\"key3\", \"value3\"); (\"key4\", \"value4\")]) = [\"key3 value3\"; \"key4 value4\"]));\n  (assert ((candidate [(\"k1\", \"v1\"); (\"k2\", \"v2\"); (\"k3\", \"v3\"); (\"k4\", \"v4\"); (\"k5\", \"v5\")]) = [\"k1 v1\"; \"k2 v2\"; \"k3 v3\"; \"k4 v4\"; \"k5 v5\"]));\n  (assert ((candidate [(\"k1\", \"v1\")]) = [\"k1 v1\"]));\n  (assert ((candidate [(\"k1\", \"v1\"); (\"k2\", \"v2\"); (\"k3\", \"v3\")]) = [\"k1 v1\"; \"k2 v2\"; \"k3 v3\"]));\n  (assert ((candidate [(\"key5\", \"value5\"); (\"key6\", \"value6\")]) = [\"key5 value5\"; \"key6 value6\"]));\n  (assert ((candidate [(\"k1\", \"v1\"); (\"k2\", \"v2\"); (\"k3\", \"v3\"); (\"k4\", \"v4\")]) = [\"k1 v1\"; \"k2 v2\"; \"k3 v3\"; \"k4 v4\"]));\n  (assert ((candidate [(\"k1\", \"v1\"); (\"k2\", \"v2\"); (\"k3\", \"v3\"); (\"k4\", \"v4\"); (\"k5\", \"v5\"); (\"k6\", \"v6\")]) = [\"k1 v1\"; \"k2 v2\"; \"k3 v3\"; \"k4 v4\"; \"k5 v5\"; \"k6 v6\"]));\n  (assert ((candidate [(\"key7\", \"value7\"); (\"key8\", \"value8\")]) = [\"key7 value7\"; \"key8 value8\"]));\n  (assert ((candidate [(\"k1\", \"v1\"); (\"k2\", \"v2\")]) = [\"k1 v1\"; \"k2 v2\"]));\n  (assert ((candidate [(\"key1\", \"value1\"); (\"key2\", \"value2\")]) = [\"key1 value1\"; \"key2 value2\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_105820_jaccard_dependency", "language": "ml", "prompt": "(**calculate the direction of dependence of 2 experiments \nif exp1 is parent of exp2 return 0 \n * otherwise return 1\n*)\nlet jaccard_dependency (exp1 :  string * string) (exp2 :  string * string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_105820_jaccard_dependency.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = jaccard_dependency in\n  (assert ((candidate (\"word1\", \"word2\") (\"word1\", \"word3\")) = 0));\n  (assert ((candidate (\"word1\", \"word2\") (\"word2\", \"word2\")) = 0));\n  (assert ((candidate (\"word1\", \"word2\") (\"word1\", \"word1\")) = 0));\n  (assert ((candidate (\"word1\", \"word2\") (\"word1\", \"word2\")) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_106177__divides", "language": "ml", "prompt": "(**divide 1-w\n(i.e. a1+a2*w -> (1-w)^k * (x+y*w))\n*)\nlet _divides (a1 : int) (a2 : int) :  int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_106177__divides.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _divides in\n  (assert ((candidate 0 1) = (0, 1, 0)));\n  (assert ((candidate 1 0) = (1, 0, 0)));\n  (assert ((candidate 1 2) = (0, 1, 1)));\n  (assert ((candidate 0 0) = (0, 0, 0)));\n  (assert ((candidate 1 1) = (1, 1, 0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_106375_calib_time", "language": "ml", "prompt": "(**Given a list of normalized triggers, return the time (acquisition) clock\nwhen the calibration trigger was displayed.\n*)\nlet calib_time (normalized_triggers :  int * string list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_106375_calib_time.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = calib_time in\n  (assert ((candidate [(10, \"calibration_trigger\")]) = 10));\n  (assert ((candidate [(1, \"other_stim\"); (2, \"calibration_trigger\"); (3, \"calibration_trigger\"); (4, \"other_stim\")]) = 2));\n  (assert ((candidate [(0, \"other_stim\"); (1, \"other_stim\"); (2, \"other_stim\"); (3, \"other_stim\"); (4, \"calibration_trigger\")]) = 4));\n  (assert ((candidate [(0, \"calibration_trigger\"); (1, \"other_stim\"); (2, \"calibration_trigger\"); (3, \"other_stim\"); (4, \"other_stim\")]) = 0));\n  (assert ((candidate [(0, \"calibration_trigger\"); (1, \"calibration_trigger\"); (2, \"other_stim\"); (3, \"other_stim\")]) = 0));\n  (assert ((candidate [(5, \"calibration_trigger\"); (6, \"not_calibration_trigger\")]) = 5));\n  (assert ((candidate [(0, \"other_stim\"); (1, \"other_stim\"); (2, \"calibration_trigger\"); (3, \"other_stim\"); (4, \"other_stim\")]) = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_106887_symmetric_residue", "language": "ml", "prompt": "(**Return the residual mod m such that it is within half of the modulus.\n>>> symmetric_residue(1, 6)\n1\n>>> symmetric_residue(4, 6)\n-2\n*)\nlet symmetric_residue (a : int) (m : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_106887_symmetric_residue.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = symmetric_residue in\n  (assert ((candidate 1 13) = 1));\n  (assert ((candidate 10 11) = (~1)));\n  (assert ((candidate 1 6) = 1));\n  (assert ((candidate 4 6) = (~2)));\n  (assert ((candidate 1 11) = 1));\n  (assert ((candidate 1 10) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_107516_extract_uri_schema", "language": "ml", "prompt": "(**Extract schema of given uri\n*)\nlet extract_uri_schema (uri : string option) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_107516_extract_uri_schema.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = extract_uri_schema in\n  (assert ((candidate Some(\"https://example.com:80\")) = Some(\"https\")));\n  (assert ((candidate Some(\"http://\")) = Some(\"http\")));\n  (assert ((candidate Some(\"http://www.google.com/something?a=1\")) = Some(\"http\")));\n  (assert ((candidate Some(\"ftp://a.com/p?a=1\")) = Some(\"ftp\")));\n  (assert ((candidate Some(\"ssh://example.com\")) = Some(\"ssh\")));\n  (assert ((candidate Some(None)) = Some(None)));\n  (assert ((candidate Some(\"http://google.com\")) = Some(\"http\")));\n  (assert ((candidate Some(\"http://example.com\")) = Some(\"http\")));\n  (assert ((candidate Some(\"https://foo.bar\")) = Some(\"https\")));\n  (assert ((candidate Some(\"http://a.com\")) = Some(\"http\")));\n  (assert ((candidate Some(\"https://:1234\")) = Some(\"https\")));\n  (assert ((candidate Some(\"https://\")) = Some(\"https\")));\n  (assert ((candidate Some(\"https://foo.bar/baz?qux=1\")) = Some(\"https\")));\n  (assert ((candidate Some(\"https://a.com/p?a=1\")) = Some(\"https\")));\n  (assert ((candidate Some(\"https://a.com/\")) = Some(\"https\")));\n  (assert ((candidate Some(\"telnet://example.com\")) = Some(\"telnet\")));\n  (assert ((candidate Some(\"ftp://google.com\")) = Some(\"ftp\")));\n  (assert ((candidate Some(\"http://a.com/p?a=1\")) = Some(\"http\")));\n  (assert ((candidate Some(\"https://foo.bar/baz?qux=1#quux\")) = Some(\"https\")));\n  (assert ((candidate Some(\"file:///path/to/file.ext\")) = Some(\"file\")));\n  (assert ((candidate Some(\"ftp://a.com\")) = Some(\"ftp\")));\n  (assert ((candidate Some(\"https://www.google.com\")) = Some(\"https\")));\n  (assert ((candidate Some(\"http://www.google.com\")) = Some(\"http\")));\n  (assert ((candidate Some(\"a.com\")) = Some(None)));\n  (assert ((candidate Some(\"ftp://www.google.com/something\")) = Some(\"ftp\")));\n  (assert ((candidate Some(\"https://a.com\")) = Some(\"https\")));\n  (assert ((candidate Some(\"https:///:1234\")) = Some(\"https\")));\n  (assert ((candidate Some(\"https://a.com:1234/\")) = Some(\"https\")));\n  (assert ((candidate Some(\"ldaps://example.com\")) = Some(\"ldaps\")));\n  (assert ((candidate Some(\"https://www.google.com/something\")) = Some(\"https\")));\n  (assert ((candidate Some(\"foo:bar\")) = Some(\"foo\")));\n  (assert ((candidate Some(\"https://google.com\")) = Some(\"https\")));\n  (assert ((candidate Some(\"http://www.google.com/something\")) = Some(\"http\")));\n  (assert ((candidate Some(\"https://a.com:1234\")) = Some(\"https\")));\n  (assert ((candidate Some(\"https://www.google.com/something?a=1\")) = Some(\"https\")));\n  (assert ((candidate Some(\"foo:bar:baz:qux?quux#corge?grault\")) = Some(\"foo\")));\n  (assert ((candidate Some(\"ftp://a.com:1234\")) = Some(\"ftp\")));\n  (assert ((candidate Some(\"foo:bar:baz:qux\")) = Some(\"foo\")));\n  (assert ((candidate Some(\"https:///\")) = Some(\"https\")));\n  (assert ((candidate Some(\"ldap://example.com\")) = Some(\"ldap\")));\n  (assert ((candidate Some(\"foo:bar:baz:qux?quux#corge?grault#garply\")) = Some(\"foo\")));\n  (assert ((candidate Some(\"file://localhost/path/to/something.txt\")) = Some(\"file\")));\n  (assert ((candidate Some(\"mailto:<EMAIL>\")) = Some(\"mailto\")));\n  (assert ((candidate Some(\"https://foo.bar/baz\")) = Some(\"https\")));\n  (assert ((candidate Some(\"https://example.com\")) = Some(\"https\")));\n  (assert ((candidate Some(\"foo:bar:baz\")) = Some(\"foo\")));\n  (assert ((candidate Some(\"http:///\")) = Some(\"http\")));\n  (assert ((candidate Some(\"https://example.com:443\")) = Some(\"https\")));\n  (assert ((candidate Some(\"http://a.com/\")) = Some(\"http\")));\n  (assert ((candidate Some(\"foo:bar:baz:qux?quux\")) = Some(\"foo\")));\n  (assert ((candidate Some(\"foo:bar:baz:qux?quux#corge\")) = Some(\"foo\")));\n  (assert ((candidate Some(\"ftp://www.google.com/something?a=1\")) = Some(\"ftp\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_107566_hour_min_sec", "language": "ml", "prompt": "(**Convert seconds into a more readable hh:mm:ss representation\n:secs Number of seconds\n:hms Hours:Minutes:Seconds representation, rather than the default seconds.\n*)\nlet hour_min_sec (secs : int) (hms : int option) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_107566_hour_min_sec.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = hour_min_sec in\n  (assert ((candidate 86399) = \"23:59:59\"));\n  (assert ((candidate 10) = \"0:10\"));\n  (assert ((candidate 3601) = \"1:00:01\"));\n  (assert ((candidate 7200) = \"2:00:00\"));\n  (assert ((candidate 3660) = \"1:01:00\"));\n  (assert ((candidate 7199) = \"1:59:59\"));\n  (assert ((candidate 100) = \"1:40\"));\n  (assert ((candidate 61) = \"1:01\"));\n  (assert ((candidate 3610) = \"1:00:10\"));\n  (assert ((candidate 3600) = \"1:00:00\"));\n  (assert ((candidate 3) = \"0:03\"));\n  (assert ((candidate 3721) = \"1:02:01\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_107578_preprocessText", "language": "ml", "prompt": "(**This script parses text and removes stop words\n*)\nlet preprocessText (text : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_107578_preprocessText.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = preprocessText in\n  (assert ((candidate \"hello @name?\") = \"hello name\"));\n  (assert ((candidate \"hello @name;\") = \"hello name\"));\n  (assert ((candidate \"hello @name/\") = \"hello name\"));\n  (assert ((candidate \"@\") = \"\"));\n  (assert ((candidate \"I'm\") = \"im\"));\n  (assert ((candidate \"I'll\") = \"ill\"));\n  (assert ((candidate \"hello @name!\") = \"hello name\"));\n  (assert ((candidate \"hello @name_\") = \"hello name\"));\n  (assert ((candidate \"hello @name\") = \"hello name\"));\n  (assert ((candidate \"hello @name:\") = \"hello name\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"hello @name+\") = \"hello name\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_10767_regenerate_response", "language": "ml", "prompt": "(**Unique message generator.\nArgs:\n * db_entry (dict?): Stored response from the database that has already been created.\nReturns:\n * JSON string which contains the message response\n*)\nlet regenerate_response (db_entry : (string, string) list) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_10767_regenerate_response.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = regenerate_response in\n  (assert ((candidate [(\"wallet_address\", \"0x12345\"); (\"contract_address\", \"0x67890\"); (\"tokenId\", \"3\"); (\"random_str\", \"98765\"); (\"message\", \"Hello World!\")]) = [(\"wallet_address\", \"0x12345\"); (\"contract_address\", \"0x67890\"); (\"tokenId\", \"3\"); (\"random_str\", \"98765\"); (\"message\", \"Hello World!\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_107867_bottom_up_partition_problem", "language": "ml", "prompt": "(**Parameters\n----------\nnumbers : list of integers\nReturns\n-------\nbool\n * Boolean representing whether subsets exist which are equal to each other\n>>> bottom_up_partition_problem([1, 2, 3, 4])\nTrue\n*)\nlet bottom_up_partition_problem (numbers : int list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_107867_bottom_up_partition_problem.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = bottom_up_partition_problem in\n  (assert ((candidate [1; 2; 3; 4; 5; 6]) = false));\n  (assert ((candidate list range 100 0 (~1)) = true));\n  (assert ((candidate [1; 1; 1; 1; 5; 6]) = false));\n  (assert ((candidate [2; 2; 1; 1]) = true));\n  (assert ((candidate [1; 1; 3; 4; 5; 6]) = true));\n  (assert ((candidate [1; 2; 3; 4; 5]) = false));\n  (assert ((candidate [10; 7; 8; 9]) = true));\n  (assert ((candidate [1; 2; 3; 5]) = false));\n  (assert ((candidate [1; 2; 3; 4]) = true));\n  (assert ((candidate [100000]) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_108043_nearly_equal", "language": "ml", "prompt": "(**A helper function to determine whether two floats are nearly equal.\nCan be replaced by math.isclose in Py3\n*)\nlet nearly_equal (a : float) (b : float) (sig_fig : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_108043_nearly_equal.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = nearly_equal in\n  (assert ((candidate 1e-09.0 1e-09.0) = true));\n  (assert ((candidate 0.123456789 0.1234567891 3) = true));\n  (assert ((candidate 12345678900.0 12345678900.0) = true));\n  (assert ((candidate 0.12345 0.12346 7) = false));\n  (assert ((candidate 0.123456789 0.1234567891 5) = true));\n  (assert ((candidate 2.5 2.5 1) = true));\n  (assert ((candidate 0.12345 0.12346 3) = true));\n  (assert ((candidate 1e-09.0 2e-09.0 1) = true));\n  (assert ((candidate 1.25 1.25) = true));\n  (assert ((candidate 1e-09.0 2e-09.0 0) = true));\n  (assert ((candidate 1e-09.0 2e-09.0 5) = true));\n  (assert ((candidate 2.5 2.5 3) = true));\n  (assert ((candidate 1e-09.0 1e-09.0 5) = true));\n  (assert ((candidate 0.12345 0.12346 6) = false));\n  (assert ((candidate 2.5 2.5 1) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_10822_isIrrelevantManualRules", "language": "ml", "prompt": "(**Hand-crafted rules to remove paragraphs or entire documents from job advertisements\n:param s: String\n:param cdoc: List of parts of document (String)\n:returns: Boolean (ie. True if removal is needed), list of parts of documents (String), length of irrelevant parts\n*)\nlet isIrrelevantManualRules (s : string) (cdoc : string list) :  bool * string list * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_10822_isIrrelevantManualRules.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = isIrrelevantManualRules in\n  (assert ((candidate \"Job Responsibilities\" [\"Job Responsibilities\"; \"We're hiring\"]) = (false, [\"Job Responsibilities\"; \"We're hiring\"], 0)));\n  (assert ((candidate \"Why Work with Us\" [\"About the Job\"; \"We're hiring\"]) = (false, [\"About the Job\"; \"We're hiring\"], 0)));\n  (assert ((candidate \"What We Do\" [\"What We Do\"; \"We're hiring\"]) = (false, [\"What We Do\"; \"We're hiring\"], 0)));\n  (assert ((candidate \"Why Work with Us\" [\"Why Work with Us\"; \"We're hiring\"]) = (false, [\"Why Work with Us\"; \"We're hiring\"], 0)));\n  (assert ((candidate \"What We Offer\" [\"What We Offer\"; \"We're hiring\"]) = (false, [\"What We Offer\"; \"We're hiring\"], 0)));\n  (assert ((candidate \"a b c d e f g h i j k l m n o p q r s t u v w x y z 1 2 3 4 5 6 7 8 9 0\" [\"1\"; \"2\"; \"3\"; \"4\"; \"5\"; \"6\"; \"7\"; \"8\"; \"9\"; \"0\"]) = (false, [\"1\"; \"2\"; \"3\"; \"4\"; \"5\"; \"6\"; \"7\"; \"8\"; \"9\"; \"0\"], 0)));\n  (assert ((candidate \"What We Do\" [\"About the Job\"; \"We're hiring\"]) = (false, [\"About the Job\"; \"We're hiring\"], 0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_109004_temp_to_str", "language": "ml", "prompt": "(**converts temperature from format 0.1 to format 0.100 by adding three places after decimal\n*)\nlet temp_to_str (temp : float) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_109004_temp_to_str.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = temp_to_str in\n  (assert ((candidate -12.345) = \"-12.345\"));\n  (assert ((candidate 0.001) = \"0.001\"));\n  (assert ((candidate 0.1) = \"0.100\"));\n  (assert ((candidate 0.01) = \"0.010\"));\n  (assert ((candidate 1.1) = \"1.100\"));\n  (assert ((candidate 123.456) = \"123.456\"));\n  (assert ((candidate 0.1) = \"0.100\"));\n  (assert ((candidate 2.0) = \"2.000\"));\n  (assert ((candidate 0.0) = \"0.000\"));\n  (assert ((candidate 12.345) = \"12.345\"));\n  (assert ((candidate 0.12) = \"0.120\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_109336_all_is_same", "language": "ml", "prompt": "(**Test that all elements in a vector are the same\n*)\nlet all_is_same (vec : int list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_109336_all_is_same.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = all_is_same in\n  (assert ((candidate [1; 1]) = true));\n  (assert ((candidate [1; 1; 1; 1; 1; 1; 1]) = true));\n  (assert ((candidate [1; 1; 1]) = true));\n  (assert ((candidate []) = true));\n  (assert ((candidate [1; 1; 1; 1; 1]) = true));\n  (assert ((candidate [1]) = true));\n  (assert ((candidate [1; 1; 1; 2]) = false));\n  (assert ((candidate [1; 1; 1; 1; 1; 1]) = true));\n  (assert ((candidate [1; 1; 1; 1]) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_109878__to_initials", "language": "ml", "prompt": "(**Given a state, returns its initials\n*)\nlet _to_initials (state : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_109878__to_initials.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _to_initials in\n  (assert ((candidate \"American Samoa\") = \"AS\"));\n  (assert ((candidate \"Indiana\") = \"IN\"));\n  (assert ((candidate \"Guam\") = \"GU\"));\n  (assert ((candidate \"Georgia\") = \"GA\"));\n  (assert ((candidate \"Kentucky\") = \"KY\"));\n  (assert ((candidate \"Maryland\") = \"MD\"));\n  (assert ((candidate \"Alabama\") = \"AL\"));\n  (assert ((candidate \"Hawaii\") = \"HI\"));\n  (assert ((candidate \"Texas\") = \"TX\"));\n  (assert ((candidate \"Arizona\") = \"AZ\"));\n  (assert ((candidate \"Arkansas\") = \"AR\"));\n  (assert ((candidate \"Louisiana\") = \"LA\"));\n  (assert ((candidate \"Connecticut\") = \"CT\"));\n  (assert ((candidate \"Maine\") = \"ME\"));\n  (assert ((candidate \"Iowa\") = \"IA\"));\n  (assert ((candidate \"Florida\") = \"FL\"));\n  (assert ((candidate \"District of Columbia\") = \"DC\"));\n  (assert ((candidate \"Colorado\") = \"CO\"));\n  (assert ((candidate \"California\") = \"CA\"));\n  (assert ((candidate \"Alaska\") = \"AK\"));\n  (assert ((candidate \"Kansas\") = \"KS\"));\n  (assert ((candidate \"Delaware\") = \"DE\"));\n  (assert ((candidate \"Illinois\") = \"IL\"));\n  (assert ((candidate \"Idaho\") = \"ID\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_110506_fish", "language": "ml", "prompt": "(**Transform a list of fish represented by their time-to-spawn state into a list of the\nnumber of fish in each state indexed by their time-to-spawn.\nUnder this strategy, the example input [3, 4, 3, 1, 2] would be transformed into\n[0, 1, 1, 2, 1, 0, 0, 0, 0].\n*)\nlet fish (fs : int list) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_110506_fish.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = fish in\n  (assert ((candidate list ) = [0; 0; 0; 0; 0; 0; 0; 0; 0]));\n  (assert ((candidate [3; 4; 3; 1; 2]) = [0; 1; 1; 2; 1; 0; 0; 0; 0]));\n  (assert ((candidate [3; 4; 3; 1; 2]) = [0; 1; 1; 2; 1; 0; 0; 0; 0]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_110590_check_hcl", "language": "ml", "prompt": "(**>>> check_hcl(\"#333333\")\nTrue\n>>> check_hcl(\"#eeeee\")\nFalse\n>>> check_hcl(\"3eeeee\")\nFalse\n*)\nlet check_hcl (s : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_110590_check_hcl.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = check_hcl in\n  (assert ((candidate \"#123abc\") = true));\n  (assert ((candidate \"#333333\") = true));\n  (assert ((candidate \"#123abz\") = false));\n  (assert ((candidate \"eeeee\") = false));\n  (assert ((candidate \"#eeeee\") = false));\n  (assert ((candidate \"#eeeee\") = false));\n  (assert ((candidate \"123abc\") = false));\n  (assert ((candidate \"3eeeee\") = false));\n  (assert ((candidate \"#333333\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_110596_discretisation_length", "language": "ml", "prompt": "(**Returns the length of a linspace where there are N points with d intermediate (in-between) points.\n*)\nlet discretisation_length (N : int) (d : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_110596_discretisation_length.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = discretisation_length in\n  (assert ((candidate 5 5) = 25));\n  (assert ((candidate 1 1) = 1));\n  (assert ((candidate 2 3) = 5));\n  (assert ((candidate 3 2) = 7));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_11081_gcd_looping_with_divrem", "language": "ml", "prompt": "(**Computes the greatest common divisor of two numbers by getting remainder from division in a\nloop.\n:param int m: First number.\n:param int n: Second number.\n:returns: GCD as a number.\n*)\nlet gcd_looping_with_divrem (m : int) (n : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_11081_gcd_looping_with_divrem.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = gcd_looping_with_divrem in\n  (assert ((candidate 100000 1) = 1));\n  (assert ((candidate 1 3) = 1));\n  (assert ((candidate 2 5) = 1));\n  (assert ((candidate 15 5) = 5));\n  (assert ((candidate 1 7) = 1));\n  (assert ((candidate 1 6) = 1));\n  (assert ((candidate 1 1) = 1));\n  (assert ((candidate 1 100000) = 1));\n  (assert ((candidate 2 4) = 2));\n  (assert ((candidate 2 8) = 2));\n  (assert ((candidate 10 20) = 10));\n  (assert ((candidate 1 4) = 1));\n  (assert ((candidate 2 0) = 2));\n  (assert ((candidate 1 9) = 1));\n  (assert ((candidate 42 12) = 6));\n  (assert ((candidate 2 3) = 1));\n  (assert ((candidate 2 6) = 2));\n  (assert ((candidate 3 6) = 3));\n  (assert ((candidate 20 10) = 10));\n  (assert ((candidate 3 3) = 3));\n  (assert ((candidate 5 15) = 5));\n  (assert ((candidate 1000 900) = 100));\n  (assert ((candidate 2 7) = 1));\n  (assert ((candidate 4 3) = 1));\n  (assert ((candidate 100000 100000) = 100000));\n  (assert ((candidate 10 15) = 5));\n  (assert ((candidate 1 5) = 1));\n  (assert ((candidate 2 1) = 1));\n  (assert ((candidate 1 8) = 1));\n  (assert ((candidate 2 9) = 1));\n  (assert ((candidate 15 10) = 5));\n  (assert ((candidate 5 6) = 1));\n  (assert ((candidate 10 5) = 5));\n  (assert ((candidate 1 0) = 1));\n  (assert ((candidate 2 2) = 2));\n  (assert ((candidate 3 2) = 1));\n  (assert ((candidate 1 2) = 1));\n  (assert ((candidate 10 3) = 1));\n  (assert ((candidate 12 15) = 3));\n  (assert ((candidate 5 10) = 5));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_110834_get_overlap", "language": "ml", "prompt": "(**report overlap of coordinates\n*)\nlet get_overlap (a :  int * int) (b :  int * int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_110834_get_overlap.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_overlap in\n  (assert ((candidate (1, 5) (8, 8)) = 0));\n  (assert ((candidate (1, 5) (7, 8)) = 0));\n  (assert ((candidate (1, 5) (3, 4)) = 1));\n  (assert ((candidate (0, 2) (1, 5)) = 1));\n  (assert ((candidate (1, 4) (4, 6)) = 0));\n  (assert ((candidate (1, 5) (6, 8)) = 0));\n  (assert ((candidate (1, 3) (3, 4)) = 0));\n  (assert ((candidate (1, 4) (2, 3)) = 1));\n  (assert ((candidate (1, 4) ((~2), (~1))) = 0));\n  (assert ((candidate (3, 4) (1, 3)) = 0));\n  (assert ((candidate (1, 5) (6, 7)) = 0));\n  (assert ((candidate (2, 4) (1, 3)) = 1));\n  (assert ((candidate (3, 4) (1, 5)) = 1));\n  (assert ((candidate (1, 3) (2, 4)) = 1));\n  (assert ((candidate (4, 6) (1, 4)) = 0));\n  (assert ((candidate ((~1), 0) (0, 1)) = 0));\n  (assert ((candidate ((~1), (~1)) (1, 4)) = 0));\n  (assert ((candidate (2, 3) (1, 4)) = 1));\n  (assert ((candidate (1, 2) (3, 4)) = 0));\n  (assert ((candidate (1, 5) (0, 2)) = 1));\n  (assert ((candidate (5, 9) (8, 11)) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_111495_scale_vars", "language": "ml", "prompt": "(**Scale a variable sequence.\n*)\nlet scale_vars (var_seq : int list) (scale : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_111495_scale_vars.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = scale_vars in\n  (assert ((candidate list range 1 6 5) = [5; 10; 15; 20; 25]));\n  (assert ((candidate [1; 2; 3] 5) = [5; 10; 15]));\n  (assert ((candidate list range 1 6 10) = [10; 20; 30; 40; 50]));\n  (assert ((candidate [1; 2; 3] (~1)) = [(~1); (~2); (~3)]));\n  (assert ((candidate [1; 2; 3] 10) = [10; 20; 30]));\n  (assert ((candidate [2; 3] 4) = [8; 12]));\n  (assert ((candidate [1; 2; 3] 0) = [0; 0; 0]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_1122_get_bit", "language": "ml", "prompt": "(**retrieve bit value from byte at provided index\n*)\nlet get_bit (byteval : int) (index : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_1122_get_bit.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_bit in\n  (assert ((candidate 254 3) = true));\n  (assert ((candidate 0 5) = false));\n  (assert ((candidate 0 4) = false));\n  (assert ((candidate 0 1) = false));\n  (assert ((candidate 2 0) = 0));\n  (assert ((candidate 0 0) = false));\n  (assert ((candidate 1 5) = false));\n  (assert ((candidate 0 6) = false));\n  (assert ((candidate 128 1) = false));\n  (assert ((candidate 254 0) = false));\n  (assert ((candidate 1 1) = false));\n  (assert ((candidate 0 5) = false));\n  (assert ((candidate 0 2) = false));\n  (assert ((candidate 2 1) = true));\n  (assert ((candidate 32 0) = false));\n  (assert ((candidate 1 3) = false));\n  (assert ((candidate 2 0) = false));\n  (assert ((candidate 128 0) = false));\n  (assert ((candidate 32 1) = false));\n  (assert ((candidate 0 7) = false));\n  (assert ((candidate 0 0) = false));\n  (assert ((candidate 0 3) = false));\n  (assert ((candidate 1 0) = true));\n  (assert ((candidate 2 2) = false));\n  (assert ((candidate 0 6) = false));\n  (assert ((candidate 254 2) = true));\n  (assert ((candidate 128 7) = 1));\n  (assert ((candidate 64 0) = false));\n  (assert ((candidate 255 2) = true));\n  (assert ((candidate 128 7) = true));\n  (assert ((candidate 2 2) = 0));\n  (assert ((candidate 1 3) = false));\n  (assert ((candidate 255 1) = true));\n  (assert ((candidate 2 3) = 0));\n  (assert ((candidate 0 4) = false));\n  (assert ((candidate 0 7) = false));\n  (assert ((candidate 16 0) = false));\n  (assert ((candidate 255 5) = true));\n  (assert ((candidate 4 1) = false));\n  (assert ((candidate 16 1) = false));\n  (assert ((candidate 1 0) = true));\n  (assert ((candidate 255 6) = true));\n  (assert ((candidate 0 2) = false));\n  (assert ((candidate 1 2) = false));\n  (assert ((candidate 1 6) = false));\n  (assert ((candidate 8 0) = false));\n  (assert ((candidate 254 6) = true));\n  (assert ((candidate 1 4) = false));\n  (assert ((candidate 254 1) = true));\n  (assert ((candidate 4 0) = false));\n  (assert ((candidate 0 1) = false));\n  (assert ((candidate 0 3) = false));\n  (assert ((candidate 255 7) = true));\n  (assert ((candidate 255 3) = true));\n  (assert ((candidate 2 0) = false));\n  (assert ((candidate 1 0) = 1));\n  (assert ((candidate 1 7) = false));\n  (assert ((candidate 8 1) = false));\n  (assert ((candidate 2 1) = true));\n  (assert ((candidate 1 1) = false));\n  (assert ((candidate 1 2) = false));\n  (assert ((candidate 254 5) = true));\n  (assert ((candidate 2 3) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_112319_find_divisor", "language": "ml", "prompt": "(**Find all divisor of an integer\nArgs:\n * x (int)\nReturns:\n * list: list of divisor\n*)\nlet find_divisor (x : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_112319_find_divisor.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = find_divisor in\n  (assert ((candidate 1) = [1]));\n  (assert ((candidate 0) = []));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_112396_process_args", "language": "ml", "prompt": "(**Basic kwarg handler to process input list of keyword arguments from the \ncommandline and return a dictionary of values.\nParameters\n----------\nargs : LIST\n * List of kwargs from command line.\nReturns\n-------\nargs_dict : DICT\n * Dictionary of kwargs, split by '=' sign.\n*)\nlet process_args (args : string list) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_112396_process_args.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = process_args in\n  (assert ((candidate [\"candidate\"; \"in_filename=test.csv\"]) = [(\"in_filename\", \"test.csv\")]));\n  (assert ((candidate [\"candidate\"; \"in_filename=test.csv\"; \"in_column=a\"; \"out_column=b\"]) = [(\"in_filename\", \"test.csv\"); (\"in_column\", \"a\"); (\"out_column\", \"b\")]));\n  (assert ((candidate [\"prog\"; \"a=b\"; \"c=d\"]) = [(\"a\", \"b\"); (\"c\", \"d\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_11241_match_with_batchsize", "language": "ml", "prompt": "(**Function used by modify_datasets below to match return the integer closest to lim\nwhich is multiple of batchsize, i.e., lim%batchsize=0.\n*)\nlet match_with_batchsize (lim : int) (batchsize : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_11241_match_with_batchsize.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = match_with_batchsize in\n  (assert ((candidate 17 4) = 16));\n  (assert ((candidate 2 1) = 2));\n  (assert ((candidate 16 2) = 16));\n  (assert ((candidate 1 1) = 1));\n  (assert ((candidate 13 4) = 12));\n  (assert ((candidate 200 100) = 200));\n  (assert ((candidate 10 1) = 10));\n  (assert ((candidate 19 4) = 16));\n  (assert ((candidate 16 4) = 16));\n  (assert ((candidate 3 6) = 0));\n  (assert ((candidate 5 5) = 5));\n  (assert ((candidate 10 6) = 6));\n  (assert ((candidate 4 2) = 4));\n  (assert ((candidate 4 4) = 4));\n  (assert ((candidate 10 3) = 9));\n  (assert ((candidate 4 1) = 4));\n  (assert ((candidate 20 4) = 20));\n  (assert ((candidate 3 1) = 3));\n  (assert ((candidate 2 2) = 2));\n  (assert ((candidate 3 3) = 3));\n  (assert ((candidate 12 4) = 12));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_112930_numPointsInSpans", "language": "ml", "prompt": "(**>>> numPointsInSpans([(1, 3)])\n3\n>>> numPointsInSpans([(1, 3), (5, 7)])\n6\n>>> numPointsInSpans([(1, 3), (3, 5)])\n5\n>>> numPointsInSpans([(1, 3), (2, 5)])\n5\n*)\nlet numPointsInSpans (spans :  int * int list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_112930_numPointsInSpans.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = numPointsInSpans in\n  (assert ((candidate [(1, 3); (3, 5)]) = 5));\n  (assert ((candidate [(1, 3); (5, 7)]) = 6));\n  (assert ((candidate [(1, 3)]) = 3));\n  (assert ((candidate [(1, 3); (5, 7)]) = 6));\n  (assert ((candidate [(1, 3); (2, 5)]) = 5));\n  (assert ((candidate [(1, 3); (2, 5)]) = 5));\n  (assert ((candidate [(1, 3); (3, 5)]) = 5));\n  (assert ((candidate [(1, 3)]) = 3));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_113074_linearized_best_response", "language": "ml", "prompt": "(**A linearization of the best-response of the weights to some hyperparameter at some point.\n:param y: The hyperparameter to evaluate the linearization at.\n:return: The linearized best-response.\n*)\nlet linearized_best_response (y : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_113074_linearized_best_response.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = linearized_best_response in\n  (assert ((candidate 0.5) = -0.5));\n  (assert ((candidate 1.0) = -1.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_113300__get_alignments_skipped_bad_char_rule", "language": "ml", "prompt": "(**Get the number of alignments that can be skipped according to bad\ncharacter rule in Boyer Moore's exact matching algorithm\n>>> _get_alignments_skipped_bad_char_rule(\"C\", \"ATCTTTATCATA\")\n3\n>>> _get_alignments_skipped_bad_char_rule(\"G\", \"ATCTTTATCATA\")\n12\n>>> _get_alignments_skipped_bad_char_rule(\"T\", \"GTAGCGGC\")\n6\n>>> _get_alignments_skipped_bad_char_rule(\"C\", \"GTAGC\")\n0\n>>> _get_alignments_skipped_bad_char_rule(\"C\", \"GT\")\n2\n*)\nlet _get_alignments_skipped_bad_char_rule (mismatched_char : string) (pattern_prefix : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_113300__get_alignments_skipped_bad_char_rule.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _get_alignments_skipped_bad_char_rule in\n  (assert ((candidate \"G\" \"ATCTTTATCATA\") = 12));\n  (assert ((candidate \"C\" \"GTAGC\") = 0));\n  (assert ((candidate \"C\" \"GTAGC\") = 0));\n  (assert ((candidate \"C\" \"GT\") = 2));\n  (assert ((candidate \"T\" \"GTAGCGGC\") = 6));\n  (assert ((candidate \"C\" \"GT\") = 2));\n  (assert ((candidate \"T\" \"GTAGCGGC\") = 6));\n  (assert ((candidate \"C\" \"ATCTTTATCATA\") = 3));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_113934_color_distance", "language": "ml", "prompt": "(**Compute absolute difference between 3-channels.\n*)\nlet color_distance (rgb1 :  int * int * int) (rgb2 :  int * int * int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_113934_color_distance.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = color_distance in\n  (assert ((candidate (255, 255, 255) (254, 254, 254)) = 3));\n  (assert ((candidate (255, 255, 255) (254, 255, 254)) = 2));\n  (assert ((candidate (0, 0, 0) (0, 0, 0)) = 0));\n  (assert ((candidate (255, 255, 255) (255, 255, 255)) = 0));\n  (assert ((candidate (255, 255, 255) (255, 254, 255)) = 1));\n  (assert ((candidate (0, 0, 0) (0, 1, 2)) = 3));\n  (assert ((candidate (255, 255, 255) (255, 255, 254)) = 1));\n  (assert ((candidate (255, 255, 255) (254, 254, 255)) = 2));\n  (assert ((candidate (10, 10, 10) (10, 10, 10)) = 0));\n  (assert ((candidate (255, 255, 255) (254, 255, 255)) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_114068_format_value", "language": "ml", "prompt": "(**When scraping indexable content from the search API, we joined\norganisation and topic titles with pipes. Since we are combining\nall the columns together here we need to make sure these get treated as\nseparate words.\n*)\nlet format_value (value : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_114068_format_value.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = format_value in\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"foo|bar\") = \"foo bar\"));\n  (assert ((candidate \"foo|bar|baz\") = \"foo bar baz\"));\n  (assert ((candidate \"A|B\") = \"A B\"));\n  (assert ((candidate \"Foo Bar\") = \"Foo Bar\"));\n  (assert ((candidate \"foo\") = \"foo\"));\n  (assert ((candidate \"Foo\") = \"Foo\"));\n  (assert ((candidate \"Foo|Bar|Baz\") = \"Foo Bar Baz\"));\n  (assert ((candidate \"Foo|Bar\") = \"Foo Bar\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_114884_parse_duration", "language": "ml", "prompt": "(**Parses duration value string 'Xhr', 'Ymin' or 'Zsec' and returns (X::Y::Z) as seconds\n*)\nlet parse_duration (row : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_114884_parse_duration.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_duration in\n  (assert ((candidate \"6hr\") = 21600));\n  (assert ((candidate \"5min\") = 300));\n  (assert ((candidate \"1hr 30min\") = 5400));\n  (assert ((candidate \"6sec\") = 6));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_114921_generate_wms_and_wfs_query_urls", "language": "ml", "prompt": "(**Generate WMS and WFS query URLs for individual data layers.\n*)\nlet generate_wms_and_wfs_query_urls (wms : string list) (wms_base : string) (wfs : (string, string) list) (wfs_base : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_114921_generate_wms_and_wfs_query_urls.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = generate_wms_and_wfs_query_urls in\n  (assert ((candidate [\"1\"; \"2\"] \"{0}?request=GetCapabilities\" [(\"3\", \"4\")] \"{1}?service=WFS&version=1.0.0&request=GetFeature&typeName={0}&outputFormat=SHAPE-ZIP\") = [\"1?request=GetCapabilities\"; \"2?request=GetCapabilities\"; \"4?service=WFS&version=1.0.0&request=GetFeature&typeName=3&outputFormat=SHAPE-ZIP\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_115127_plusone", "language": "ml", "prompt": "(**add 1 to a\n*)\nlet plusone (a : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_115127_plusone.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = plusone in\n  (assert ((candidate 3000) = 3001));\n  (assert ((candidate 6) = 7));\n  (assert ((candidate 10) = 11));\n  (assert ((candidate 30) = 31));\n  (assert ((candidate 3) = 4));\n  (assert ((candidate 300000) = 300001));\n  (assert ((candidate 5) = 6));\n  (assert ((candidate 30000000000) = 30000000001));\n  (assert ((candidate 8) = 9));\n  (assert ((candidate 4) = 5));\n  (assert ((candidate (~1)) = 0));\n  (assert ((candidate 3000000000) = 3000000001));\n  (assert ((candidate 2) = 3));\n  (assert ((candidate 3000000000000) = 3000000000001));\n  (assert ((candidate 3000000) = 3000001));\n  (assert ((candidate 1) = 2));\n  (assert ((candidate 30000) = 30001));\n  (assert ((candidate 300000000) = 300000001));\n  (assert ((candidate 300) = 301));\n  (assert ((candidate 30000000) = 30000001));\n  (assert ((candidate 0) = 1));\n  (assert ((candidate 300000000000) = 300000000001));\n  (assert ((candidate 7) = 8));\n  (assert ((candidate 9) = 10));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_116084_trans", "language": "ml", "prompt": "(**transformation between 2 tiles\n[n,m] -> [n',m']\n*)\nlet trans (n : int) (m : int) :  int * int * bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_116084_trans.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = trans in\n  (assert ((candidate 2 5) = (2, 5, false)));\n  (assert ((candidate 0 12) = (0, 12, false)));\n  (assert ((candidate 0 0) = (0, 0, false)));\n  (assert ((candidate 0 2) = (0, 2, false)));\n  (assert ((candidate 14 2) = (14, 2, false)));\n  (assert ((candidate 0 1) = (0, 1, false)));\n  (assert ((candidate 3 5) = (3, 5, false)));\n  (assert ((candidate 1 1) = (0, 2, true)));\n  (assert ((candidate 1 0) = (0, 1, false)));\n  (assert ((candidate 4 5) = (4, 5, false)));\n  (assert ((candidate 6 2) = (6, 2, false)));\n  (assert ((candidate 3 2) = (3, 2, false)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_116189_convert_time", "language": "ml", "prompt": "(**Convert time into a years, hours, minute, seconds thing.\n*)\nlet convert_time (_time : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_116189_convert_time.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = convert_time in\n  (assert ((candidate 172800) = \"2 days\"));\n  (assert ((candidate 0) = \"0 seconds\"));\n  (assert ((candidate 86399) = \"23 hours 59 minutes 59 seconds\"));\n  (assert ((candidate 3) = \"3 seconds\"));\n  (assert ((candidate 7200) = \"2 hours\"));\n  (assert ((candidate 0) = \"0 seconds\"));\n  (assert ((candidate 59) = \"59 seconds\"));\n  (assert ((candidate 120) = \"2 minutes\"));\n  (assert ((candidate 3599) = \"59 minutes 59 seconds\"));\n  (assert ((candidate 1209600) = \"2 weeks\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_116230_hash_function", "language": "ml", "prompt": "(**Hash function for calculating signature matrix\n:return hash number for each row number\n*)\nlet hash_function (num_row : int) (a : int) (b : int) (m : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_116230_hash_function.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = hash_function in\n  (assert ((candidate 3 1 3 4) = 2));\n  (assert ((candidate 4 3 1 6) = 1));\n  (assert ((candidate 10 2 5 6) = 1));\n  (assert ((candidate 7 1 1 2) = 0));\n  (assert ((candidate 4 2 5 6) = 1));\n  (assert ((candidate 1 3 1 6) = 4));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_117035_getR", "language": "ml", "prompt": "(**Returns the matrix R as in the canonical form [[Q,R],[0,I]]\nm is the input matrix, t is the list of the transient states,\na is the list of the absorbing states.\n*)\nlet getR (m : int list list) (t : int list) (a : int list) : int list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_117035_getR.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = getR in\n  (assert ((candidate [[0; 1; 0]; [1; 0; 1]; [0; 1; 0]] [0] [1; 2]) = [[1; 0]]));\n  (assert ((candidate [[0; 1; 0]; [1; 0; 1]; [0; 1; 0]] [] [1; 2]) = []));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_117164_PEER_cmd", "language": "ml", "prompt": "(**Command to execute PEER covariate correction. Be sure to use r-4.0.3\n*)\nlet PEER_cmd (PEER_exec_path : string) (phenotype_file : string) (covariates_file : string) (num_peer : int) (output_prefix : string) (output_dir : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_117164_PEER_cmd.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = PEER_cmd in\n  (assert ((candidate \"peer.R\" \"peer_test_phenotype_file.txt\" \"peer_test_covariates_file.txt\" 100 \"peer_test_output_prefix\" \"peer_test_output_dir\") = \"time Rscript peer.R peer_test_phenotype_file.txt peer_test_output_prefix 100 -o peer_test_output_dir --covariates peer_test_covariates_file.txt\"));\n  (assert ((candidate \"/home/user/PEER/PEER/peer.R\" \"/home/user/PEER/PEER/peer_example/pheno1.csv\" \"/home/user/PEER/PEER/peer_example/covar1.csv\" 10 \"10_peer\" \"/home/user/PEER/PEER/peer_example/out\") = \"time Rscript /home/user/PEER/PEER/peer.R /home/user/PEER/PEER/peer_example/pheno1.csv 10_peer 10 -o /home/user/PEER/PEER/peer_example/out --covariates /home/user/PEER/PEER/peer_example/covar1.csv\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_117496_is_leap", "language": "ml", "prompt": "(**https://stackoverflow.com/a/30714165\n*)\nlet is_leap (year : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_117496_is_leap.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_leap in\n  (assert ((candidate 2019) = false));\n  (assert ((candidate 2401) = false));\n  (assert ((candidate 1900) = false));\n  (assert ((candidate 2012) = true));\n  (assert ((candidate 2100) = false));\n  (assert ((candidate 2800) = true));\n  (assert ((candidate 1988) = true));\n  (assert ((candidate 1999) = false));\n  (assert ((candidate 2801) = false));\n  (assert ((candidate 2021) = false));\n  (assert ((candidate 2900) = false));\n  (assert ((candidate 2004) = true));\n  (assert ((candidate 2001) = false));\n  (assert ((candidate 2400) = true));\n  (assert ((candidate 3000) = false));\n  (assert ((candidate 2000) = true));\n  (assert ((candidate 2008) = true));\n  (assert ((candidate 2020) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_118038__textTypeForDefStyleName", "language": "ml", "prompt": "(**' ' for code\n'c' for comments\n'b' for block comments\n'h' for here documents\n*)\nlet _textTypeForDefStyleName (attribute : string) (defStyleName : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_118038__textTypeForDefStyleName.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _textTypeForDefStyleName in\n  (assert ((candidate \"string\" \"dsString\") = \"s\"));\n  (assert ((candidate \"char\" \"dsChar\") = \"s\"));\n  (assert ((candidate \"comment\" \"dsComment\") = \"c\"));\n  (assert ((candidate \"block\" \"dsComment\") = \"b\"));\n  (assert ((candidate \"here\" \"dsOthers\") = \"h\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_118563_parse_centrifuge", "language": "ml", "prompt": "(**Parse a line in a Centrifuge mapping file.\nParameters\n----------\nline : str\n * Line to parse.\nReturns\n-------\ntuple of (str, str, int, int)\n * Query, subject, score, length.\nNotes\n-----\nCentrifuge output format:\n * readID, seqID, taxID, score, 2ndBestScore, hitLength, queryLength,\n * numMatches\n.. _Centrifuge manual:\n * https://ccb.jhu.edu/software/centrifuge/manual.shtml\n*)\nlet parse_centrifuge (line : string) :  string * string * int * int option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_118563_parse_centrifuge.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_centrifuge in\n  (assert ((candidate \"readID,seqID,taxID,score,2ndBestScore,hitLength,queryLength,numMatches\") = Some(None)));\n  (assert ((candidate \"1\tseq1\t1\t500\t2\t1000\t2000\t3\") = Some((\"1\", \"seq1\", 500, 1000))));\n  (assert ((candidate \"read1\tseq2\t1\t123\t456\t100\t200\t3\") = Some((\"read1\", \"seq2\", 123, 100))));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_118723_replace_newlines", "language": "ml", "prompt": "(**remove newlines\n*)\nlet replace_newlines (html_str : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_118723_replace_newlines.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = replace_newlines in\n  (assert ((candidate \"<html><body><p>This is a paragraph.</p> This is another.</body></html>\") = \"<html><body><p>This is a paragraph.</p> This is another.</body></html>\"));\n  (assert ((candidate \"<html><head><title>test</title></head><body>test\n1</body></html>\") = \"<html><head><title>test</title></head><body>test\n1</body></html>\"));\n  (assert ((candidate \"<html><head><title>test</title></head><body>test\n1\n2\n3\n4\n5</body></html>\") = \"<html><head><title>test</title></head><body>test\n1\n2\n3\n4\n5</body></html>\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_119408_get_content_type", "language": "ml", "prompt": "(**getting content_type via file_type.\n:param file_extension\n:return: content_type\n*)\nlet get_content_type (file_extension : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_119408_get_content_type.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_content_type in\n  (assert ((candidate \"jpg\") = \"image/jpeg\"));\n  (assert ((candidate \"jpeg\") = \"image/jpeg\"));\n  (assert ((candidate \"docx\") = \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"));\n  (assert ((candidate \"png\") = \"image/png\"));\n  (assert ((candidate \"doc\") = \"application/msword\"));\n  (assert ((candidate \"bmp\") = \"image/bmp\"));\n  (assert ((candidate \"pdf\") = \"application/pdf\"));\n  (assert ((candidate \"text\") = \"text/plain\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_120250_is_contained_in", "language": "ml", "prompt": "(**Is the first region contained in the second.\n:param frst: a tuple representing the first region\n * with chromosome, start, end as the first\n * 3 columns\n:param scnd: a tuple representing the second region\n * with chromosome, start, end as the first\n * 3 columns\n:return: True or False\n*)\nlet is_contained_in (frst :  string * int * int) (scnd :  string * int * int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_120250_is_contained_in.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_contained_in in\n  (assert ((candidate (\"chr1\", 1, 100) (\"chr1\", 1, 150)) = true));\n  (assert ((candidate (\"1\", 10, 15) (\"1\", 10, 20)) = true));\n  (assert ((candidate (\"1\", 0, 2) (\"1\", 0, 1)) = false));\n  (assert ((candidate (\"chr1\", 1, 100) (\"chr1\", 50, 150)) = false));\n  (assert ((candidate (\"1\", 10, 15) (\"1\", 12, 16)) = false));\n  (assert ((candidate (\"1\", 0, 1) (\"1\", 0, 1)) = true));\n  (assert ((candidate (\"chr1\", 1, 100) (\"chr1\", 1, 200)) = true));\n  (assert ((candidate (\"1\", 10, 15) (\"1\", 9, 9)) = false));\n  (assert ((candidate (\"1\", 10, 15) (\"1\", 15, 16)) = false));\n  (assert ((candidate (\"1\", 10, 15) (\"1\", 9, 14)) = false));\n  (assert ((candidate (\"1\", 10, 15) (\"1\", 9, 8)) = false));\n  (assert ((candidate (\"1\", 10, 15) (\"1\", 15, 15)) = false));\n  (assert ((candidate (\"1\", 10, 15) (\"1\", 16, 16)) = false));\n  (assert ((candidate (\"1\", 0, 1) (\"2\", 0, 2)) = false));\n  (assert ((candidate (\"1\", 0, 2) (\"1\", 0, 2)) = true));\n  (assert ((candidate (\"1\", 0, 2) (\"1\", 1, 2)) = false));\n  (assert ((candidate (\"1\", 10, 15) (\"1\", 10, 15)) = true));\n  (assert ((candidate (\"1\", 0, 1) (\"1\", 0, 2)) = true));\n  (assert ((candidate (\"1\", 10, 15) (\"1\", 10, 10)) = false));\n  (assert ((candidate (\"chr2\", 1, 100) (\"chr1\", 1, 100)) = false));\n  (assert ((candidate (\"chr1\", 1, 100) (\"chr1\", 1, 100)) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_120570_IsEven", "language": "ml", "prompt": "(**Returns a Z3 condition for if an Int is even\n*)\nlet IsEven (i : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_120570_IsEven.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = IsEven in\n  (assert ((candidate (~1)) = false));\n  (assert ((candidate 4) = true));\n  (assert ((candidate 5) = false));\n  (assert ((candidate (~2)) = true));\n  (assert ((candidate 8) = true));\n  (assert ((candidate 2) = true));\n  (assert ((candidate 1) = false));\n  (assert ((candidate 7) = false));\n  (assert ((candidate 9) = false));\n  (assert ((candidate 6) = true));\n  (assert ((candidate 0) = true));\n  (assert ((candidate 3) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_120905_fibonacci", "language": "ml", "prompt": "(**Method that prints the fibonacci sequence until the n-th number\n*)\nlet fibonacci (n_terms : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_120905_fibonacci.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = fibonacci in\n  (assert ((candidate 12) = 144));\n  (assert ((candidate 2) = 1));\n  (assert ((candidate 13) = 233));\n  (assert ((candidate 24) = 46368));\n  (assert ((candidate 16) = 987));\n  (assert ((candidate 25) = 75025));\n  (assert ((candidate 20) = 6765));\n  (assert ((candidate 28) = 317811));\n  (assert ((candidate 11) = 89));\n  (assert ((candidate 29) = 514229));\n  (assert ((candidate 30) = 832040));\n  (assert ((candidate 19) = 4181));\n  (assert ((candidate 3) = 2));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 18) = 2584));\n  (assert ((candidate 5) = 5));\n  (assert ((candidate 4) = 3));\n  (assert ((candidate 8) = 21));\n  (assert ((candidate 21) = 10946));\n  (assert ((candidate 15) = 610));\n  (assert ((candidate 9) = 34));\n  (assert ((candidate 10) = 55));\n  (assert ((candidate 6) = 8));\n  (assert ((candidate 7) = 13));\n  (assert ((candidate 22) = 17711));\n  (assert ((candidate 14) = 377));\n  (assert ((candidate 23) = 28657));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 26) = 121393));\n  (assert ((candidate 27) = 196418));\n  (assert ((candidate 17) = 1597));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_121456__GenerateMakePrivateGetter", "language": "ml", "prompt": "(**Internal helper method to actually get the data. It calls the DLL and passes the correct data to it.\nIt then returns that value back to ML.NET.\n*)\nlet _GenerateMakePrivateGetter (return_type : string) (variable_names : string list) (function_name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_121456__GenerateMakePrivateGetter.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _GenerateMakePrivateGetter in\n  (assert ((candidate \"System.Single\" [\"x\"] \"Foo\") = \"\n\nprivate Delegate MakeGetter(DataViewRow input, int iinfo)\n{\nValueGetter<System.Single> result = (ref System.Single dst) =>\n{\nvar xVal =  _parent._x.GetValue(input);\ndst = Foo(xVal);\n};\n\nreturn result;\n}\"));\n  (assert ((candidate \"System.Single\" [\"x\"; \"y\"; \"z\"] \"Foo\") = \"\n\nprivate Delegate MakeGetter(DataViewRow input, int iinfo)\n{\nValueGetter<System.Single> result = (ref System.Single dst) =>\n{\nvar xVal =  _parent._x.GetValue(input);\nvar yVal =  _parent._y.GetValue(input);\nvar zVal =  _parent._z.GetValue(input);\ndst = Foo(xVal, yVal, zVal);\n};\n\nreturn result;\n}\"));\n  (assert ((candidate \"System.Single\" [\"x\"; \"y\"] \"Foo\") = \"\n\nprivate Delegate MakeGetter(DataViewRow input, int iinfo)\n{\nValueGetter<System.Single> result = (ref System.Single dst) =>\n{\nvar xVal =  _parent._x.GetValue(input);\nvar yVal =  _parent._y.GetValue(input);\ndst = Foo(xVal, yVal);\n};\n\nreturn result;\n}\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_121971_months_of_gregorian_calendar", "language": "ml", "prompt": "(**Months of the Gregorian calendar.\nParameters\n----------\nyear : int, optional\n * (dummy value).\nReturns\n-------\nout : dict\n * integers as keys, months of the Gregorian calendar as values.\nNotes\n-----\nAppropriate for use as 'year_cycles' function in :class:`Calendar`.\nThis module has a built-in calendar with months only:\n:data:`CalMonthsOnly`.\n*)\nlet months_of_gregorian_calendar (year : int) : (int, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_121971_months_of_gregorian_calendar.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = months_of_gregorian_calendar in\n  (assert ((candidate 2000) = [(1, \"January\"); (2, \"February\"); (3, \"March\"); (4, \"April\"); (5, \"May\"); (6, \"June\"); (7, \"July\"); (8, \"August\"); (9, \"September\"); (10, \"October\"); (11, \"November\"); (12, \"December\")]));\n  (assert ((candidate 2009) = [(1, \"January\"); (2, \"February\"); (3, \"March\"); (4, \"April\"); (5, \"May\"); (6, \"June\"); (7, \"July\"); (8, \"August\"); (9, \"September\"); (10, \"October\"); (11, \"November\"); (12, \"December\")]));\n  (assert ((candidate 2020) = [(1, \"January\"); (2, \"February\"); (3, \"March\"); (4, \"April\"); (5, \"May\"); (6, \"June\"); (7, \"July\"); (8, \"August\"); (9, \"September\"); (10, \"October\"); (11, \"November\"); (12, \"December\")]));\n  (assert ((candidate 1999) = [(1, \"January\"); (2, \"February\"); (3, \"March\"); (4, \"April\"); (5, \"May\"); (6, \"June\"); (7, \"July\"); (8, \"August\"); (9, \"September\"); (10, \"October\"); (11, \"November\"); (12, \"December\")]));\n  (assert ((candidate 2002) = [(1, \"January\"); (2, \"February\"); (3, \"March\"); (4, \"April\"); (5, \"May\"); (6, \"June\"); (7, \"July\"); (8, \"August\"); (9, \"September\"); (10, \"October\"); (11, \"November\"); (12, \"December\")]));\n  (assert ((candidate 2001) = [(1, \"January\"); (2, \"February\"); (3, \"March\"); (4, \"April\"); (5, \"May\"); (6, \"June\"); (7, \"July\"); (8, \"August\"); (9, \"September\"); (10, \"October\"); (11, \"November\"); (12, \"December\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_122909_limit_count", "language": "ml", "prompt": "(**Handling of the optional \"count\" parameter, common in many commands.\nParameters:\n * - count     -- desired number of elements\n * - on_device -- number of elements on device\nIf count is None or 0 return what's on device\nIf count > 0 use count, unless it is more than what's on device. \nIf count < 0 that means \"abs(count) less than what's on device\nTypical usage: \n * count = limit_count(count, mc.mgrp_get_count())\n*)\nlet limit_count (count : int option) (on_device : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_122909_limit_count.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = limit_count in\n  (assert ((candidate Some((~10)) (~10)) = 0));\n  (assert ((candidate Some((~2)) 0) = 0));\n  (assert ((candidate Some(3) 0) = 0));\n  (assert ((candidate Some(None) 2) = 2));\n  (assert ((candidate Some(10) 10) = 10));\n  (assert ((candidate Some(None) 1) = 1));\n  (assert ((candidate Some(None) 0) = 0));\n  (assert ((candidate Some(0) (~10)) = 0));\n  (assert ((candidate Some(3) 2) = 2));\n  (assert ((candidate Some((~3)) 1) = 0));\n  (assert ((candidate Some(1) 10) = 1));\n  (assert ((candidate Some((~1)) 0) = 0));\n  (assert ((candidate Some(3) 1) = 1));\n  (assert ((candidate Some(10) 0) = 0));\n  (assert ((candidate Some(None) 10) = 10));\n  (assert ((candidate Some((~1)) 10) = 9));\n  (assert ((candidate Some((~3)) 2) = 0));\n  (assert ((candidate Some((~10)) 10) = 0));\n  (assert ((candidate Some(0) 0) = 0));\n  (assert ((candidate Some((~2)) 2) = 0));\n  (assert ((candidate Some(1) 0) = 0));\n  (assert ((candidate Some(None) 5) = 5));\n  (assert ((candidate Some(2) 2) = 2));\n  (assert ((candidate Some(10) 1) = 1));\n  (assert ((candidate Some((~1)) 2) = 1));\n  (assert ((candidate Some(2) 0) = 0));\n  (assert ((candidate Some((~3)) 0) = 0));\n  (assert ((candidate Some(2) 1) = 1));\n  (assert ((candidate Some(10) 5) = 5));\n  (assert ((candidate Some(1) 1) = 1));\n  (assert ((candidate Some((~2)) 1) = 0));\n  (assert ((candidate Some(10) 2) = 2));\n  (assert ((candidate Some(1) 2) = 1));\n  (assert ((candidate Some((~10)) 0) = 0));\n  (assert ((candidate Some(0) (~5)) = 0));\n  (assert ((candidate Some((~5)) 0) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_122974_distManhattan", "language": "ml", "prompt": "(**calcule la distance de Manhattan entre le tuple \np1 et le tuple p2\n*)\nlet distManhattan (p1 :  int * int) (p2 :  int * int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_122974_distManhattan.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = distManhattan in\n  (assert ((candidate (1, 1) (0, 0)) = 2));\n  (assert ((candidate ((~1), (~1)) ((~1), (~1))) = 0));\n  (assert ((candidate (0, 0) (1, 2)) = 3));\n  (assert ((candidate ((~1), (~1)) (1, (~1))) = 2));\n  (assert ((candidate ((~1), 0) (0, (~1))) = 2));\n  (assert ((candidate ((~1), (~1)) (1, 1)) = 4));\n  (assert ((candidate (1, 1) (1, 1)) = 0));\n  (assert ((candidate (0, 0) (1, 1)) = 2));\n  (assert ((candidate ((~1), 1) (1, 1)) = 2));\n  (assert ((candidate (1, 1) ((~1), (~1))) = 4));\n  (assert ((candidate (1, 0) (0, 1)) = 2));\n  (assert ((candidate ((~2), 0) (2, 0)) = 4));\n  (assert ((candidate (0, 0) (3, 3)) = 6));\n  (assert ((candidate (1, 1) ((~1), (~1))) = 4));\n  (assert ((candidate (0, 0) ((~1), (~1))) = 2));\n  (assert ((candidate (0, 0) (3, 4)) = 7));\n  (assert ((candidate (0, 0) ((~1), (~1))) = 2));\n  (assert ((candidate (0, 0) (1, 1)) = 2));\n  (assert ((candidate (100, 100) (0, 0)) = 200));\n  (assert ((candidate (0, 0) (0, 1)) = 1));\n  (assert ((candidate (0, 0) (100, 100)) = 200));\n  (assert ((candidate (1, 1) (0, 0)) = 2));\n  (assert ((candidate (0, 0) (0, 0)) = 0));\n  (assert ((candidate (0, 0) ((~2), (~2))) = 4));\n  (assert ((candidate (1, 1) (2, 2)) = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_123440_is_power_of_2", "language": "ml", "prompt": "(**Returns True if an integer is a power of 2. Only works for x > 0.\n*)\nlet is_power_of_2 (val : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_123440_is_power_of_2.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_power_of_2 in\n  (assert ((candidate 4) = true));\n  (assert ((candidate 17) = false));\n  (assert ((candidate 26) = false));\n  (assert ((candidate 6) = false));\n  (assert ((candidate 22) = false));\n  (assert ((candidate 25) = false));\n  (assert ((candidate 7) = false));\n  (assert ((candidate 1) = true));\n  (assert ((candidate 14) = false));\n  (assert ((candidate 10) = false));\n  (assert ((candidate 65) = false));\n  (assert ((candidate 18) = false));\n  (assert ((candidate 21) = false));\n  (assert ((candidate 11) = false));\n  (assert ((candidate 2) = true));\n  (assert ((candidate 15) = false));\n  (assert ((candidate 13) = false));\n  (assert ((candidate 16) = true));\n  (assert ((candidate 12) = false));\n  (assert ((candidate 23) = false));\n  (assert ((candidate 27) = false));\n  (assert ((candidate 19) = false));\n  (assert ((candidate 9) = false));\n  (assert ((candidate 8) = true));\n  (assert ((candidate 64) = true));\n  (assert ((candidate 5) = false));\n  (assert ((candidate 3) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_123581_htmlentities", "language": "ml", "prompt": "(**Escape chars in the text for HTML presentation\nArgs:\n * text (str): subject to replace\nReturns:\n * str : result of replacement\n*)\nlet htmlentities (text : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_123581_htmlentities.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = htmlentities in\n  (assert ((candidate \">\") = \"&gt;\"));\n  (assert ((candidate \"a < b\") = \"a &lt; b\"));\n  (assert ((candidate \"<\") = \"&lt;\"));\n  (assert ((candidate \"\"\") = \"&quot;\"));\n  (assert ((candidate \"Testing & testing\") = \"Testing &amp; testing\"));\n  (assert ((candidate \"Testing & testing > testing < testing\") = \"Testing &amp; testing &gt; testing &lt; testing\"));\n  (assert ((candidate \"a & b\") = \"a &amp; b\"));\n  (assert ((candidate \"I have a new line of text\n\") = \"I have a new line of text\n\"));\n  (assert ((candidate \"a > b\") = \"a &gt; b\"));\n  (assert ((candidate \"&\") = \"&amp;\"));\n  (assert ((candidate \"'\") = \"&#39;\"));\n  (assert ((candidate \"I have a new line of text\") = \"I have a new line of text\"));\n  (assert ((candidate \"Testing\") = \"Testing\"));\n  (assert ((candidate \"Testing & testing > testing <\") = \"Testing &amp; testing &gt; testing &lt;\"));\n  (assert ((candidate \"a \" b\") = \"a &quot; b\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_123984_decimal_to_hexadecimal", "language": "ml", "prompt": "(**Return hexadecimal version of the specified decimal number.\n*)\nlet decimal_to_hexadecimal (number : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_123984_decimal_to_hexadecimal.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = decimal_to_hexadecimal in\n  (assert ((candidate 7) = \"7\"));\n  (assert ((candidate 5) = \"5\"));\n  (assert ((candidate 10) = \"a\"));\n  (assert ((candidate 3) = \"3\"));\n  (assert ((candidate 15) = \"f\"));\n  (assert ((candidate 257) = \"101\"));\n  (assert ((candidate 1) = \"1\"));\n  (assert ((candidate 32767) = \"7fff\"));\n  (assert ((candidate 255) = \"ff\"));\n  (assert ((candidate 0) = \"0\"));\n  (assert ((candidate 25) = \"19\"));\n  (assert ((candidate 255) = \"ff\"));\n  (assert ((candidate 10) = \"a\"));\n  (assert ((candidate 12345) = \"3039\"));\n  (assert ((candidate 11) = \"b\"));\n  (assert ((candidate 100) = \"64\"));\n  (assert ((candidate 16) = \"10\"));\n  (assert ((candidate 256) = \"100\"));\n  (assert ((candidate 174) = \"ae\"));\n  (assert ((candidate 0) = \"0\"));\n  (assert ((candidate 256) = \"100\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_12403_degrees_to_meters", "language": "ml", "prompt": "(**111195 = (Earth mean radius)*PI/180\n(supposedly 'maximum error using this method is ~ 0.1%')\n:see: https://stackoverflow.com/questions/12204834/get-distance-in-meters-instead-of-degrees-in-spatialite\n*)\nlet degrees_to_meters (degrees : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_12403_degrees_to_meters.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = degrees_to_meters in\n  (assert ((candidate 6) = 667170));\n  (assert ((candidate 10000) = 1111950000));\n  (assert ((candidate 3) = 333585));\n  (assert ((candidate 10) = 1111950));\n  (assert ((candidate 5) = 555975));\n  (assert ((candidate 4) = 444780));\n  (assert ((candidate 1) = 111195));\n  (assert ((candidate 1000) = 111195000));\n  (assert ((candidate 100000) = 11119500000));\n  (assert ((candidate 100) = 11119500));\n  (assert ((candidate 2) = 222390));\n  (assert ((candidate 0) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_125020__is_temp_garbage", "language": "ml", "prompt": "(**Is this a Microsoft Office temp file?\n*)\nlet _is_temp_garbage (filename : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_125020__is_temp_garbage.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _is_temp_garbage in\n  (assert ((candidate \"c:\\users\\someone\\somefile.docx~123.tmp\") = true));\n  (assert ((candidate \"c:\\users\\someone\\somefile.docx~123.tmp~123\") = false));\n  (assert ((candidate \"c:\\users\\someone\\somefile.docx~1\") = false));\n  (assert ((candidate \"c:\\users\\someone\\somefile.docx.tmp\") = true));\n  (assert ((candidate \"c:\\users\\someone\\somefile.docx~123\") = false));\n  (assert ((candidate \"c:\\users\\someone\\somefile.docx~123.tmp~123.tmp\") = true));\n  (assert ((candidate \"c:\\users\\someone\\somefile.docx\") = false));\n  (assert ((candidate \"c:\\users\\someone\\~somefile.docx\") = false));\n  (assert ((candidate \"c:\\users\\someone\\somefile.docx~123.tmp~\") = false));\n  (assert ((candidate \"c:\\users\\someone\\somefile.docx~\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_125164_debugsquare", "language": "ml", "prompt": "(**Return x squared but also print a debug value of x.\n*)\nlet debugsquare (x : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_125164_debugsquare.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = debugsquare in\n  (assert ((candidate (~2)) = 4));\n  (assert ((candidate 4) = 16));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 5) = 25));\n  (assert ((candidate 3) = 9));\n  (assert ((candidate 2) = 4));\n  (assert ((candidate 12) = 144));\n  (assert ((candidate 10) = 100));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_125500_cmds_to_bash", "language": "ml", "prompt": "(**Turn a list of cmds into a bash script.\n*)\nlet cmds_to_bash (cmds : string list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_125500_cmds_to_bash.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = cmds_to_bash in\n  (assert ((candidate [\"echo hello\"; \"echo world\"]) = \"#!/bin/bash\nset -vexubE -o pipefail\necho hello\necho world\n\"));\n  (assert ((candidate [\"echo hello world\"]) = \"#!/bin/bash\nset -vexubE -o pipefail\necho hello world\n\"));\n  (assert ((candidate [\"set -ex\"; \"echo hello world\"]) = \"#!/bin/bash\nset -vexubE -o pipefail\nset -ex\necho hello world\n\"));\n  (assert ((candidate [\"a\"; \"b c\"]) = \"#!/bin/bash\nset -vexubE -o pipefail\na\nb c\n\"));\n  (assert ((candidate []) = \"#!/bin/bash\nset -vexubE -o pipefail\n\n\"));\n  (assert ((candidate [\"ls\"; \"non-existent\"; \"file\"]) = \"#!/bin/bash\nset -vexubE -o pipefail\nls\nnon-existent\nfile\n\"));\n  (assert ((candidate [\"set -v\"; \"echo hello world\"]) = \"#!/bin/bash\nset -vexubE -o pipefail\nset -v\necho hello world\n\"));\n  (assert ((candidate [\"set -u\"; \"echo hello world\"]) = \"#!/bin/bash\nset -vexubE -o pipefail\nset -u\necho hello world\n\"));\n  (assert ((candidate [\"do a thing\"; \"do another thing\"]) = \"#!/bin/bash\nset -vexubE -o pipefail\ndo a thing\ndo another thing\n\"));\n  (assert ((candidate [\"echo hello 'world'\"; \"echo hello $var\"]) = \"#!/bin/bash\nset -vexubE -o pipefail\necho hello 'world'\necho hello $var\n\"));\n  (assert ((candidate [\"set -e\"; \"echo hello world\"]) = \"#!/bin/bash\nset -vexubE -o pipefail\nset -e\necho hello world\n\"));\n  (assert ((candidate [\"set -x\"; \"echo hello world\"]) = \"#!/bin/bash\nset -vexubE -o pipefail\nset -x\necho hello world\n\"));\n  (assert ((candidate [\"do a thing\"; \"do another thing\"]) = \"#!/bin/bash\nset -vexubE -o pipefail\ndo a thing\ndo another thing\n\"));\n  (assert ((candidate [\"a\"; \"b c | d\"]) = \"#!/bin/bash\nset -vexubE -o pipefail\na\nb c | d\n\"));\n  (assert ((candidate [\"echo \"hello\"\"; \"grep f\"; \"cat out.txt\"]) = \"#!/bin/bash\nset -vexubE -o pipefail\necho \"hello\"\ngrep f\ncat out.txt\n\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_125653_reverse_number", "language": "ml", "prompt": "(**Reverse a number.\n*)\nlet reverse_number (num : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_125653_reverse_number.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = reverse_number in\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 123) = 321));\n  (assert ((candidate 981) = 189));\n  (assert ((candidate 1234) = 4321));\n  (assert ((candidate 1000) = 1));\n  (assert ((candidate 321) = 123));\n  (assert ((candidate 12) = 21));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 23) = 32));\n  (assert ((candidate 100) = 1));\n  (assert ((candidate 10) = 1));\n  (assert ((candidate 999) = 999));\n  (assert ((candidate 500) = 5));\n  (assert ((candidate 123456789) = 987654321));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_125811_compare_bits", "language": "ml", "prompt": "(**Subtract 2D list to determine changes to bit state.\n*)\nlet compare_bits (olds : int list list) (news : int list list) : int list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_125811_compare_bits.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = compare_bits in\n  (assert ((candidate [[1; 1]; [1; 1]] [[1; 1]; [1; 1]]) = [[0; 0]; [0; 0]]));\n  (assert ((candidate [[0; 0; 0]; [0; 0; 0]; [0; 0; 0]] [[0; 0; 0]; [0; 0; 0]; [0; 0; 0]]) = [[0; 0; 0]; [0; 0; 0]; [0; 0; 0]]));\n  (assert ((candidate [[0; 0]; [0; 0]] [[0; 0]; [0; 0]]) = [[0; 0]; [0; 0]]));\n  (assert ((candidate [[0; 0]; [0; 0]] [[1; 1]; [1; 1]]) = [[1; 1]; [1; 1]]));\n  (assert ((candidate [[1; 1]; [1; 1]] [[0; 0]; [0; 0]]) = [[(~1); (~1)]; [(~1); (~1)]]));\n  (assert ((candidate [[1; 1]; [0; 1]] [[1; 1]; [1; 1]]) = [[0; 0]; [1; 0]]));\n  (assert ((candidate [[1; 0]; [1; 1]] [[0; 1]; [0; 0]]) = [[(~1); 1]; [(~1); (~1)]]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_126107__compressed_name_to_c_string", "language": "ml", "prompt": "(**Convert a compressed name (with fragment references) to a string that\nthe C++ compiler will accept. The primary reason for this function is\nbecause the hex escape sequence (\\xHH) in C/C++ has no length limit, so\nwill happily run into the characters after the HH. So we have to break\nthose references into separate strings. Example: converts (\"\u0001ab\")\ninto (\"\u0001\" \"ab\").\n*)\nlet _compressed_name_to_c_string (compressed_name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_126107__compressed_name_to_c_string.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _compressed_name_to_c_string in\n  (assert ((candidate \"a\"b\"c\"d\") = \"\"a\"b\"c\"d\"\"));\n  (assert ((candidate \"abc\\nabc\") = \"\"abc\\nabc\"\"));\n  (assert ((candidate \"a\u0001\u0002b\") = \"\"a\" \"\\x01\" \"\\x02\" \"b\"\"));\n  (assert ((candidate \"a\\x00b\") = \"\"a\\x00b\"\"));\n  (assert ((candidate \"a\u0001b\") = \"\"a\" \"\\x01\" \"b\"\"));\n  (assert ((candidate \"a\") = \"\"a\"\"));\n  (assert ((candidate \"\u0001ab\") = \"\"\\x01\" \"ab\"\"));\n  (assert ((candidate \"a\u0001\u0002\u0003\u0004b\") = \"\"a\" \"\\x01\" \"\\x02\" \"\\x03\" \"\\x04\" \"b\"\"));\n  (assert ((candidate \"a\u0001\u0002\u0003b\") = \"\"a\" \"\\x01\" \"\\x02\" \"\\x03\" \"b\"\"));\n  (assert ((candidate \"a\u0001\u0002\u0003\u0004\u0005b\") = \"\"a\" \"\\x01\" \"\\x02\" \"\\x03\" \"\\x04\" \"\\x05\" \"b\"\"));\n  (assert ((candidate \"a\\b\") = \"\"a\\b\"\"));\n  (assert ((candidate \"a\"b\") = \"\"a\"b\"\"));\n  (assert ((candidate \"ab\") = \"\"ab\"\"));\n  (assert ((candidate \"a\\b\\c\") = \"\"a\\b\\c\"\"));\n  (assert ((candidate \"a\"b\"c\") = \"\"a\"b\"c\"\"));\n  (assert ((candidate \"abc\") = \"\"abc\"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_12626_mysql_quote", "language": "ml", "prompt": "(**Quote the string x using MySQL quoting rules. If x is the empty string,\nreturn \"NULL\". Probably not safe against maliciously formed strings, but\nour input is fixed and from a basically trustable source.\n*)\nlet mysql_quote (x : string option) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_12626_mysql_quote.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = mysql_quote in\n  (assert ((candidate Some(\"foo\\bar\")) = \"'foo\\\\bar'\"));\n  (assert ((candidate Some(\"\n\")) = \"'\\n'\"));\n  (assert ((candidate Some(None)) = \"NULL\"));\n  (assert ((candidate Some(\"hello\")) = \"'hello'\"));\n  (assert ((candidate Some(\"\")) = \"NULL\"));\n  (assert ((candidate Some(\"foo\")) = \"'foo'\"));\n  (assert ((candidate Some(\"c\\\")) = \"'c\\\\'\"));\n  (assert ((candidate Some(\"a\")) = \"'a'\"));\n  (assert ((candidate Some(\"'\")) = \"''''\"));\n  (assert ((candidate Some(\"\n\n\")) = \"'\\n\\n'\"));\n  (assert ((candidate Some(\"\\\")) = \"'\\\\'\"));\n  (assert ((candidate Some(None)) = \"NULL\"));\n  (assert ((candidate Some(\"\n\n\n\")) = \"'\\n\\n\\n'\"));\n  (assert ((candidate Some(\"hello\nworld\")) = \"'hello\\nworld'\"));\n  (assert ((candidate Some(\"foo\nbar\")) = \"'foo\\nbar'\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_126701__is_file_valid", "language": "ml", "prompt": "(**Decide if a file is valid.\n*)\nlet _is_file_valid (name : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_126701__is_file_valid.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _is_file_valid in\n  (assert ((candidate \".foo\") = false));\n  (assert ((candidate \"foo.txt\") = true));\n  (assert ((candidate \".foo.bak\") = false));\n  (assert ((candidate \".foo.txt\") = false));\n  (assert ((candidate \".foo.txt.bak\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_12710_splitRPMFilename", "language": "ml", "prompt": "(**Pass in a standard style rpm fullname\nReturn a name, version, release, epoch, arch, e.g.::\n * foo-1.0-1.i386.rpm returns foo, 1.0, 1, i386\n * 1:bar-9-123a.ia64.rpm returns bar, 9, 123a, 1, ia64\n*)\nlet splitRPMFilename (filename : string) :  string * string * string * string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_12710_splitRPMFilename.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = splitRPMFilename in\n  (assert ((candidate \"1:baz-999-1.i386.rpm\") = (\"baz\", \"999\", \"1\", \"1\", \"i386\")));\n  (assert ((candidate \"foo-1.0-1.i386.rpm\") = (\"foo\", \"1.0\", \"1\", \"\", \"i386\")));\n  (assert ((candidate \"1:foo-9-123a.ia64.rpm\") = (\"foo\", \"9\", \"123a\", \"1\", \"ia64\")));\n  (assert ((candidate \"foo-1.0-1.i386.rpm\") = (\"foo\", \"1.0\", \"1\", \"\", \"i386\")));\n  (assert ((candidate \"1:bar-9-123a.ia64.rpm\") = (\"bar\", \"9\", \"123a\", \"1\", \"ia64\")));\n  (assert ((candidate \"bar-9-123a.ia64.rpm\") = (\"bar\", \"9\", \"123a\", \"\", \"ia64\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_127284_matches", "language": "ml", "prompt": "(**Checks if the pattern is in the line currently being searched. Uses the flags to modify the patter and/or the\nline being searched through.\n`-i` Match line using a case-insensitive comparison.\n`-v` Invert the program -- collect all lines that fail to match the pattern.\n`-x` Only match entire lines, instead of lines that contain a match.\n:param line: the line to search through in the file or the string provided\n:param pattern: the pattern to use for the search\n:param flags: the flags to narrow down the search\n:return: Boolean value, returns True if the pattern is in the line\n:rtype: bool\n*)\nlet matches (line : string) (pattern : string) (flags : string list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_127284_matches.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = matches in\n  (assert ((candidate \"hello\" \"hello\" [\"-x\"]) = true));\n  (assert ((candidate \"test line\" \"test line\" [\"-v\"]) = false));\n  (assert ((candidate \"This line contains a python pattern.\" \"python\" [\"-i\"; \"-x\"]) = false));\n  (assert ((candidate \"hello\" \"Hello\" []) = false));\n  (assert ((candidate \"hello\" \"hello\" [\"-x\"; \"-v\"]) = false));\n  (assert ((candidate \"This line contains a python pattern.\" \"Python\" [\"-i\"; \"-x\"; \"-v\"]) = false));\n  (assert ((candidate \"This line contains a python pattern.\" \"python\" []) = true));\n  (assert ((candidate \"test line\" \"test line\" [\"-x\"]) = true));\n  (assert ((candidate \"hello\" \"ell\" []) = true));\n  (assert ((candidate \"This line contains a python pattern.\" \"python\" [\"-v\"]) = false));\n  (assert ((candidate \"This line contains a python pattern.\" \"PYTHON\" [\"-i\"]) = true));\n  (assert ((candidate \"test line\" \"TEST LINE\" [\"-x\"]) = false));\n  (assert ((candidate \"hello\" \"Hello\" [\"-i\"]) = true));\n  (assert ((candidate \"This line contains a python pattern.\" \"python\" [\"-x\"]) = false));\n  (assert ((candidate \"hello\" \"ell\" [\"-v\"]) = false));\n  (assert ((candidate \"test line\" \"TEST LINE\" [\"-i\"]) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_127444_parse_host_port", "language": "ml", "prompt": "(**Interpret a string as a host:port pair.\nAn IPv6 address MUST be escaped if accompanied by a port,\nbecause otherwise ambiguity ensues: 2001:db8:85a3::8a2e:370:7334\nmeans both [2001:db8:85a3::8a2e:370:7334] and\n[2001:db8:85a3::8a2e:370]:7334.\n>>> parse_host_port('server01:80')\n('server01', 80)\n>>> parse_host_port('server01')\n('server01', None)\n>>> parse_host_port('server01', default_port=1234)\n('server01', 1234)\n>>> parse_host_port('[::1]:80')\n('::1', 80)\n>>> parse_host_port('[::1]')\n('::1', None)\n>>> parse_host_port('[::1]', default_port=1234)\n('::1', 1234)\n>>> parse_host_port('2001:db8:85a3::8a2e:370:7334', default_port=1234)\n('2001:db8:85a3::8a2e:370:7334', 1234)\n>>> parse_host_port(None)\n(None, None)\n*)\nlet parse_host_port (address : string option) (default_port : int option) :  string option * int option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_127444_parse_host_port.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_host_port in\n  (assert ((candidate Some(\"a:1234\") Some(None)) = (\"a\", 1234)));\n  (assert ((candidate Some(\"server01:80\")) = (\"server01\", 80)));\n  (assert ((candidate Some(\"a:1234\") Some(123)) = (\"a\", 1234)));\n  (assert ((candidate Some(\"[::1]:80\")) = (\"::1\", 80)));\n  (assert ((candidate Some(\"[::1]:1234\") Some(123)) = (\"::1\", 1234)));\n  (assert ((candidate Some(\"foo:80\")) = (\"foo\", 80)));\n  (assert ((candidate Some(\"[::1]:1234\") Some(None)) = (\"::1\", 1234)));\n  (assert ((candidate Some(\"localhost:80\")) = (\"localhost\", 80)));\n  (assert ((candidate Some(\"a:123\")) = (\"a\", 123)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_127862_convert_to_cents", "language": "ml", "prompt": "(**Convert the price to cents, stripping the currency sign\nParameters\n----------\nprice : str\n * Price provided in string format\nReturns\n-------\nint\n * Price converted to cents\n*)\nlet convert_to_cents (price : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_127862_convert_to_cents.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = convert_to_cents in\n  (assert ((candidate \"$0\") = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_12854_get_metric", "language": "ml", "prompt": "(**Get metric value from output line\n:param line: console output line\n:param name: name of metric\n:param split: split character\n:return: metric value\n*)\nlet get_metric (line : string) (name : string) (split : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_12854_get_metric.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_metric in\n  (assert ((candidate \"MetricA\" \"MetricA\" \" \") = \"\"));\n  (assert ((candidate \"MetricA : 0.1\" \"MetricB\" \" : \") = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_128799_match_subroutine_call", "language": "ml", "prompt": "(**\n*)\nlet match_subroutine_call (names : string list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_128799_match_subroutine_call.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = match_subroutine_call in\n  (assert ((candidate list \" \") = \"\"));\n  (assert ((candidate list \"\") = \"\"));\n  (assert ((candidate list \"SUB1 SUB2\") = \"\"));\n  (assert ((candidate [\"FOO\"; \"CALL\"; \"BAR\"; \"BAZ\"]) = \"BAR\"));\n  (assert ((candidate list ) = \"\"));\n  (assert ((candidate list \"SUB1 CALL SUB2\") = \"\"));\n  (assert ((candidate list \"CALL \") = \"\"));\n  (assert ((candidate list \"SUB1 SUB2 SUB3 SUB4\") = \"\"));\n  (assert ((candidate [\"FOO\"; \"BAR\"; \"BAZ\"]) = \"\"));\n  (assert ((candidate list \"SUB1\") = \"\"));\n  (assert ((candidate list \"SUB1 SUB2 SUB3\") = \"\"));\n  (assert ((candidate list \"SUB1 SUB2 CALL\") = \"\"));\n  (assert ((candidate [\"CALL\"; \"FOO\"]) = \"FOO\"));\n  (assert ((candidate list \"CALL\") = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_129353_has_QRp", "language": "ml", "prompt": "(**Euler's criterion\nx**2 = a % p -> does x exist? \nnot all a's in p have an x\n*)\nlet has_QRp (a : int) (p : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_129353_has_QRp.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = has_QRp in\n  (assert ((candidate 22 31) = false));\n  (assert ((candidate 7 7) = false));\n  (assert ((candidate 2 91) = false));\n  (assert ((candidate 1 31) = true));\n  (assert ((candidate 42 43) = false));\n  (assert ((candidate 19 31) = true));\n  (assert ((candidate 11 20) = false));\n  (assert ((candidate 4 11) = true));\n  (assert ((candidate 3 11) = true));\n  (assert ((candidate 8 11) = false));\n  (assert ((candidate 7 31) = true));\n  (assert ((candidate 15 13) = false));\n  (assert ((candidate 2 5) = false));\n  (assert ((candidate 7 5) = false));\n  (assert ((candidate 5 31) = true));\n  (assert ((candidate 12 31) = false));\n  (assert ((candidate 5 11) = true));\n  (assert ((candidate 6 31) = false));\n  (assert ((candidate 2 7) = true));\n  (assert ((candidate 5 5) = false));\n  (assert ((candidate 6 5) = true));\n  (assert ((candidate 24 31) = false));\n  (assert ((candidate 9 31) = true));\n  (assert ((candidate 0 31) = false));\n  (assert ((candidate 3 5) = false));\n  (assert ((candidate 8 5) = false));\n  (assert ((candidate 11 13) = false));\n  (assert ((candidate 25 31) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_129399_hex_to_rgb", "language": "ml", "prompt": "(**Convert a hex value to RGB\n:param value: the hex color\n:type value: string\n:returns: rgb tuple\n:rtype: tuple\n*)\nlet hex_to_rgb (value : string option) :  int * int * int option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_129399_hex_to_rgb.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = hex_to_rgb in\n  (assert ((candidate Some(\"#FFFFFF\")) = Some((255, 255, 255))));\n  (assert ((candidate Some(\"000\")) = Some((0, 0, 0))));\n  (assert ((candidate Some(\"#ff0000\")) = Some((255, 0, 0))));\n  (assert ((candidate Some(\"999999\")) = Some((153, 153, 153))));\n  (assert ((candidate Some(\"#000000\")) = Some((0, 0, 0))));\n  (assert ((candidate Some(\"112233\")) = Some((17, 34, 51))));\n  (assert ((candidate Some(None)) = Some(None)));\n  (assert ((candidate Some(\"#808080\")) = Some((128, 128, 128))));\n  (assert ((candidate Some(\"\")) = Some(None)));\n  (assert ((candidate Some(\"FFFFFF\")) = Some((255, 255, 255))));\n  (assert ((candidate Some(\"abcdef\")) = Some((171, 205, 239))));\n  (assert ((candidate Some(\"ff0000\")) = Some((255, 0, 0))));\n  (assert ((candidate Some(\"#000\")) = Some((0, 0, 0))));\n  (assert ((candidate Some(\"#123456\")) = Some((18, 52, 86))));\n  (assert ((candidate Some(\"F0F0F0\")) = Some((240, 240, 240))));\n  (assert ((candidate Some(\"#999999\")) = Some((153, 153, 153))));\n  (assert ((candidate Some(\"000000\")) = Some((0, 0, 0))));\n  (assert ((candidate Some(\"#F0F0F0\")) = Some((240, 240, 240))));\n  (assert ((candidate Some(\"FF0000\")) = Some((255, 0, 0))));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_129402_join_as_compacted_paragraphs", "language": "ml", "prompt": "(**:param paragraphs: List containing individual paragraphs; potentially with extraneous whitespace within\n:return: String with \n * separated paragraphs and no extra whitespace\n*)\nlet join_as_compacted_paragraphs (paragraphs : string list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_129402_join_as_compacted_paragraphs.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = join_as_compacted_paragraphs in\n  (assert ((candidate [\"A paragraph with a \n newline character, and a couple of\t tabs\"]) = \"A paragraph with a newline character, and a couple of tabs\"));\n  (assert ((candidate [\"I ate a\n\n\n\n\n\n\n\nball\"; \"I drank a\n\n\n\n\n\n\n\ncoffee\"]) = \"I ate a ball\nI drank a coffee\"));\n  (assert ((candidate [\"A paragraph with a\nnewline character, and a couple of\ttabs\"]) = \"A paragraph with a newline character, and a couple of tabs\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_129406_R10_yield", "language": "ml", "prompt": "(**R10 Determining the surface pressure Pmax\n(Sec 5.5.4)\n * For the maximum surface pressure with yield\n * or angle controlled tightening techniques.\n*)\nlet R10_yield (FMTab : float) (Apmin : float) (PG : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_129406_R10_yield.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = R10_yield in\n  (assert ((candidate 0.1 0.1 1.0) = 1.4));\n  (assert ((candidate 1.0 1.0 0.1) = 1.4));\n  (assert ((candidate 2.0 1.0 2.0) = 2.8));\n  (assert ((candidate 0.1 0.1 0.1) = 1.4));\n  (assert ((candidate 1.0 1.0 2.0) = 1.4));\n  (assert ((candidate 1.0 1.0 1.0) = 1.4));\n  (assert ((candidate 1.0 1.0 1.0) = 1.4));\n  (assert ((candidate 2.0 1.0 1.0) = 2.8));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_129442_solution", "language": "ml", "prompt": "(**Complete the function such that:\nGiven a list of digits LD, reverse all the digits in LD to a new list LR.\nReturn the LR and largest element in LR in a tuple such that:\n * - [123] -> ([321], 321)\n * - [-789, 10] -> ([-987, 1], 1)\n * - [11020, 3512] -> ([2011, 2153], 2153)\nConstraints:\nEliminate leading zeros.\nNote the position of the negative operator after the reversal.\n*)\nlet solution (num_list : int list) :  int list * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_129442_solution.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = solution in\n  (assert ((candidate [11020; 3512]) = ([2011; 2153], 2153)));\n  (assert ((candidate [(~789); 10]) = ([(~987); 1], 1)));\n  (assert ((candidate [123]) = ([321], 321)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_129631_levenshtein_distance", "language": "ml", "prompt": "(**Parameters:\n----------\n * w1: str\n * w2: str\nReturns:\n--------\n * int:\n * Returns Levenshtein edit distance between the two strings\n*)\nlet levenshtein_distance (w1 : string) (w2 : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_129631_levenshtein_distance.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = levenshtein_distance in\n  (assert ((candidate \"aa\" \"aa\") = 0));\n  (assert ((candidate \"hello\" \"halo\") = 2));\n  (assert ((candidate \"kitten\" \"kitt\") = 2));\n  (assert ((candidate \"a\" \"\") = 1));\n  (assert ((candidate \"\" \"\") = 0));\n  (assert ((candidate \"5678\" \"1234\") = 4));\n  (assert ((candidate \"b\" \"a\") = 1));\n  (assert ((candidate \"1234\" \"5678\") = 4));\n  (assert ((candidate \"\" \"a\") = 1));\n  (assert ((candidate \"kitten\" \"sitting\") = 3));\n  (assert ((candidate \"kitten\" \"sittin\") = 2));\n  (assert ((candidate \"cut\" \"cat\") = 1));\n  (assert ((candidate \"a\" \"b\") = 1));\n  (assert ((candidate \"kitten\" \"kit\") = 3));\n  (assert ((candidate \"dog\" \"cat\") = 3));\n  (assert ((candidate \"kitten\" \"kittten\") = 1));\n  (assert ((candidate \"kitten\" \"sitting\") = 3));\n  (assert ((candidate \"b\" \"a\") = 1));\n  (assert ((candidate \"hello\" \"hallo\") = 1));\n  (assert ((candidate \"k\" \"\") = 1));\n  (assert ((candidate \"sitting\" \"kitten\") = 3));\n  (assert ((candidate \"kitten\" \"kitte\") = 1));\n  (assert ((candidate \"cat\" \"dog\") = 3));\n  (assert ((candidate \"a\" \"b\") = 1));\n  (assert ((candidate \"cat\" \"cut\") = 1));\n  (assert ((candidate \"\" \"\") = 0));\n  (assert ((candidate \"s\" \"s\") = 0));\n  (assert ((candidate \"kitten\" \"k\") = 5));\n  (assert ((candidate \"\" \"k\") = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_130049_get_beta_skewness", "language": "ml", "prompt": "(**Compute skewness of beta distribution based on shape parameters `a` and `b`.\n*)\nlet get_beta_skewness (a : float) (b : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_130049_get_beta_skewness.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_beta_skewness in\n  (assert ((candidate 0.5 0.5) = 0.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_130400_sub", "language": "ml", "prompt": "(**Subtracts the two Polynomials, 'p1' and 'p2'\nThe arguments can be a sequence of coefficients or an instance of the Polynomial class.\n*)\nlet sub (p1 : int list) (p2 : int list) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_130400_sub.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sub in\n  (assert ((candidate [3; 4] [1; 2]) = [2; 2]));\n  (assert ((candidate [0; 0; 0; 0; 0; 0; 0] [1; 1; 1; 1; 1; 1; 1]) = [(~1); (~1); (~1); (~1); (~1); (~1); (~1)]));\n  (assert ((candidate [1; 2] [3; 4]) = [(~2); (~2)]));\n  (assert ((candidate [2] [1]) = [1]));\n  (assert ((candidate [1] []) = [1]));\n  (assert ((candidate [] [3; 2; 1]) = [(~3); (~2); (~1)]));\n  (assert ((candidate [1; 2; 3; 4] [5; 6; 7; 8]) = [(~4); (~4); (~4); (~4)]));\n  (assert ((candidate [1; 0] [0; 1]) = [1; (~1)]));\n  (assert ((candidate [1; 2; 3] [4; 5; 6]) = [(~3); (~3); (~3)]));\n  (assert ((candidate [0] [0]) = [0]));\n  (assert ((candidate [5; 6; 7; 8] [1; 2; 3; 4]) = [4; 4; 4; 4]));\n  (assert ((candidate [1] [2]) = [(~1)]));\n  (assert ((candidate [4; 5; 6] [1; 2; 3]) = [3; 3; 3]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_130569_get_command_from_state", "language": "ml", "prompt": "(**This method gets appropriate command name for the state specified. It\nreturns the command name for the specified state.\n:param state: The state for which the respective command name is required.\n*)\nlet get_command_from_state (state : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_130569_get_command_from_state.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_command_from_state in\n  (assert ((candidate \"present\") = \"vrouter-create\"));\n  (assert ((candidate \"update\") = \"vrouter-modify\"));\n  (assert ((candidate \"absent\") = \"vrouter-delete\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_13090_get_urn_from_raw_update", "language": "ml", "prompt": "(**Return the URN of a raw group update\nExample: urn:li:fs_miniProfile:<id>\nExample: urn:li:fs_updateV2:(<urn>,GROUP_FEED,EMPTY,DEFAULT,false)\n*)\nlet get_urn_from_raw_update (raw_string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_13090_get_urn_from_raw_update.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_urn_from_raw_update in\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:32423423432,MEMBER_COUNT_UPDATED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:32423423432\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:6161898594178132904,GROUP_FEED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:6161898594178132904\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:3243252353,GROUP_FEED,EMPTY,DEFAULT,false),EMPTY,EMPTY,EMPTY,false)\") = \"urn:li:fs_miniProfile:3243252353\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:1,GROUP_FEED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:1\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:1,GROUP_FEED,EMPTY,DEFAULT,false),(urn:li:fs_miniProfile:2,GROUP_FEED,EMPTY,DEFAULT,false),(urn:li:fs_miniProfile:3,GROUP_FEED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:1\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:123456789,GROUP_JOIN_REQUEST_ACCEPTED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:123456789\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:32423423432,UPCOMING_EVENT_CREATED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:32423423432\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:921474837697135657,GROUP_FEED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:921474837697135657\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(<urn>,PROMOTED,EMPTY,DEFAULT,false)\") = \"<urn>\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:1234567890123456789,GROUP_FEED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:1234567890123456789\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:123456789,GROUP_FEED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:123456789\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:1159,GROUP_FEED,EMPTY,DEFAULT,false)garbage\") = \"urn:li:fs_miniProfile:1159\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:32423423432,EVENT_ORGANIZER_CREATED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:32423423432\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:55555,GROUP_FEED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:55555\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:123456,MEMBERSHIP_UPDATED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:123456\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:123456,FEED_UPDATED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:123456\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:1,GROUP_FEED,EMPTY,DEFAULT,false),(urn:li:fs_updateV2:(urn:li:fs_miniProfile:2,GROUP_FEED,EMPTY,DEFAULT,false),GROUP_FEED,EMPTY,DEFAULT,false),(urn:li:fs_miniProfile:3,GROUP_FEED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:1\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:3243252353,GROUP_FEED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:3243252353\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(<urn>,GROUP_FEED,EMPTY,DEFAULT,false)\") = \"<urn>\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:1159,GROUP_FEED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:1159\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:32423423432,GROUP_FEED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:32423423432\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:5dc5e35e3e5e0340a5a1872e,GROUP_FEED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:5dc5e35e3e5e0340a5a1872e\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:123456789,OWNERSHIP_TRANSFER,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:123456789\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(<urn>,REMOVED,EMPTY,DEFAULT,false)\") = \"<urn>\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:55555,GROUP_FEED,EMPTY,DEFAULT,true)\") = \"urn:li:fs_miniProfile:55555\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:123456,GROUP_FEED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:123456\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(<urn>,UPDATED,EMPTY,DEFAULT,false)\") = \"<urn>\"));\n  (assert ((candidate \"urn:li:fs_miniProfile:(urn:li:fs_miniProfile:1234567890123456789,urn:li:organization:1234567890123456789)\") = \"urn:li:fs_miniProfile:1234567890123456789\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(<urn>,GROUP_FEED,EMPTY,DEFAULT,false)\") = \"<urn>\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(<urn>,GROUP_FEED,EMPTY,DEFAULT,true)\") = \"<urn>\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:123456789,MEMBERSHIP_CHANGE,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:123456789\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(<urn>,UNSUBSCRIBED,EMPTY,DEFAULT,false)\") = \"<urn>\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:d52191c1-9b2c-45a9-a721-2a3317a8047c,GROUP_FEED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:d52191c1-9b2c-45a9-a721-2a3317a8047c\"));\n  (assert ((candidate \"urn:li:fs_updateV2:(urn:li:fs_miniProfile:123456,POSTS_UPDATED,EMPTY,DEFAULT,false)\") = \"urn:li:fs_miniProfile:123456\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_131292_GetEnvCall", "language": "ml", "prompt": "(**Maps the types availabe via env->Call__Method.\n*)\nlet GetEnvCall (is_constructor : bool) (is_static : bool) (return_type : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_131292_GetEnvCall.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = GetEnvCall in\n  (assert ((candidate false false \"void\") = \"CallVoidMethod\"));\n  (assert ((candidate false false \"Object\") = \"CallObjectMethod\"));\n  (assert ((candidate true false \"boolean\") = \"NewObject\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_132314_get_full_policy_path", "language": "ml", "prompt": "(**Resource string will output strings like the following examples.\nCase 1:\n * Input: arn:aws:iam::aws:policy/aws-service-role/AmazonGuardDutyServiceRolePolicy\nOutput:\n * aws-service-role/AmazonGuardDutyServiceRolePolicy\nCase 2:\n * Input: arn:aws:iam::123456789012:role/ExampleRole\n * Output: ExampleRole\n:param arn:\n:return:\n*)\nlet get_full_policy_path (arn : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_132314_get_full_policy_path.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_full_policy_path in\n  (assert ((candidate \"arn:aws:iam::aws:policy/aws-service-role/AmazonGuardDutyServiceRolePolicy\") = \"aws-service-role/AmazonGuardDutyServiceRolePolicy\"));\n  (assert ((candidate \"arn:aws:iam::aws:policy/aws-service-role/AmazonGuardDutyServiceRolePolicy\") = \"aws-service-role/AmazonGuardDutyServiceRolePolicy\"));\n  (assert ((candidate \"arn:aws:iam::123456789012:role/ExampleRole\") = \"ExampleRole\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_132458_digitToInt", "language": "ml", "prompt": "(**digitToInt :: str -> int\nConvert a single digit Char to the corresponding Int. This function fails\nunless its argument satisfies isHexDigit, but recognises both upper and\nlower-case hexadecimal digits (i.e. '0'..'9', 'a'..'f', 'A'..'F').\n*)\nlet digitToInt (s : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_132458_digitToInt.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = digitToInt in\n  (assert ((candidate \"A\") = 10));\n  (assert ((candidate \"7\") = 7));\n  (assert ((candidate \"D\") = 13));\n  (assert ((candidate \"6\") = 6));\n  (assert ((candidate \"2\") = 2));\n  (assert ((candidate \"1\") = 1));\n  (assert ((candidate \"B\") = 11));\n  (assert ((candidate \"f\") = 15));\n  (assert ((candidate \"d\") = 13));\n  (assert ((candidate \"9\") = 9));\n  (assert ((candidate \"4\") = 4));\n  (assert ((candidate \"F\") = 15));\n  (assert ((candidate \"C\") = 12));\n  (assert ((candidate \"c\") = 12));\n  (assert ((candidate \"5\") = 5));\n  (assert ((candidate \"f\") = 15));\n  (assert ((candidate \"f\") = 15));\n  (assert ((candidate \"1\") = 1));\n  (assert ((candidate \"a\") = 10));\n  (assert ((candidate \"3\") = 3));\n  (assert ((candidate \"A\") = 10));\n  (assert ((candidate \"a\") = 10));\n  (assert ((candidate \"e\") = 14));\n  (assert ((candidate \"0\") = 0));\n  (assert ((candidate \"f\") = int \"f\" 16));\n  (assert ((candidate \"1\") = 1));\n  (assert ((candidate \"b\") = 11));\n  (assert ((candidate \"5\") = 5));\n  (assert ((candidate \"1\") = int \"1\" 10));\n  (assert ((candidate \"8\") = 8));\n  (assert ((candidate \"E\") = 14));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_132637_drop_command", "language": "ml", "prompt": "(**Given a message text, drops the command prefix from the string.\n*)\nlet drop_command (message : string) (command : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_132637_drop_command.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = drop_command in\n  (assert ((candidate \"!command parameter1 parameter2 parameter3\" \"!COMMAND\") = \"parameter1 parameter2 parameter3\"));\n  (assert ((candidate \"!command parameter1 parameter2 parameter3\" \"!command\") = \"parameter1 parameter2 parameter3\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_132755_appartient_au_triangle", "language": "ml", "prompt": "(**verifie si le point P(x;y) appartient au triangle ABC\n*)\nlet appartient_au_triangle (X : int list) (Y : int list) (x : int) (y : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_132755_appartient_au_triangle.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = appartient_au_triangle in\n  (assert ((candidate [10; 10; 10] [10; 10; 10] 10 10) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_133001_dequebecify", "language": "ml", "prompt": "(**Normalizes text to pure english\nFrom <http://stackoverflow.com/questions/517923>\nThis function only transliterates French diacritics.\nIf you need to separate Quebec from Canada, try:\nroc,qc = canada.sovereignty_referendum('quebec')\n*)\nlet dequebecify (input : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_133001_dequebecify.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = dequebecify in\n  (assert ((candidate \"C'est pas faux\") = \"C'est pas faux\"));\n  (assert ((candidate \"Je suis une phrase.\") = \"Je suis une phrase.\"));\n  (assert ((candidate \"\u00c9vang\u00e9liste fran\u00e7ais\") = \"Evangeliste francais\"));\n  (assert ((candidate \"test\") = \"test\"));\n  (assert ((candidate \"\u00c9quipe fran\u00e7aise\") = \"Equipe francaise\"));\n  (assert ((candidate \"Mais comment?\") = \"Mais comment?\"));\n  (assert ((candidate \"Deja vu\") = \"Deja vu\"));\n  (assert ((candidate \"L'\u00e9cole\") = \"L'ecole\"));\n  (assert ((candidate \"\u00c7a va?\") = \"Ca va?\"));\n  (assert ((candidate \"Et ca?\") = \"Et ca?\"));\n  (assert ((candidate \"Le \u00e9v\u00eaque\") = \"Le eveque\"));\n  (assert ((candidate \"R\u00e9sidence de la Madeleine\") = \"Residence de la Madeleine\"));\n  (assert ((candidate \"M\u00e8re de la Madeleine\") = \"Mere de la Madeleine\"));\n  (assert ((candidate \"Bonjour\") = \"Bonjour\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_133468_filesafe", "language": "ml", "prompt": "(**Convert a string to something safe for filenames.\n*)\nlet filesafe (str_ : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_133468_filesafe.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = filesafe in\n  (assert ((candidate \"This is a normal filename\") = \"This is a normal filename\"));\n  (assert ((candidate \"A very normal filename\") = \"A very normal filename\"));\n  (assert ((candidate \"True.0\") = \"True.0\"));\n  (assert ((candidate \"True\") = \"True\"));\n  (assert ((candidate \".\") = \".\"));\n  (assert ((candidate \"..\") = \"..\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_135211_transform_basis_name", "language": "ml", "prompt": "(**Transforms the name of a basis set to an internal representation\nThis makes comparison of basis set names easier by, for example,\nconverting the name to all lower case.\n*)\nlet transform_basis_name (name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_135211_transform_basis_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = transform_basis_name in\n  (assert ((candidate \"foo_sl_bar\") = \"foo_sl_bar\"));\n  (assert ((candidate \"foo123\") = \"foo123\"));\n  (assert ((candidate \"foo/bar/baz\") = \"foo_sl_bar_sl_baz\"));\n  (assert ((candidate \"A\") = \"a\"));\n  (assert ((candidate \"foo*BAR\") = \"foo_st_bar\"));\n  (assert ((candidate \"foo*bar\") = \"foo_st_bar\"));\n  (assert ((candidate \"foo_st_bar\") = \"foo_st_bar\"));\n  (assert ((candidate \"a\") = \"a\"));\n  (assert ((candidate \"FOO\") = \"foo\"));\n  (assert ((candidate \"foo_sl_BAR\") = \"foo_sl_bar\"));\n  (assert ((candidate \"foo_st_BAR\") = \"foo_st_bar\"));\n  (assert ((candidate \"FOO123\") = \"foo123\"));\n  (assert ((candidate \"foo/BAR\") = \"foo_sl_bar\"));\n  (assert ((candidate \"foo*bar*baz\") = \"foo_st_bar_st_baz\"));\n  (assert ((candidate \"foo/bar\") = \"foo_sl_bar\"));\n  (assert ((candidate \"foo\") = \"foo\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_135424_people_in_rec_area", "language": "ml", "prompt": "(**This function's job is to tell us how many people can fit in a rectangular area. We model people as equally sized circles, with the distance between the center of two circles being the \"social distance\" between them. Our function takes the lengths of the rectangle and the distance between the center of two adjacent circles as inputs.\nThe circles are laid out in a rectangular grid within the rectangular area. This way, the lengths of the sides of the rectange can be given by L1=n*2r and L2 = m*2r where n and m are the number of circles and r is the radius of each circle. We also let social_d = 2r, the distane between the center of two circles.\n*)\nlet people_in_rec_area (length_1 : int) (length_2 : int) (social_d : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_135424_people_in_rec_area.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = people_in_rec_area in\n  (assert ((candidate 1 1 1) = 1));\n  (assert ((candidate 1 4 1) = 4));\n  (assert ((candidate 20 20 20) = 1));\n  (assert ((candidate 5 10 1) = 50));\n  (assert ((candidate 1 20 1) = 20));\n  (assert ((candidate 1 2 1) = 2));\n  (assert ((candidate 1 6 1) = 6));\n  (assert ((candidate 10 10 10) = 1));\n  (assert ((candidate 5 5 1) = 25));\n  (assert ((candidate 1 1 1) = 1));\n  (assert ((candidate 1 5 1) = 5));\n  (assert ((candidate 1 3 1) = 3));\n  (assert ((candidate 5 5 3) = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_13659__split_left", "language": "ml", "prompt": "(**Split a string by a delimiter which can be escaped by \\\n*)\nlet _split_left (val : string) (sep : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_13659__split_left.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _split_left in\n  (assert ((candidate \"::foo:\" \":\") = [\"\"; \"\"; \"foo\"; \"\"]));\n  (assert ((candidate \"foo\\\" \",\") = [\"foo\\\"]));\n  (assert ((candidate \"foo\" \",\") = [\"foo\"]));\n  (assert ((candidate \"foo:bar\" \":\") = [\"foo\"; \"bar\"]));\n  (assert ((candidate \":::foo:\" \":\") = [\"\"; \"\"; \"\"; \"foo\"; \"\"]));\n  (assert ((candidate \":foo:\" \":\") = [\"\"; \"foo\"; \"\"]));\n  (assert ((candidate \"foo\\x\" \"x\\y\") = [\"foo\\x\"]));\n  (assert ((candidate \"foo\\x\" \"\\x\\y\") = [\"foo\\x\"]));\n  (assert ((candidate \"a,b,c,\" \",\") = [\"a\"; \"b\"; \"c\"; \"\"]));\n  (assert ((candidate \"foo,bar\" \",,\") = [\"foo,bar\"]));\n  (assert ((candidate \"foo\" \"x\") = [\"foo\"]));\n  (assert ((candidate \"a,b,c\" \",\") = [\"a\"; \"b\"; \"c\"]));\n  (assert ((candidate \"foo:\" \":\") = [\"foo\"; \"\"]));\n  (assert ((candidate \"foo\" \":\") = [\"foo\"]));\n  (assert ((candidate \"foo\" \"\\x\") = [\"foo\"]));\n  (assert ((candidate \"foo,bar\" \",\") = [\"foo\"; \"bar\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_136605_is_tissue_compatible", "language": "ml", "prompt": "(**Modeling actual  compatibility is complex, and depends on\nproperties of different HLA markers and various other complications.\nInstead of dealing with the medical complexities, we use a simple \nmodel that produces a uniformly-distributed value that is dependent\non the two inputs, and outputs a discretized probability.\nIt's not important to understand the following code. But you should \ncall this function with the receiver's PRA-type, receiver's ID, \nand the donor's  ID to check if their tissues are compatible or not.\nExample usage: is_tissue_compatible('Low', 4474, 3587)\n*)\nlet is_tissue_compatible (recv_pra : string) (recv_id : int) (don_id : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_136605_is_tissue_compatible.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_tissue_compatible in\n  (assert ((candidate \"High\" 4474 3587) = false));\n  (assert ((candidate \"Medium\" 4474 3587) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_136714_blasius", "language": "ml", "prompt": "(**Calculate friction coefficient according to Blasius.\nParameters\n----------\nre : float\n * Reynolds number.\nReturns\n-------\ndarcy_friction_factor : float\n * Darcy friction factor.\n*)\nlet blasius (re : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_136714_blasius.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = blasius in\n  (assert ((candidate 1.0) = 0.3164));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_136879_clamp", "language": "ml", "prompt": "(**Clam n in [MIN, MAX[\n*)\nlet clamp (MIN : int) (n : int) (MAX : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_136879_clamp.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = clamp in\n  (assert ((candidate 0 5 10) = 5));\n  (assert ((candidate 0 2 2) = 1));\n  (assert ((candidate 3 3 6) = 3));\n  (assert ((candidate 3 5 6) = 5));\n  (assert ((candidate 3 4 6) = 4));\n  (assert ((candidate 0 (~2) 2) = 0));\n  (assert ((candidate 2 3 4) = 3));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_137389_unit_form", "language": "ml", "prompt": "(**Return generated quadratic form with the given discriminant.\n*)\nlet unit_form (disc : int) :  int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_137389_unit_form.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = unit_form in\n  (assert ((candidate 0) = (1, 0, 0)));\n  (assert ((candidate 1) = (1, 1, 0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_13746_rotation_cs", "language": "ml", "prompt": "(**For numpy arrays X and Y returns the numpy arrays of Xrot and Yrot\nfor specified rotation angle cosine and sine values.\n*)\nlet rotation_cs (X : int) (Y : int) (c : int) (s : int) :  int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_13746_rotation_cs.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = rotation_cs in\n  (assert ((candidate 0 0 1 0) = (0, 0)));\n  (assert ((candidate 0 0 0 1) = (0, 0)));\n  (assert ((candidate 0 0 0 0) = (0, 0)));\n  (assert ((candidate 1 0 0 (~1)) = (0, (~1))));\n  (assert ((candidate 1 1 0 1) = ((~1), 1)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_13749_get_parent_technique_id", "language": "ml", "prompt": "(**Given a sub-technique id, return parent\n*)\nlet get_parent_technique_id (sub_tid : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_13749_get_parent_technique_id.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_parent_technique_id in\n  (assert ((candidate \"T1001.001\") = \"T1001\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_137905_parse_function_path", "language": "ml", "prompt": "(**Util to parse path to functions.\n*)\nlet parse_function_path (function_path : string) :  string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_137905_parse_function_path.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_function_path in\n  (assert ((candidate \"a_module.a_function.another_function\") = (\"a_module.a_function\", \"another_function\")));\n  (assert ((candidate \"a_module.a_function\") = (\"a_module\", \"a_function\")));\n  (assert ((candidate \"test.func\") = (\"test\", \"func\")));\n  (assert ((candidate \"test.func.func2\") = (\"test.func\", \"func2\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_139038_prazen_kvadrat_n", "language": "ml", "prompt": "(**vrni string, ki bo narisal prazen kvadrat v velikost n_vrstic\n*)\nlet prazen_kvadrat_n (n_vrstic : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_139038_prazen_kvadrat_n.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = prazen_kvadrat_n in\n  (assert ((candidate 0) = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_140092_parse_addr", "language": "ml", "prompt": "(**Parse the --liveserver argument into a host/IP address and port range\n*)\nlet parse_addr (specified_address : string) :  string * int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_140092_parse_addr.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_addr in\n  (assert ((candidate \"127.0.0.1:8000-8010\") = (\"127.0.0.1\", [8000; 8001; 8002; 8003; 8004; 8005; 8006; 8007; 8008; 8009; 8010])));\n  (assert ((candidate \"127.0.0.1:8000\") = (\"127.0.0.1\", [8000])));\n  (assert ((candidate \"127.0.0.1:8000-8010,8080\") = (\"127.0.0.1\", [8000; 8001; 8002; 8003; 8004; 8005; 8006; 8007; 8008; 8009; 8010; 8080])));\n  (assert ((candidate \"127.0.0.1:8000,8001\") = (\"127.0.0.1\", [8000; 8001])));\n  (assert ((candidate \"localhost:8000,8001,8003-8010\") = (\"localhost\", [8000; 8001; 8003; 8004; 8005; 8006; 8007; 8008; 8009; 8010])));\n  (assert ((candidate \"127.0.0.1:8000,8001,8002-8005\") = (\"127.0.0.1\", [8000; 8001; 8002; 8003; 8004; 8005])));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_140262_DNAtoRNA", "language": "ml", "prompt": "(**dna_to_rna == PEP8 (forced camelCase by CodeWars)\n*)\nlet DNAtoRNA (dna : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_140262_DNAtoRNA.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = DNAtoRNA in\n  (assert ((candidate candidate \"ACGT\") = \"ACGU\"));\n  (assert ((candidate \"GCAT\") = \"GCAU\"));\n  (assert ((candidate \"TTTT\") = \"UUUU\"));\n  (assert ((candidate \"GATGGAACTTGACTACGTAAATT\") = \"GAUGGAACUUGACUACGUAAAUU\"));\n  (assert ((candidate \"GCAT\") = \"GCAU\"));\n  (assert ((candidate \"GCAT\") = \"GCAU\"));\n  (assert ((candidate \"GACCGCCGCC\") = \"GACCGCCGCC\"));\n  (assert ((candidate \"TTTT\") = \"UUUU\"));\n  (assert ((candidate \"GACCGCCGCC\") = \"GACCGCCGCC\"));\n  (assert ((candidate \"TTTT\") = \"UUUU\"));\n  (assert ((candidate \"ACGT\") = \"ACGU\"));\n  (assert ((candidate \"TTTT\") = \"UUUU\"));\n  (assert ((candidate \"GACCGCCGCC\") = \"GACCGCCGCC\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_14050_box_sizing", "language": "ml", "prompt": "(**Validation for the ``box-sizing`` property from css3-ui\n*)\nlet box_sizing (keyword : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_14050_box_sizing.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = box_sizing in\n  (assert ((candidate \"content-box\") = true));\n  (assert ((candidate \"foo\") = false));\n  (assert ((candidate \"padding-box\") = true));\n  (assert ((candidate \"border-box\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_140877_parse_photo_link", "language": "ml", "prompt": "(**Extracts the base URL (URL without query parameters) and the photo name from a Onedrive photo URL\n:param photo_url: photo URL\n:return: base URL and photo name\n*)\nlet parse_photo_link (photo_url : string) :  string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_140877_parse_photo_link.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_photo_link in\n  (assert ((candidate \"https://graph.microsoft.com/v1.0/me/drive/items/root/children/F22222222222222222222222222222222\") = (\"https://graph.microsoft.com/v1.0/me/drive/items/root/children/F22222222222222222222222222222222\", \"F22222222222222222222222222222222\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_142183_is_parenthetical", "language": "ml", "prompt": "(**(str) -> bool\nReturns True if s starts with '(' and ends with ')'\n*)\nlet is_parenthetical (s : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_142183_is_parenthetical.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_parenthetical in\n  (assert ((candidate \"This string is not parenthetical (()())())\") = false));\n  (assert ((candidate \"(abc(def)(ghi)jkl)\") = true));\n  (assert ((candidate \"\") = false));\n  (assert ((candidate \")\") = false));\n  (assert ((candidate \"This string is not parenthetical ()()\") = false));\n  (assert ((candidate \"this is not a test(\") = false));\n  (assert ((candidate \"(abc(def)ghi)\") = true));\n  (assert ((candidate \"(abc)\") = true));\n  (assert ((candidate \"This string is not parenthetical\") = false));\n  (assert ((candidate \"(this is a test)\") = true));\n  (assert ((candidate \"This string is not parenthetical (()\") = false));\n  (assert ((candidate \"this is not a test)\") = false));\n  (assert ((candidate \"This string is not parenthetical (()())(\") = false));\n  (assert ((candidate \"(\") = false));\n  (assert ((candidate \"((abc)def)ghi\") = false));\n  (assert ((candidate \"\") = false));\n  (assert ((candidate \"(abc)def(ghi)jkl\") = false));\n  (assert ((candidate \"()\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_142478_construct_vocab", "language": "ml", "prompt": "(**Combines words from two sentences into a single\ndictionary\nInput: words1 - List of strings\n * words2 - List of strings\nOutput: vocab - dictionary where key is word,\n * value is weight of word\n*)\nlet construct_vocab (words1 : string list) (words2 : string list) : (string, int) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_142478_construct_vocab.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = construct_vocab in\n  (assert ((candidate [\"orange\"; \"banana\"; \"apple\"] [\"orange\"]) = [(\"orange\", 1); (\"banana\", 1); (\"apple\", 1)]));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"] [\"d\"; \"e\"; \"f\"]) = [(\"a\", 1); (\"b\", 1); (\"c\", 1); (\"d\", 1); (\"e\", 1); (\"f\", 1)]));\n  (assert ((candidate [\"orange\"; \"banana\"; \"apple\"] []) = [(\"orange\", 1); (\"banana\", 1); (\"apple\", 1)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_142835_has_divider_smaller_than", "language": "ml", "prompt": "(**Get True if n has a divided smaller than i\n:param n: number\n:param i: number\n:return: boolean\n*)\nlet has_divider_smaller_than (n : int) (i : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_142835_has_divider_smaller_than.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = has_divider_smaller_than in\n  (assert ((candidate 234 22) = true));\n  (assert ((candidate 7 5) = false));\n  (assert ((candidate 7 3) = false));\n  (assert ((candidate 10 4) = true));\n  (assert ((candidate 6 5) = true));\n  (assert ((candidate 234 1000) = true));\n  (assert ((candidate 6 3) = true));\n  (assert ((candidate 9 5) = true));\n  (assert ((candidate 1 1) = false));\n  (assert ((candidate 10 5) = true));\n  (assert ((candidate (~10) 5) = true));\n  (assert ((candidate 3 3) = true));\n  (assert ((candidate 234 12) = true));\n  (assert ((candidate 1 2) = false));\n  (assert ((candidate 3 1) = false));\n  (assert ((candidate 2 1) = false));\n  (assert ((candidate 6 2) = true));\n  (assert ((candidate 5 1) = false));\n  (assert ((candidate 13 2) = false));\n  (assert ((candidate (~9) 5) = true));\n  (assert ((candidate 7 1) = false));\n  (assert ((candidate 6 4) = true));\n  (assert ((candidate (~1) 5) = false));\n  (assert ((candidate 6 1) = false));\n  (assert ((candidate 200 5) = true));\n  (assert ((candidate 4 2) = true));\n  (assert ((candidate 12 2) = true));\n  (assert ((candidate 1 5) = false));\n  (assert ((candidate 4 1) = false));\n  (assert ((candidate (~7) 5) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_143409_get_chunk_label", "language": "ml", "prompt": "(**Returns a readable elapsed time.\n*)\nlet get_chunk_label (tot_minutes : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_143409_get_chunk_label.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_chunk_label in\n  (assert ((candidate 122) = \"02h:02m\"));\n  (assert ((candidate 12) = \"00h:12m\"));\n  (assert ((candidate 65) = \"01h:05m\"));\n  (assert ((candidate 135) = \"02h:15m\"));\n  (assert ((candidate 61) = \"01h:01m\"));\n  (assert ((candidate 98) = \"01h:38m\"));\n  (assert ((candidate 3599) = \"59h:59m\"));\n  (assert ((candidate 132) = \"02h:12m\"));\n  (assert ((candidate 1) = \"00h:01m\"));\n  (assert ((candidate 0) = \"00h:00m\"));\n  (assert ((candidate 60) = \"01h:00m\"));\n  (assert ((candidate 2) = \"00h:02m\"));\n  (assert ((candidate 1220) = \"20h:20m\"));\n  (assert ((candidate 20) = \"00h:20m\"));\n  (assert ((candidate 18) = \"00h:18m\"));\n  (assert ((candidate 120) = \"02h:00m\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_1437_check_host", "language": "ml", "prompt": "(**Helper function to get the hostname in desired format\n*)\nlet check_host (host : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_1437_check_host.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = check_host in\n  (assert ((candidate candidate \"https://example.com\") = \"https://example.com\"));\n  (assert ((candidate \"example.com\") = \"http://example.com\"));\n  (assert ((candidate \"https://example.com/\") = \"https://example.com\"));\n  (assert ((candidate \"codecademy.com\") = \"http://codecademy.com\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_144168_even", "language": "ml", "prompt": "(**returns true if even number, false if odd\n*)\nlet even (x : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_144168_even.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = even in\n  (assert ((candidate 2) = true));\n  (assert ((candidate 0) = true));\n  (assert ((candidate 100) = true));\n  (assert ((candidate 3) = false));\n  (assert ((candidate (~2)) = true));\n  (assert ((candidate 42) = true));\n  (assert ((candidate 15) = false));\n  (assert ((candidate 2017) = false));\n  (assert ((candidate 1) = false));\n  (assert ((candidate (~1)) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_144200_curate_list", "language": "ml", "prompt": "(**:param input_list:\n:type input_list:\n:param words_list:\n:type words_list:\n:return:\n:rtype:\n*)\nlet curate_list (input_list : string list) (words_list : string list) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_144200_curate_list.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = curate_list in\n  (assert ((candidate [] []) = []));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"; \"d\"; \"e\"; \"f\"; \"g\"] [\"a\"; \"b\"; \"c\"; \"d\"; \"e\"]) = [\"a\"; \"b\"; \"c\"; \"d\"; \"e\"]));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"; \"d\"; \"e\"] [\"a\"; \"b\"; \"c\"; \"d\"; \"e\"; \"f\"; \"g\"]) = [\"a\"; \"b\"; \"c\"; \"d\"; \"e\"]));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"; \"d\"; \"e\"] [\"a\"; \"b\"; \"c\"; \"d\"; \"e\"]) = [\"a\"; \"b\"; \"c\"; \"d\"; \"e\"]));\n  (assert ((candidate [] [\"a\"; \"b\"; \"c\"]) = []));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"] []) = []));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"; \"d\"; \"e\"; \"f\"; \"g\"] [\"h\"; \"i\"; \"j\"; \"k\"; \"l\"; \"m\"; \"n\"]) = []));\n  (assert ((candidate [\"the\"; \"quick\"; \"brown\"; \"fox\"; \"jumped\"; \"over\"; \"the\"; \"lazy\"; \"dog\"] [\"the\"; \"quick\"; \"brown\"; \"fox\"; \"jumped\"; \"the\"; \"lazy\"; \"dog\"]) = [\"the\"; \"quick\"; \"brown\"; \"fox\"; \"jumped\"; \"the\"; \"lazy\"; \"dog\"]));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"; \"d\"; \"e\"; \"f\"; \"g\"] []) = []));\n  (assert ((candidate [\"the\"; \"quick\"; \"brown\"; \"fox\"; \"jumped\"; \"over\"; \"the\"; \"lazy\"; \"dog\"] [\"the\"; \"quick\"; \"brown\"; \"fox\"; \"over\"; \"the\"; \"lazy\"; \"dog\"]) = [\"the\"; \"quick\"; \"brown\"; \"fox\"; \"over\"; \"the\"; \"lazy\"; \"dog\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_144223_line_id_2_txt", "language": "ml", "prompt": "(**Convert line id (integer) to string nnnn\n:return: line_id_txt -> <string> ID de la linia introduit en format text\n*)\nlet line_id_2_txt (line_id : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_144223_line_id_2_txt.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = line_id_2_txt in\n  (assert ((candidate 3) = \"0003\"));\n  (assert ((candidate 19) = \"0019\"));\n  (assert ((candidate 999) = \"0999\"));\n  (assert ((candidate 24) = \"0024\"));\n  (assert ((candidate 9999) = \"9999\"));\n  (assert ((candidate 17) = \"0017\"));\n  (assert ((candidate 25) = \"0025\"));\n  (assert ((candidate 255) = \"0255\"));\n  (assert ((candidate 0) = \"0000\"));\n  (assert ((candidate 9) = \"0009\"));\n  (assert ((candidate 6) = \"0006\"));\n  (assert ((candidate 1) = \"0001\"));\n  (assert ((candidate 12) = \"0012\"));\n  (assert ((candidate 16) = \"0016\"));\n  (assert ((candidate 7) = \"0007\"));\n  (assert ((candidate 12) = \"0012\"));\n  (assert ((candidate 10) = \"0010\"));\n  (assert ((candidate 18) = \"0018\"));\n  (assert ((candidate 5000) = \"5000\"));\n  (assert ((candidate 15) = \"0015\"));\n  (assert ((candidate 2) = \"0002\"));\n  (assert ((candidate 8) = \"0008\"));\n  (assert ((candidate 1) = \"0001\"));\n  (assert ((candidate 99) = \"0099\"));\n  (assert ((candidate 1000) = \"1000\"));\n  (assert ((candidate 13) = \"0013\"));\n  (assert ((candidate 20) = \"0020\"));\n  (assert ((candidate 240) = \"0240\"));\n  (assert ((candidate 5) = \"0005\"));\n  (assert ((candidate 0) = \"0000\"));\n  (assert ((candidate 100) = \"0100\"));\n  (assert ((candidate 4) = \"0004\"));\n  (assert ((candidate 14) = \"0014\"));\n  (assert ((candidate 99999) = \"99999\"));\n  (assert ((candidate 12345) = \"12345\"));\n  (assert ((candidate 11) = \"0011\"));\n  (assert ((candidate 111) = \"0111\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_144251_keyword_filter", "language": "ml", "prompt": "(**return true if url contains all keywords,\nreturn false otherwise\n*)\nlet keyword_filter (url : string) (keywords : string list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_144251_keyword_filter.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = keyword_filter in\n  (assert ((candidate \"http://foo.com/bar?a=1&b=2\" [\"a\"; \"b\"]) = true));\n  (assert ((candidate \"http://foo.com/bar?a=1&b=2\" [\"b\"]) = true));\n  (assert ((candidate \"http://foo.com/bar?a=1&b=2\" [\"a\"; \"b\"; \"c\"; \"d\"]) = false));\n  (assert ((candidate \"http://foo.com/bar?a=1&b=2\" [\"a\"]) = true));\n  (assert ((candidate \"http://foo.com/bar?a=1&b=2\" []) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_144645__remove_prefix", "language": "ml", "prompt": "(**Removes prefixed from absolute etcd paths\n*)\nlet _remove_prefix (path : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_144645__remove_prefix.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _remove_prefix in\n  (assert ((candidate \"/a/b/c\") = \"c\"));\n  (assert ((candidate \"/a/b\") = \"b\"));\n  (assert ((candidate \"/a\") = \"a\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"/foo/bar\") = \"bar\"));\n  (assert ((candidate \"/\") = \"\"));\n  (assert ((candidate \"/foo\") = \"foo\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_144790_iscsi_portal_with_port", "language": "ml", "prompt": "(**Add default port 3260 to iSCSI portal\n:param address: iSCSI portal without port\n:return: iSCSI portal with default port 3260\n*)\nlet iscsi_portal_with_port (address : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_144790_iscsi_portal_with_port.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = iscsi_portal_with_port in\n  (assert ((candidate \"10.1.2.3\") = \"10.1.2.3:3260\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_14508_betweenness_index", "language": "ml", "prompt": "(**find the index associated to a point in the static graph. See betweenness_centrality.\n*)\nlet betweenness_index (n_nodes : int) (n_times : int) (node_index : int) (time_index : int) (layer_index : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_14508_betweenness_index.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = betweenness_index in\n  (assert ((candidate 1 1 0 0 0) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_145532_middle_me", "language": "ml", "prompt": "(**This function takes a key of X and place it in the middle of Y repeated N times.\n*)\nlet middle_me (N : int) (X : string) (Y : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_145532_middle_me.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = middle_me in\n  (assert ((candidate 1 \"abc\" \"xyz\") = \"abc\"));\n  (assert ((candidate 2 \"\" \"abc\") = \"abcabc\"));\n  (assert ((candidate 2 \"abc\" \"z\") = \"zabcz\"));\n  (assert ((candidate 2 \"\" \"\") = \"\"));\n  (assert ((candidate 2 \"\" \"def\") = \"defdef\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_145712_valid_ip", "language": "ml", "prompt": "(**Check if an IP address is valid.\n*)\nlet valid_ip (query : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_145712_valid_ip.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = valid_ip in\n  (assert ((candidate \"127.0.0.1:8080\") = false));\n  (assert ((candidate \"127.0.0.1\") = true));\n  (assert ((candidate \"192.168.1.1.1.1\") = false));\n  (assert ((candidate \"192.168.1.1.1.1.1.1\") = false));\n  (assert ((candidate \"192.168.255.255\") = true));\n  (assert ((candidate \"0.0.0.0.0\") = false));\n  (assert ((candidate \"192.168.1.1\") = true));\n  (assert ((candidate \"255.255.255.255\") = true));\n  (assert ((candidate \"0.0.0.0\") = true));\n  (assert ((candidate \"255.255.255.255\") = true));\n  (assert ((candidate \"1.2.3.4\") = true));\n  (assert ((candidate \"\") = false));\n  (assert ((candidate \"192.168.3.11\") = true));\n  (assert ((candidate \"256.127.0.1\") = false));\n  (assert ((candidate \"abc\") = false));\n  (assert ((candidate \"127.0.0.256\") = false));\n  (assert ((candidate \"abc\") = false));\n  (assert ((candidate \"192.168.1.255\") = true));\n  (assert ((candidate \"127.0.256.1\") = false));\n  (assert ((candidate \"192.168.1.1.1.1.1\") = false));\n  (assert ((candidate \"127.0.0.300\") = false));\n  (assert ((candidate \"256.0.0.0\") = false));\n  (assert ((candidate \"192.168.1.1.1\") = false));\n  (assert ((candidate \"1.2.3.4.5\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_145929_containsExploit", "language": "ml", "prompt": "(**Returns whether or not the given str contains evidence that it is an open redirect exploit\n*)\nlet containsExploit (text : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_145929_containsExploit.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = containsExploit in\n  (assert ((candidate \"hi there! http://localhost/\") = true));\n  (assert ((candidate \"hi there! http://[::1]\") = true));\n  (assert ((candidate \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc euismod purus sit amet ante facilisis, quis rhoncus urna tempor. In hac habitasse platea dictumst. Aenean ullamcorper, diam in ornare posuere, eros odio tempus purus, vel vehicula sem dolor ut lorem. Vivamus a tincidunt turpis. Etiam eu dui vel odio commodo fringilla. Vestibulum ultrices, neque in facilisis pellentesque, nunc nibh interdum tortor, at venenatis risus nulla nec libero. Quisque viverra sapien vel lectus ultricies, quis mollis nisl fermentum. Morbi semper auctor mi, id hendrerit nunc. Mauris mattis eros non magna faucibus, id tincidunt diam interdum. Quisque congue lorem at arcu rhoncus, a gravida urna aliquet. Nunc vel diam lacinia, ullamcorper felis ut, convallis magna.\") = false));\n  (assert ((candidate \"hi there! https://[::1]/foo\") = true));\n  (assert ((candidate \"hi there! https://[::1]:8000/\") = true));\n  (assert ((candidate \"hello\") = false));\n  (assert ((candidate \"hi there! http://[::1]:8000/\") = true));\n  (assert ((candidate \"hi there! http://[::1]/foo\") = true));\n  (assert ((candidate \"hi there! http://example.com/test/123456?abc=1\") = true));\n  (assert ((candidate \"javascript:alert(1)\") = true));\n  (assert ((candidate \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer vel dolor ac diam bibendum placerat non non erat. Praesent non massa sit amet erat dapibus posuere. Sed quis orci et nisl dapibus iaculis.\") = false));\n  (assert ((candidate \"http://example.com\") = true));\n  (assert ((candidate \"https://example.com\") = true));\n  (assert ((candidate \"hi there! https://[::1]\") = true));\n  (assert ((candidate \"hi there! http://127.0.0.1/\") = true));\n  (assert ((candidate \"\") = false));\n  (assert ((candidate \"hi there! https://[::1]/\") = true));\n  (assert ((candidate \"hi there! http://example.com\") = true));\n  (assert ((candidate \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\") = false));\n  (assert ((candidate \"hi there! javascript:alert(1)\") = true));\n  (assert ((candidate \"hi there! http://[::1]:8000\") = true));\n  (assert ((candidate \"hi there\") = false));\n  (assert ((candidate \"hi there! https://example.com/test/123456\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_146824_is_fq", "language": "ml", "prompt": "(**Return True if the supplied 'name' is fully-qualified, False otherwise.\nUsage examples:\n * >>> is_fq('master')\n * False\n * >>> is_fq('refs/heads/master')\n * True\n:name: string name of the ref to test\n:returns: bool\n*)\nlet is_fq (name : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_146824_is_fq.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_fq in\n  (assert ((candidate \"master\") = false));\n  (assert ((candidate \"master\") = false));\n  (assert ((candidate \"refs/heads/master\") = true));\n  (assert ((candidate \"refs/heads/master\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_147099_style_to_dict", "language": "ml", "prompt": "(**Parses an HTML tag style attribute.\n:param style:\n*)\nlet style_to_dict (style : string) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_147099_style_to_dict.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = style_to_dict in\n  (assert ((candidate \"font-style: italic; font-style: normal\") = [(\"font-style\", \"normal\")]));\n  (assert ((candidate \"font-weight: bold; font-style: italic\") = [(\"font-weight\", \"bold\"); (\"font-style\", \"italic\")]));\n  (assert ((candidate \"color: rgb(255, 0, 0)\") = [(\"color\", \"rgb(255, 0, 0)\")]));\n  (assert ((candidate \"display: block; display: inline-block; display: none\") = [(\"display\", \"none\")]));\n  (assert ((candidate \"color: red; margin: 5px; font-size: 20px;\") = [(\"color\", \"red\"); (\"margin\", \"5px\"); (\"font-size\", \"20px\")]));\n  (assert ((candidate \"foo\") = []));\n  (assert ((candidate \"color: red; margin: 5px;\") = [(\"color\", \"red\"); (\"margin\", \"5px\")]));\n  (assert ((candidate \"foo;\") = []));\n  (assert ((candidate \"margin:10px\") = [(\"margin\", \"10px\")]));\n  (assert ((candidate \"color: rgba(255, 0, 0, 0.5)\") = [(\"color\", \"rgba(255, 0, 0, 0.5)\")]));\n  (assert ((candidate \";;\") = []));\n  (assert ((candidate \"font-size: 123;\") = [(\"font-size\", \"123\")]));\n  (assert ((candidate \"\") = []));\n  (assert ((candidate \"font-size: 14px\") = [(\"font-size\", \"14px\")]));\n  (assert ((candidate \"font-size: 123; color: #fff; color: #abc;\") = [(\"font-size\", \"123\"); (\"color\", \"#abc\")]));\n  (assert ((candidate \"background-color:red;\") = [(\"background-color\", \"red\")]));\n  (assert ((candidate \" \") = []));\n  (assert ((candidate \"font-size: 13px; color: white; background-color: blue;\") = [(\"font-size\", \"13px\"); (\"color\", \"white\"); (\"background-color\", \"blue\")]));\n  (assert ((candidate \";\") = []));\n  (assert ((candidate \"color: #f00\") = [(\"color\", \"#f00\")]));\n  (assert ((candidate \"margin-top:10px; margin-right:10px; margin-bottom:10px; margin-left:10px;\") = [(\"margin-top\", \"10px\"); (\"margin-right\", \"10px\"); (\"margin-bottom\", \"10px\"); (\"margin-left\", \"10px\")]));\n  (assert ((candidate \"color: #ff0000\") = [(\"color\", \"#ff0000\")]));\n  (assert ((candidate \"color: red; margin: 5px; font-size: 20px;;\") = [(\"color\", \"red\"); (\"margin\", \"5px\"); (\"font-size\", \"20px\")]));\n  (assert ((candidate \"\") = []));\n  (assert ((candidate \"margin-top:10px; padding:20px\") = [(\"margin-top\", \"10px\"); (\"padding\", \"20px\")]));\n  (assert ((candidate \"color: #ff0000;\") = [(\"color\", \"#ff0000\")]));\n  (assert ((candidate \"color: red;\") = [(\"color\", \"red\")]));\n  (assert ((candidate \" ; \") = []));\n  (assert ((candidate \"font-size: 123; color: #fff;\") = [(\"font-size\", \"123\"); (\"color\", \"#fff\")]));\n  (assert ((candidate \";\") = []));\n  (assert ((candidate \"font-size: 123; font-size: 456;\") = [(\"font-size\", \"456\")]));\n  (assert ((candidate \"foo;bar\") = []));\n  (assert ((candidate \"border:1px solid blue; font-size:18pt\") = [(\"border\", \"1px solid blue\"); (\"font-size\", \"18pt\")]));\n  (assert ((candidate \"color: red; font-size: 12; display: block; display: inline-block\") = [(\"color\", \"red\"); (\"font-size\", \"12\"); (\"display\", \"inline-block\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_14777_sqlite3_quote_name", "language": "ml", "prompt": "(**Quote `name` as a SQL identifier, e.g. a table or column name.\nDo NOT use this for strings, e.g. inserting data into a table.\nUse query parameters instead.\n*)\nlet sqlite3_quote_name (name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_14777_sqlite3_quote_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sqlite3_quote_name in\n  (assert ((candidate \"a\rb\nc\") = \"\"a\rb\nc\"\"));\n  (assert ((candidate \"a.b.c\") = \"\"a.b.c\"\"));\n  (assert ((candidate \"\") = \"\"\"\"));\n  (assert ((candidate \"a1\") = \"\"a1\"\"));\n  (assert ((candidate \"ABC\") = \"\"ABC\"\"));\n  (assert ((candidate \"a\") = \"\"a\"\"));\n  (assert ((candidate \"a\"b.c.d\") = \"\"a\"\"b.c.d\"\"));\n  (assert ((candidate \"a.b.c\"d\") = \"\"a.b.c\"\"d\"\"));\n  (assert ((candidate \"a.b\"c.d\") = \"\"a.b\"\"c.d\"\"));\n  (assert ((candidate \"a.b.c.d\") = \"\"a.b.c.d\"\"));\n  (assert ((candidate \"a.b\") = \"\"a.b\"\"));\n  (assert ((candidate \"a b\"c d\") = \"\"a b\"\"c d\"\"));\n  (assert ((candidate \"a.b.c.d\"\") = \"\"a.b.c.d\"\"\"\"));\n  (assert ((candidate \"abc\"def\") = \"\"abc\"\"def\"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_148003_Name_Validation", "language": "ml", "prompt": "(**Function to Validate a Name for Input: Allowing Spaces, - and '\n*)\nlet Name_Validation (Name : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_148003_Name_Validation.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = Name_Validation in\n  (assert ((candidate \"Anne-Marie\") = true));\n  (assert ((candidate \"Sabrina\") = true));\n  (assert ((candidate \"<NAME>\") = false));\n  (assert ((candidate \"Anne Marie\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_148266_get_env", "language": "ml", "prompt": "(**If args contain `pypi-dev`, the package name will be `knackpy-dev`. Else the\npackage name will be Knackpy.\n*)\nlet get_env (args : string list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_148266_get_env.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_env in\n  (assert ((candidate [\"pypi-dev\"]) = \"dev\"));\n  (assert ((candidate []) = \"prod\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_148854_toHex", "language": "ml", "prompt": "(**Converts the given value (0-255) into its hexadecimal representation\n*)\nlet toHex (val : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_148854_toHex.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = toHex in\n  (assert ((candidate 128) = \"80\"));\n  (assert ((candidate 1) = \"01\"));\n  (assert ((candidate 47) = \"2f\"));\n  (assert ((candidate 167) = \"a7\"));\n  (assert ((candidate 17) = \"11\"));\n  (assert ((candidate 5) = \"05\"));\n  (assert ((candidate 10) = \"0a\"));\n  (assert ((candidate 118) = \"76\"));\n  (assert ((candidate 20) = \"14\"));\n  (assert ((candidate 16) = \"10\"));\n  (assert ((candidate 23) = \"17\"));\n  (assert ((candidate 15) = \"0f\"));\n  (assert ((candidate 2) = \"02\"));\n  (assert ((candidate 12) = \"0c\"));\n  (assert ((candidate 254) = \"fe\"));\n  (assert ((candidate 0) = \"00\"));\n  (assert ((candidate 255) = \"ff\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_14894_copy_dict", "language": "ml", "prompt": "(**Returns a copy of source_dict, updated with the new key-value pairs in diffs.\n*)\nlet copy_dict (source_dict : (string, int) list) (diffs : (string, int) list) : (string, int) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_14894_copy_dict.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = copy_dict in\n  (assert ((candidate [(\"a\", 1); (\"b\", 2)] [(\"b\", 2)]) = [(\"a\", 1); (\"b\", 2)]));\n  (assert ((candidate [(\"x\", 1); (\"y\", 2); (\"z\", 3)] [(\"x\", 1); (\"y\", 2); (\"z\", 3)]) = [(\"x\", 1); (\"y\", 2); (\"z\", 3)]));\n  (assert ((candidate dict  []) = []));\n  (assert ((candidate [] [(\"a\", 1); (\"b\", 2); (\"c\", 3)]) = [(\"a\", 1); (\"b\", 2); (\"c\", 3)]));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2)] [(\"a\", 2); (\"b\", 2)]) = [(\"a\", 2); (\"b\", 2)]));\n  (assert ((candidate [(\"x\", 1); (\"y\", 2); (\"z\", 3)] []) = [(\"x\", 1); (\"y\", 2); (\"z\", 3)]));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2)] [(\"b\", 2); (\"c\", 3); (\"d\", 4)]) = [(\"a\", 1); (\"b\", 2); (\"c\", 3); (\"d\", 4)]));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2)] [(\"a\", 2); (\"b\", 2); (\"c\", 3); (\"d\", 4)]) = [(\"a\", 2); (\"b\", 2); (\"c\", 3); (\"d\", 4)]));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2)] [(\"b\", 2); (\"c\", 3)]) = [(\"a\", 1); (\"b\", 2); (\"c\", 3)]));\n  (assert ((candidate [(\"x\", 1); (\"y\", 2); (\"z\", 3)] [(\"a\", 1); (\"b\", 2); (\"c\", 3)]) = [(\"a\", 1); (\"b\", 2); (\"c\", 3); (\"x\", 1); (\"y\", 2); (\"z\", 3)]));\n  (assert ((candidate [(\"x\", 1); (\"y\", 2); (\"z\", 3)] [(\"w\", 7); (\"x\", 8)]) = [(\"w\", 7); (\"x\", 8); (\"y\", 2); (\"z\", 3)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_149266_ascii_replace", "language": "ml", "prompt": "(**replace quotes with their ASCII character representation\nArgs:\n * text (str): text to replace in\nReturns:\n * str: replaced text\n*)\nlet ascii_replace (text : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_149266_ascii_replace.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = ascii_replace in\n  (assert ((candidate \"[This] [is a] [test].\") = \"[This] [is a] [test].\"));\n  (assert ((candidate \"This is [a] test\") = \"This is [a] test\"));\n  (assert ((candidate \"This [is] a test.\") = \"This [is] a test.\"));\n  (assert ((candidate \"Bob's favorite language is [&#39;]Python\") = \"Bob&#39;s favorite language is [']Python\"));\n  (assert ((candidate \"I love to ride my bike.\") = \"I love to ride my bike.\"));\n  (assert ((candidate \"This is [a] [test]\") = \"This is [a] [test]\"));\n  (assert ((candidate \"[This] is [a] [test].\") = \"[This] is [a] [test].\"));\n  (assert ((candidate \"This is a test]\") = \"This is a test]\"));\n  (assert ((candidate \"''\") = \"&#39;&#39;\"));\n  (assert ((candidate \"This is a test.\") = \"This is a test.\"));\n  (assert ((candidate \"&#39;\") = \"&#39;\"));\n  (assert ((candidate \"[This is a test].\") = \"[This is a test].\"));\n  (assert ((candidate \"There's no place like home, home is where the heart is.\") = \"There&#39;s no place like home, home is where the heart is.\"));\n  (assert ((candidate \"[This] is a test.\") = \"[This] is a test.\"));\n  (assert ((candidate \"Hi, my name is 'Bob'\") = \"Hi, my name is &#39;Bob&#39;\"));\n  (assert ((candidate \"This is [a test\") = \"This is [a test\"));\n  (assert ((candidate \"This is a [test]\") = \"This is a [test]\"));\n  (assert ((candidate \"I&#39;m a programmer\") = candidate \"I'm a programmer\"));\n  (assert ((candidate \"this should be a simple quote: '&#39;\") = \"this should be a simple quote: &#39;&#39;\"));\n  (assert ((candidate \"this should be a simple quote: '\") = \"this should be a simple quote: &#39;\"));\n  (assert ((candidate \"This is [a] test.\") = \"This is [a] test.\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_149402_obtenerBinario", "language": "ml", "prompt": "(**bin(numero) obtiene el valor binario de numero\n[2:] obtiene los elementos de del binario anterior excepto los primeros 2, por ejemplo 11000000[2:] regresa 000000\nzfill(8) rellena con ceros a la izquiera el valor anterior hasta que este tenga longitud 8, por ejemplo 111111 regresa 00111111\n*)\nlet obtenerBinario (numero : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_149402_obtenerBinario.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = obtenerBinario in\n  (assert ((candidate 12) = \"00001100\"));\n  (assert ((candidate 0) = \"00000000\"));\n  (assert ((candidate 2) = \"00000010\"));\n  (assert ((candidate 128) = \"10000000\"));\n  (assert ((candidate 2048) = \"100000000000\"));\n  (assert ((candidate 21) = \"00010101\"));\n  (assert ((candidate 64) = \"01000000\"));\n  (assert ((candidate 19) = \"00010011\"));\n  (assert ((candidate 15) = \"00001111\"));\n  (assert ((candidate 8) = \"00001000\"));\n  (assert ((candidate 7) = \"00000111\"));\n  (assert ((candidate 19) = \"00010011\"));\n  (assert ((candidate 128) = \"10000000\"));\n  (assert ((candidate 6) = \"00000110\"));\n  (assert ((candidate 0) = \"00000000\"));\n  (assert ((candidate 9) = \"00001001\"));\n  (assert ((candidate 18) = \"00010010\"));\n  (assert ((candidate 9) = \"00001001\"));\n  (assert ((candidate 187) = \"10111011\"));\n  (assert ((candidate 3) = \"00000011\"));\n  (assert ((candidate 1024) = \"10000000000\"));\n  (assert ((candidate 14) = \"00001110\"));\n  (assert ((candidate 2) = \"00000010\"));\n  (assert ((candidate 12) = \"00001100\"));\n  (assert ((candidate 13) = \"00001101\"));\n  (assert ((candidate 1) = \"00000001\"));\n  (assert ((candidate 0) = \"00000000\"));\n  (assert ((candidate 17) = \"00010001\"));\n  (assert ((candidate 6) = \"00000110\"));\n  (assert ((candidate 7) = \"00000111\"));\n  (assert ((candidate 17) = \"00010001\"));\n  (assert ((candidate 18) = \"00010010\"));\n  (assert ((candidate 16) = \"00010000\"));\n  (assert ((candidate 64) = \"01000000\"));\n  (assert ((candidate 5) = \"00000101\"));\n  (assert ((candidate 10) = \"00001010\"));\n  (assert ((candidate 2) = \"00000010\"));\n  (assert ((candidate 16) = \"00010000\"));\n  (assert ((candidate 15) = \"00001111\"));\n  (assert ((candidate 4) = \"00000100\"));\n  (assert ((candidate 4) = \"00000100\"));\n  (assert ((candidate 14) = \"00001110\"));\n  (assert ((candidate 1) = \"00000001\"));\n  (assert ((candidate 32) = \"00100000\"));\n  (assert ((candidate 4) = \"00000100\"));\n  (assert ((candidate 5) = \"00000101\"));\n  (assert ((candidate 8) = \"00001000\"));\n  (assert ((candidate 128) = \"10000000\"));\n  (assert ((candidate 3) = \"00000011\"));\n  (assert ((candidate 1) = \"00000001\"));\n  (assert ((candidate 10) = \"00001010\"));\n  (assert ((candidate 20) = \"00010100\"));\n  (assert ((candidate 170) = \"10101010\"));\n  (assert ((candidate 8) = \"00001000\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_149428_squared_loss", "language": "ml", "prompt": "(**Returns the squared difference between two numbers\n*)\nlet squared_loss (x1 : float) (x2 : float) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_149428_squared_loss.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = squared_loss in\n  (assert ((candidate 0.0 0.0) = 0));\n  (assert ((candidate (~1).0 (~2).0) = 1));\n  (assert ((candidate 3.0 3.0) = 0));\n  (assert ((candidate 5.0 2.0) = 9));\n  (assert ((candidate 5.0 5.0) = 0));\n  (assert ((candidate 1.0 1.0) = 0));\n  (assert ((candidate 1.0 2.0) = 1));\n  (assert ((candidate 5.0 3.0) = 4));\n  (assert ((candidate 4.0 3.0) = 1));\n  (assert ((candidate 10.0 5.0) = 25));\n  (assert ((candidate 9.0 0.0) = 81));\n  (assert ((candidate 3.0 5.0) = 4));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_149915_next_enum_variation", "language": "ml", "prompt": "(**Loop through indices from [0, 0, ...] to [L0-1, L1-1, ...]\nwhere Li is len(enums[i]).  The list can be thought of as a number with many\ndigits, where each digit is in [0, Li), and this function effectively implements\nthe increment operation, with the least-significant digit being the first item.\n*)\nlet next_enum_variation (enums :  string * string list list) (enum_indices : int list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_149915_next_enum_variation.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = next_enum_variation in\n  (assert ((candidate [(\"a\", [\"a\"; \"b\"; \"c\"]); (\"b\", [\"x\"; \"y\"; \"z\"])] [0; 0]) = true));\n  (assert ((candidate [(\"a\", [\"a\"; \"b\"; \"c\"]); (\"b\", [\"x\"; \"y\"; \"z\"])] [2; 1]) = true));\n  (assert ((candidate [(\"a\", [\"a\"; \"b\"; \"c\"]); (\"b\", [\"x\"; \"y\"; \"z\"])] [2; 0]) = true));\n  (assert ((candidate [(\"A\", [\"a\"; \"b\"]); (\"B\", [\"c\"; \"d\"])] [1; 0]) = true));\n  (assert ((candidate [(\"A\", [\"a\"; \"b\"]); (\"B\", [\"c\"])] [0; 0]) = true));\n  (assert ((candidate [(\"a\", [\"a\"; \"b\"; \"c\"]); (\"b\", [\"x\"; \"y\"; \"z\"])] [1; 1]) = true));\n  (assert ((candidate [(\"a\", [\"b\"; \"c\"]); (\"d\", [\"e\"; \"f\"])] [1; 2]) = false));\n  (assert ((candidate [(\"a\", [\"b\"; \"c\"]); (\"d\", [\"e\"; \"f\"])] [0; 0]) = true));\n  (assert ((candidate [(\"A\", [\"a\"; \"b\"]); (\"B\", [\"c\"])] [1; 0]) = false));\n  (assert ((candidate [(\"a\", [\"a\"; \"b\"; \"c\"]); (\"b\", [\"x\"; \"y\"; \"z\"])] [0; 1]) = true));\n  (assert ((candidate [(\"a\", [\"b\"; \"c\"]); (\"d\", [\"e\"; \"f\"])] [1; 0]) = true));\n  (assert ((candidate [(\"a\", [\"a\"; \"b\"; \"c\"]); (\"b\", [\"x\"; \"y\"; \"z\"])] [1; 0]) = true));\n  (assert ((candidate [(\"a\", [\"b\"; \"c\"]); (\"d\", [\"e\"; \"f\"])] [2; 1]) = false));\n  (assert ((candidate [(\"a\", [\"b\"; \"c\"]); (\"d\", [\"e\"; \"f\"])] [0; 1]) = true));\n  (assert ((candidate [(\"A\", [\"a\"; \"b\"]); (\"B\", [\"c\"; \"d\"])] [0; 0]) = true));\n  (assert ((candidate [(\"a\", [\"b\"; \"c\"]); (\"d\", [\"e\"; \"f\"])] [1; 1]) = false));\n  (assert ((candidate [(\"A\", [\"a\"; \"b\"]); (\"B\", [\"c\"; \"d\"]); (\"C\", [\"e\"; \"f\"])] [0; 0; 0]) = true));\n  (assert ((candidate [(\"A\", [\"a\"; \"b\"]); (\"B\", [\"c\"; \"d\"]); (\"C\", [\"e\"; \"f\"])] [1; 0; 0]) = true));\n  (assert ((candidate [(\"a\", [\"b\"; \"c\"]); (\"d\", [\"e\"; \"f\"])] [2; 2]) = false));\n  (assert ((candidate [(\"a\", [\"a\"; \"b\"; \"c\"]); (\"b\", [\"x\"; \"y\"; \"z\"])] [1; 2]) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_149954_to_lutron_level", "language": "ml", "prompt": "(**Convert the given Home Assistant light level (0-255) to Lutron (0-100).\n*)\nlet to_lutron_level (level : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_149954_to_lutron_level.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = to_lutron_level in\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 254) = 99));\n  (assert ((candidate 255) = 100));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_150881_position", "language": "ml", "prompt": "(**Return a heuristic value based on the position of the largest value on the board.\n*)\nlet position (b : int list list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_150881_position.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = position in\n  (assert ((candidate [[0; 0; 0; 0; 0]; [0; 0; 0; 0; 0]; [0; 0; 0; 0; 0]; [0; 0; 0; 0; 0]; [0; 0; 0; 0; 0]]) = 0));\n  (assert ((candidate [[3; 5; 7]; [3; 5; 7]]) = 0));\n  (assert ((candidate [[1; 0; 3]; [4; 5; 6]; [7; 8; 9]]) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_152130_parse_list", "language": "ml", "prompt": "(**Parse a list of input strings\n*)\nlet parse_list (val : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_152130_parse_list.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_list in\n  (assert ((candidate \" 1, 2, 3\") = \"[1, 2, 3]\"));\n  (assert ((candidate \"  1, 2, 3  \") = \"[1, 2, 3]\"));\n  (assert ((candidate \"\") = \"[]\"));\n  (assert ((candidate \"    \") = \"[]\"));\n  (assert ((candidate \"1, 2, 3\") = \"[1, 2, 3]\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_154389_roman_to_int", "language": "ml", "prompt": "(**Convert a Roman numeral to an integer.\nAdopted from https://www.oreilly.com/library/view/python-cookbook/0596001673/ch03s24.html\n*)\nlet roman_to_int (expr : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_154389_roman_to_int.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = roman_to_int in\n  (assert ((candidate \"MMXXIV\") = 2024));\n  (assert ((candidate \"L\") = 50));\n  (assert ((candidate \"MCMXCIV\") = 1994));\n  (assert ((candidate \"MCMLXXXIX\") = 1989));\n  (assert ((candidate \"IIII\") = 4));\n  (assert ((candidate \"IX\") = 9));\n  (assert ((candidate \"MCMLXXXIV\") = 1984));\n  (assert ((candidate \"V\") = 5));\n  (assert ((candidate \"I\") = 1));\n  (assert ((candidate \"XXXV\") = 35));\n  (assert ((candidate \"C\") = 100));\n  (assert ((candidate \"X\") = 10));\n  (assert ((candidate \"MMMM\") = 4000));\n  (assert ((candidate \"LVIII\") = 58));\n  (assert ((candidate \"D\") = 500));\n  (assert ((candidate \"II\") = 2));\n  (assert ((candidate \"CLXVI\") = 166));\n  (assert ((candidate \"M\") = 1000));\n  (assert ((candidate \"IV\") = 4));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_154778__clamp_transpose", "language": "ml", "prompt": "(**Clamps the specified transpose amount to keep a ns in the desired bounds.\nArgs:\n * transpose_amount: Number of steps to transpose up or down.\n * ns_min_pitch: The lowest pitch in the target note sequence.\n * ns_max_pitch: The highest pitch in the target note sequence.\n * min_allowed_pitch: The lowest pitch that should be allowed in the transposed\n * note sequence.\n * max_allowed_pitch: The highest pitch that should be allowed in the\n * transposed note sequence.\nReturns:\n * A new transpose amount that, if applied to the target note sequence, will\n * keep all notes within the range [MIN_PITCH, MAX_PITCH]\n*)\nlet _clamp_transpose (transpose_amount : int) (ns_min_pitch : int) (ns_max_pitch : int) (min_allowed_pitch : int) (max_allowed_pitch : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_154778__clamp_transpose.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _clamp_transpose in\n  (assert ((candidate 1 24 25 24 26) = 1));\n  (assert ((candidate 1 24 25 21 26) = 1));\n  (assert ((candidate 1 24 25 23 26) = 1));\n  (assert ((candidate 0 21 108 0 127) = 0));\n  (assert ((candidate 0 21 108 0 108) = 0));\n  (assert ((candidate 1 24 25 22 26) = 1));\n  (assert ((candidate 1 24 25 20 26) = 1));\n  (assert ((candidate 1 24 25 25 26) = 1));\n  (assert ((candidate 1 24 25 20 24) = (~1)));\n  (assert ((candidate 1 24 25 25 24) = (~1)));\n  (assert ((candidate 1 21 108 0 127) = 1));\n  (assert ((candidate 1 24 25 21 24) = (~1)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_155131_align_up", "language": "ml", "prompt": "(**Align the input variable with unit of sizes. The aligned data will always\nbe larger than the inputs.\nArgs:\n * v: the variable to be aligned.\n * unit_size: the block size of the aligned data.\nReturn:\n * aligned variable.\n*)\nlet align_up (v : int) (unit_size : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_155131_align_up.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = align_up in\n  (assert ((candidate 5 4) = 8));\n  (assert ((candidate 8 8) = 8));\n  (assert ((candidate 1024) = 1024));\n  (assert ((candidate 1 4) = 4));\n  (assert ((candidate 3) = 4));\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 1 2) = 2));\n  (assert ((candidate 1023) = 1024));\n  (assert ((candidate 2 3) = 3));\n  (assert ((candidate 8) = 8));\n  (assert ((candidate 7 4) = 8));\n  (assert ((candidate 3 8) = 8));\n  (assert ((candidate 1023 512) = 1024));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 2 2) = 2));\n  (assert ((candidate 3 4) = 4));\n  (assert ((candidate (~1) 512) = 0));\n  (assert ((candidate 1024 512) = 1024));\n  (assert ((candidate 6) = 6));\n  (assert ((candidate (~1)) = 0));\n  (assert ((candidate 1) = 2));\n  (assert ((candidate 4 4) = 4));\n  (assert ((candidate 5 16) = 16));\n  (assert ((candidate 7) = 8));\n  (assert ((candidate 11) = 12));\n  (assert ((candidate 0 512) = 0));\n  (assert ((candidate 6 4) = 8));\n  (assert ((candidate 8 16) = 16));\n  (assert ((candidate 5) = 6));\n  (assert ((candidate 4) = 4));\n  (assert ((candidate 7 128) = 128));\n  (assert ((candidate 9) = 10));\n  (assert ((candidate 10) = 10));\n  (assert ((candidate 1 3) = 3));\n  (assert ((candidate 3 2) = 4));\n  (assert ((candidate 2 4) = 4));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_155421_get_bandwidth", "language": "ml", "prompt": "(**Module to determine the bandwidth for a segment\ndownload\n*)\nlet get_bandwidth (data : int) (duration : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_155421_get_bandwidth.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_bandwidth in\n  (assert ((candidate 0 1) = 0));\n  (assert ((candidate 0 2) = 0));\n  (assert ((candidate 0 3) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_155975_get_false_positive", "language": "ml", "prompt": "(**Returns True, False for false positive as per DefectDojo standards.\n:param false_p:\n:return:\n*)\nlet get_false_positive (false_p : bool) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_155975_get_false_positive.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_false_positive in\n  (assert ((candidate true) = true));\n  (assert ((candidate false) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_15619_is_anagram_0", "language": "ml", "prompt": "(**This is my first solution, and it's incorrect because this method checks palindrome, not anagram.\n*)\nlet is_anagram_0 (s1 : string option) (s2 : string option) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_15619_is_anagram_0.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_anagram_0 in\n  (assert ((candidate Some(\"dog\") Some(\"dog\")) = false));\n  (assert ((candidate Some(\"\") Some(\" \")) = false));\n  (assert ((candidate Some(\" \") Some(\"\")) = false));\n  (assert ((candidate Some(\"ab\") Some(\"ba\")) = true));\n  (assert ((candidate Some(\"a\") Some(\"ab\")) = false));\n  (assert ((candidate Some(\"aba\") Some(\"aba\")) = true));\n  (assert ((candidate Some(\"listen\") Some(\"silent\")) = false));\n  (assert ((candidate Some(\"abc\") Some(\"\")) = false));\n  (assert ((candidate Some(\"a\") Some(None)) = false));\n  (assert ((candidate Some(\"abcd\") Some(\"badc\")) = false));\n  (assert ((candidate Some(\"a\") Some(\"a\")) = true));\n  (assert ((candidate Some(None) Some(None)) = false));\n  (assert ((candidate Some(\"ab\") Some(None)) = false));\n  (assert ((candidate Some(\"ab\") Some(\"a\")) = false));\n  (assert ((candidate Some(\"\") Some(\"a\")) = false));\n  (assert ((candidate Some(\"abc\") Some(\"def\")) = false));\n  (assert ((candidate Some(\"abcd\") Some(\"dbac\")) = false));\n  (assert ((candidate Some(\"ab\") Some(\"ac\")) = false));\n  (assert ((candidate Some(\"  d\") Some(\"d  \")) = true));\n  (assert ((candidate Some(None) Some(\"ab\")) = false));\n  (assert ((candidate Some(\"dog\") Some(\"god\")) = true));\n  (assert ((candidate Some(\"aabbcc\") Some(\"bbcca\")) = false));\n  (assert ((candidate Some(\"dog\") Some(\"\")) = false));\n  (assert ((candidate Some(\"ab\") Some(\"bb\")) = false));\n  (assert ((candidate Some(\"a\") Some(\"\")) = false));\n  (assert ((candidate Some(\"aabb\") Some(\"bbaa\")) = true));\n  (assert ((candidate Some(\"a b\") Some(\"b a\")) = true));\n  (assert ((candidate Some(\"a\") Some(\"b\")) = false));\n  (assert ((candidate Some(None) Some(\"a\")) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_156273__extract_param", "language": "ml", "prompt": "(**Extract a parameter in the style of \"key=value\".\nReturn `''` if the `arg == name`,\n * :obj:`None` if the key does not match name,\n * value otherwise (might be `''`).\n*)\nlet _extract_param (arg : string) (name : string) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_156273__extract_param.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _extract_param in\n  (assert ((candidate \"notkey=value\" \"key\") = Some(None)));\n  (assert ((candidate \"key=value\" \"notkey\") = Some(None)));\n  (assert ((candidate \"\" \"a\") = Some(None)));\n  (assert ((candidate \"a=\" \"a\") = Some(\"\")));\n  (assert ((candidate \"someother=\" \"someother\") = Some(\"\")));\n  (assert ((candidate \"a=b\" \"a=c\") = Some(None)));\n  (assert ((candidate \"a=b\" \"c=\") = Some(None)));\n  (assert ((candidate \"some=value\" \"some\") = Some(\"value\")));\n  (assert ((candidate \"key=value\" \"key\") = Some(\"value\")));\n  (assert ((candidate \"a=b\" \"\") = Some(None)));\n  (assert ((candidate \"=a\" \"a\") = Some(None)));\n  (assert ((candidate \"a\" \"\") = Some(None)));\n  (assert ((candidate \"key=value=more\" \"key\") = Some(\"value=more\")));\n  (assert ((candidate \"key\" \"key\") = Some(\"\")));\n  (assert ((candidate \"a=b\" \"c\") = Some(None)));\n  (assert ((candidate \"=a\" \"=a\") = Some(\"\")));\n  (assert ((candidate \"a=b\" \"a\") = Some(\"b\")));\n  (assert ((candidate \"a=b\" \"a=\") = Some(None)));\n  (assert ((candidate \"a=\" \"a=\") = Some(\"\")));\n  (assert ((candidate \"\" \"key\") = Some(None)));\n  (assert ((candidate \"some=\" \"some\") = Some(\"\")));\n  (assert ((candidate \"key=\" \"key\") = Some(\"\")));\n  (assert ((candidate \"someother=value\" \"someother\") = Some(\"value\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_156491_numbits", "language": "ml", "prompt": "(**Gets the minimum number of bits required to encode given number of different values.\nThis method implements zserio built-in operator numBits.\n:param num_values: The number of different values from which to calculate number of bits.\n:returns: Number of bits required to encode num_values different values.\n*)\nlet numbits (num_values : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_156491_numbits.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = numbits in\n  (assert ((candidate 26) = 5));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 12) = 4));\n  (assert ((candidate 25) = 5));\n  (assert ((candidate 23) = 5));\n  (assert ((candidate 33) = 6));\n  (assert ((candidate 9) = 4));\n  (assert ((candidate 31) = 5));\n  (assert ((candidate 14) = 4));\n  (assert ((candidate 10) = 4));\n  (assert ((candidate 7) = 3));\n  (assert ((candidate 15) = 4));\n  (assert ((candidate 35) = 6));\n  (assert ((candidate 19) = 5));\n  (assert ((candidate 21) = 5));\n  (assert ((candidate 8) = 3));\n  (assert ((candidate 3) = 2));\n  (assert ((candidate 24) = 5));\n  (assert ((candidate 22) = 5));\n  (assert ((candidate 11) = 4));\n  (assert ((candidate 30) = 5));\n  (assert ((candidate 34) = 6));\n  (assert ((candidate 20) = 5));\n  (assert ((candidate 36) = 6));\n  (assert ((candidate 4) = 2));\n  (assert ((candidate 18) = 5));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 27) = 5));\n  (assert ((candidate 2) = 1));\n  (assert ((candidate 28) = 5));\n  (assert ((candidate 29) = 5));\n  (assert ((candidate 6) = 3));\n  (assert ((candidate 17) = 5));\n  (assert ((candidate 5) = 3));\n  (assert ((candidate 13) = 4));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_157050_takemod", "language": "ml", "prompt": "(**Determine if the input is odd or even values and \nreturn a of 0 and 1 depending on the truth value\nParameters\n----------\nnvols : int\nReturns\n-------\ndecisions : int\n*)\nlet takemod (nvols : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_157050_takemod.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = takemod in\n  (assert ((candidate 1) = 0));\n  (assert ((candidate 2) = 1));\n  (assert ((candidate 3) = 0));\n  (assert ((candidate 5) = 0));\n  (assert ((candidate 8) = 1));\n  (assert ((candidate 6) = 1));\n  (assert ((candidate 4) = 1));\n  (assert ((candidate 7) = 0));\n  (assert ((candidate 200) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_157096_unquote", "language": "ml", "prompt": "(**Remove namespace from prefixed tag.\nSee: [Python issue 18304](https://bugs.python.org/issue18304)\nArguments:\n * tag {str} -- (possibly-)namespaced tag\nReturns:\n * str -- tag name without namespace\n*)\nlet unquote (tag : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_157096_unquote.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = unquote in\n  (assert ((candidate \"{http://www.w3.org/1999/02/22-rdf-syntax-ns#}Description\") = \"Description\"));\n  (assert ((candidate \"{http://www.w3.org/1999/xhtml}html\") = \"html\"));\n  (assert ((candidate \"{http://www.w3.org/2000/01/rdf-schema#}subClassOf\") = \"subClassOf\"));\n  (assert ((candidate \"{http://www.w3.org/2000/01/rdf-schema#}domain\") = \"domain\"));\n  (assert ((candidate \"{http://www.w3.org/1999/02/22-rdf-syntax-ns#}li\") = \"li\"));\n  (assert ((candidate \"{http://purl.org/dc/elements/1.1/}rights\") = \"rights\"));\n  (assert ((candidate \"bar\") = \"bar\"));\n  (assert ((candidate \"html\") = \"html\"));\n  (assert ((candidate \"{http://www.w3.org/2000/01/rdf-schema#}label\") = \"label\"));\n  (assert ((candidate \"{http://www.example.com}bar\") = \"bar\"));\n  (assert ((candidate \"{http://www.w3.org/1999/xhtml}p\") = \"p\"));\n  (assert ((candidate \"{http://www.w3.org/1999/02/22-rdf-syntax-ns#}Bag\") = \"Bag\"));\n  (assert ((candidate \"{http://www.w3.org/2000/01/rdf-schema#}subPropertyOf\") = \"subPropertyOf\"));\n  (assert ((candidate \"p\") = \"p\"));\n  (assert ((candidate \"{http://schemas.opengis.net/kml/2.2}MultiGeometry\") = \"MultiGeometry\"));\n  (assert ((candidate \"{http://www.w3.org/XML/1998/namespace}lang\") = \"lang\"));\n  (assert ((candidate \"{http://www.w3.org/1999/02/22-rdf-syntax-ns#}RDF\") = \"RDF\"));\n  (assert ((candidate \"foo bar\") = \"foo bar\"));\n  (assert ((candidate \"{http://www.w3.org/2000/01/rdf-schema#}seeAlso\") = \"seeAlso\"));\n  (assert ((candidate \"{http://www.w3.org/2000/01/rdf-schema#}isDefinedBy\") = \"isDefinedBy\"));\n  (assert ((candidate \"{http://www.w3.org/2000/01/rdf-schema#}range\") = \"range\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_157569_queen_constraint", "language": "ml", "prompt": "(**Constraint is satisfied (true) if A, B are really the same variable,\nor if they are not in the same row, down diagonal, or up diagonal.\n*)\nlet queen_constraint (A : int) (a : int) (B : int) (b : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_157569_queen_constraint.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = queen_constraint in\n  (assert ((candidate 1 1 3 1) = false));\n  (assert ((candidate 1 1 2 2) = false));\n  (assert ((candidate 1 2 2 3) = false));\n  (assert ((candidate 0 3 1 3) = false));\n  (assert ((candidate 1 3 2 2) = false));\n  (assert ((candidate 0 1 1 3) = true));\n  (assert ((candidate 1 2 4 2) = false));\n  (assert ((candidate 1 2 2 1) = false));\n  (assert ((candidate 4 4 2 4) = false));\n  (assert ((candidate 1 3 3 1) = false));\n  (assert ((candidate 0 1 2 3) = false));\n  (assert ((candidate 1 2 2 2) = false));\n  (assert ((candidate 1 1 1 1) = true));\n  (assert ((candidate 1 3 3 3) = false));\n  (assert ((candidate 0 1 2 1) = false));\n  (assert ((candidate 1 1 2 1) = false));\n  (assert ((candidate 1 3 2 3) = false));\n  (assert ((candidate 1 2 3 2) = false));\n  (assert ((candidate 1 3 3 2) = true));\n  (assert ((candidate 1 2 1 2) = true));\n  (assert ((candidate 1 2 3 3) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_158362_fix_typo", "language": "ml", "prompt": "(**Helper function. Fix typo in one of the tags\n*)\nlet fix_typo (name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_158362_fix_typo.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = fix_typo in\n  (assert ((candidate \"jednostkaAdmnistracyjna\") = \"jednostkaAdministracyjna\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_158852_frames", "language": "ml", "prompt": "(**Find the number of frames shown.\n*)\nlet frames (minutes : int) (fps : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_158852_frames.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = frames in\n  (assert ((candidate 1 1) = 60));\n  (assert ((candidate 1 30) = 1800));\n  (assert ((candidate 1 5) = 300));\n  (assert ((candidate 0 60) = 0));\n  (assert ((candidate 1 60) = 3600));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_158961_parse_custom_data", "language": "ml", "prompt": "(**Parse SCOUT_CUSTOM info field\nInput: \"key1|val1,key2|val2\"\nOutput: [ [\"key1\",\"val1\"], [\"key2\", \"val2\"] ]\n*)\nlet parse_custom_data (custom_str : string) : string list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_158961_parse_custom_data.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_custom_data in\n  (assert ((candidate \"key1|val1,key2|val2\") = [[\"key1\"; \"val1\"]; [\"key2\"; \"val2\"]]));\n  (assert ((candidate \"key1|val1,key2|val2\") = [[\"key1\"; \"val1\"]; [\"key2\"; \"val2\"]]));\n  (assert ((candidate \"key1|val1,key2|val2\") = [[\"key1\"; \"val1\"]; [\"key2\"; \"val2\"]]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_159043_rational_to_cfrac", "language": "ml", "prompt": "(**Terms of the simple continued fraction representation of n/d\n*)\nlet rational_to_cfrac (n : int) (d : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_159043_rational_to_cfrac.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = rational_to_cfrac in\n  (assert ((candidate 6 4) = [1; 2]));\n  (assert ((candidate 2 1) = [2]));\n  (assert ((candidate 0 3) = [0]));\n  (assert ((candidate 1234567890 1) = [1234567890]));\n  (assert ((candidate 3 1) = [3]));\n  (assert ((candidate 1 1) = [1]));\n  (assert ((candidate 2 4) = [0; 2]));\n  (assert ((candidate 0 1) = [0]));\n  (assert ((candidate 6 2) = [3]));\n  (assert ((candidate 5 5) = [1]));\n  (assert ((candidate 0 1) = [0]));\n  (assert ((candidate 4 4) = [1]));\n  (assert ((candidate 4 3) = [1; 3]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_159200_linear", "language": "ml", "prompt": "(**linear\nParameters\n----------\nx : int\na : float\nb : float\nReturns\n-------\nfloat\n * a*x + b\n*)\nlet linear (x : int) (a : int) (b : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_159200_linear.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = linear in\n  (assert ((candidate 3 2 1) = 7));\n  (assert ((candidate 5 3 1) = 16));\n  (assert ((candidate 1 1 0) = 1));\n  (assert ((candidate 0 1 1) = 1));\n  (assert ((candidate 0 0 (~1)) = (~1)));\n  (assert ((candidate 6 1 0) = 6));\n  (assert ((candidate 0 1 (~1)) = (~1)));\n  (assert ((candidate 0 1 0) = 0));\n  (assert ((candidate 4 3 1) = 13));\n  (assert ((candidate 0 0 0) = 0));\n  (assert ((candidate 3 3 1) = 10));\n  (assert ((candidate 1 2 3) = 5));\n  (assert ((candidate 1 3 1) = 4));\n  (assert ((candidate 3 1 0) = 3));\n  (assert ((candidate 6 3 1) = 19));\n  (assert ((candidate 3 5 6) = 21));\n  (assert ((candidate 0 2 2) = 2));\n  (assert ((candidate 5 1 0) = 5));\n  (assert ((candidate 10 0 0) = 0));\n  (assert ((candidate 2 1 0) = 2));\n  (assert ((candidate 4 1 0) = 4));\n  (assert ((candidate 0 0 1) = 1));\n  (assert ((candidate 2 3 1) = 7));\n  (assert ((candidate 1 0 0) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_159279__kamb_radius", "language": "ml", "prompt": "(**Radius of kernel for Kamb-style smoothing.\n*)\nlet _kamb_radius (n : int) (sigma : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_159279__kamb_radius.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _kamb_radius in\n  (assert ((candidate 10 0) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_159762_contains_sublist", "language": "ml", "prompt": "(**Check if one list contains the items from another list (in the same order).\n:param lst: The main list.\n:param sublist: The sublist to check for.\n:returns: :data:`True` if the main list contains the items from the\n * sublist in the same order, :data:`False` otherwise.\nBased on `this StackOverflow answer <http://stackoverflow.com/a/3314913>`_.\n*)\nlet contains_sublist (lst : int list) (sublst : int list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_159762_contains_sublist.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = contains_sublist in\n  (assert ((candidate [1; 2; 3; 4; 5; 6] [2; 3]) = true));\n  (assert ((candidate [1; 2; 3; 4; 5; 6] [1; 2; 3; 4; 5; 6]) = true));\n  (assert ((candidate [1; 2; 3; 4; 5; 6] [4; 5; 6]) = true));\n  (assert ((candidate [1; 2; 3; 4; 5; 6] [5; 6]) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_159828_make_key", "language": "ml", "prompt": "(**Make a single string, combining multiple fields.\n*)\nlet make_key (dir : string) (cmdline : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_159828_make_key.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = make_key in\n  (assert ((candidate \"/home/user/src/project1\" \"command line argument 2\") = \"/home/user/src/project1|command line argument 2\"));\n  (assert ((candidate \"foo|bar\" \"ls | grep\") = \"foo|bar|ls | grep\"));\n  (assert ((candidate \"dir\" \"other_cmdline\") = \"dir|other_cmdline\"));\n  (assert ((candidate \"foo|bar\" \"ls | grep && touch\") = \"foo|bar|ls | grep && touch\"));\n  (assert ((candidate \"foo|bar\" \"ls | grep && touch\") = \"foo|bar|ls | grep && touch\"));\n  (assert ((candidate \"foobar\" \"echo\") = \"foobar|echo\"));\n  (assert ((candidate \"/home/user/src/project2\" \"command line argument 2\") = \"/home/user/src/project2|command line argument 2\"));\n  (assert ((candidate \"foobar\" \"ls\") = \"foobar|ls\"));\n  (assert ((candidate \"/home/user/src/project2\" \"command line argument 1\") = \"/home/user/src/project2|command line argument 1\"));\n  (assert ((candidate \"dir\" \"cmdline\") = \"dir|cmdline\"));\n  (assert ((candidate \"foo bar\" \"ls\") = \"foo bar|ls\"));\n  (assert ((candidate \"/usr\" \"-h\") = \"/usr|-h\"));\n  (assert ((candidate \"foo|bar\" \"ls\") = \"foo|bar|ls\"));\n  (assert ((candidate \"/home/user/src/project1\" \"command line argument 1\") = \"/home/user/src/project1|command line argument 1\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_160355_life_counter", "language": "ml", "prompt": "(**returns quanity of living squares\n*)\nlet life_counter (field : string option list list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_160355_life_counter.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = life_counter in\n  (assert ((candidate [[\"o\"; \"o\"; \"o\"; \"o\"; \"o\"]; [\"o\"; \"o\"; \"x\"; \"o\"; \"o\"]; [\"o\"; \"o\"; \"o\"; \"o\"; \"o\"]; [\"o\"; \"o\"; \"o\"; \"o\"; \"o\"]; [\"o\"; \"o\"; \"o\"; \"o\"; \"o\"]]) = 24));\n  (assert ((candidate [[\"o\"; \"o\"; \"o\"; \"o\"; \"o\"]; [\"o\"; \"o\"; \"o\"; \"o\"; \"o\"]; [\"o\"; \"o\"; \"o\"; \"o\"; \"o\"]; [\"o\"; \"o\"; \"o\"; \"o\"; \"o\"]; [\"o\"; \"o\"; \"o\"; \"o\"; \"o\"]]) = 25));\n  (assert ((candidate [[\".\"; \".\"; \".\"]; [\"o\"; \"o\"; \"o\"]; [\"o\"; \"o\"; \"o\"]]) = 6));\n  (assert ((candidate [[\".\"; \".\"; \".\"; \".\"; \".\"; \".\"]; [\".\"; \"o\"; \".\"; \".\"; \".\"; \".\"]; [\".\"; \".\"; \".\"; \".\"; \".\"; \".\"]; [\".\"; \".\"; \".\"; \".\"; \".\"; \".\"]; [\".\"; \".\"; \".\"; \".\"; \".\"; \".\"]; [\".\"; \".\"; \".\"; \".\"; \".\"; \".\"]]) = 1));\n  (assert ((candidate [[\"o\"; \"o\"; \"o\"; \"o\"; \"o\"]; [\"o\"; \"o\"; \"o\"; \"o\"; \"o\"]; [\"o\"; \"o\"; \"o\"; \"o\"; \"o\"]; [\"o\"; \"o\"; \"o\"; \"o\"; \"o\"]; [\"o\"; \"o\"; \"o\"; \"o\"; \"o\"]]) = 25));\n  (assert ((candidate [[\"o\"; \"o\"; \"o\"; \"o\"]; [\"o\"; \"o\"; \"o\"; \"o\"]; [\"o\"; \"o\"; \"o\"; \"o\"]; [\"o\"; \"o\"; \"o\"; \"o\"]]) = 16));\n  (assert ((candidate [[\".\"; \".\"; \".\"]; [\".\"; \".\"; \".\"]; [\".\"; \".\"; \".\"]]) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_161014_compute_returns", "language": "ml", "prompt": "(**Compute returns for each time step, given the rewards\n@param rewards: list of floats, where rewards[t] is the reward\n * obtained at time step t\n@param gamma: the discount factor\n@returns list of floats representing the episode's returns\n * G_t = r_t + \\gamma r_{t+1} + \\gamma^2 r_{t+2} + ... \n * >>> compute_returns([0,0,0,1], 1.0)\n * [1.0, 1.0, 1.0, 1.0]\n * >>> compute_returns([0,0,0,1], 0.9)\n * [0.7290000000000001, 0.81, 0.9, 1.0]\n * >>> compute_returns([0,-0.5,5,0.5,-10], 0.9)\n * [-2.5965000000000003, -2.8850000000000002, -2.6500000000000004, -8.5, -10.0]\n*)\nlet compute_returns (rewards : int list) (gamma : float) : float list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_161014_compute_returns.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = compute_returns in\n  (assert ((candidate [0; 0; 0; 1] 1.0) = [1.0; 1.0; 1.0; 1.0]));\n  (assert ((candidate [0; 0; 0; 1] 0.9) = [0.7290000000000001; 0.81; 0.9; 1.0]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_161910_get_F1score", "language": "ml", "prompt": "(**correct like [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\npredict like [0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n:return: F1\n*)\nlet get_F1score (correct : int list) (predict : int list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_161910_get_F1score.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_F1score in\n  (assert ((candidate [1; 0; 0; 0; 0; 0; 0; 0; 0; 0; 0; 0] [1; 0; 0; 0; 0; 0; 0; 0; 0; 0; 0; 0]) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_162923_tricks_to_result", "language": "ml", "prompt": "(**Convert tricks made to a result, e.g. 8 tricks\nin a 4-level contract becomes -2\n*)\nlet tricks_to_result (tricks : int) (level : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_162923_tricks_to_result.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = tricks_to_result in\n  (assert ((candidate 8 4) = (~2)));\n  (assert ((candidate 3 1) = (~4)));\n  (assert ((candidate 1 1) = (~6)));\n  (assert ((candidate 5 1) = (~2)));\n  (assert ((candidate 9 1) = 2));\n  (assert ((candidate 6 1) = (~1)));\n  (assert ((candidate 8 1) = 1));\n  (assert ((candidate 7 1) = 0));\n  (assert ((candidate 2 1) = (~5)));\n  (assert ((candidate 4 1) = (~3)));\n  (assert ((candidate 10 1) = 3));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_164096_denoise", "language": "ml", "prompt": "(**Set or get denoise\n*)\nlet denoise (val : bool) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_164096_denoise.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = denoise in\n  (assert ((candidate true) = true));\n  (assert ((candidate false) = false));\n  (assert ((candidate true) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_164767_get_competitive_tier_mi18n", "language": "ml", "prompt": "(**Turn the tier returned by the API into the respective tier name displayed in-game.\n*)\nlet get_competitive_tier_mi18n (tier : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_164767_get_competitive_tier_mi18n.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_competitive_tier_mi18n in\n  (assert ((candidate 1) = \"bbs/area1\"));\n  (assert ((candidate 3) = \"bbs/area3\"));\n  (assert ((candidate 2) = \"bbs/area2\"));\n  (assert ((candidate 4) = \"bbs/area4\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_16478_batting_average", "language": "ml", "prompt": "(**Calculates the batting average to 3 decimal places using number of at bats and hits\n*)\nlet batting_average (at_bats : int) (hits : int) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_16478_batting_average.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = batting_average in\n  (assert ((candidate 1 1) = 1.0));\n  (assert ((candidate 10 0) = 0.0));\n  (assert ((candidate 1 0) = 0.0));\n  (assert ((candidate 20 10) = 0.5));\n  (assert ((candidate 20 20) = 1.0));\n  (assert ((candidate 100 0) = 0.0));\n  (assert ((candidate 100 30) = 0.3));\n  (assert ((candidate 100 20) = 0.2));\n  (assert ((candidate 3 2) = 0.667));\n  (assert ((candidate 5 2) = 0.4));\n  (assert ((candidate 2 2) = 1.0));\n  (assert ((candidate 10 10) = 1.0));\n  (assert ((candidate 10 5) = 0.5));\n  (assert ((candidate 100 10) = 0.1));\n  (assert ((candidate 4 2) = 0.5));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_165045__test", "language": "ml", "prompt": "(**Miller-Rabin strong pseudoprime test for one base.\nReturn False if n is definitely composite, True if n is\nprobably prime, with a probability greater than 3/4.\n*)\nlet _test (n : int) (base : int) (s : int) (t : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_165045__test.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _test in\n  (assert ((candidate 33 7 1 1) = false));\n  (assert ((candidate 341 5 10 3) = false));\n  (assert ((candidate 15 2 1 1) = false));\n  (assert ((candidate 1341 3 2 3) = false));\n  (assert ((candidate 2 3 1 1) = true));\n  (assert ((candidate 41 2 1 4) = false));\n  (assert ((candidate 341 3 2 4) = false));\n  (assert ((candidate 65 2 1 1) = false));\n  (assert ((candidate 41 2 5 3) = false));\n  (assert ((candidate 341 3 2 3) = false));\n  (assert ((candidate 130 2 1 1) = false));\n  (assert ((candidate 3 19 1 2) = true));\n  (assert ((candidate 3 11 1 2) = true));\n  (assert ((candidate 64 2 1 1) = false));\n  (assert ((candidate 5 3 1 3) = false));\n  (assert ((candidate 6 3 1 3) = false));\n  (assert ((candidate 341 3 10 3) = false));\n  (assert ((candidate 129 2 1 1) = false));\n  (assert ((candidate 15 7 1 1) = false));\n  (assert ((candidate 5 2 1 1) = false));\n  (assert ((candidate 9 7 1 1) = false));\n  (assert ((candidate 1341 5 10 3) = false));\n  (assert ((candidate 33 2 1 1) = false));\n  (assert ((candidate 341 2 10 3) = false));\n  (assert ((candidate 1341 2 10 3) = false));\n  (assert ((candidate 128 2 1 1) = false));\n  (assert ((candidate 11 2 1 1) = false));\n  (assert ((candidate 2 2 1 1) = false));\n  (assert ((candidate 7 3 1 3) = true));\n  (assert ((candidate 102 2 1 1) = false));\n  (assert ((candidate 1341 3 10 3) = false));\n  (assert ((candidate 6 2 1 1) = false));\n  (assert ((candidate 41 2 1 3) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_165051__convert_from_F", "language": "ml", "prompt": "(**Convert F temp to C\nparam temp: temp in F to convert\nreturn: float\n*)\nlet _convert_from_F (temp : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_165051__convert_from_F.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _convert_from_F in\n  (assert ((candidate 90.0) = 32.2));\n  (assert ((candidate 212.0) = 100.0));\n  (assert ((candidate 32.0) = 0.0));\n  (assert ((candidate 212.0) = 100.0));\n  (assert ((candidate 70.0) = 21.1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_165396_rgb_to_hex", "language": "ml", "prompt": "(**[255,255,255] -> \"#FFFFFF\"\n*)\nlet rgb_to_hex (rgb : int list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_165396_rgb_to_hex.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = rgb_to_hex in\n  (assert ((candidate [0; 0; 0]) = \"#000000\"));\n  (assert ((candidate [1; 2; 3]) = \"#010203\"));\n  (assert ((candidate [0; 0; 0]) = \"#000000\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_165487_get_uce_name", "language": "ml", "prompt": "(**use own function vs. import from match_contigs_to_probes - we don't want lowercase\n*)\nlet get_uce_name (header : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_165487_get_uce_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_uce_name in\n  (assert ((candidate \">uce-1_1202_10807_10836_2401_2430_0_0_0\") = \"uce-1\"));\n  (assert ((candidate \">uce-1 1202 10807 10836 2401 2430 0 0 0.000000 0.000000\") = \"uce-1\"));\n  (assert ((candidate \">uce-1 1202 10807 10836 2401 2430 0 0 0\") = \"uce-1\"));\n  (assert ((candidate \">uce-1_1202_10807_10836_2401_2430_0_0_0 1213 1389\") = \"uce-1\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_16588_rst_heading", "language": "ml", "prompt": "(**Provides an underline for restructured text heading.\nSyntax::\n * {{ value|rst_heading:\"=\" }}\nResults in:\n``value``\n``=====``\n*)\nlet rst_heading (value : string) (arg : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_16588_rst_heading.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = rst_heading in\n  (assert ((candidate \"value\" \"=\") = candidate \"value\" \"=\"));\n  (assert ((candidate \"value\" \"=\") = \"value\n=====\"));\n  (assert ((candidate \"foo bar\" \"*\") = \"foo bar\n*******\"));\n  (assert ((candidate \"value\" \"=\") = candidate \"value\" \"=\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_16590_format_time", "language": "ml", "prompt": "(**Defines how to format time in FunctionEvent\n*)\nlet format_time (time_us : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_16590_format_time.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = format_time in\n  (assert ((candidate 0) = \"0.000us\"));\n  (assert ((candidate 10) = \"10.000us\"));\n  (assert ((candidate 1) = \"1.000us\"));\n  (assert ((candidate 100) = \"100.000us\"));\n  (assert ((candidate 123456) = \"123.456ms\"));\n  (assert ((candidate 123) = \"123.000us\"));\n  (assert ((candidate 123456789) = \"123.457s\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_167250_det_matriz", "language": "ml", "prompt": "(**Calcula a determinante de uma matriz\n*)\nlet det_matriz (matriz : int list list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_167250_det_matriz.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = det_matriz in\n  (assert ((candidate [[1; 2; 3; 4]; [5; 6; 7; 8]; [9; 10; 11; 12]; [13; 14; 15; 16]]) = 0));\n  (assert ((candidate [[0; 2; 3]; [0; 4; 5]; [0; 0; 6]]) = 0));\n  (assert ((candidate [[1; 2]; [3; 4]]) = (~2)));\n  (assert ((candidate [[1; 2; 3; 4]; [3; 4; 5; 6]; [5; 6; 7; 8]; [7; 8; 9; 10]]) = 0));\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]; [7; 8; 9]]) = 0));\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]; [7; 8; 9]]) = 0));\n  (assert ((candidate [[2; 2; 2; 2]; [2; 2; 2; 2]; [2; 2; 2; 2]; [2; 2; 2; 2]]) = 0));\n  (assert ((candidate [[1; 2; 3; 4]; [5; 6; 7; 8]; [9; 10; 11; 12]; [13; 14; 15; 16]]) = 0));\n  (assert ((candidate [[1; 2; 3]; [1; 2; 3]; [1; 2; 3]]) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_167319_build_years_list", "language": "ml", "prompt": "(**create a list of 10 years counting backward from the start year\n*)\nlet build_years_list (start : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_167319_build_years_list.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = build_years_list in\n  (assert ((candidate 2017) = [2017; 2016; 2015; 2014; 2013; 2012; 2011; 2010; 2009; 2008]));\n  (assert ((candidate 2012) = [2012; 2011; 2010; 2009; 2008; 2007; 2006; 2005; 2004; 2003]));\n  (assert ((candidate 1995) = [1995; 1994; 1993; 1992; 1991; 1990; 1989; 1988; 1987; 1986]));\n  (assert ((candidate 2021) = [2021; 2020; 2019; 2018; 2017; 2016; 2015; 2014; 2013; 2012]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_167707_validate_ticket_name", "language": "ml", "prompt": "(**validate that the ticket name is valid\n:param name: the name of the ticket\n:return: an error message (if any) or nothing if the ticket name is in the correct format\n*)\nlet validate_ticket_name (name : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_167707_validate_ticket_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = validate_ticket_name in\n  (assert ((candidate \" \") = [\"Ticket name cannot begin/end with a space\"]));\n  (assert ((candidate \"hello@world\") = [\"Ticket name must be alphanumeric only\"]));\n  (assert ((candidate \"Hello \") = [\"Ticket name cannot begin/end with a space\"]));\n  (assert ((candidate \"Hello World\") = []));\n  (assert ((candidate \"hello world\") = []));\n  (assert ((candidate \"0123456789012345678901234567890123456789012345678901234567890\") = [\"Ticket name exceeds character limit (60)\"]));\n  (assert ((candidate \"\") = [\"Ticket name must contain at least (1) character\"]));\n  (assert ((candidate \"012345678901234567890123456789012345678901234567890123456789\") = []));\n  (assert ((candidate \" Hello\") = [\"Ticket name cannot begin/end with a space\"]));\n  (assert ((candidate \"Ticket$100\") = [\"Ticket name must be alphanumeric only\"]));\n  (assert ((candidate \"\") = [\"Ticket name must contain at least (1) character\"]));\n  (assert ((candidate \"\") = [\"Ticket name must contain at least (1) character\"]));\n  (assert ((candidate \"123456789012345678901234567890\") = []));\n  (assert ((candidate \"Hello, World\") = [\"Ticket name must be alphanumeric only\"]));\n  (assert ((candidate \"Hello World!\") = [\"Ticket name must be alphanumeric only\"]));\n  (assert ((candidate \"hello world \") = [\"Ticket name cannot begin/end with a space\"]));\n  (assert ((candidate \"hello+world\") = [\"Ticket name must be alphanumeric only\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_168621_create_new_id", "language": "ml", "prompt": "(**Create a new unique id for the record to be added.\n*)\nlet create_new_id (region : string) (last_id_number : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_168621_create_new_id.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = create_new_id in\n  (assert ((candidate \"North Carolina\" 2499) = \"North Carolina2500\"));\n  (assert ((candidate \"New York\" 5999) = \"New York6000\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_169552_is_group", "language": "ml", "prompt": "(**Return ``True`` if passed object is Group and ``False`` otherwise.\n*)\nlet is_group (group : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_169552_is_group.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_group in\n  (assert ((candidate 10) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_169608_address_fixup", "language": "ml", "prompt": "(**Some Kern Co. addresses have typos.\n*)\nlet address_fixup (a : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_169608_address_fixup.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = address_fixup in\n  (assert ((candidate candidate \"3225 PANAMA LANE, BAKERSFIELD, CA 93313\") = \"3225 PANAMA LANE, BAKERSFIELD, CA 93313\"));\n  (assert ((candidate candidate \"3500 Stine Rd, Bakersfield, CA 93309\") = \"3500 Stine Rd, Bakersfield, CA 93309\"));\n  (assert ((candidate \"2901 Silent Ave Suite 201, Bakersfield, CA 93308\") = \"2901 Sillect Ave Suite 201, Bakersfield, CA 93308\"));\n  (assert ((candidate candidate \"2901 Sillect Ave Suite 201, Bakersfield, CA 93308\") = \"2901 Sillect Ave Suite 201, Bakersfield, CA 93308\"));\n  (assert ((candidate candidate \"3300 Buena Vista Rd Bldg A, Bakersfield, CA 93311\") = \"3300 Buena Vista Rd Bldg A, Bakersfield, CA 93311\"));\n  (assert ((candidate \"3500 Stine Rd Bakersfield, Bakersfield, CA 93309\") = \"3500 Stine Rd, Bakersfield, CA 93309\"));\n  (assert ((candidate \"3300 BUENA VISTA RD A, Bakersfield, CA 93311\") = \"3300 Buena Vista Rd Bldg A, Bakersfield, CA 93311\"));\n  (assert ((candidate candidate \"8000 WHITE LANE, BAKERSFIELD, CA 93309\") = \"8000 WHITE LANE, BAKERSFIELD, CA 93309\"));\n  (assert ((candidate \"8000 WHITE LANE, Bakersfield, CA 93301\") = \"8000 WHITE LANE, BAKERSFIELD, CA 93309\"));\n  (assert ((candidate \"3500 Stine Rd Bakersfield, Bakersfield, CA 93309\") = \"3500 Stine Rd, Bakersfield, CA 93309\"));\n  (assert ((candidate \"Rite Aid Store 06303, Bakersfield, CA 93313\") = \"3225 PANAMA LANE, BAKERSFIELD, CA 93313\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_170197_mask_to_cidr", "language": "ml", "prompt": "(**Convert netmask in dot-notation to decimal CIDR notation\n*)\nlet mask_to_cidr (netmask : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_170197_mask_to_cidr.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = mask_to_cidr in\n  (assert ((candidate \"255.255.248.128\") = 22));\n  (assert ((candidate \"255.255.255.0\") = 24));\n  (assert ((candidate \"255.255.192.128\") = 19));\n  (assert ((candidate \"255.255.255.252\") = 30));\n  (assert ((candidate \"255.255.240.128\") = 21));\n  (assert ((candidate \"255.255.0.0\") = 16));\n  (assert ((candidate \"255.255.240.0\") = 20));\n  (assert ((candidate \"255.255.252.128\") = 23));\n  (assert ((candidate \"255.255.192.0\") = 18));\n  (assert ((candidate \"255.255.248.0\") = 21));\n  (assert ((candidate \"255.255.252.0\") = 22));\n  (assert ((candidate \"255.255.255.0\") = 24));\n  (assert ((candidate \"255.255.255.255\") = 32));\n  (assert ((candidate \"255.255.255.128\") = 25));\n  (assert ((candidate \"255.0.0.0\") = 8));\n  (assert ((candidate \"255.255.254.128\") = 24));\n  (assert ((candidate \"255.255.254.0\") = 23));\n  (assert ((candidate \"255.255.224.0\") = 19));\n  (assert ((candidate \"255.255.224.128\") = 20));\n  (assert ((candidate \"255.255.255.0\") = 24));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_170431_prelogin_url", "language": "ml", "prompt": "(**Fetches the correct dimagi.com url for a \"prelogin\" view.\n*)\nlet prelogin_url (urlname : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_170431_prelogin_url.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = prelogin_url in\n  (assert ((candidate \"public_pricing\") = \"https://dimagi.com/commcare/pricing/\"));\n  (assert ((candidate \"go_to_pricing\") = \"https://dimagi.com/commcare/pricing/\"));\n  (assert ((candidate \"https://dimagi.com/commcare/\") = \"https://dimagi.com/commcare/\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_170606_gcd_modulus", "language": "ml", "prompt": "(**finds the GCD of a and b\nArgs:\n * a, b: non-negative integers\nReturns:\n * int: the GCD of a and b\n*)\nlet gcd_modulus (a : int) (b : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_170606_gcd_modulus.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = gcd_modulus in\n  (assert ((candidate 1 1) = 1));\n  (assert ((candidate 92 14) = 2));\n  (assert ((candidate 69 19) = 1));\n  (assert ((candidate 0 0) = 0));\n  (assert ((candidate 3 2) = 1));\n  (assert ((candidate 2 9) = 1));\n  (assert ((candidate 1 0) = 1));\n  (assert ((candidate 1000 10) = 10));\n  (assert ((candidate 29 51) = 1));\n  (assert ((candidate 4 19) = 1));\n  (assert ((candidate 3 7) = 1));\n  (assert ((candidate 89 46) = 1));\n  (assert ((candidate 3 4) = 1));\n  (assert ((candidate 12 10) = 2));\n  (assert ((candidate 0 10) = 10));\n  (assert ((candidate 1000 0) = 1000));\n  (assert ((candidate 37 53) = 1));\n  (assert ((candidate 1000000000 1000000001) = 1));\n  (assert ((candidate 5 81) = 1));\n  (assert ((candidate 82 90) = 2));\n  (assert ((candidate 2 1) = 1));\n  (assert ((candidate 89 77) = 1));\n  (assert ((candidate 70 97) = 1));\n  (assert ((candidate 12 6) = 6));\n  (assert ((candidate 42 56) = 14));\n  (assert ((candidate 42 6) = 6));\n  (assert ((candidate 93 22) = 1));\n  (assert ((candidate 2 8) = 2));\n  (assert ((candidate 48 18) = 6));\n  (assert ((candidate 10 5) = 5));\n  (assert ((candidate 10 100) = 10));\n  (assert ((candidate 4 2) = 2));\n  (assert ((candidate 96 22) = 2));\n  (assert ((candidate 2 4) = 2));\n  (assert ((candidate 2 6) = 2));\n  (assert ((candidate 6 24) = 6));\n  (assert ((candidate 100 5) = 5));\n  (assert ((candidate 38 17) = 1));\n  (assert ((candidate 2 2) = 2));\n  (assert ((candidate 1 2) = 1));\n  (assert ((candidate 29 90) = 1));\n  (assert ((candidate 73 88) = 1));\n  (assert ((candidate 5 6) = 1));\n  (assert ((candidate 4 3) = 1));\n  (assert ((candidate 1000000000 1000000000) = 1000000000));\n  (assert ((candidate 11 49) = 1));\n  (assert ((candidate 0 1) = 1));\n  (assert ((candidate 15 20) = 5));\n  (assert ((candidate 1000000001 1000000000) = 1));\n  (assert ((candidate 4 8) = 4));\n  (assert ((candidate 5 2) = 1));\n  (assert ((candidate 10 0) = 10));\n  (assert ((candidate 10 1000) = 10));\n  (assert ((candidate 100 10) = 10));\n  (assert ((candidate 4 9) = 1));\n  (assert ((candidate 12 18) = 6));\n  (assert ((candidate 2 5) = 1));\n  (assert ((candidate 3 6) = 3));\n  (assert ((candidate 3 9) = 3));\n  (assert ((candidate 3 8) = 1));\n  (assert ((candidate 4 5) = 1));\n  (assert ((candidate 5 4) = 1));\n  (assert ((candidate 4 6) = 2));\n  (assert ((candidate 2 3) = 1));\n  (assert ((candidate 20 12) = 4));\n  (assert ((candidate 41 69) = 1));\n  (assert ((candidate 5 10) = 5));\n  (assert ((candidate 12 30) = 6));\n  (assert ((candidate 2 7) = 1));\n  (assert ((candidate 100 12) = 4));\n  (assert ((candidate 4 7) = 1));\n  (assert ((candidate 8 4) = 4));\n  (assert ((candidate 97 7) = 1));\n  (assert ((candidate 0 1000) = 1000));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_171423_greatest_common_divisor", "language": "ml", "prompt": "(**Function to calculate the greatest common divisor\n*)\nlet greatest_common_divisor (a : int) (b : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_171423_greatest_common_divisor.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = greatest_common_divisor in\n  (assert ((candidate 30 10) = 10));\n  (assert ((candidate 54 24) = 6));\n  (assert ((candidate 2 6) = 2));\n  (assert ((candidate 1 10) = 1));\n  (assert ((candidate 10 15) = 5));\n  (assert ((candidate 20 10) = 10));\n  (assert ((candidate 123 45) = 3));\n  (assert ((candidate 100 10) = 10));\n  (assert ((candidate 1000000 4000000000) = 1000000));\n  (assert ((candidate 10 1) = 1));\n  (assert ((candidate 5 10) = 5));\n  (assert ((candidate 3 15) = 3));\n  (assert ((candidate 20 30) = 10));\n  (assert ((candidate 100 100) = 100));\n  (assert ((candidate 100 25) = 25));\n  (assert ((candidate 6 15) = 3));\n  (assert ((candidate 15 5) = 5));\n  (assert ((candidate 2 3) = 1));\n  (assert ((candidate 25 100) = 25));\n  (assert ((candidate 2 4) = 2));\n  (assert ((candidate 7 3) = 1));\n  (assert ((candidate 25 25) = 25));\n  (assert ((candidate 5 2) = 1));\n  (assert ((candidate 4000000000 1000000) = 1000000));\n  (assert ((candidate 4 6) = 2));\n  (assert ((candidate 30 20) = 10));\n  (assert ((candidate 10 30) = 10));\n  (assert ((candidate 234567 89) = 1));\n  (assert ((candidate 3 5) = 1));\n  (assert ((candidate 10 5) = 5));\n  (assert ((candidate 1 1) = 1));\n  (assert ((candidate 15 20) = 5));\n  (assert ((candidate 20 15) = 5));\n  (assert ((candidate 10 100) = 10));\n  (assert ((candidate 2 1) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_171452_normalize", "language": "ml", "prompt": "(**Normalizes whitespace in a specified string of text.\n*)\nlet normalize (text : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_171452_normalize.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = normalize in\n  (assert ((candidate \"I   \t\t\n love\n\n\nthis course!\") = \"I love this course!\"));\n  (assert ((candidate \"This is a test!\") = \"This is a test!\"));\n  (assert ((candidate \"I love this        course!\") = \"I love this course!\"));\n  (assert ((candidate \"The  quick   brown      fox    jumps over the lazy dog.\") = \"The quick brown fox jumps over the lazy dog.\"));\n  (assert ((candidate \"I love\n\n\n\n        this\n\n\n\n\n        course!\") = \"I love this course!\"));\n  (assert ((candidate \"I love this\n        course!\") = \"I love this course!\"));\n  (assert ((candidate \"I love this course!\") = \"I love this course!\"));\n  (assert ((candidate \"I   \t\t\n love this course!\") = \"I love this course!\"));\n  (assert ((candidate \"This is a test?\") = \"This is a test?\"));\n  (assert ((candidate \"This is a test.\") = \"This is a test.\"));\n  (assert ((candidate \"  I love this course!  \") = \"I love this course!\"));\n  (assert ((candidate \" I love this course!\") = \"I love this course!\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_171829_obter_pos_c", "language": "ml", "prompt": "(**obter_pos_c: posicao -> str\nEsta funcao devolve a componente coluna da posicao.\n*)\nlet obter_pos_c (pos :  int * int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_171829_obter_pos_c.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = obter_pos_c in\n  (assert ((candidate (3, 3)) = \"c\"));\n  (assert ((candidate (9, 9)) = \"c\"));\n  (assert ((candidate (2, 2)) = \"b\"));\n  (assert ((candidate (6, 6)) = \"c\"));\n  (assert ((candidate (1, 1)) = \"a\"));\n  (assert ((candidate (5, 5)) = \"b\"));\n  (assert ((candidate (7, 7)) = \"a\"));\n  (assert ((candidate (4, 4)) = \"a\"));\n  (assert ((candidate (8, 8)) = \"b\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_1724_map", "language": "ml", "prompt": "(**Map a value from one range to another\n:param in_min: minimum of input range\n:param in_max: maximum of input range\n:param out_min: minimum of output range\n:param out_max: maximum of output range\n:return: The value scaled to the new range\n:rtype: int\n*)\nlet map (x : int) (in_min : int) (in_max : int) (out_min : int) (out_max : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_1724_map.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = map in\n  (assert ((candidate 100 100 0 1 10) = 1));\n  (assert ((candidate 100 0 100 0 100) = 100));\n  (assert ((candidate (~100) (~100) 100 0 100) = 0));\n  (assert ((candidate 0 0 100 0 100) = 0));\n  (assert ((candidate 99 0 99 0 100) = 100));\n  (assert ((candidate 10 0 10 0 10) = 10));\n  (assert ((candidate 1 0 10 1 10) = 1));\n  (assert ((candidate 8 0 10 0 10) = 8));\n  (assert ((candidate 50 0 100 (~100) 100) = 0));\n  (assert ((candidate 50 0 100 0 200) = 100));\n  (assert ((candidate 9 0 10 0 10) = 9));\n  (assert ((candidate 3 0 10 0 10) = 3));\n  (assert ((candidate 1 0 10 0 10) = 1));\n  (assert ((candidate (~100) (~100) 100 0 200) = 0));\n  (assert ((candidate 1 0 10 1 20) = 2));\n  (assert ((candidate 2 0 10 0 10) = 2));\n  (assert ((candidate 0 0 10 0 10) = 0));\n  (assert ((candidate 1 0 10 10 0) = 9));\n  (assert ((candidate 3 0 10 1 20) = 6));\n  (assert ((candidate 4 0 10 1 20) = 8));\n  (assert ((candidate 2 0 10 1 20) = 4));\n  (assert ((candidate 10 10 0 1 10) = 1));\n  (assert ((candidate 42 0 100 0 100) = 42));\n  (assert ((candidate 50 0 100 0 100) = 50));\n  (assert ((candidate 4 0 10 0 10) = 4));\n  (assert ((candidate 5 0 10 1 20) = 10));\n  (assert ((candidate 1 0 1 0 100) = 100));\n  (assert ((candidate 100 0 100 1 10) = 10));\n  (assert ((candidate 5 0 10 0 10) = 5));\n  (assert ((candidate 6 0 10 0 10) = 6));\n  (assert ((candidate 7 0 10 0 10) = 7));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_172573_replace_word_choice", "language": "ml", "prompt": "(**Replace a word in the provided sentence with a new one.\n:param sentence: str - a sentence to replace words in.\n:param old_word: str - word to replace.\n:param new_word: str - replacement word.\n:return: str - input sentence with new words in place of old words.\n*)\nlet replace_word_choice (sentence : string) (old_word : string) (new_word : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_172573_replace_word_choice.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = replace_word_choice in\n  (assert ((candidate \"The rain in Spain falls mainly on the plain.\" \"plain\" \"lake\") = \"The rain in Spain falls mainly on the lake.\"));\n  (assert ((candidate \"There was a girl with a telescope\" \"robot\" \"girl\") = \"There was a girl with a telescope\"));\n  (assert ((candidate \"I'm so happy to have you here.\" \"happy\" \"excited\") = \"I'm so excited to have you here.\"));\n  (assert ((candidate \"I am so happy\" \"happy\" \"glad\") = \"I am so glad\"));\n  (assert ((candidate \"There was a girl with a telescope\" \"girl\" \"robot\") = \"There was a robot with a telescope\"));\n  (assert ((candidate \"There was a girl with a telescope\" \"telescope\" \"robot\") = \"There was a girl with a robot\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_172804_to_rtl", "language": "ml", "prompt": "(**Modifies a path to look like the RTL net/register names\n*)\nlet to_rtl (path : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_172804_to_rtl.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = to_rtl in\n  (assert ((candidate \"net_a.field_b.field_c\") = \"net_a_field_b_field_c\"));\n  (assert ((candidate \"net_a.field_b.field_c.field_d.field_e.field_f\") = \"net_a_field_b_field_c_field_d_field_e_field_f\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_172880_get_key", "language": "ml", "prompt": "(**Return the first key in the dictionary \"dict\" that contains the\nreceived value \"value\".\nParameters\n==========\ndict: Dict[Any, Any]\n * Dictionary to be used.\nvalue: Any\n * Value to be found in the dictionary.\n*)\nlet get_key (dict : (string, int) list) (value : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_172880_get_key.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_key in\n  (assert ((candidate [(\"a\", 0); (\"b\", 1); (\"c\", 2)] 2) = \"c\"));\n  (assert ((candidate [(\"a\", 1); (\"b\", 0); (\"c\", 0)] 0) = \"b\"));\n  (assert ((candidate [(\"a\", 0); (\"b\", 1); (\"c\", 0)] 0) = \"a\"));\n  (assert ((candidate [(\"1\", 1)] 1) = \"1\"));\n  (assert ((candidate [(\"1\", 1); (\"2\", 2)] 1) = \"1\"));\n  (assert ((candidate [(\"a\", 0); (\"b\", 0); (\"c\", 1)] 1) = \"c\"));\n  (assert ((candidate [(\"1\", 1); (\"2\", 2)] 2) = \"2\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_173041__get_authority_url", "language": "ml", "prompt": "(**Convert authority endpoint (active_directory) to MSAL authority:\n- AAD: https://login.microsoftonline.com/your_tenant\n- ADFS: https://adfs.redmond.azurestack.corp.microsoft.com/adfs\n * For ADFS, tenant is discarded.\n*)\nlet _get_authority_url (authority_endpoint : string) (tenant : string option) :  string * bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_173041__get_authority_url.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _get_authority_url in\n  (assert ((candidate \"https://login.microsoftonline.com\" Some(None)) = (\"https://login.microsoftonline.com/organizations\", false)));\n  (assert ((candidate \"https://login.microsoftonline.com/\" Some(None)) = (\"https://login.microsoftonline.com/organizations\", false)));\n  (assert ((candidate \"https://login.microsoftonline.com/\" Some(\"common\")) = (\"https://login.microsoftonline.com/common\", false)));\n  (assert ((candidate \"https://login.microsoftonline.com\" Some(\"common\")) = (\"https://login.microsoftonline.com/common\", false)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_173554_part_one", "language": "ml", "prompt": "(**Part one\n*)\nlet part_one (data : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_173554_part_one.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = part_one in\n  (assert ((candidate \"1122\") = 3));\n  (assert ((candidate \"91212129\") = 9));\n  (assert ((candidate \"1234\") = 0));\n  (assert ((candidate \"1111\") = 4));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_17433_get_max", "language": "ml", "prompt": "(**compare two input numbers, and return bigger one.\n:param current_max: int, the current max score.\n:param input_score: int, the score just input.\n:return: int, compare two numbers and return bigger one.\n*)\nlet get_max (current_max : int) (input_score : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_17433_get_max.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_max in\n  (assert ((candidate 10 1) = 10));\n  (assert ((candidate 1 2) = 2));\n  (assert ((candidate 15 15) = 15));\n  (assert ((candidate 0 1) = 1));\n  (assert ((candidate 10 0) = 10));\n  (assert ((candidate 0 0) = 0));\n  (assert ((candidate 10 15) = 15));\n  (assert ((candidate 10 10) = 10));\n  (assert ((candidate 1 1) = 1));\n  (assert ((candidate 3 5) = 5));\n  (assert ((candidate (~1) 2) = 2));\n  (assert ((candidate 2 (~1)) = 2));\n  (assert ((candidate 15 10) = 15));\n  (assert ((candidate 1 0) = 1));\n  (assert ((candidate 2 1) = 2));\n  (assert ((candidate 0 10) = 10));\n  (assert ((candidate 5 10) = 10));\n  (assert ((candidate 1 10) = 10));\n  (assert ((candidate 10 5) = 10));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_174589_ngrams", "language": "ml", "prompt": "(**Return min_n to max_n n-grams of elements from a given sequence.\n*)\nlet ngrams (seq : string) (min_n : int) (max_n : int) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_174589_ngrams.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = ngrams in\n  (assert ((candidate \"Hello\" 6 6) = []));\n  (assert ((candidate \"abcde\" 1 1) = [\"a\"; \"b\"; \"c\"; \"d\"; \"e\"]));\n  (assert ((candidate \"abcd\" 1 1) = [\"a\"; \"b\"; \"c\"; \"d\"]));\n  (assert ((candidate \"abcd\" 1 2) = [\"a\"; \"b\"; \"c\"; \"d\"; \"ab\"; \"bc\"; \"cd\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_175069__link_environment", "language": "ml", "prompt": "(**Generate the environment variables used for defining a docker link.\nDocker containers expect an enviroment variable\n`<alias>_PORT_<local_port>_TCP`` which contains the URL of the remote end\nof a link, as well as parsed variants ``_ADDR``, ``_PORT``, ``_PROTO``.\n:param unicode protocol: The protocol used for the link.\n:param unicode alias: The name of the link.\n:param int local_port: The port the local application expects to access.\n:param unicode hostname: The remote hostname to connect to.\n:param int remote_port: The remote port to connect to.\n*)\nlet _link_environment (protocol : string) (alias : string) (local_port : int) (hostname : string) (remote_port : int) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_175069__link_environment.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _link_environment in\n  (assert ((candidate \"udp\" \"ALIAS\" 123 \"HOST\" 456) = [(\"ALIAS_PORT_123_UDP\", \"udp://HOST:456\"); (\"ALIAS_PORT_123_UDP_ADDR\", \"HOST\"); (\"ALIAS_PORT_123_UDP_PORT\", \"456\"); (\"ALIAS_PORT_123_UDP_PROTO\", \"udp\")]));\n  (assert ((candidate \"tcp\" \"ALIAS\" 123 \"10.0.0.1\" 456) = [(\"ALIAS_PORT_123_TCP\", \"tcp://10.0.0.1:456\"); (\"ALIAS_PORT_123_TCP_ADDR\", \"10.0.0.1\"); (\"ALIAS_PORT_123_TCP_PORT\", \"456\"); (\"ALIAS_PORT_123_TCP_PROTO\", \"tcp\")]));\n  (assert ((candidate \"tcp\" \"ALIAS\" 123 \"HOST\" 456) = [(\"ALIAS_PORT_123_TCP\", \"tcp://HOST:456\"); (\"ALIAS_PORT_123_TCP_ADDR\", \"HOST\"); (\"ALIAS_PORT_123_TCP_PORT\", \"456\"); (\"ALIAS_PORT_123_TCP_PROTO\", \"tcp\")]));\n  (assert ((candidate \"tcp\" \"bar\" 8080 \"foo\" 5000) = [(\"BAR_PORT_8080_TCP\", \"tcp://foo:5000\"); (\"BAR_PORT_8080_TCP_ADDR\", \"foo\"); (\"BAR_PORT_8080_TCP_PORT\", \"5000\"); (\"BAR_PORT_8080_TCP_PROTO\", \"tcp\")]));\n  (assert ((candidate \"tcp\" \"name\" 5000 \"hostname\" 5001) = [(\"NAME_PORT_5000_TCP\", \"tcp://hostname:5001\"); (\"NAME_PORT_5000_TCP_ADDR\", \"hostname\"); (\"NAME_PORT_5000_TCP_PORT\", \"5001\"); (\"NAME_PORT_5000_TCP_PROTO\", \"tcp\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_176136_array_reverse_order_transform_next_index_to_current_index", "language": "ml", "prompt": "(**Transforms the position depending on the move.\nWorks with the array_swap move type.\nThis function transforms the position so that it can be used as the indice\nin the unaltered array, yet return the value it would have had if the move\nwas actually performed and the position was used as indice.\nParameters\n----------\nposition : int\n * The index that one wants to use in the array if the move was performed.\nmove : tuple of int\n * A tuple with that represents a single, unique move.\nReturns\n-------\nint\n * The index in the unaltered array that has the same value as the\n * location in an array where the move was performed.\nExamples\n--------\nSome simple examples, the move remains the same, but the position changes:\n.. doctest::\n * >>> from lclpy.evaluation.deltaeval.delta_qap \\\n * ...     import array_reverse_order_transform_next_index_to_current_index \\\n * ...         as transform_next_index_to_current_index\n * ... # tests\n * >>> transform_next_index_to_current_index(0, (1, 4))\n * 0\n * >>> transform_next_index_to_current_index(1, (1, 4))\n * 4\n * >>> transform_next_index_to_current_index(2, (1, 4))\n * 3\n * >>> transform_next_index_to_current_index(3, (1, 4))\n * 2\n * >>> transform_next_index_to_current_index(4, (1, 4))\n * 1\n * >>> transform_next_index_to_current_index(5, (1, 4))\n * 5\n*)\nlet array_reverse_order_transform_next_index_to_current_index (position : int) (move :  int * int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_176136_array_reverse_order_transform_next_index_to_current_index.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = array_reverse_order_transform_next_index_to_current_index in\n  (assert ((candidate 5 (1, 4)) = 5));\n  (assert ((candidate 2 (1, 4)) = 3));\n  (assert ((candidate 0 (1, 4)) = 0));\n  (assert ((candidate 4 (1, 4)) = 1));\n  (assert ((candidate 1 (1, 4)) = 4));\n  (assert ((candidate 3 (1, 4)) = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_176194_other_classes", "language": "ml", "prompt": "(**Returns a list of class indices excluding the class indexed by class_ind\n:param nb_classes: number of classes in the task\n:param class_ind: the class index to be omitted\n:return: list of class indices excluding the class indexed by class_ind\n*)\nlet other_classes (nb_classes : int) (class_ind : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_176194_other_classes.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = other_classes in\n  (assert ((candidate 10 3) = [0; 1; 2; 4; 5; 6; 7; 8; 9]));\n  (assert ((candidate 5 2) = [0; 1; 3; 4]));\n  (assert ((candidate 6 2) = [0; 1; 3; 4; 5]));\n  (assert ((candidate 5 1) = [0; 2; 3; 4]));\n  (assert ((candidate 5 4) = [0; 1; 2; 3]));\n  (assert ((candidate 3 2) = [0; 1]));\n  (assert ((candidate 2 1) = [0]));\n  (assert ((candidate 3 0) = [1; 2]));\n  (assert ((candidate 2 0) = [1]));\n  (assert ((candidate 5 3) = [0; 1; 2; 4]));\n  (assert ((candidate 8 4) = [0; 1; 2; 3; 5; 6; 7]));\n  (assert ((candidate 4 1) = [0; 2; 3]));\n  (assert ((candidate 3 1) = [0; 2]));\n  (assert ((candidate 5 0) = [1; 2; 3; 4]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_17889_clean_query_string", "language": "ml", "prompt": "(**Cleans string of ' 's and 's\n*)\nlet clean_query_string (string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_17889_clean_query_string.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = clean_query_string in\n  (assert ((candidate \"Hello%20World\") = \"Hello%20World\"));\n  (assert ((candidate \"Hello%2C+World\") = \"Hello%2C+World\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_179175_partition_2", "language": "ml", "prompt": "(**partition array a[l..r]\nPivot: Use the last element of the array. Swap with the first element.\n*)\nlet partition_2 (a : int list) (l : int) (r : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_179175_partition_2.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = partition_2 in\n  (assert ((candidate [1; 2; 3; 4; 5] 0 4) = 4));\n  (assert ((candidate [3; 1; 2; 5; 4; 6] 0 3) = 3));\n  (assert ((candidate [1; 4; 2; 3] 0 3) = 2));\n  (assert ((candidate [3; 1; 2; 5; 4; 6] 0 4) = 3));\n  (assert ((candidate list range 20 0 19) = 19));\n  (assert ((candidate [1; 2; 3; 4; 5] 0 3) = 3));\n  (assert ((candidate [4; 3; 2; 1] 0 3) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_180440_dir_filter", "language": "ml", "prompt": "(**Accept each item which doesn't start with _\n:type item: str\n:param item: a string item to filter\n:return: true if item doesn't start with _\n*)\nlet dir_filter (item : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_180440_dir_filter.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = dir_filter in\n  (assert ((candidate \"1\") = true));\n  (assert ((candidate \"foo/_bar.py\") = true));\n  (assert ((candidate \"___\") = false));\n  (assert ((candidate \"_____\") = false));\n  (assert ((candidate \"_foo.py\") = false));\n  (assert ((candidate \"a\") = true));\n  (assert ((candidate \"____\") = false));\n  (assert ((candidate \"a_1\") = true));\n  (assert ((candidate \"foo.py\") = true));\n  (assert ((candidate \"_\") = false));\n  (assert ((candidate \"a1\") = true));\n  (assert ((candidate \"_foo/_bar.py\") = false));\n  (assert ((candidate \"_1\") = false));\n  (assert ((candidate \"________\") = false));\n  (assert ((candidate \"__\") = false));\n  (assert ((candidate \"_______\") = false));\n  (assert ((candidate \"not_underscore\") = true));\n  (assert ((candidate \"_\") = false));\n  (assert ((candidate \"__init__.py\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_180566_factorial", "language": "ml", "prompt": "(**Return factorial of number.\n*)\nlet factorial (number : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_180566_factorial.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = factorial in\n  (assert ((candidate 8) = 40320));\n  (assert ((candidate 5) = 120));\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 16) = 20922789888000));\n  (assert ((candidate 17) = 355687428096000));\n  (assert ((candidate 20) = 2432902008176640000));\n  (assert ((candidate 4) = 24));\n  (assert ((candidate 11) = 39916800));\n  (assert ((candidate 0) = 1));\n  (assert ((candidate 12) = 479001600));\n  (assert ((candidate 10) = 3628800));\n  (assert ((candidate 19) = 121645100408832000));\n  (assert ((candidate 15) = 1307674368000));\n  (assert ((candidate 13) = 6227020800));\n  (assert ((candidate 9) = 362880));\n  (assert ((candidate 18) = 6402373705728000));\n  (assert ((candidate 3) = 6));\n  (assert ((candidate 6) = 720));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 14) = 87178291200));\n  (assert ((candidate 7) = 5040));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_180620_compute_iou", "language": "ml", "prompt": "(**Compute IoU between two boxes.\nbox1: [b1_y1, b1_x1, b1_y2, b1_x2]\nbox2: [b2_y1, b2_x1, b2_y2, b2_x2]\nreturn: float\n*)\nlet compute_iou (box1 : int list) (box2 : int list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_180620_compute_iou.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = compute_iou in\n  (assert ((candidate [0; 0; 1; 1] [0; 0; 0; 1]) = 0));\n  (assert ((candidate [0; 0; 1; 1] [0; 0; 1; 1]) = 1));\n  (assert ((candidate [0; 0; 1; 1] [0; 1; 1; 1]) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_180956__fabric_network_ipam_name", "language": "ml", "prompt": "(**:param fabric_name: string\n:param network_type: string (One of the constants defined in NetworkType)\n:return: string\n*)\nlet _fabric_network_ipam_name (fabric_name : string) (network_type : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_180956__fabric_network_ipam_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _fabric_network_ipam_name in\n  (assert ((candidate \"fab9\" \"management\") = \"fab9-management-network-ipam\"));\n  (assert ((candidate \"foo\" \"bar\") = \"foo-bar-network-ipam\"));\n  (assert ((candidate \"fab10\" \"management\") = \"fab10-management-network-ipam\"));\n  (assert ((candidate \"my-fabric-name\" \"management\") = \"my-fabric-name-management-network-ipam\"));\n  (assert ((candidate \"foo-bar\" \"vlan\") = \"foo-bar-vlan-network-ipam\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_181012_get_msg", "language": "ml", "prompt": "(**Create a message telling the user what kind of model we're training.\nArgs:\n * feat (bool): whether this model is being trained with external features\n * mpnn (bool): whether this model is being trained with an mpnn (vs. just with\n * external features)\n * train_folder (str): path to the training folder\nReturns:\n * msg (str): the message\n*)\nlet get_msg (feat : bool) (mpnn : bool) (train_folder : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_181012_get_msg.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_msg in\n  (assert ((candidate false true \"test\") = \"Training a ChemProp model with an MPNN in folder test\n\"));\n  (assert ((candidate true true \"folder1\") = \"Training a ChemProp model with set features and an MPNN in folder folder1\n\"));\n  (assert ((candidate false true \"folder1\") = \"Training a ChemProp model with an MPNN in folder folder1\n\"));\n  (assert ((candidate true false \"folder1\") = \"Training a ChemProp model with set features in folder folder1\n\"));\n  (assert ((candidate true true \"test\") = \"Training a ChemProp model with set features and an MPNN in folder test\n\"));\n  (assert ((candidate true false \"test\") = \"Training a ChemProp model with set features in folder test\n\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_181215_b_add", "language": "ml", "prompt": "(**add two bitstrings encoded as strings of '0's and '1's.\n*)\nlet b_add (a : string) (b : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_181215_b_add.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = b_add in\n  (assert ((candidate \"0000\" \"0001\") = \"0001\"));\n  (assert ((candidate \"0010\" \"0000\") = \"0010\"));\n  (assert ((candidate \"0000\" \"0000\") = \"0000\"));\n  (assert ((candidate \"0001\" \"0010\") = \"0011\"));\n  (assert ((candidate \"0001\" \"0000\") = \"0001\"));\n  (assert ((candidate \"0011\" \"0000\") = \"0011\"));\n  (assert ((candidate \"0010\" \"0001\") = \"0011\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_181976_get_entity_name", "language": "ml", "prompt": "(**Returns the entity name after stripping off namespace and/or version information\nArgs:\n * entity: The full entity name\n*)\nlet get_entity_name (entity : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_181976_get_entity_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_entity_name in\n  (assert ((candidate \"entity_name\") = \"entity_name\"));\n  (assert ((candidate \"org.sagebionetworks.repo.model.FileEntity\") = \"FileEntity\"));\n  (assert ((candidate \"org.sagebionetworks.repo.model.Folder\") = \"Folder\"));\n  (assert ((candidate \"my_namespace.my_entity\") = \"my_entity\"));\n  (assert ((candidate \"my_entity\") = \"my_entity\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_182034_strip_url", "language": "ml", "prompt": "(**receive a URL Field and remove leading http:// or https://\noptionally remove www.\n:param url: eg. http://www.medyear.com\n:param www remove the prefix passed = \"www.\"\n:return:\n*)\nlet strip_url (domain : string) (www : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_182034_strip_url.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = strip_url in\n  (assert ((candidate \"www.medyear.com\" \"www\") = \"medyear.com\"));\n  (assert ((candidate \"http://www.medyear.com\") = \"www.medyear.com\"));\n  (assert ((candidate \"www.medyear.com\" \"www\") = \"medyear.com\"));\n  (assert ((candidate \"https://www.medyear.com\" \"www\") = \"medyear.com\"));\n  (assert ((candidate \"www.medyear.com\") = \"www.medyear.com\"));\n  (assert ((candidate \"https://www.medyear.com\") = \"www.medyear.com\"));\n  (assert ((candidate \"http://www.medyear.com\" \"www\") = \"medyear.com\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_182677_pddl_to_tarski_type", "language": "ml", "prompt": "(**Translate a few PDDL types into their corresponding Tarski names\n(e.g. the FSTRIPS type \"int\" corresponds to the Tarski type \"Integer\").\n*)\nlet pddl_to_tarski_type (typename : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_182677_pddl_to_tarski_type.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = pddl_to_tarski_type in\n  (assert ((candidate \"int\") = \"Integer\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_184499_get_bucket_key", "language": "ml", "prompt": "(**Return bucket name and key from given S3 URI\n*)\nlet get_bucket_key (uri : string) :  string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_184499_get_bucket_key.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_bucket_key in\n  (assert ((candidate \"s3://mybucket/foo/bar.json\") = (\"mybucket\", \"foo/bar.json\")));\n  (assert ((candidate \"s3://mybucket\") = (\"mybucket\", \"\")));\n  (assert ((candidate \"s3://mybucket/foo/bar/\") = (\"mybucket\", \"foo/bar/\")));\n  (assert ((candidate \"s3://foo/bar/baz\") = (\"foo\", \"bar/baz\")));\n  (assert ((candidate \"s3://mybucket/\") = (\"mybucket\", \"\")));\n  (assert ((candidate \"s3://foo/bar\") = (\"foo\", \"bar\")));\n  (assert ((candidate \"s3://mybucket/foo/bar.json\") = (\"mybucket\", \"foo/bar.json\")));\n  (assert ((candidate \"s3://mybucket\") = (\"mybucket\", \"\")));\n  (assert ((candidate \"s3://mybucket/\") = (\"mybucket\", \"\")));\n  (assert ((candidate \"s3://mybucket/foo/bar/\") = (\"mybucket\", \"foo/bar/\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_18473_find_sum_of_arithmetic_sequence", "language": "ml", "prompt": "(**Finds the sum of an arithmetic sequence\n:param requested_terms:\n:param first_term:\n:param common_difference:\n:return: the sum of an arithmetic sequence\n*)\nlet find_sum_of_arithmetic_sequence (requested_terms : int) (first_term : int) (common_difference : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_18473_find_sum_of_arithmetic_sequence.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = find_sum_of_arithmetic_sequence in\n  (assert ((candidate 10 1 1) = 55));\n  (assert ((candidate 1 1 2) = 1));\n  (assert ((candidate 1 5 1) = 5));\n  (assert ((candidate 5 1 1) = 15));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_185648_IRAF_image_type", "language": "ml", "prompt": "(**Convert MaximDL default image type names to IRAF\nParameters\n----------\nimage_type : str\n * Value of the FITS header keyword IMAGETYP; acceptable values are\n * below in Notes.\nReturns\n-------\nstr\n * IRAF image type (one of 'BIAS', 'DARK', 'FLAT' or 'LIGHT')\nNotes\n-----\nThe MaximDL default is, e.g. 'Bias Frame', which IRAF calls\n'BIAS'. Can safely be called with an IRAF-style image_type.\n*)\nlet IRAF_image_type (image_type : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_185648_IRAF_image_type.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = IRAF_image_type in\n  (assert ((candidate candidate \"FLAT\") = \"FLAT\"));\n  (assert ((candidate \"Flat Frame\") = \"FLAT\"));\n  (assert ((candidate candidate \"BIAS\") = \"BIAS\"));\n  (assert ((candidate \"Bias Frame\") = \"BIAS\"));\n  (assert ((candidate candidate \"DARK\") = \"DARK\"));\n  (assert ((candidate \"Light Frame\") = \"LIGHT\"));\n  (assert ((candidate candidate \"LIGHT\") = \"LIGHT\"));\n  (assert ((candidate \"Dark Frame\") = \"DARK\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_185855_length_range_for_entropy", "language": "ml", "prompt": "(**Returns length range to sample from for given entropy.\n*)\nlet length_range_for_entropy (entropy : int) :  int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_185855_length_range_for_entropy.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = length_range_for_entropy in\n  (assert ((candidate 2) = (3, 4)));\n  (assert ((candidate 5) = (3, 5)));\n  (assert ((candidate 0) = (3, 3)));\n  (assert ((candidate 1234) = candidate 1234));\n  (assert ((candidate 4) = (3, 5)));\n  (assert ((candidate 3) = (3, 4)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_186735_string_to_list", "language": "ml", "prompt": "(**converts string to list of ints\n*)\nlet string_to_list (the_string : string) : int list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_186735_string_to_list.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = string_to_list in\n  (assert ((candidate \"1,\") = [[1]]));\n  (assert ((candidate \"3, 4, 5,\") = [[3]; [4]; [5]]));\n  (assert ((candidate \"3,\") = [[3]]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_186984__module_descriptor_file", "language": "ml", "prompt": "(**Returns the name of the file containing descriptor for the 'module_dir'.\n*)\nlet _module_descriptor_file (module_dir : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_186984__module_descriptor_file.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _module_descriptor_file in\n  (assert ((candidate \"foo/bar\") = \"foo/bar.descriptor.txt\"));\n  (assert ((candidate \"foo\") = \"foo.descriptor.txt\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_188499_bond_energy", "language": "ml", "prompt": "(**Calculate the bond energy using the harmonic potential.\nArgs:\n * r (float):  distance between atoms [angstrom]\n * fc (float):  force constant [kcal/mol]\n * r0 (float):  equilibrium distance [angstrom]\nReturns:\n * e_bond (float):  energy of bond [kcal/mol]\n*)\nlet bond_energy (r : float) (fc : float) (r0 : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_188499_bond_energy.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = bond_energy in\n  (assert ((candidate 0.0 0.0 0.0) = 0.0));\n  (assert ((candidate 1.0 1.0 0.0) = 0.5));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_189051_is_return", "language": "ml", "prompt": "(**Determine if a parameter is named as a (internal) return.\n:param param_name: String with a parameter name\n:returns: True iff the name has the form of an internal return name\n*)\nlet is_return (param_name : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_189051_is_return.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_return in\n  (assert ((candidate \" _return_ \") = false));\n  (assert ((candidate \"$return\") = true));\n  (assert ((candidate \"$return_8\") = true));\n  (assert ((candidate \"return.\") = false));\n  (assert ((candidate \"$return_values[0][1]\") = true));\n  (assert ((candidate \"$return_17\") = true));\n  (assert ((candidate \"$return_26\") = true));\n  (assert ((candidate \"$return_7\") = true));\n  (assert ((candidate \"$return_18\") = true));\n  (assert ((candidate \"$return_0\") = true));\n  (assert ((candidate \"return_\") = false));\n  (assert ((candidate \"$return_values[0][1][2][3]\") = true));\n  (assert ((candidate \"$return_28\") = true));\n  (assert ((candidate \"$return_25\") = true));\n  (assert ((candidate \"$return_values[0][1][2]\") = true));\n  (assert ((candidate \"$return_values\") = true));\n  (assert ((candidate \"$return_values[0][1][2][3][4]\") = true));\n  (assert ((candidate \"$return_9\") = true));\n  (assert ((candidate \"_return_\") = false));\n  (assert ((candidate \"$return_23\") = true));\n  (assert ((candidate \"$return_14\") = true));\n  (assert ((candidate \"$return_29\") = true));\n  (assert ((candidate \"_return \") = false));\n  (assert ((candidate \"$return_16\") = true));\n  (assert ((candidate \" return\") = false));\n  (assert ((candidate \"$return_19\") = true));\n  (assert ((candidate \"return\") = false));\n  (assert ((candidate \"$return_21\") = true));\n  (assert ((candidate \"$return_20\") = true));\n  (assert ((candidate \".return.\") = false));\n  (assert ((candidate \"$return\") = true));\n  (assert ((candidate \" return_\") = false));\n  (assert ((candidate \".return\") = false));\n  (assert ((candidate \"$return_15\") = true));\n  (assert ((candidate \"return \") = false));\n  (assert ((candidate \"$return_27\") = true));\n  (assert ((candidate \"$return_value\") = true));\n  (assert ((candidate \"$return_values[0]\") = true));\n  (assert ((candidate \"$return_24\") = true));\n  (assert ((candidate \"not_a_return\") = false));\n  (assert ((candidate \"$return_22\") = true));\n  (assert ((candidate \"$return_values[0][1][2][3][4][5]\") = true));\n  (assert ((candidate \"$return_12\") = true));\n  (assert ((candidate \"$return_6\") = true));\n  (assert ((candidate \"$return_13\") = true));\n  (assert ((candidate \"$return_11\") = true));\n  (assert ((candidate \"$return_10\") = true));\n  (assert ((candidate \"$return_5\") = true));\n  (assert ((candidate \"_return\") = false));\n  (assert ((candidate \" return \") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_189531_composite_colors", "language": "ml", "prompt": "(**Composite two colors together using their given alpha.\nThe first color will be composited on top of the second color.\nParameters\n----------\nfirst : tuple\n * The rgba tuple of the first color. All values are floats in\n * the range 0.0 - 1.0.\nsecond : tuple\n * The rgba tuple of the second color. The format of this tuple\n * is the same as the first color.\nReturns\n-------\nresult : tuple\n * The composited rgba color tuple.\n*)\nlet composite_colors (first :  float * float * float * float) (second :  float * float * float * float) :  float * float * float * float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_189531_composite_colors.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = composite_colors in\n  (assert ((candidate (1.0, 1.0, 1.0, 1.0) (0.0, 0.0, 0.0, 1.0)) = (1.0, 1.0, 1.0, 1.0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_189571_infer_emg_channels", "language": "ml", "prompt": "(**This function receives a list of channel names and will return\none frontal, one central and one occipital channel.\n*)\nlet infer_emg_channels (ch_names : string list) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_189571_infer_emg_channels.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = infer_emg_channels in\n  (assert ((candidate [\"EMG Chin\"]) = [\"EMG Chin\"]));\n  (assert ((candidate [\"EMG Chin\"]) = [\"EMG Chin\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_189989_constrain", "language": "ml", "prompt": "(**constrain a position (pos) in the area defined by size\n*)\nlet constrain (pos :  int * int) (size :  int * int) :  int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_189989_constrain.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = constrain in\n  (assert ((candidate (99, 199) (100, 200)) = (99, 199)));\n  (assert ((candidate ((~1), (~1)) (100, 200)) = (0, 0)));\n  (assert ((candidate (101, 201) (100, 200)) = (99, 199)));\n  (assert ((candidate (100, 200) (100, 200)) = (99, 199)));\n  (assert ((candidate (9, 19) (100, 200)) = (9, 19)));\n  (assert ((candidate (0, 0) (0, 0)) = (0, 0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_19021_diff_possible", "language": "ml", "prompt": "(**Given a list of sorted integers and a non negative\ninteger k, find if there exists 2 indicies i and j\nsuch that A[i] - A[j] = k, i != j\n*)\nlet diff_possible (numbers : int list) (k : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_19021_diff_possible.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = diff_possible in\n  (assert ((candidate list range 1000 1000) = false));\n  (assert ((candidate [1; 2; 3; 5; 6; 10] 5) = true));\n  (assert ((candidate [1; 2; 3; 5; 6; 10] 3) = true));\n  (assert ((candidate list range 10 7) = true));\n  (assert ((candidate list range 10 8) = true));\n  (assert ((candidate list range 20 4) = true));\n  (assert ((candidate list range 10 3) = true));\n  (assert ((candidate list range 10 2) = true));\n  (assert ((candidate list range 20 9) = true));\n  (assert ((candidate list range 10 4) = true));\n  (assert ((candidate list range 1000 999) = true));\n  (assert ((candidate list range 10 10) = false));\n  (assert ((candidate [1; 2; 3; 5; 6; 10] 9) = true));\n  (assert ((candidate list range 10 9) = true));\n  (assert ((candidate [1; 2; 3; 5; 6; 10] 6) = false));\n  (assert ((candidate [1; 2; 3; 5; 6; 10] 1) = true));\n  (assert ((candidate list range 5 3) = true));\n  (assert ((candidate list range 100 1000) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_190761_seg_text2listxy", "language": "ml", "prompt": "(**Purpose: parse x, y coordinates from text of seg (segmentation) annotation in xml\nArgs: \n * text: text of seg (segmentation) annotation in xml, \"[x0,y0, x1,y1, x2,y2, x3,y3, ...]\"\nReturns:  lists of storing x y coordinates, \n * x: [x0, x1, x2, x3, ...]\n * y: [y0, y1, y2, y3, ...]\n*)\nlet seg_text2listxy (text : string) :  int list * int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_190761_seg_text2listxy.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = seg_text2listxy in\n  (assert ((candidate \"[1, 2, 3, 4, 5, 6]\") = ([1; 3; 5], [2; 4; 6])));\n  (assert ((candidate \"[1, 2, 3, 4]\") = ([1; 3], [2; 4])));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_190870___get_list_str", "language": "ml", "prompt": "(**Get value of the categorical variable, and put 3 value in one line\n:param x: str\n:return: list\n*)\nlet __get_list_str (x : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_190870___get_list_str.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = __get_list_str in\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"1,2,3\") = \"1,2,3\"));\n  (assert ((candidate \"a\") = \"a\"));\n  (assert ((candidate \"a,b,c\") = \"a,b,c\"));\n  (assert ((candidate \"1\u00012\u00013\") = \"1,2,3\"));\n  (assert ((candidate \"1\") = \"1\"));\n  (assert ((candidate \"1,2,3\") = \"1,2,3\"));\n  (assert ((candidate \"a\u0001b\u0001c\") = \"a,b,c\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_191156_caesar", "language": "ml", "prompt": "(**:type c: str\n:type x: int\n:rtype: str\n*)\nlet caesar (c : string) (x : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_191156_caesar.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = caesar in\n  (assert ((candidate \"Z\" 1) = \"A\"));\n  (assert ((candidate \"N\" 1) = \"O\"));\n  (assert ((candidate \"a\" 3) = \"d\"));\n  (assert ((candidate \"n\" 0) = \"n\"));\n  (assert ((candidate \"Z\" 2) = \"B\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_191557_calc_permutation", "language": "ml", "prompt": "(**Evaluates the permutation expression\n*)\nlet calc_permutation (m : int) (mm : int) (_accuracy : float) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_191557_calc_permutation.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = calc_permutation in\n  (assert ((candidate 1 1 0.9) = 1));\n  (assert ((candidate 5 5 0.9) = 1));\n  (assert ((candidate 10 10 0.9) = 1));\n  (assert ((candidate 9 9 0.9) = 1));\n  (assert ((candidate 6 6 0.9) = 1));\n  (assert ((candidate 2 2 0.9) = 1));\n  (assert ((candidate 3 3 0.9) = 1));\n  (assert ((candidate 4 4 0.9) = 1));\n  (assert ((candidate 7 7 0.9) = 1));\n  (assert ((candidate 8 8 0.9) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_192692_tordist", "language": "ml", "prompt": "(**Calculate the toroidial distance between two scalars\nArgs:\n * x1(float) : first datapoint\n * x2(float) : second datapoint\n * wrap_dist(float) : wrapping distance (highest value), values higher than this will wrap around to zero\nReturns:\n * distance(float) : toroidial distance between x1 and x2, wrapping around wrap_dist\n*)\nlet tordist (x1 : float) (x2 : float) (wrap_dist : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_192692_tordist.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = tordist in\n  (assert ((candidate 0.75 1.0 2.0) = 0.25));\n  (assert ((candidate 100.0 100.0 10.0) = 0.0));\n  (assert ((candidate 0.75 1.25 2.0) = 0.5));\n  (assert ((candidate 9.0 10.0 10.0) = 1.0));\n  (assert ((candidate 0.0 1.0 10.0) = 1.0));\n  (assert ((candidate 0.0 9.0 10.0) = 1.0));\n  (assert ((candidate 1.25 0.75 2.0) = 0.5));\n  (assert ((candidate 1.0 0.5 1.0) = 0.5));\n  (assert ((candidate 0.5 1.0 1.0) = 0.5));\n  (assert ((candidate 1.0 0.75 2.0) = 0.25));\n  (assert ((candidate 2.0 11.0 10.0) = 1.0));\n  (assert ((candidate 1.0 2.0 3.0) = 1.0));\n  (assert ((candidate 1.0 1.0 1.0) = 0.0));\n  (assert ((candidate 0.0 0.0 10.0) = 0.0));\n  (assert ((candidate 0.5 0.75 1.0) = 0.25));\n  (assert ((candidate 5.0 0.0 10.0) = 5.0));\n  (assert ((candidate 0.75 0.5 1.0) = 0.25));\n  (assert ((candidate 0.0 5.0 10.0) = 5.0));\n  (assert ((candidate 2.0 1.0 10.0) = 1.0));\n  (assert ((candidate 0.0 (~1).0 10.0) = 1.0));\n  (assert ((candidate 0.0 10.0 10.0) = 0.0));\n  (assert ((candidate 2.0 1.0 2.0) = 1.0));\n  (assert ((candidate 0.0 (~9).0 10.0) = 1.0));\n  (assert ((candidate 0.0 (~10).0 10.0) = 0.0));\n  (assert ((candidate 0.0 0.0 10.0) = 0.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_193452_g_iter", "language": "ml", "prompt": "(**Return the value of G(n), computed iteratively.\n>>> g_iter(1)\n1\n>>> g_iter(2)\n2\n>>> g_iter(3)\n3\n>>> g_iter(4)\n10\n>>> g_iter(5)\n22\n>>> from construct_check import check\n>>> # ban recursion\n>>> check(HW_SOURCE_FILE, 'g_iter', ['Recursion'])\nTrue\n*)\nlet g_iter (n : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_193452_g_iter.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = g_iter in\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 5) = 22));\n  (assert ((candidate 3) = 3));\n  (assert ((candidate 4) = 10));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_193505_decoupParagraphEnPhrases", "language": "ml", "prompt": "(**returns the paragraph splited in phrases ignoring specifics titles. To be completed\n*)\nlet decoupParagraphEnPhrases (paragraph : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_193505_decoupParagraphEnPhrases.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = decoupParagraphEnPhrases in\n  (assert ((candidate \"Bonjour, comment vous allez?\") = [\"Bonjour, comment vous allez?\"]));\n  (assert ((candidate \"Ceci est une phrase. Ceci est une autre. Ceci est une derni\u00e8re. Ceci est un quatri\u00e8me.\") = [\"Ceci est une phrase.\"; \"Ceci est une autre.\"; \"Ceci est une derni\u00e8re.\"; \"Ceci est un quatri\u00e8me.\"]));\n  (assert ((candidate \"Bonjour, comment allez vous?\") = [\"Bonjour, comment allez vous?\"]));\n  (assert ((candidate \"Bonjour, comment allez-vous?\") = [\"Bonjour, comment allez-vous?\"]));\n  (assert ((candidate \"\") = []));\n  (assert ((candidate \"Ceci est une phrase. Ceci est une autre.\") = [\"Ceci est une phrase.\"; \"Ceci est une autre.\"]));\n  (assert ((candidate \"Ceci est une phrase.\") = [\"Ceci est une phrase.\"]));\n  (assert ((candidate \"Hello world!\") = [\"Hello world!\"]));\n  (assert ((candidate \"Ceci est une phrase. Ceci est une autre. Ceci est une derni\u00e8re.\") = [\"Ceci est une phrase.\"; \"Ceci est une autre.\"; \"Ceci est une derni\u00e8re.\"]));\n  (assert ((candidate \"Bonjour, comment allez vous?\") = [\"Bonjour, comment allez vous?\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_193898_to_devport", "language": "ml", "prompt": "(**Convert a (pipe, port) combination into a 9-bit (devport) number\nNOTE: For now this is a Tofino-specific method\n*)\nlet to_devport (pipe : int) (port : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_193898_to_devport.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = to_devport in\n  (assert ((candidate 0 129) = 129));\n  (assert ((candidate 1 5) = 133));\n  (assert ((candidate 1 12) = 140));\n  (assert ((candidate 2 5) = 261));\n  (assert ((candidate 0 15) = 15));\n  (assert ((candidate 0 63) = 63));\n  (assert ((candidate 2 6) = 262));\n  (assert ((candidate 1 4) = 132));\n  (assert ((candidate 1 14) = 142));\n  (assert ((candidate 1 4) = 132));\n  (assert ((candidate 1 0) = 128));\n  (assert ((candidate 1 1) = 129));\n  (assert ((candidate 2 3) = 259));\n  (assert ((candidate 0 128) = 128));\n  (assert ((candidate 1 8) = 136));\n  (assert ((candidate 1 10) = 138));\n  (assert ((candidate 1 6) = 134));\n  (assert ((candidate 1 0) = 128));\n  (assert ((candidate 2 7) = 263));\n  (assert ((candidate 1 5) = 133));\n  (assert ((candidate 1 6) = 134));\n  (assert ((candidate 2 0) = 256));\n  (assert ((candidate 2 128) = 384));\n  (assert ((candidate 1 1) = 129));\n  (assert ((candidate 0 2) = 2));\n  (assert ((candidate 0 6) = 6));\n  (assert ((candidate 1 11) = 139));\n  (assert ((candidate 2 4) = 260));\n  (assert ((candidate 0 305419896) = 305419896));\n  (assert ((candidate 0 1311768467463790320) = 1311768467463790320));\n  (assert ((candidate 0 3) = 3));\n  (assert ((candidate 1 9) = 137));\n  (assert ((candidate 0 159) = 159));\n  (assert ((candidate 0 1) = 1));\n  (assert ((candidate 0 7) = 7));\n  (assert ((candidate 1 2) = 130));\n  (assert ((candidate 0 8) = 8));\n  (assert ((candidate 0 0) = 0));\n  (assert ((candidate 2 1) = 257));\n  (assert ((candidate 0 5) = 5));\n  (assert ((candidate 0 4) = 4));\n  (assert ((candidate 1 15) = 143));\n  (assert ((candidate 1 7) = 135));\n  (assert ((candidate 1 3) = 131));\n  (assert ((candidate 2 2) = 258));\n  (assert ((candidate 1 3) = 131));\n  (assert ((candidate 1 2) = 130));\n  (assert ((candidate 0 255) = 255));\n  (assert ((candidate 0 127) = 127));\n  (assert ((candidate 1 13) = 141));\n  (assert ((candidate 1 7) = 135));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_193960__is_mgmt_url", "language": "ml", "prompt": "(**small helper to test if URL is for management API.\n*)\nlet _is_mgmt_url (path : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_193960__is_mgmt_url.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _is_mgmt_url in\n  (assert ((candidate \"\") = false));\n  (assert ((candidate \"/mgmt/foo\") = true));\n  (assert ((candidate \"/mgmt/\") = true));\n  (assert ((candidate \"/\") = false));\n  (assert ((candidate \"/mgmt/not-mgmt\") = true));\n  (assert ((candidate \"not-mgmt\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_194153__fix_endpoint", "language": "ml", "prompt": "(**Remove all text before \"http\".\nWorkaround because the endpoint is automatically prefixed with the data folder. However this does not make sense for\na sparql endpoint.\n:param endpoint:\n:return:\n*)\nlet _fix_endpoint (endpoint : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_194153__fix_endpoint.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _fix_endpoint in\n  (assert ((candidate \"https://dbpedia.org/sparql\") = \"https://dbpedia.org/sparql\"));\n  (assert ((candidate \"http://dbpedia.org/sparql\") = \"http://dbpedia.org/sparql\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_194405_factorial", "language": "ml", "prompt": "(**To Find Factorial Of n\n*)\nlet factorial (n : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_194405_factorial.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = factorial in\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 4) = 24));\n  (assert ((candidate 9) = 362880));\n  (assert ((candidate 7) = 5040));\n  (assert ((candidate 5) = 120));\n  (assert ((candidate 6) = 720));\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 3) = 6));\n  (assert ((candidate 8) = 40320));\n  (assert ((candidate 10) = 3628800));\n  (assert ((candidate 0) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_196090_max_subarray", "language": "ml", "prompt": "(**Maximum subarray - optimized version\n*)\nlet max_subarray (sequence : int list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_196090_max_subarray.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = max_subarray in\n  (assert ((candidate [1]) = 1));\n  (assert ((candidate list ) = 0));\n  (assert ((candidate list [10]) = 10));\n  (assert ((candidate list [10; 20]) = 30));\n  (assert ((candidate [(~1); 1; 2; (~2); 3]) = 4));\n  (assert ((candidate list [10; 20; 30; 40; 50; 60]) = 210));\n  (assert ((candidate list [10; (~20)]) = 10));\n  (assert ((candidate [1; 2; 3; 4; 5]) = 15));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_196910_is_event", "language": "ml", "prompt": "(**Test if a method is an event.\n*)\nlet is_event (attribute : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_196910_is_event.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_event in\n  (assert ((candidate \"on_anything\") = true));\n  (assert ((candidate \"on_event123\") = true));\n  (assert ((candidate \"_on_event\") = false));\n  (assert ((candidate \"on_Event123\") = true));\n  (assert ((candidate \"on_event1\") = true));\n  (assert ((candidate \"on\") = false));\n  (assert ((candidate \"on_event3\") = true));\n  (assert ((candidate \"on_my_button_2\") = true));\n  (assert ((candidate \"on_event5\") = true));\n  (assert ((candidate \"on_123\") = true));\n  (assert ((candidate \"On_event\") = false));\n  (assert ((candidate \"on_Event\") = true));\n  (assert ((candidate \"on_event4\") = true));\n  (assert ((candidate \"on_Event_with_dashes\") = true));\n  (assert ((candidate \"on_Event\") = true));\n  (assert ((candidate \"on_event\") = true));\n  (assert ((candidate \"on_event_with_dashes\") = true));\n  (assert ((candidate \"on_event2\") = true));\n  (assert ((candidate \"abc\") = false));\n  (assert ((candidate \"on_my_button\") = true));\n  (assert ((candidate \"1\") = false));\n  (assert ((candidate \"foo\") = false));\n  (assert ((candidate \"on_my_button_3\") = true));\n  (assert ((candidate \"On\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_197145_calc_average_ig", "language": "ml", "prompt": "(**Helper function for SHSEL filter algorithm. It returns the average\nInfomation gain value of one existing path in pruning function.\nArgs:\n * path_nodes (list): Node in path whose node_availability is True.\n * node_values (dict): Dictionary about every node in the directed graph\n * and its information gain value.\nReturns:\n * float: The average InfoGain value of one existing path.\n*)\nlet calc_average_ig (path_nodes : int list) (node_values : (int, int) list) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_197145_calc_average_ig.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = calc_average_ig in\n  (assert ((candidate [0; 1; 2] [(0, 1); (1, 2); (2, 3)]) = 2.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_197672_get_search_threshs", "language": "ml", "prompt": "(**Clips the thresholds for binary search based on current word counts.\nThe upper threshold parameter typically has a large default value that can\nresult in many iterations of unnecessary search. Thus we clip the upper and\nlower bounds of search to the maximum and the minimum wordcount values.\nArgs:\n * word_counts: list of (string, int) tuples\n * upper_thresh: int, upper threshold for binary search\n * lower_thresh: int, lower threshold for binary search\nReturns:\n * upper_search: int, clipped upper threshold for binary search\n * lower_search: int, clipped lower threshold for binary search\n*)\nlet get_search_threshs (word_counts :  string * int list) (upper_thresh : int option) (lower_thresh : int option) :  int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_197672_get_search_threshs.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_search_threshs in\n  (assert ((candidate [(\"a\", 2); (\"b\", 3); (\"c\", 4); (\"d\", 5); (\"e\", 6); (\"f\", 7); (\"g\", 8)] Some(None) Some(7)) = (8, 7)));\n  (assert ((candidate [(\"cat\", 3); (\"dog\", 5); (\"bird\", 7); (\"fish\", 9); (\"dog\", 11)] Some(11) Some(9)) = (11, 9)));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3)] Some(None) Some(5)) = (3, 5)));\n  (assert ((candidate [(\"cat\", 3); (\"dog\", 5); (\"bird\", 7); (\"fish\", 9); (\"dog\", 11)] Some(11) Some(11)) = (11, 11)));\n  (assert ((candidate [(\"a\", 10); (\"b\", 20); (\"c\", 30)] Some(20) Some(30)) = (20, 30)));\n  (assert ((candidate [(\"a\", 2); (\"b\", 3); (\"c\", 4); (\"d\", 5); (\"e\", 6); (\"f\", 7); (\"g\", 8)] Some(None) Some(6)) = (8, 6)));\n  (assert ((candidate [(\"a\", 2); (\"b\", 3); (\"c\", 4); (\"d\", 5); (\"e\", 6); (\"f\", 7); (\"g\", 8)] Some(None) Some(3)) = (8, 3)));\n  (assert ((candidate [(\"a\", 10); (\"b\", 20); (\"c\", 30)] Some(10) Some(15)) = (10, 15)));\n  (assert ((candidate [(\"a\", 10); (\"b\", 20); (\"c\", 30)] Some(25) Some(25)) = (25, 25)));\n  (assert ((candidate [(\"cat\", 3); (\"dog\", 5); (\"bird\", 7); (\"fish\", 9); (\"dog\", 11)] Some(8) Some(8)) = (8, 8)));\n  (assert ((candidate [(\"a\", 10); (\"b\", 20); (\"c\", 30)] Some(None) Some(None)) = (30, 10)));\n  (assert ((candidate [(\"cat\", 3); (\"dog\", 5); (\"bird\", 7); (\"fish\", 9); (\"dog\", 11)] Some(8) Some(6)) = (8, 6)));\n  (assert ((candidate [(\"a\", 10); (\"b\", 20); (\"c\", 30)] Some(None) Some(30)) = (30, 30)));\n  (assert ((candidate list zip [\"a\"; \"b\"; \"c\"] [5; 2; 1] Some(None) Some(None)) = (5, 1)));\n  (assert ((candidate [(\"a\", 1); (\"b\", 1); (\"c\", 1)] Some(None) Some(2)) = (1, 2)));\n  (assert ((candidate list zip [\"a\"; \"b\"; \"c\"] [5; 2; 1] Some(100) Some(0)) = (5, 1)));\n  (assert ((candidate [(\"a\", 2); (\"b\", 3); (\"c\", 4); (\"d\", 5); (\"e\", 6); (\"f\", 7); (\"g\", 8)] Some(None) Some(5)) = (8, 5)));\n  (assert ((candidate [(\"a\", 10); (\"b\", 20); (\"c\", 30)] Some(20) Some(None)) = (20, 10)));\n  (assert ((candidate [(\"a\", 10); (\"b\", 20); (\"c\", 30)] Some(25) Some(15)) = (25, 15)));\n  (assert ((candidate [(\"a\", 10); (\"b\", 20); (\"c\", 30)] Some(10) Some(25)) = (10, 25)));\n  (assert ((candidate [(\"a\", 2); (\"b\", 3); (\"c\", 4); (\"d\", 5); (\"e\", 6); (\"f\", 7); (\"g\", 8)] Some(None) Some(4)) = (8, 4)));\n  (assert ((candidate [(\"a\", 10); (\"b\", 3); (\"c\", 5); (\"d\", 8); (\"e\", 20); (\"f\", 25)] Some(None) Some(3)) = (25, 3)));\n  (assert ((candidate [(\"a\", 2); (\"b\", 3); (\"c\", 4); (\"d\", 5); (\"e\", 6); (\"f\", 7); (\"g\", 8)] Some(None) Some(2)) = (8, 2)));\n  (assert ((candidate [(\"a\", 10); (\"b\", 20); (\"c\", 30)] Some(None) Some(None)) = (30, 10)));\n  (assert ((candidate [(\"cat\", 3); (\"dog\", 5); (\"bird\", 7); (\"fish\", 9); (\"dog\", 11)] Some(8) Some(None)) = (8, 3)));\n  (assert ((candidate [(\"a\", 10); (\"b\", 20); (\"c\", 30)] Some(None) Some(15)) = (30, 15)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_197814_contar_letras", "language": "ml", "prompt": "(**Cuenta la cantidad de letras especificas en la cadena\nArgumentos:\n * cadena (str) -- cadena sobre la que contar\n * letra (str) -- letra que quiero contar\n*)\nlet contar_letras (cadena : string) (letras : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_197814_contar_letras.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = contar_letras in\n  (assert ((candidate \"hola a todos\" \"e\") = 0));\n  (assert ((candidate \"hola a todos\" \"t\") = 1));\n  (assert ((candidate \"hola a todos\" \"a\") = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_198063__get_docstring_default_value", "language": "ml", "prompt": "(**Get the description of argument's default value from docstring.\nParameters\n----------\nvar_doc : str\n * Docstring's part of argument.\nReturns\n-------\ndefault_val : str\n * Description of the defautl value.\n*)\nlet _get_docstring_default_value (var_doc : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_198063__get_docstring_default_value.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _get_docstring_default_value in\n  (assert ((candidate \"name : str, default None\n   A name for the user.\") = \"None\"));\n  (assert ((candidate \"name : str, optional\n   A name for the user.\") = \"\"));\n  (assert ((candidate \"name : str, default\n   A name for the user.\") = \"\"));\n  (assert ((candidate \"name: str, optional\n   A name for the user.\") = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_198911_is_quantity_range", "language": "ml", "prompt": "(**Checks if [] are present in val.\n*)\nlet is_quantity_range (val : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_198911_is_quantity_range.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_quantity_range in\n  (assert ((candidate \"4[]m]\") = true));\n  (assert ((candidate \"\") = false));\n  (assert ((candidate \"   \") = false));\n  (assert ((candidate \"6[m]\") = true));\n  (assert ((candidate \"1[m]\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_199908_ats_url", "language": "ml", "prompt": "(**Return the URL for the ESGF SAML AttributeService\n*)\nlet ats_url (base_url : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_199908_ats_url.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = ats_url in\n  (assert ((candidate \"http://esgf.org\") = \"http://esgf.org/esgf-idp/saml/soap/secure/attributeService.htm\"));\n  (assert ((candidate \"https://esgf-node.llnl.gov/idp/shibboleth\") = \"https://esgf-node.llnl.gov/idp/shibboleth/esgf-idp/saml/soap/secure/attributeService.htm\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_200188_RPL_ENDOFWHOIS", "language": "ml", "prompt": "(**Reply Code 318\n*)\nlet RPL_ENDOFWHOIS (sender : string) (receipient : string) (message : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_200188_RPL_ENDOFWHOIS.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = RPL_ENDOFWHOIS in\n  (assert ((candidate \"foo\" \"bar\" \"baz\") = \"<foo>: baz\"));\n  (assert ((candidate \"TestSender\" \"TestReceipient\" \"TestMessage\") = \"<TestSender>: TestMessage\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_200932_get_position_from_periods", "language": "ml", "prompt": "(**Get the position from a period list.\nIt will return the index of the right-closest number in the period list.\nFor example, the cumulative_period = [100, 200, 300, 400],\nif iteration == 50, return 0;\nif iteration == 210, return 2;\nif iteration == 300, return 2.\nArgs:\n * iteration (int): Current iteration.\n * cumulative_period (list[int]): Cumulative period list.\nReturns:\n * int: The position of the right-closest number in the period list.\n*)\nlet get_position_from_periods (iteration : int) (cumulative_period : int list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_200932_get_position_from_periods.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_position_from_periods in\n  (assert ((candidate 10 [10; 20]) = 0));\n  (assert ((candidate 210 [100; 200; 300; 400]) = 2));\n  (assert ((candidate 201 [100; 200; 300]) = 2));\n  (assert ((candidate 2 [100; 200; 300]) = 0));\n  (assert ((candidate 99 [100; 200]) = 0));\n  (assert ((candidate 299 [100; 200; 300]) = 2));\n  (assert ((candidate 1 [100; 200; 300; 400]) = 0));\n  (assert ((candidate 99 [100; 200; 300]) = 0));\n  (assert ((candidate 0 [100]) = 0));\n  (assert ((candidate 99 [100]) = 0));\n  (assert ((candidate 101 [100; 200; 300]) = 1));\n  (assert ((candidate 199 [100; 200; 300]) = 1));\n  (assert ((candidate 199 [100; 200]) = 1));\n  (assert ((candidate 300 [100; 200; 300; 400]) = 2));\n  (assert ((candidate 50 [100; 200; 300; 400]) = 0));\n  (assert ((candidate 100 [100]) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_202385_removeallspaces", "language": "ml", "prompt": "(**Remove all spaces.\n*)\nlet removeallspaces (s : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_202385_removeallspaces.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = removeallspaces in\n  (assert ((candidate \" this   is a     mess of   spaces   \") = \"thisisamessofspaces\"));\n  (assert ((candidate \"Hello   World  \") = \"HelloWorld\"));\n  (assert ((candidate \"Hello   World\") = \"HelloWorld\"));\n  (assert ((candidate \"     a b c     \") = \"abc\"));\n  (assert ((candidate \" Hello   World  \") = \"HelloWorld\"));\n  (assert ((candidate \"abc\") = \"abc\"));\n  (assert ((candidate \"     This is a mess of spaces\") = \"Thisisamessofspaces\"));\n  (assert ((candidate \"This is a mess of spaces\") = \"Thisisamessofspaces\"));\n  (assert ((candidate \"     \") = \"\"));\n  (assert ((candidate \"      \") = \"\"));\n  (assert ((candidate \"Hello World \") = \"HelloWorld\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"This is a mess of spaces     \") = \"Thisisamessofspaces\"));\n  (assert ((candidate \"      a b c      \") = \"abc\"));\n  (assert ((candidate \"Hello World  \") = \"HelloWorld\"));\n  (assert ((candidate \"  This is a mess of spaces  \") = \"Thisisamessofspaces\"));\n  (assert ((candidate \" Hello World  \") = \"HelloWorld\"));\n  (assert ((candidate \"Hello World\") = \"HelloWorld\"));\n  (assert ((candidate \"     This is a mess of spaces     \") = \"Thisisamessofspaces\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_203080_format", "language": "ml", "prompt": "(**Format a FastQ entry.\n:param name: the read name\n:param sequence: the read sequence\n:param quality: the read quality\n:return: a formatted fastq entry\n*)\nlet format (name : string) (sequence : string) (quality : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_203080_format.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = format in\n  (assert ((candidate \"name\" \"ACGT\" \"####\") = \"@name\nACGT\n+\n####\n\"));\n  (assert ((candidate \"name\" \"ACGT\" \"####\") = \"@name\nACGT\n+\n####\n\"));\n  (assert ((candidate \"foo\" \"bar\" \"baz\") = \"@foo\nbar\n+\nbaz\n\"));\n  (assert ((candidate \"name\" \"ATCGATCG\" \"#####\") = \"@name\nATCGATCG\n+\n#####\n\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_204072_make_subtype", "language": "ml", "prompt": "(**Make subtype from type and biotype.\n*)\nlet make_subtype (type_ : string option) (biotype : string option) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_204072_make_subtype.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = make_subtype in\n  (assert ((candidate Some(\"gene\") Some(\"macro_lncRNA antisense\")) = Some(\"gene macro_lncRNA antisense\")));\n  (assert ((candidate Some(None) Some(None)) = Some(None)));\n  (assert ((candidate Some(\"gene\") Some(\"sense_overlapping\")) = Some(\"gene sense_overlapping\")));\n  (assert ((candidate Some(\"TF_binding\") Some(None)) = Some(\"TF_binding\")));\n  (assert ((candidate Some(\"gene\") Some(\"antisense lincRNA\")) = Some(\"gene antisense lincRNA\")));\n  (assert ((candidate Some(\"TF_binding\") Some(\"protein_coding\")) = Some(\"TF_binding protein_coding\")));\n  (assert ((candidate Some(\"gene\") Some(\"tRNA\")) = Some(\"gene tRNA\")));\n  (assert ((candidate Some(\"TF_binding\") Some(\"protein_coding TF_binding\")) = Some(\"TF_binding protein_coding TF_binding\")));\n  (assert ((candidate Some(\"gene\") Some(\"snRNA\")) = Some(\"gene snRNA\")));\n  (assert ((candidate Some(\"gene\") Some(\"tRNA-pseudogene\")) = Some(\"gene tRNA-pseudogene\")));\n  (assert ((candidate Some(\"gene\") Some(\"antisense\")) = Some(\"gene antisense\")));\n  (assert ((candidate Some(\"gene\") Some(\"snoRNA\")) = Some(\"gene snoRNA\")));\n  (assert ((candidate Some(\"gene\") Some(\"miRNA\")) = Some(\"gene miRNA\")));\n  (assert ((candidate Some(\"gene\") Some(\"lincRNA\")) = Some(\"gene lincRNA\")));\n  (assert ((candidate Some(\"gene\") Some(\"macro_lncRNA\")) = Some(\"gene macro_lncRNA\")));\n  (assert ((candidate Some(\"gene\") Some(\"rRNA\")) = Some(\"gene rRNA\")));\n  (assert ((candidate Some(\"TF_binding\") Some(\"protein_coding TF_binding TF_binding\")) = Some(\"TF_binding protein_coding TF_binding TF_binding\")));\n  (assert ((candidate Some(\"gene\") Some(None)) = Some(\"gene\")));\n  (assert ((candidate Some(\"gene\") Some(\"pseudogene\")) = Some(\"gene pseudogene\")));\n  (assert ((candidate Some(\"gene\") Some(\"sense_intronic\")) = Some(\"gene sense_intronic\")));\n  (assert ((candidate Some(\"gene\") Some(\"protein_coding\")) = Some(\"gene protein_coding\")));\n  (assert ((candidate Some(\"gene\") Some(\"rRNA-pseudogene\")) = Some(\"gene rRNA-pseudogene\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_20424_bbox_to_pixel_offsets", "language": "ml", "prompt": "(**Helper function for zonal_stats(). Modified from:\nhttps://gist.github.com/perrygeo/5667173\nOriginal code copyright 2013 Matthew Perry\n*)\nlet bbox_to_pixel_offsets (gt :  int * int * int * int * int * int) (bbox :  float * float * float * float) :  int * int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_20424_bbox_to_pixel_offsets.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = bbox_to_pixel_offsets in\n  (assert ((candidate (0, 1, 2, 3, 4, 5) (-0.1, 0.1, 0.3, 0.4)) = (0, 0, 1, 1)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_204699_prepare_summary_line", "language": "ml", "prompt": "(**Prepares a summary line by formatting it.\nArgs:\n * cost: The cost of the summary line item.\n * currency: The currency to append to the summary line item.\nReturns:\n * The formatted summary line.\n*)\nlet prepare_summary_line (cost : float) (currency : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_204699_prepare_summary_line.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = prepare_summary_line in\n  (assert ((candidate 20000.12 \"JPY\") = \"20000.12 JPY\"));\n  (assert ((candidate 20.14 \"USD\") = \"20.14 USD\"));\n  (assert ((candidate 456.0 \"EUR\") = \"456 EUR\"));\n  (assert ((candidate 789.0 \"GBP\") = \"789 GBP\"));\n  (assert ((candidate 10.55 \"JPY\") = \"10.55 JPY\"));\n  (assert ((candidate 123.0 \"USD\") = \"123 USD\"));\n  (assert ((candidate 0.05 \"CAD\") = \"0.05 CAD\"));\n  (assert ((candidate 200.1 \"EUR\") = \"200.1 EUR\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_205474_get_chain_length", "language": "ml", "prompt": "(**Get length of the chain with index \"chain_idx\", starting from (and including)\ngeneration \"start_gen_idx\" to end of chain, or until first\nempty bin (while excluding empty bin).\n*)\nlet get_chain_length (chains : int list list list) (chain_idx : int) (start_gen_idx : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_205474_get_chain_length.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_chain_length in\n  (assert ((candidate [[[0; 0]; [0; 0]; [0; 0]]; [[0; 0]; [0; 0]; [0; 0]]; [[0; 0]; [0; 0]; [0; 0]]] 1 0) = 3));\n  (assert ((candidate [[[0; 0]; [0; 0]]; [[0; 0]; [0; 0]]; [[0; 0]; [0; 0]]; [[0; 0]; [0; 0]]] 1 0) = 4));\n  (assert ((candidate [[[0; 0]; [0; 0]; [0; 0]]; [[0; 0]; [0; 0]]; [[0; 0]; [0; 0]; [0; 0]]] 1 0) = 3));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_206622_iso_date2", "language": "ml", "prompt": "(**Returns int tuple (yyyy,mm,dd) if adate is in form of 'yyyy-dd-mm' else (0,0,0)\n*)\nlet iso_date2 (adate : string option) :  int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_206622_iso_date2.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = iso_date2 in\n  (assert ((candidate Some(\"\")) = (0, 0, 0)));\n  (assert ((candidate Some(\"201-1-00\")) = (0, 0, 0)));\n  (assert ((candidate Some(\"201-1-1\")) = (0, 0, 0)));\n  (assert ((candidate Some(\"2018-1-1\")) = (0, 0, 0)));\n  (assert ((candidate Some(\"20-1-01\")) = (0, 0, 0)));\n  (assert ((candidate Some(None)) = (0, 0, 0)));\n  (assert ((candidate Some(\"201-01-1\")) = (0, 0, 0)));\n  (assert ((candidate Some(\"201-00-1\")) = (0, 0, 0)));\n  (assert ((candidate Some(\"2022-1-3\")) = (0, 0, 0)));\n  (assert ((candidate Some(\"20-01-01\")) = (0, 0, 0)));\n  (assert ((candidate Some(\"1987-02-03\")) = (1987, 2, 3)));\n  (assert ((candidate Some(\"2022-11-1\")) = (0, 0, 0)));\n  (assert ((candidate Some(\"2022-1-32\")) = (0, 0, 0)));\n  (assert ((candidate Some(\"201-1-01\")) = (0, 0, 0)));\n  (assert ((candidate Some(\"2018-01-1\")) = (0, 0, 0)));\n  (assert ((candidate Some(\"1987-02-100\")) = (0, 0, 0)));\n  (assert ((candidate Some(\"2018-00-1\")) = (0, 0, 0)));\n  (assert ((candidate Some(\"2018-01-21\")) = (2018, 1, 21)));\n  (assert ((candidate Some(\"2020-01-02\")) = (2020, 1, 2)));\n  (assert ((candidate Some(\"2018-01-01\")) = (2018, 1, 1)));\n  (assert ((candidate Some(\"1987-3-03\")) = (0, 0, 0)));\n  (assert ((candidate Some(\"20-1-1\")) = (0, 0, 0)));\n  (assert ((candidate Some(\"20-01-1\")) = (0, 0, 0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_207245_get_binary_category", "language": "ml", "prompt": "(**Get an integer binary classification label from a score between 0 and 1.\n*)\nlet get_binary_category (score : float) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_207245_get_binary_category.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_binary_category in\n  (assert ((candidate 0.75) = 1));\n  (assert ((candidate 0.99) = 1));\n  (assert ((candidate 0.01) = 0));\n  (assert ((candidate 0.25) = 0));\n  (assert ((candidate 0.6) = 1));\n  (assert ((candidate 0.2) = 0));\n  (assert ((candidate 0.9) = 1));\n  (assert ((candidate 0.4) = 0));\n  (assert ((candidate 0.8) = 1));\n  (assert ((candidate 1.0) = 1));\n  (assert ((candidate 0.0) = 0));\n  (assert ((candidate 0.3) = 0));\n  (assert ((candidate 0.9999) = 1));\n  (assert ((candidate 0.0001) = 0));\n  (assert ((candidate 0.1) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_207726_get_stride_sequence", "language": "ml", "prompt": "(**Return the sequence of the secondary structure.\nParameters\n----------\nstride_desc : list of (str, str, float, float, float)\n * The Stride description.\nReturns\n-------\nsequence : list of str\n * The secondary structure sequence.\n*)\nlet get_stride_sequence (stride_desc :  string * string * int * int * int list) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_207726_get_stride_sequence.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_stride_sequence in\n  (assert ((candidate [(\"H\", \"H\", 1, 2, 1); (\"E\", \"E\", 3, 4, 3); (\"L\", \"L\", 5, 6, 5); (\"H\", \"H\", 7, 8, 7); (\"E\", \"E\", 9, 10, 9)]) = [\"H\"; \"E\"; \"L\"; \"H\"; \"E\"]));\n  (assert ((candidate [(\"H\", \"H\", 1, 2, 1); (\"E\", \"E\", 3, 4, 3); (\"L\", \"L\", 5, 6, 5); (\"H\", \"H\", 7, 8, 7); (\"E\", \"E\", 9, 10, 9); (\"L\", \"L\", 11, 12, 11)]) = [\"H\"; \"E\"; \"L\"; \"H\"; \"E\"; \"L\"]));\n  (assert ((candidate [(\"H\", \"H\", 1, 2, 1); (\"E\", \"E\", 3, 4, 3); (\"L\", \"L\", 5, 6, 5); (\"H\", \"H\", 7, 8, 7)]) = [\"H\"; \"E\"; \"L\"; \"H\"]));\n  (assert ((candidate [(\"H\", \"H\", 1, 2, 1); (\"E\", \"E\", 3, 4, 3); (\"L\", \"L\", 5, 6, 5)]) = [\"H\"; \"E\"; \"L\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_209252_parse_size", "language": "ml", "prompt": "(**Parses a size specification. Valid specifications are:\n123: bytes\n123k: kilobytes\n123m: megabytes\n123g: gigabytes\n*)\nlet parse_size (s : string option) : int option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_209252_parse_size.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_size in\n  (assert ((candidate Some(\"1k\")) = Some(1024)));\n  (assert ((candidate Some(\"1\")) = Some(1)));\n  (assert ((candidate Some(\"123\")) = Some(123)));\n  (assert ((candidate Some(\"1000\")) = Some(1000)));\n  (assert ((candidate Some(None)) = Some(None)));\n  (assert ((candidate Some(\"\")) = Some(None)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_209453_contrasting_text_color", "language": "ml", "prompt": "(**Get a contrasting foreground text color for specified background hex color\n:param hext_str: A hex string color ('#XXXXXX') for which to determine a black-or-white\n * foreground color.\n:return: '#FFF' or '#000'.\n*)\nlet contrasting_text_color (hex_str : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_209453_contrasting_text_color.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = contrasting_text_color in\n  (assert ((candidate \"#FFFFFF\") = \"#000\"));\n  (assert ((candidate \"#012345\") = \"#FFF\"));\n  (assert ((candidate \"#000000\") = \"#FFF\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_209455_is_glob_mask", "language": "ml", "prompt": "(**Checks whether text contains mathing symbols usable with glob.glob()\n*)\nlet is_glob_mask (text : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_209455_is_glob_mask.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_glob_mask in\n  (assert ((candidate \"a/b/c/**.py\") = true));\n  (assert ((candidate \"foo\\?\") = true));\n  (assert ((candidate \"*\") = true));\n  (assert ((candidate \"foo*\") = true));\n  (assert ((candidate \"a/b/*.py\") = true));\n  (assert ((candidate \"foo?\") = true));\n  (assert ((candidate \"a/b/**/*.py\") = true));\n  (assert ((candidate \"foo\\*\") = true));\n  (assert ((candidate \"a/b/c\") = false));\n  (assert ((candidate \"a/b/**.py\") = true));\n  (assert ((candidate \"foo\") = false));\n  (assert ((candidate \"*.py\") = true));\n  (assert ((candidate \"some_text\") = false));\n  (assert ((candidate \"a/b/c/**/*.py\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_209668_to_yx", "language": "ml", "prompt": "(**transform a scalar from [0;4095] to a (y,x) coordinate in [0:63,0:63]\n*)\nlet to_yx (point : int) :  int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_209668_to_yx.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = to_yx in\n  (assert ((candidate 4095) = (63, 63)));\n  (assert ((candidate 1) = (1, 0)));\n  (assert ((candidate 0) = (0, 0)));\n  (assert ((candidate 65) = (1, 1)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_210558_is_matched", "language": "ml", "prompt": "(**Finds out how balanced an expression is.\nWith a string containing only brackets.\n>>> is_matched('[]()()(((([])))')\nFalse\n>>> is_matched('[](){{{[]}}}')\nTrue\n*)\nlet is_matched (expression : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_210558_is_matched.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_matched in\n  (assert ((candidate \"[](){{{[]}}}\") = true));\n  (assert ((candidate \"[]()()()\") = true));\n  (assert ((candidate \"[]()()()(((([])))\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_211884_simple_atmo_opstring", "language": "ml", "prompt": "(**Make a simple atmospheric correction formula.\n*)\nlet simple_atmo_opstring (haze : float) (contrast : float) (bias : float) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_211884_simple_atmo_opstring.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = simple_atmo_opstring in\n  (assert ((candidate 0.0 1.0 0.0) = \"gamma g 1.0, gamma b 1.0, sigmoidal rgb 1.0 0.0\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_212029_fix_url_path", "language": "ml", "prompt": "(**Add \"/\" to end of URL, if URL has path and doesn't end with \"/\"\nthe path will be removed by urljoin.\n*)\nlet fix_url_path (url : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_212029_fix_url_path.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = fix_url_path in\n  (assert ((candidate \"https://www.example.com\") = \"https://www.example.com/\"));\n  (assert ((candidate \"https://www.example.com/\") = \"https://www.example.com/\"));\n  (assert ((candidate \"https://www.example.com/test\") = \"https://www.example.com/test/\"));\n  (assert ((candidate \"https://www.example.com/test/\") = \"https://www.example.com/test/\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_212643_binary_to_integer", "language": "ml", "prompt": "(**Convert R or G or B pixel values from binary to integer.\nINPUT: A string tuple (e.g. (\"00101010\"))\nOUTPUT: Return an int tuple (e.g. (220))\n*)\nlet binary_to_integer (binary : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_212643_binary_to_integer.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = binary_to_integer in\n  (assert ((candidate \"011011101\") = 221));\n  (assert ((candidate \"10101010\") = 170));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_212796_is_abs", "language": "ml", "prompt": "(**Check if field is absolute value.\nParameters\n----------\nfield : str\n * Field name.\nReturns\n-------\n(bool, str)\n * Whether the field is absolute or not along with the basic field itself.\n*)\nlet is_abs (field : string) :  string * bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_212796_is_abs.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_abs in\n  (assert ((candidate \"hello\") = (\"hello\", false)));\n  (assert ((candidate \"hello)world\") = (\"hello)world\", false)));\n  (assert ((candidate \"ABS(ABS(hello))\") = (\"ABS(hello)\", true)));\n  (assert ((candidate \"ABS(hello)\") = (\"hello\", true)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_212940_path2ParentPath", "language": "ml", "prompt": "(**>>> path2ParentPath('/xxx/yyy/zzz/')\n'/xxx/yyy/zzz'\n>>> path2ParentPath('/xxx/yyy/zzz')\n'/xxx/yyy'\n>>> path2ParentPath('/xxx/yyy/zzz.gif')\n'/xxx/yyy'\n*)\nlet path2ParentPath (path : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_212940_path2ParentPath.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = path2ParentPath in\n  (assert ((candidate \"/xxx/yyy/zzz\") = \"/xxx/yyy\"));\n  (assert ((candidate \"/xxx/yyy/zzz/\") = \"/xxx/yyy/zzz\"));\n  (assert ((candidate \"/xxx/yyy/zzz.gif\") = \"/xxx/yyy\"));\n  (assert ((candidate \"/xxx/yyy/zzz\") = \"/xxx/yyy\"));\n  (assert ((candidate \"/xxx/yyy/zzz/\") = \"/xxx/yyy/zzz\"));\n  (assert ((candidate \"/xxx/yyy/zzz.gif\") = \"/xxx/yyy\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_213348__mask_to_shift", "language": "ml", "prompt": "(**Return the index of the least significant bit in the mask\n*)\nlet _mask_to_shift (mask : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_213348__mask_to_shift.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _mask_to_shift in\n  (assert ((candidate 1) = 0));\n  (assert ((candidate 15) = 0));\n  (assert ((candidate 64) = 6));\n  (assert ((candidate 2) = 1));\n  (assert ((candidate 251658240) = 24));\n  (assert ((candidate 1) = 0));\n  (assert ((candidate 128) = 7));\n  (assert ((candidate 8) = 3));\n  (assert ((candidate 65536) = 16));\n  (assert ((candidate 3) = 0));\n  (assert ((candidate 12) = 2));\n  (assert ((candidate 2) = 1));\n  (assert ((candidate 2) = 1));\n  (assert ((candidate 4) = 2));\n  (assert ((candidate 1) = 0));\n  (assert ((candidate 32) = 5));\n  (assert ((candidate 4) = 2));\n  (assert ((candidate 16) = 4));\n  (assert ((candidate 8) = 3));\n  (assert ((candidate 8) = 3));\n  (assert ((candidate 4) = 2));\n  (assert ((candidate 6) = 1));\n  (assert ((candidate 14) = 1));\n  (assert ((candidate 256) = 8));\n  (assert ((candidate 7) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_21334_azimu_half", "language": "ml", "prompt": "(**Transform azimuth from 180-360 range to range 0-180.\n:param degrees: Degrees in range 0 - 360\n:return: Degrees in range 0 - 180\n*)\nlet azimu_half (degrees : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_21334_azimu_half.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = azimu_half in\n  (assert ((candidate 360.0) = 180.0));\n  (assert ((candidate 180.0) = 0.0));\n  (assert ((candidate 210.0) = 30.0));\n  (assert ((candidate 0.0) = 0.0));\n  (assert ((candidate 60.0) = 60.0));\n  (assert ((candidate 135.0) = 135.0));\n  (assert ((candidate 350.0) = 170.0));\n  (assert ((candidate 270.0) = 90.0));\n  (assert ((candidate 90.0) = 90.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_213491_calculate_a", "language": "ml", "prompt": "(**Private function\n*)\nlet calculate_a (cl_i : int) (int_ : float) (n_term : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_213491_calculate_a.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = calculate_a in\n  (assert ((candidate 0 0.08 10) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_213836_decodeModifiers", "language": "ml", "prompt": "(**{:032b}\n0 0 0 0 0 0 0 0 0 0 0 1   1   1   1   1   0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1\n0                     11  12  13  14  15                                31\ncmd  00000000000100000000000100001000 b11\nalt  00000000000010000000000100100000 b12\nctrl 00000000000001000000000100000001 b13\nshft 00000000000000100000000100000010 b14\ncaps 00000000000000010000000100000000 b15\n*)\nlet decodeModifiers (modifier : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_213836_decodeModifiers.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = decodeModifiers in\n  (assert ((candidate 65536) = \"Caps\"));\n  (assert ((candidate 0) = \"\"));\n  (assert ((candidate 1) = \"\"));\n  (assert ((candidate 0) = \"\"));\n  (assert ((candidate 0) = \"\"));\n  (assert ((candidate 0) = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_213973_choice_verification", "language": "ml", "prompt": "(**Check choice and return True according.\n*)\nlet choice_verification (choice : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_213973_choice_verification.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = choice_verification in\n  (assert ((candidate \"O\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_214021_joinargs", "language": "ml", "prompt": "(**Joins given args (if valid) using join_str.\nThe result is stored in a context variable.\nExample usage: {% join '/' str1 str2 str3 ... as var %}\n*)\nlet joinargs (join_str : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_214021_joinargs.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = joinargs in\n  (assert ((candidate \"/\") = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_214624_metacyc_url", "language": "ml", "prompt": "(**Return the url for the pathway on the MetaCyc website \nArgs:\n * pathway (string): The MetaCyc pathway\nReturns\n * (string): The url to the website for the pathway\n*)\nlet metacyc_url (pathway : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_214624_metacyc_url.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = metacyc_url in\n  (assert ((candidate \"PFK\") = \"http://metacyc.org/META/NEW-IMAGE?type=NIL&object=PFK\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_215353_sum_2_dictionaries", "language": "ml", "prompt": "(**Given two dictionaries of totals, where each total refers to a key\nin the dictionary, add the totals.\nE.g.:  dicta = { 'a' : 3, 'b' : 1 }\n * dictb = { 'a' : 1, 'c' : 5 }\n * dicta + dictb = { 'a' : 4, 'b' : 1, 'c' : 5 }\n@param dicta: (dictionary)\n@param dictb: (dictionary)\n@return: (dictionary) - the sum of the 2 dictionaries\n*)\nlet sum_2_dictionaries (dicta : (string, int) list) (dictb : (string, int) list) : (string, int) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_215353_sum_2_dictionaries.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sum_2_dictionaries in\n  (assert ((candidate [(\"a\", 1)] []) = [(\"a\", 1)]));\n  (assert ((candidate [(\"a\", 0); (\"b\", 0)] [(\"a\", 0); (\"b\", 0)]) = [(\"a\", 0); (\"b\", 0)]));\n  (assert ((candidate [(\"a\", 0)] [(\"a\", 0)]) = [(\"a\", 0)]));\n  (assert ((candidate [(\"a\", 0); (\"b\", 0)] [(\"a\", 0); (\"b\", 0)]) = [(\"a\", 0); (\"b\", 0)]));\n  (assert ((candidate [] [(\"a\", 3); (\"b\", 1); (\"c\", 5)]) = [(\"a\", 3); (\"b\", 1); (\"c\", 5)]));\n  (assert ((candidate [] []) = []));\n  (assert ((candidate [(\"a\", 3)] [(\"b\", 1); (\"c\", 5)]) = [(\"a\", 3); (\"b\", 1); (\"c\", 5)]));\n  (assert ((candidate [(\"a\", 3); (\"b\", 1); (\"c\", 5)] []) = [(\"a\", 3); (\"b\", 1); (\"c\", 5)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_215837_verify", "language": "ml", "prompt": "(**To check whether `url` belongs to YouTube, if yes returns True\nelse False\n*)\nlet verify (url : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_215837_verify.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = verify in\n  (assert ((candidate \"https://www.youtube.com/watch?v=vZ19cI4k-oI&index=12\") = true));\n  (assert ((candidate \"https://www.youtube.com\") = true));\n  (assert ((candidate \"https://www.youttube.com\") = false));\n  (assert ((candidate \"\") = false));\n  (assert ((candidate \"https://youtu.be/dQw4w9WgXcQ\") = true));\n  (assert ((candidate \"https://www.youtube.com/watch?v=vZ19cI4k-oI\") = true));\n  (assert ((candidate \"https://www.youtube.com/watch?v=vZ19cI4k-oI&list=PLhTjy8cBISEqY-J1w0J6iC613vudN2Y4B\") = true));\n  (assert ((candidate \"https://www.youtube.com/watch?v=vZ19cI4k-oI&list=PLhTjy8cBISEqY-J1w0J6iC613vudN2Y4B&index=12&t=454s\") = true));\n  (assert ((candidate \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_215878_is_duplicate", "language": "ml", "prompt": "(**Return True if the string 'Possible Duplicate is in string s or False, otherwise.'\n:param s:\n:return:\n*)\nlet is_duplicate (s : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_215878_is_duplicate.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_duplicate in\n  (assert ((candidate str 16) = false));\n  (assert ((candidate \"Possible Duplicate: 6221711006451504961, 6221711006451504962, 6221711006451504963, 6221711006451504964, 6221711006451504965\") = true));\n  (assert ((candidate \"Possible Duplicate: 13.24 13.24 13.24 13.24\") = true));\n  (assert ((candidate \"4\") = false));\n  (assert ((candidate \"0\") = false));\n  (assert ((candidate \"Possible Duplicate: 13.24 13.24 13.24 13.24 13.24\") = true));\n  (assert ((candidate str 4) = false));\n  (assert ((candidate str 8) = false));\n  (assert ((candidate \"Possible Duplicate: 0.00014341297035841606 0.00014341297035841606\") = true));\n  (assert ((candidate \"Possible Duplicate: 13.24\") = true));\n  (assert ((candidate \"12\") = false));\n  (assert ((candidate \"\nPossible Duplicate:\nFirst name: John\nLast name: Doe\nEmail: <EMAIL>\nFirst name: John\nLast name: Doe\nEmail: <EMAIL>\n\") = true));\n  (assert ((candidate str 0) = false));\n  (assert ((candidate str 2) = false));\n  (assert ((candidate str 6) = false));\n  (assert ((candidate \"8\") = false));\n  (assert ((candidate \"Possible Duplicate: 13.24 \") = true));\n  (assert ((candidate \"Possible Duplicate: 6221711006451504961, 6221711006451504962, 6221711006451504963, 6221711006451504964\") = true));\n  (assert ((candidate str 10) = false));\n  (assert ((candidate \"10\") = false));\n  (assert ((candidate str 14) = false));\n  (assert ((candidate \"2\") = false));\n  (assert ((candidate str 12) = false));\n  (assert ((candidate \"6\") = false));\n  (assert ((candidate str 18) = false));\n  (assert ((candidate \"\nPossible Duplicate:\nFirst name: John\nLast name: Doe\nEmail: <EMAIL>\nFirst name: John\nLast name: Doe\nEmail: <EMAIL>\n\nPossible Duplicate:\nFirst name: John\nLast name: Doe\nEmail: <EMAIL>\nFirst name: Mary\nLast name: Smith\nEmail: <EMAIL>\n\") = true));\n  (assert ((candidate \"14\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_216479_find_common_left", "language": "ml", "prompt": "(**:param list[str] strings: list of strings we want to find a common left part in\n:rtype: str\n*)\nlet find_common_left (strings : string list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_216479_find_common_left.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = find_common_left in\n  (assert ((candidate [\"a\"; \"b\"]) = \"\"));\n  (assert ((candidate [\"abc\"; \"def\"]) = \"\"));\n  (assert ((candidate [\"aa\"; \"ab\"; \"a\"]) = \"a\"));\n  (assert ((candidate [\"aba\"; \"cdc\"; \"eae\"]) = \"\"));\n  (assert ((candidate [\"ab\"; \"a\"; \"ac\"]) = \"a\"));\n  (assert ((candidate [\"abcd\"; \"abab\"; \"ababd\"; \"abcdx\"]) = \"ab\"));\n  (assert ((candidate [\"abc\"; \"a\"; \"acb\"]) = \"a\"));\n  (assert ((candidate [\"aaa\"; \"aab\"; \"abb\"; \"bbb\"; \"ccc\"]) = \"\"));\n  (assert ((candidate [\"abc\"; \"d\"; \"cba\"]) = \"\"));\n  (assert ((candidate [\"\"; \"c\"; \"c\"]) = \"\"));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"; \"d\"]) = \"\"));\n  (assert ((candidate [\"\"; \"T\"; \"a\"; \"t\"; \"a\"; \"a\"; \"T\"; \"T\"; \"\"]) = \"\"));\n  (assert ((candidate [\"aa\"; \"a\"]) = \"a\"));\n  (assert ((candidate [\"\"; \"\"]) = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_216526_center_position", "language": "ml", "prompt": "(**Center bounds within available space.\n:param low_bound: current lower bound\n:param high_bound: current upper bound\n:param low_limit: minimum allowed bound\n:param high_limit: maximum allowed bound\n:param space: available space\n:return: centered low bound, centered high bound\n*)\nlet center_position (low_bound : int) (high_bound : int) (low_limit : int) (high_limit : int) (space : int) :  int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_216526_center_position.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = center_position in\n  (assert ((candidate 0 0 0 0 10) = (0, 0)));\n  (assert ((candidate 1 3 0 4 4) = (1, 3)));\n  (assert ((candidate 0 3 0 4 2) = (0, 3)));\n  (assert ((candidate 0 5 0 0 10) = (0, 5)));\n  (assert ((candidate 0 1 0 2 2) = (0, 1)));\n  (assert ((candidate 0 10 0 0 10) = (0, 10)));\n  (assert ((candidate 0 1 0 0 10) = (0, 1)));\n  (assert ((candidate 0 2 0 4 2) = (0, 2)));\n  (assert ((candidate 0 4 0 6 10) = (0, 4)));\n  (assert ((candidate 0 4 0 8 10) = (0, 4)));\n  (assert ((candidate 0 1 1 2 2) = (0, 1)));\n  (assert ((candidate 0 2 0 3 2) = (0, 2)));\n  (assert ((candidate 1 3 0 4 2) = (0, 2)));\n  (assert ((candidate 0 2 0 4 4) = (0, 2)));\n  (assert ((candidate 0 1 1 2 3) = (1, 2)));\n  (assert ((candidate 0 4 0 0 10) = (0, 4)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_217312_and_is_true", "language": "ml", "prompt": "(**Function:  and_is_true\nDescription:  Uses a truth table to do an AND check between two values of\n * {Yes (True) / No (False)}.\nArguments:\n * (input) itemx -> Yes or No value.\n * (input) itemy -> Yes or No value.\n * (output) Return True | False based on AND comparsion.\n*)\nlet and_is_true (itemx : string) (itemy : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_217312_and_is_true.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = and_is_true in\n  (assert ((candidate \"No\" \"Yes\") = false));\n  (assert ((candidate \"Yes\" \"No\") = false));\n  (assert ((candidate \"No\" \"No\") = false));\n  (assert ((candidate \"Yes\" \"Yes\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_217479__number_channels", "language": "ml", "prompt": "(**Determines the number of channels corresponding to a RGB flag.\n*)\nlet _number_channels (rgb : bool) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_217479__number_channels.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _number_channels in\n  (assert ((candidate true) = 3));\n  (assert ((candidate false) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_217549_is_valid_git_sha1", "language": "ml", "prompt": "(**check if a string is a valid git sha1 string\nInput:\nhash: string to validate\nOutput:\nTrue if the string has 40 characters and is an hexadecimal number, False\notherwise.\n*)\nlet is_valid_git_sha1 (hash : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_217549_is_valid_git_sha1.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_valid_git_sha1 in\n  (assert ((candidate \"0123456789012345678901234567890123456789x\") = false));\n  (assert ((candidate \"012345678901234567890123456789012345678x\") = false));\n  (assert ((candidate \"a\") = false));\n  (assert ((candidate \"\") = false));\n  (assert ((candidate \"01234567890\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_217944_upsample", "language": "ml", "prompt": "(**Stretch bits worth of data to fill the byte.\nThis is done by duplicating the MSB to fill the remaining space.\n*)\nlet upsample (bits : int) (data : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_217944_upsample.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = upsample in\n  (assert ((candidate 9 0) = 0));\n  (assert ((candidate 0 0) = 0));\n  (assert ((candidate 0 1) = 1));\n  (assert ((candidate 1 0) = 0));\n  (assert ((candidate 8 0) = 0));\n  (assert ((candidate 0 255) = 255));\n  (assert ((candidate 3 0) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_218685_capitalized", "language": "ml", "prompt": "(**Return a string with its first character capitalized.\n*)\nlet capitalized (s : string option) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_218685_capitalized.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = capitalized in\n  (assert ((candidate Some(\"Word\")) = Some(\"Word\")));\n  (assert ((candidate Some(\"sentence\")) = Some(\"Sentence\")));\n  (assert ((candidate Some(\"abc\")) = Some(\"Abc\")));\n  (assert ((candidate Some(\"\")) = Some(\"\")));\n  (assert ((candidate Some(\"a\")) = Some(\"A\")));\n  (assert ((candidate Some(None)) = Some(None)));\n  (assert ((candidate Some(\"A\")) = Some(\"A\")));\n  (assert ((candidate Some(\"word\")) = Some(\"Word\")));\n  (assert ((candidate Some(\"Sentence\")) = Some(\"Sentence\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_218914_problem_26", "language": "ml", "prompt": "(**longest recurring cycle in decimal fractions\n*)\nlet problem_26 (lim : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_218914_problem_26.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = problem_26 in\n  (assert ((candidate 1000) = 983));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_220758_arabic_to_roman", "language": "ml", "prompt": "(**Return roman version of the specified arabic number.\n*)\nlet arabic_to_roman (number : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_220758_arabic_to_roman.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = arabic_to_roman in\n  (assert ((candidate 891) = \"DCCCXCI\"));\n  (assert ((candidate 25) = \"XXV\"));\n  (assert ((candidate 16) = \"XVI\"));\n  (assert ((candidate 80) = \"LXXX\"));\n  (assert ((candidate 501) = \"DI\"));\n  (assert ((candidate 990) = \"CMXC\"));\n  (assert ((candidate 14) = \"XIV\"));\n  (assert ((candidate 15) = \"XV\"));\n  (assert ((candidate 6) = \"VI\"));\n  (assert ((candidate 649) = \"DCXLIX\"));\n  (assert ((candidate 93) = \"XCIII\"));\n  (assert ((candidate 500) = \"D\"));\n  (assert ((candidate 88) = \"LXXXVIII\"));\n  (assert ((candidate 9) = \"IX\"));\n  (assert ((candidate 99) = \"XCIX\"));\n  (assert ((candidate 12) = \"XII\"));\n  (assert ((candidate 10) = \"X\"));\n  (assert ((candidate 1) = \"I\"));\n  (assert ((candidate 7) = \"VII\"));\n  (assert ((candidate 8) = \"VIII\"));\n  (assert ((candidate 19) = \"XIX\"));\n  (assert ((candidate 3) = \"III\"));\n  (assert ((candidate 2) = \"II\"));\n  (assert ((candidate 600) = \"DC\"));\n  (assert ((candidate 17) = \"XVII\"));\n  (assert ((candidate 400) = \"CD\"));\n  (assert ((candidate 23) = \"XXIII\"));\n  (assert ((candidate 27) = \"XXVII\"));\n  (assert ((candidate 20) = \"XX\"));\n  (assert ((candidate 100) = \"C\"));\n  (assert ((candidate 40) = \"XL\"));\n  (assert ((candidate 21) = \"XXI\"));\n  (assert ((candidate 0) = \"\"));\n  (assert ((candidate 30) = \"XXX\"));\n  (assert ((candidate 798) = \"DCCXCVIII\"));\n  (assert ((candidate 22) = \"XXII\"));\n  (assert ((candidate 300) = \"CCC\"));\n  (assert ((candidate 13) = \"XIII\"));\n  (assert ((candidate 70) = \"LXX\"));\n  (assert ((candidate 200) = \"CC\"));\n  (assert ((candidate 11) = \"XI\"));\n  (assert ((candidate 24) = \"XXIV\"));\n  (assert ((candidate 5) = \"V\"));\n  (assert ((candidate 60) = \"LX\"));\n  (assert ((candidate 90) = \"XC\"));\n  (assert ((candidate 18) = \"XVIII\"));\n  (assert ((candidate 50) = \"L\"));\n  (assert ((candidate 4) = \"IV\"));\n  (assert ((candidate 700) = \"DCC\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_221003_create_nonlocal_service_cluster_name", "language": "ml", "prompt": "(**Create the cluster name for the non-local namespace, service, color.\n*)\nlet create_nonlocal_service_cluster_name (namespace : string) (service : string) (color : string) (index : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_221003_create_nonlocal_service_cluster_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = create_nonlocal_service_cluster_name in\n  (assert ((candidate \"default\" \"test-service\" \"blue\" 1) = \"remote-default-test-service-blue-1\"));\n  (assert ((candidate \"default\" \"test-service\" \"blue\" 2) = \"remote-default-test-service-blue-2\"));\n  (assert ((candidate \"default\" \"test-service\" \"blue\" 2) = \"remote-default-test-service-blue-2\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_221888_FindMaximumSubarray", "language": "ml", "prompt": "(**Encuentra la mayor subsecuencia dentro de la lista A.\nSi se recibe una lista vacia se lanza una excepcion de tipo IndexError.\nRetorna:\nmax_left -- El indice izquierdo del subarreglo\nmax_right -- El indice derecho del subarreglo\nsuma -- La suma total del subarreglo\n*)\nlet FindMaximumSubarray (A : int list) :  int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_221888_FindMaximumSubarray.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = FindMaximumSubarray in\n  (assert ((candidate [1; 2; 3]) = (0, 2, 6)));\n  (assert ((candidate [(~1); (~2); (~3); (~4)]) = (0, 0, (~1))));\n  (assert ((candidate [1]) = (0, 0, 1)));\n  (assert ((candidate [(~1); (~2); 0; 1]) = (2, 3, 1)));\n  (assert ((candidate [1; 2; 3]) = (0, 2, 6)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_22246_get_chunk_slices", "language": "ml", "prompt": "(**Create list of chunk slices [(s_i, e_i), ...]\nParameters\n----------\nds_len : 'int'\n * Length of dataset axis to chunk\nchunk_size : 'int'\n * Size of chunks\nReturns\n-------\nchunks : 'list'\n * List of chunk start and end positions\n * [(s_i, e_i), (s_i+1, e_i+1), ...]\n*)\nlet get_chunk_slices (ds_dim : int) (chunk_size : int) :  int * int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_22246_get_chunk_slices.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_chunk_slices in\n  (assert ((candidate 10 15) = [(0, 10)]));\n  (assert ((candidate 2 1) = [(0, 1); (1, 2)]));\n  (assert ((candidate 6 6) = [(0, 6)]));\n  (assert ((candidate 10 13) = [(0, 10)]));\n  (assert ((candidate 10 14) = [(0, 10)]));\n  (assert ((candidate 10 12) = [(0, 10)]));\n  (assert ((candidate 9 5) = [(0, 5); (5, 9)]));\n  (assert ((candidate 10 10) = [(0, 10)]));\n  (assert ((candidate 3 2) = [(0, 2); (2, 3)]));\n  (assert ((candidate 6 2) = [(0, 2); (2, 4); (4, 6)]));\n  (assert ((candidate 10 17) = [(0, 10)]));\n  (assert ((candidate 6 1) = [(0, 1); (1, 2); (2, 3); (3, 4); (4, 5); (5, 6)]));\n  (assert ((candidate 1 1) = [(0, 1)]));\n  (assert ((candidate 2 2) = [(0, 2)]));\n  (assert ((candidate 6 4) = [(0, 4); (4, 6)]));\n  (assert ((candidate 7 2) = [(0, 2); (2, 4); (4, 6); (6, 7)]));\n  (assert ((candidate 5 1) = [(0, 1); (1, 2); (2, 3); (3, 4); (4, 5)]));\n  (assert ((candidate 3 1) = [(0, 1); (1, 2); (2, 3)]));\n  (assert ((candidate 10 5) = [(0, 5); (5, 10)]));\n  (assert ((candidate 10 16) = [(0, 10)]));\n  (assert ((candidate 6 7) = [(0, 6)]));\n  (assert ((candidate 10 18) = [(0, 10)]));\n  (assert ((candidate 5 2) = [(0, 2); (2, 4); (4, 5)]));\n  (assert ((candidate 8 4) = [(0, 4); (4, 8)]));\n  (assert ((candidate 9 2) = [(0, 2); (2, 4); (4, 6); (6, 8); (8, 9)]));\n  (assert ((candidate 7 4) = [(0, 4); (4, 7)]));\n  (assert ((candidate 4 1) = [(0, 1); (1, 2); (2, 3); (3, 4)]));\n  (assert ((candidate 4 2) = [(0, 2); (2, 4)]));\n  (assert ((candidate 5 3) = [(0, 3); (3, 5)]));\n  (assert ((candidate 5 5) = [(0, 5)]));\n  (assert ((candidate 5 6) = [(0, 5)]));\n  (assert ((candidate 6 3) = [(0, 3); (3, 6)]));\n  (assert ((candidate 10 11) = [(0, 10)]));\n  (assert ((candidate 8 2) = [(0, 2); (2, 4); (4, 6); (6, 8)]));\n  (assert ((candidate 6 5) = [(0, 5); (5, 6)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_222628_indent", "language": "ml", "prompt": "(**Indent each row of the given string block with ``n*2`` spaces.\n*)\nlet indent (block : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_222628_indent.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = indent in\n  (assert ((candidate \"foo\nbar\") = \"  foo\n  bar\"));\n  (assert ((candidate \"hello\n  world\") = \"  hello\n    world\"));\n  (assert ((candidate \"hello\nworld\") = \"  hello\n  world\"));\n  (assert ((candidate \"hello\") = \"  hello\"));\n  (assert ((candidate \"foo\") = \"  foo\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_223007_get_unlabled_last_index", "language": "ml", "prompt": "(**For example, for CIFAR100 we have len_dataset 10000 for test data.\nThe number of samples per class is 1000.\nIf we want 9000 unlabeled samples then the ratio_unlabeled is 9/10.\nThe number of samples per class for the unlabeled dataset is 9/10*100=90.\nIf the number of samples for the final test is 1000 samples and we have 100\nclasses, then the number of samples per class will be 10 (only).\n:param num_unlabeled_samples: number of unlabeled samples from the test set\n:param len_dataset: the total number of samples in the intial test set\n:param len_class: the number of samples for a given class\n:return: for the array of sample indices for the class, the last index for\nthe unlabeled part\n>>> num_unlabeled_samples = 9000\n>>> len_dataset = 10000\n>>> len_class = 100\n>>> result = get_unlabled_last_index(num_unlabeled_samples=num_unlabeled_samples, len_dataset=len_dataset, len_class=len_class)\n>>> assert result == 90\n>>> # print('result: ', result)\n*)\nlet get_unlabled_last_index (num_unlabeled_samples : int) (len_dataset : int) (len_class : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_223007_get_unlabled_last_index.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_unlabled_last_index in\n  (assert ((candidate 9000 10000 10000) = 9000));\n  (assert ((candidate 2000 1000 100) = 200));\n  (assert ((candidate 1000 1000 100) = 100));\n  (assert ((candidate 10 100 100) = 10));\n  (assert ((candidate 1 100 100) = 1));\n  (assert ((candidate 9000 10000 100) = 90));\n  (assert ((candidate 100 1000 100) = 10));\n  (assert ((candidate 0 100 100) = 0));\n  (assert ((candidate 100 100 30) = 30));\n  (assert ((candidate 100 100 50) = 50));\n  (assert ((candidate 10000 1000 100) = 1000));\n  (assert ((candidate 200 100 10) = 20));\n  (assert ((candidate 100 100 10) = 10));\n  (assert ((candidate 9000 10000 1000) = 900));\n  (assert ((candidate 50 100 10) = 5));\n  (assert ((candidate 100 100 1) = 1));\n  (assert ((candidate 9000 10000 500) = 450));\n  (assert ((candidate 9000 10000 150) = 135));\n  (assert ((candidate 9000 10000 200) = 180));\n  (assert ((candidate 100 100 40) = 40));\n  (assert ((candidate 100 100 60) = 60));\n  (assert ((candidate 100 100 20) = 20));\n  (assert ((candidate 900 1000 100) = 90));\n  (assert ((candidate 9000 10000 100) = 90));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_223709_one_to_three", "language": "ml", "prompt": "(**Take a score -1, 0, or 1, and return the three vector of labels\n*)\nlet one_to_three (one : int) :  int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_223709_one_to_three.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = one_to_three in\n  (assert ((candidate 0) = (0, 1, 0)));\n  (assert ((candidate 1) = (0, 0, 1)));\n  (assert ((candidate (~1)) = (1, 0, 0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_224204_glue_template_and_params", "language": "ml", "prompt": "(**Return wiki text of template glued from params.\nYou can use items from extract_templates_and_params here to get\nan equivalent template wiki text (it may happen that the order\nof the params changes).\n*)\nlet glue_template_and_params (template_and_params :  string * (string, string) list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_224204_glue_template_and_params.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = glue_template_and_params in\n  (assert ((candidate (\"Template\", [(\"param1\", \"value1\"); (\"param2\", \"value2\"); (\"param3\", \"value3\"); (\"param4\", \"value4\")])) = \"{{Template\n|param1=value1\n|param2=value2\n|param3=value3\n|param4=value4\n}}\"));\n  (assert ((candidate (\"Template\", [(\"param1\", \"value1\"); (\"param2\", \"value2\"); (\"param3\", \"value3\"); (\"param4\", \"value4\"); (\"param5\", \"value5\")])) = \"{{Template\n|param1=value1\n|param2=value2\n|param3=value3\n|param4=value4\n|param5=value5\n}}\"));\n  (assert ((candidate (\"Template\", [(\"param1\", \"value1\"); (\"param2\", \"value2\"); (\"param3\", \"value3\")])) = \"{{Template\n|param1=value1\n|param2=value2\n|param3=value3\n}}\"));\n  (assert ((candidate (\"Template\", [(\"param1\", \"value1\"); (\"param2\", \"value2\")])) = \"{{Template\n|param1=value1\n|param2=value2\n}}\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_224251_export_shard_uuid", "language": "ml", "prompt": "(**Sharding of the UUID for the import/export\n:param uuid: UUID to be sharded (v4)\n:type uuid: str\n:return: Sharded UUID as a subfolder path\n:rtype: str\n*)\nlet export_shard_uuid (uuid : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_224251_export_shard_uuid.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = export_shard_uuid in\n  (assert ((candidate \"412c7920-220e-45d8-b1a1-8704b04144b7\") = \"41/2c/7920-220e-45d8-b1a1-8704b04144b7\"));\n  (assert ((candidate \"a83f28ec-9b98-4036-923a-84b758b43790\") = \"a8/3f/28ec-9b98-4036-923a-84b758b43790\"));\n  (assert ((candidate \"9d241b76-b780-4a0f-98e1-400088a41f92\") = \"9d/24/1b76-b780-4a0f-98e1-400088a41f92\"));\n  (assert ((candidate \"61516d6c-3190-4434-998f-4e9179a86b61\") = \"61/51/6d6c-3190-4434-998f-4e9179a86b61\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_224338_check_header", "language": "ml", "prompt": "(**Check whether a line is header, if it is, change it into html format\n:param line: str, a line in markdown file\n:return: boolean, whether a line is header\n * str, the line in html format\n*)\nlet check_header (line : string) :  bool * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_224338_check_header.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = check_header in\n  (assert ((candidate \"This is not a header.\") = (false, \"\")));\n  (assert ((candidate \"#Heading 1\") = (false, \"\")));\n  (assert ((candidate \"##### Heading 5\") = (true, \"<h5 id=\"Heading-5\">Heading 5</h5>\")));\n  (assert ((candidate \"##Heading 2\") = (false, \"\")));\n  (assert ((candidate \"# foo\") = (true, \"<h1 id=\"foo\">foo</h1>\")));\n  (assert ((candidate \"This is not a header\") = (false, \"\")));\n  (assert ((candidate \"##### test\") = (true, \"<h5 id=\"test\">test</h5>\")));\n  (assert ((candidate \"###\") = (false, \"\")));\n  (assert ((candidate \"#####Heading 5\") = (false, \"\")));\n  (assert ((candidate \"test\") = (false, \"\")));\n  (assert ((candidate \"foo\") = (false, \"\")));\n  (assert ((candidate \"A Header\") = (false, \"\")));\n  (assert ((candidate \"##### foo\") = (true, \"<h5 id=\"foo\">foo</h5>\")));\n  (assert ((candidate \"###### Heading 6\") = (true, \"<h6 id=\"Heading-6\">Heading 6</h6>\")));\n  (assert ((candidate \"# Heading 1\") = (true, \"<h1 id=\"Heading-1\">Heading 1</h1>\")));\n  (assert ((candidate \"#### Heading 4\") = (true, \"<h4 id=\"Heading-4\">Heading 4</h4>\")));\n  (assert ((candidate \"### foo\") = (true, \"<h3 id=\"foo\">foo</h3>\")));\n  (assert ((candidate \"## foo\") = (true, \"<h2 id=\"foo\">foo</h2>\")));\n  (assert ((candidate \"####### An Un-Countable Level Header\") = (false, \"\")));\n  (assert ((candidate \"###### test\") = (true, \"<h6 id=\"test\">test</h6>\")));\n  (assert ((candidate \"# test\") = (true, \"<h1 id=\"test\">test</h1>\")));\n  (assert ((candidate \"### test\") = (true, \"<h3 id=\"test\">test</h3>\")));\n  (assert ((candidate \"#### test\") = (true, \"<h4 id=\"test\">test</h4>\")));\n  (assert ((candidate \"###### foo\") = (true, \"<h6 id=\"foo\">foo</h6>\")));\n  (assert ((candidate \"## Heading 2\") = (true, \"<h2 id=\"Heading-2\">Heading 2</h2>\")));\n  (assert ((candidate \"####Heading 4\") = (false, \"\")));\n  (assert ((candidate \"#### foo\") = (true, \"<h4 id=\"foo\">foo</h4>\")));\n  (assert ((candidate \"##\") = (false, \"\")));\n  (assert ((candidate \"######Heading 6\") = (false, \"\")));\n  (assert ((candidate \"This is not a header\n\n\") = (false, \"\")));\n  (assert ((candidate \"### Heading 3\") = (true, \"<h3 id=\"Heading-3\">Heading 3</h3>\")));\n  (assert ((candidate \"## test\") = (true, \"<h2 id=\"test\">test</h2>\")));\n  (assert ((candidate \"###Heading 3\") = (false, \"\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_225363_minify_html", "language": "ml", "prompt": "(**Perform a template-specific, rudimentary HTML minification for displaCy.\nDisclaimer: NOT a general-purpose solution, only removes indentation and\nnewlines.\nhtml (unicode): Markup to minify.\nRETURNS (unicode): \"Minified\" HTML.\n*)\nlet minify_html (html : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_225363_minify_html.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = minify_html in\n  (assert ((candidate \" \n  <p> Hello, world! </p> \n \") = \"<p> Hello, world! </p>\"));\n  (assert ((candidate \"\n    <h1>Hello, World!</h1>\n    <p>This is a paragraph.</p>\n    \") = \"<h1>Hello, World!</h1><p>This is a paragraph.</p>\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"\n    <h1>Hello, World!</h1>\n    \") = \"<h1>Hello, World!</h1>\"));\n  (assert ((candidate \"\n    <h1>Hello, World!</h1>\n\n    <p>This is a paragraph.</p>\n\n    <p>This is another paragraph.</p>\n    \") = \"<h1>Hello, World!</h1><p>This is a paragraph.</p><p>This is another paragraph.</p>\"));\n  (assert ((candidate \"   \") = \"\"));\n  (assert ((candidate \"\n\") = \"\"));\n  (assert ((candidate \"        <p>Hello, world.</p>        \") = \"<p>Hello, world.</p>\"));\n  (assert ((candidate \"   <p>Hello, world!</p> \n \n\n \") = \"<p>Hello, world!</p>\"));\n  (assert ((candidate \"    <p>Hello, world.</p>    \") = \"<p>Hello, world.</p>\"));\n  (assert ((candidate \"\n        <p>Hello, world.</p>        \n\") = \"<p>Hello, world.</p>\"));\n  (assert ((candidate \"    <p>A paragraph.</p>\") = \"<p>A paragraph.</p>\"));\n  (assert ((candidate \"<html><head><title>Test</title></head><body><p>A paragraph.</p></body></html>\") = \"<html><head><title>Test</title></head><body><p>A paragraph.</p></body></html>\"));\n  (assert ((candidate \"\n    <h1>Hello, World!</h1>\n    <p>This is a paragraph.</p>\n    <p>This is another paragraph.</p>\n    \") = \"<h1>Hello, World!</h1><p>This is a paragraph.</p><p>This is another paragraph.</p>\"));\n  (assert ((candidate \"\n    <h1>Hello, World!</h1>\n\n    <p>This is a paragraph.</p>\n    \") = \"<h1>Hello, World!</h1><p>This is a paragraph.</p>\"));\n  (assert ((candidate \"<p>A paragraph.</p>\") = \"<p>A paragraph.</p>\"));\n  (assert ((candidate \"<p>Hello, world.</p>\") = \"<p>Hello, world.</p>\"));\n  (assert ((candidate \"\n    <p>Hello, world.</p>    \n\") = \"<p>Hello, world.</p>\"));\n  (assert ((candidate \" \n\n\n\n  \n\") = \"\"));\n  (assert ((candidate \"Hello, world!\") = \"Hello, world!\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_226063_conjugatePartition", "language": "ml", "prompt": "(**Find the conjugate of a partition.\nE.g. len(p) = max(conjugate(p)) and vice versa.\nD. Eppstein, August 2005.\n*)\nlet conjugatePartition (p : int list) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_226063_conjugatePartition.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = conjugatePartition in\n  (assert ((candidate [1; 1; 1]) = [3]));\n  (assert ((candidate [3; 3; 3]) = [3; 3; 3]));\n  (assert ((candidate [1]) = [1]));\n  (assert ((candidate [1; 2; 3]) = [3; 2; 1]));\n  (assert ((candidate [1]) = [1]));\n  (assert ((candidate candidate [2; 2; 2; 2]) = [2; 2; 2; 2]));\n  (assert ((candidate [1; 1; 1; 1; 1; 1; 1; 1]) = [8]));\n  (assert ((candidate candidate [10; 5; 3; 2; 1]) = [10; 5; 3; 2; 1]));\n  (assert ((candidate []) = []));\n  (assert ((candidate candidate [2]) = [2]));\n  (assert ((candidate [1; 1]) = [2]));\n  (assert ((candidate candidate [2; 2; 2; 2; 2; 2; 1]) = [2; 2; 2; 2; 2; 2; 1]));\n  (assert ((candidate candidate [2; 2; 2; 2; 2; 2]) = [2; 2; 2; 2; 2; 2]));\n  (assert ((candidate [1; 2; 1]) = [3; 1]));\n  (assert ((candidate candidate [2; 1; 1]) = [2; 1; 1]));\n  (assert ((candidate []) = []));\n  (assert ((candidate candidate []) = []));\n  (assert ((candidate [1; 2]) = [2; 1]));\n  (assert ((candidate candidate [2; 2; 2; 2; 2]) = [2; 2; 2; 2; 2]));\n  (assert ((candidate [1; 2; 3; 4; 5; 6; 7; 8]) = [8; 7; 6; 5; 4; 3; 2; 1]));\n  (assert ((candidate candidate [2; 2]) = [2; 2]));\n  (assert ((candidate candidate [5; 4; 3; 2; 1]) = [5; 4; 3; 2; 1]));\n  (assert ((candidate [1; 1; 1; 1]) = [4]));\n  (assert ((candidate [2; 1]) = [2; 1]));\n  (assert ((candidate [1; 1; 1; 1; 1; 1; 1]) = [7]));\n  (assert ((candidate candidate [2; 2; 2]) = [2; 2; 2]));\n  (assert ((candidate [1; 1]) = [2]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_22607_float_str", "language": "ml", "prompt": "(**Convert float to string, for use in command line arguments.\n*)\nlet float_str (a : float) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_22607_float_str.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = float_str in\n  (assert ((candidate 1e-100.0) = \"1e-100\"));\n  (assert ((candidate 1e-08.0) = \"1e-08\"));\n  (assert ((candidate float \"inf\".0) = \"inf\"));\n  (assert ((candidate 1.0) = \"1.0\"));\n  (assert ((candidate 10000000000.0) = \"10000000000.0\"));\n  (assert ((candidate 1000.0) = \"1000.0\"));\n  (assert ((candidate 1e-10.0) = \"1e-10\"));\n  (assert ((candidate 0.0) = \"0.0\"));\n  (assert ((candidate float \"-inf\".0) = \"-inf\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_226474_get_version_substitute", "language": "ml", "prompt": "(**Transform provider version str to universal version type.\n*)\nlet get_version_substitute (version_str : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_226474_get_version_substitute.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_version_substitute in\n  (assert ((candidate \"The 2009 video mix\") = \"video version\"));\n  (assert ((candidate \"the 2009 spanglish version\") = \"spanish version\"));\n  (assert ((candidate \"The 2009 radio mix\") = \"radio version\"));\n  (assert ((candidate \"the remaster\") = \"remaster\"));\n  (assert ((candidate \"some other stuff\") = \"some other stuff\"));\n  (assert ((candidate \"The 2009 spanglish version\") = \"spanish version\"));\n  (assert ((candidate \"the 2009 spanish version\") = \"spanish version\"));\n  (assert ((candidate \"The 2009 spanish version\") = \"spanish version\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_226709__LJ_ab_to_ab", "language": "ml", "prompt": "(**Convert AB representation to AB representation of the LJ potential\n*)\nlet _LJ_ab_to_ab (coeffs : (string, int) list) : (string, int) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_226709__LJ_ab_to_ab.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _LJ_ab_to_ab in\n  (assert ((candidate [(\"A\", 2); (\"B\", 3)]) = [(\"A\", 2); (\"B\", 3)]));\n  (assert ((candidate [(\"A\", 1); (\"B\", 2)]) = [(\"A\", 1); (\"B\", 2)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_22682_remove_quotes", "language": "ml", "prompt": "(**This function is used here to remove quotes from\npaths used in this script.\n:param string: Path with quotes.\n:return: Path without quotes.\n*)\nlet remove_quotes (string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_22682_remove_quotes.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = remove_quotes in\n  (assert ((candidate \"C:\\Users\\Test User\\AppData\\Local\\Programs\") = \"C:\\Users\\Test User\\AppData\\Local\\Programs\"));\n  (assert ((candidate \"\"C:\\\\Users\\\\Markus\\\\Desktop\"\") = \"C:\\\\Users\\\\Markus\\\\Desktop\"));\n  (assert ((candidate \"\"C:\\Users\\Markus\\Desktop\"\") = \"C:\\Users\\Markus\\Desktop\"));\n  (assert ((candidate \"C:\\Users\\Batman\\Desktop\\not_so_important_file.txt\") = \"C:\\Users\\Batman\\Desktop\\not_so_important_file.txt\"));\n  (assert ((candidate \"\"C:\\Users\\Batman\\Desktop\\super_important_file.txt\"\") = \"C:\\Users\\Batman\\Desktop\\super_important_file.txt\"));\n  (assert ((candidate \"\"C:\\Users\\Batman\\Desktop\\not_so_important_file.txt\"\") = \"C:\\Users\\Batman\\Desktop\\not_so_important_file.txt\"));\n  (assert ((candidate \"\"/path/with/quotes/in/it.txt\"\") = \"/path/with/quotes/in/it.txt\"));\n  (assert ((candidate \"C:\\Users\\Batman\\Desktop\\super_important_file.txt\") = \"C:\\Users\\Batman\\Desktop\\super_important_file.txt\"));\n  (assert ((candidate \"\"C:\\my path\\file.txt\"\") = \"C:\\my path\\file.txt\"));\n  (assert ((candidate \"C:\\Users\\Test User\\AppData\\Local\\Programs\") = \"C:\\Users\\Test User\\AppData\\Local\\Programs\"));\n  (assert ((candidate \"\"C:\\Users\\Markus\"\") = \"C:\\Users\\Markus\"));\n  (assert ((candidate \"\"/path/with/quotes/in/it.txt\"\") = \"/path/with/quotes/in/it.txt\"));\n  (assert ((candidate \"\"C:\\Users\\Test User\\AppData\\Local\\Programs\"\") = \"C:\\Users\\Test User\\AppData\\Local\\Programs\"));\n  (assert ((candidate \"C:\\Users\\Batman\\Desktop\\super_important_file.txt\") = \"C:\\Users\\Batman\\Desktop\\super_important_file.txt\"));\n  (assert ((candidate \"C:\\Users\\Test User\\AppData\\Local\\Programs\") = \"C:\\Users\\Test User\\AppData\\Local\\Programs\"));\n  (assert ((candidate \"C:\\Users\\Batman\\Desktop\\not_so_important_file.txt\") = \"C:\\Users\\Batman\\Desktop\\not_so_important_file.txt\"));\n  (assert ((candidate \"\"C:\\Users\\Batman\\Desktop\\super_important_file.txt\"\") = \"C:\\Users\\Batman\\Desktop\\super_important_file.txt\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_227166_partition", "language": "ml", "prompt": "(**Partitions a given array using the first element as the pivot.\n*)\nlet partition (v : int list) :  int * int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_227166_partition.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = partition in\n  (assert ((candidate list range 10) = (0, [0; 1; 2; 3; 4; 5; 6; 7; 8; 9])));\n  (assert ((candidate [1]) = (0, [1])));\n  (assert ((candidate [0; 2; 4; 6; 8]) = (0, [0; 2; 4; 6; 8])));\n  (assert ((candidate [0; 1; 2; 3; 4; 5; 6; 7; 8; 9]) = (0, [0; 1; 2; 3; 4; 5; 6; 7; 8; 9])));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_227167_parse_reg_02h_byte", "language": "ml", "prompt": "(**Net ID\n*)\nlet parse_reg_02h_byte (byte_val : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_227167_parse_reg_02h_byte.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_reg_02h_byte in\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 127) = 127));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 255) = 255));\n  (assert ((candidate 255) = 255));\n  (assert ((candidate 0) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_227348__find_minmax_indices", "language": "ml", "prompt": "(**Finds the indices corresponding to the minimum and maximum values\nin an integer vector.\n:args invec: The input integer array.\n*)\nlet _find_minmax_indices (invec : int list) :  int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_227348__find_minmax_indices.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _find_minmax_indices in\n  (assert ((candidate [1; 2; 3]) = (0, 2)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_22782_extract_instance_name", "language": "ml", "prompt": "(**Given instance URL returns instance name.\n*)\nlet extract_instance_name (url : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_22782_extract_instance_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = extract_instance_name in\n  (assert ((candidate \"http://localhost:8000/instances/project_id:region:instance_id\") = \"project_id:region:instance_id\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_229260_get_status_code_value", "language": "ml", "prompt": "(**function to return appropriate status code value from the dictionary\n*)\nlet get_status_code_value (status_code : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_229260_get_status_code_value.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_status_code_value in\n  (assert ((candidate \"203\") = \"Non-authoritative Information\"));\n  (assert ((candidate \"415\") = \"Unsupported Media Type\"));\n  (assert ((candidate \"204\") = \"No Content\"));\n  (assert ((candidate \"302\") = \"Found\"));\n  (assert ((candidate \"303\") = \"See Other\"));\n  (assert ((candidate \"403\") = \"Forbidden\"));\n  (assert ((candidate \"304\") = \"Not Modified\"));\n  (assert ((candidate \"501\") = \"Not Implemented\"));\n  (assert ((candidate \"201\") = \"Created\"));\n  (assert ((candidate \"206\") = \"Partial Content\"));\n  (assert ((candidate \"400\") = \"Bad Request\"));\n  (assert ((candidate \"100\") = \"Continue\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_229673_u16leListToByteList", "language": "ml", "prompt": "(**Convert a halfword array into a byte array\n*)\nlet u16leListToByteList (data : int list) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_229673_u16leListToByteList.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = u16leListToByteList in\n  (assert ((candidate [4660; 22136]) = [52; 18; 120; 86]));\n  (assert ((candidate list ) = list ));\n  (assert ((candidate [0]) = [0; 0]));\n  (assert ((candidate [4660; 22136]) = [52; 18; 120; 86]));\n  (assert ((candidate [65535]) = [255; 255]));\n  (assert ((candidate []) = []));\n  (assert ((candidate [1; 2; 3; 4]) = [1; 0; 2; 0; 3; 0; 4; 0]));\n  (assert ((candidate [4660; 22136; 39612; 57087]) = [52; 18; 120; 86; 188; 154; 255; 222]));\n  (assert ((candidate [4660; 22136; 39612]) = [52; 18; 120; 86; 188; 154]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_229855_parse_youtube_title", "language": "ml", "prompt": "(**Parse song tags from youtube title.\nCurrent logic is to assumme the youtube title is always in format 'author-song title'.\nIf there exists dashes in the title, up to the first dash is the author and the rest is the song title.\nIf there are no dashes, return original title as song title.\nThere will never be more than one dash because of the way we clean youtube titles.\nReturn tuple (author_title, song_title)\n*)\nlet parse_youtube_title (full_title : string) :  string option * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_229855_parse_youtube_title.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_youtube_title in\n  (assert ((candidate \"author-song title\") = (\"author\", \"song title\")));\n  (assert ((candidate \"author - song title\") = (\"author\", \"song title\")));\n  (assert ((candidate \"The Beatles - Sgt. Pepper's Lonely Hearts Club Band\") = (\"The Beatles\", \"Sgt. Pepper's Lonely Hearts Club Band\")));\n  (assert ((candidate \"Someone-awesome song title\") = (\"Someone\", \"awesome song title\")));\n  (assert ((candidate \"Someone-awesome song title\") = (\"Someone\", \"awesome song title\")));\n  (assert ((candidate \"The Beatles - Sgt. Pepper Lonely Hearts Club Band\") = (\"The Beatles\", \"Sgt. Pepper Lonely Hearts Club Band\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_23033_is_basic_type", "language": "ml", "prompt": "(**Returns True if the signature is a basic type\n'a', '(', '{', and 'v' are not considered basic types because they usually\ncannot be handled the same as other types.\n*)\nlet is_basic_type (signature : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_23033_is_basic_type.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_basic_type in\n  (assert ((candidate \"q\") = true));\n  (assert ((candidate \"d\") = true));\n  (assert ((candidate \"y\") = true));\n  (assert ((candidate \"g\") = true));\n  (assert ((candidate \"i\") = true));\n  (assert ((candidate \"s\") = true));\n  (assert ((candidate \"x\") = true));\n  (assert ((candidate \"(\") = false));\n  (assert ((candidate \"b\") = true));\n  (assert ((candidate \"n\") = true));\n  (assert ((candidate \"t\") = true));\n  (assert ((candidate \"v\") = false));\n  (assert ((candidate \"a\") = false));\n  (assert ((candidate \"{\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_230829_echo", "language": "ml", "prompt": "(**Very simple endpoint that just echos your message back to you\n:param message:  str of the message to echo\n:return:         str of the message echoed\n*)\nlet echo (message : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_230829_echo.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = echo in\n  (assert ((candidate \"world\") = \"ECHO: world\"));\n  (assert ((candidate \"hello\") = \"ECHO: hello\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_231491_truncate", "language": "ml", "prompt": "(**Return text truncated to the max_length character if needed.\n*)\nlet truncate (text : string) (max_length : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_231491_truncate.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = truncate in\n  (assert ((candidate \"This is a long string.\" 10) = \"This is...\"));\n  (assert ((candidate \"Hello World\" 1000) = \"Hello World\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_231656_get_unique_tokens", "language": "ml", "prompt": "(**Delimit the input `geneset_name` by \"; \", and return a new string\nthat includes only unique tokens delimited by \"; \".\n*)\nlet get_unique_tokens (geneset_name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_231656_get_unique_tokens.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_unique_tokens in\n  (assert ((candidate \"A; A; B; C\") = \"A; B; C\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_232067_truncpad", "language": "ml", "prompt": "(**Return srcline truncated and padded to length, aligned as requested.\n*)\nlet truncpad (srcline : string) (length : int) (align : string) (ellipsis : bool) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_232067_truncpad.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = truncpad in\n  (assert ((candidate \"1234\" 3 \"l\" false) = \"123\"));\n  (assert ((candidate \"1234\" 6 \"r\") = \"  1234\"));\n  (assert ((candidate \"this is a test\" 4) = \"this\"));\n  (assert ((candidate \"1234\" 5 \"r\") = \" 1234\"));\n  (assert ((candidate \"1234\" 3 \"c\" false) = \"123\"));\n  (assert ((candidate \"12345\" 5) = \"12345\"));\n  (assert ((candidate \"hello\" 6 \"r\") = \" hello\"));\n  (assert ((candidate \"1234\" 6 \"l\") = \"1234  \"));\n  (assert ((candidate \"this is a test\" 4 \"r\" false) = \"this\"));\n  (assert ((candidate \"1234\" 5 \"c\") = \" 1234\"));\n  (assert ((candidate \"hello\" 6 \"l\") = \"hello \"));\n  (assert ((candidate \"1234567\" 10) = \"1234567   \"));\n  (assert ((candidate \"hello\" 4) = \"hell\"));\n  (assert ((candidate \"hello\" 6) = \"hello \"));\n  (assert ((candidate \"1234\" 3 \"r\" false) = \"123\"));\n  (assert ((candidate \"hello\" 4 \"l\") = \"hell\"));\n  (assert ((candidate \"1234\" 3 \"l\") = \"123\"));\n  (assert ((candidate \"hello\" 5) = \"hello\"));\n  (assert ((candidate \"1234\" 5 \"l\") = \"1234 \"));\n  (assert ((candidate \"1234\" 3 \"r\") = \"123\"));\n  (assert ((candidate \"12345\" 10) = \"12345     \"));\n  (assert ((candidate \"123456\" 10) = \"123456    \"));\n  (assert ((candidate \"1234\" 3 \"c\") = \"123\"));\n  (assert ((candidate \"hello\" 4 \"c\") = \"hell\"));\n  (assert ((candidate \"hello\" 4 \"r\") = \"hell\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_232208_linearize", "language": "ml", "prompt": "(**Generates linearization constraints for the product y = ab.\nParameters\n----------\na : str\n * First factor.\nb : str\n * Second factor.\ny : Product.\nReturns\n-------\nList[str]\n * A list holding the three linearization constraints.\n*)\nlet linearize (a : string) (b : string) (y : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_232208_linearize.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = linearize in\n  (assert ((candidate \"a1\" \"b1\" \"y1\") = [\"- y1 + a1 >= 0\"; \"- y1 + b1 >= 0\"; \"- y1 + a1 + b1 <= 1\"]));\n  (assert ((candidate \"a\" \"b\" \"y1\") = [\"- y1 + a >= 0\"; \"- y1 + b >= 0\"; \"- y1 + a + b <= 1\"]));\n  (assert ((candidate \"1\" \"2\" \"3\") = [\"- 3 + 1 >= 0\"; \"- 3 + 2 >= 0\"; \"- 3 + 1 + 2 <= 1\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_232442_padding", "language": "ml", "prompt": "(**use '0' to padding the sentence\n*)\nlet padding (sample : int list list) (seq_max_len : int) : int list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_232442_padding.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = padding in\n  (assert ((candidate [[1; 2]; [3; 4]; [5]] 4) = [[1; 2; 0; 0]; [3; 4; 0; 0]; [5; 0; 0; 0]]));\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]; [7; 8; 9]] 5) = [[1; 2; 3; 0; 0]; [4; 5; 6; 0; 0]; [7; 8; 9; 0; 0]]));\n  (assert ((candidate [[1; 2; 3]; [4; 5]; [6; 7; 8; 9]] 5) = [[1; 2; 3; 0; 0]; [4; 5; 0; 0; 0]; [6; 7; 8; 9; 0]]));\n  (assert ((candidate [[1; 2; 3]; [2; 3]] 5) = [[1; 2; 3; 0; 0]; [2; 3; 0; 0; 0]]));\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6; 7]] 4) = [[1; 2; 3; 0]; [4; 5; 6; 7]]));\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]] 5) = [[1; 2; 3; 0; 0]; [4; 5; 6; 0; 0]]));\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]; [7]] 5) = [[1; 2; 3; 0; 0]; [4; 5; 6; 0; 0]; [7; 0; 0; 0; 0]]));\n  (assert ((candidate [[1; 2]; [3; 4]; [5]] 5) = [[1; 2; 0; 0; 0]; [3; 4; 0; 0; 0]; [5; 0; 0; 0; 0]]));\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]] 4) = [[1; 2; 3; 0]; [4; 5; 6; 0]]));\n  (assert ((candidate [[1]; [2; 3]] 3) = [[1; 0; 0]; [2; 3; 0]]));\n  (assert ((candidate [[1; 2; 3]; [2; 3]] 4) = [[1; 2; 3; 0]; [2; 3; 0; 0]]));\n  (assert ((candidate [] 3) = []));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_233100_coding_problem_22", "language": "ml", "prompt": "(**Given a dictionary of words and a string made up of those words (no spaces), return the original sentence in a\nlist. If there is more than one possible reconstruction, return any of them. If there is no possible\nreconstruction, then return null.\nExamples:\n>>> coding_problem_22(['Riccardo', 'Brigittie', 'and', 'lollipop'], 'RiccardoandBrigittie')\n['Riccardo', 'and', 'Brigittie']\n>>> coding_problem_22(['quick', 'brown', 'the', 'fox'], 'thequickbrownfox')\n['the', 'quick', 'brown', 'fox']\n>>> coding_problem_22(['bed', 'bath', 'bedbath', 'and', 'beyond'], 'bedbathandbeyond')\n['bed', 'bath', 'and', 'beyond']\n*)\nlet coding_problem_22 (dictionary : string list) (the_string : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_233100_coding_problem_22.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = coding_problem_22 in\n  (assert ((candidate [\"bed\"; \"bath\"; \"bedbath\"; \"and\"; \"beyond\"] \"bedbathandbeyond\") = [\"bed\"; \"bath\"; \"and\"; \"beyond\"]));\n  (assert ((candidate [\"quick\"; \"brown\"; \"the\"; \"fox\"] \"thequickbrownfox\") = [\"the\"; \"quick\"; \"brown\"; \"fox\"]));\n  (assert ((candidate [\"Riccardo\"; \"Brigittie\"; \"and\"; \"lollipop\"] \"RiccardoandBrigittie\") = [\"Riccardo\"; \"and\"; \"Brigittie\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_234706_is_valid", "language": "ml", "prompt": "(**Returns True if the number is a sum of two discrete numbers in \nthe preceding sequence.\n*)\nlet is_valid (sequence : int list) (number : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_234706_is_valid.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_valid in\n  (assert ((candidate list range 100 200) = false));\n  (assert ((candidate [1] 1) = false));\n  (assert ((candidate list range 10 16) = true));\n  (assert ((candidate [] 10) = false));\n  (assert ((candidate [1; 2; 3; 4; 5] 6) = true));\n  (assert ((candidate list range 10 1) = true));\n  (assert ((candidate list range 10 15) = true));\n  (assert ((candidate [1; 2; 3; 4; 5; 6; 7; 8; 9; 10] 12) = true));\n  (assert ((candidate list range 10 19) = false));\n  (assert ((candidate list range 100 201) = false));\n  (assert ((candidate [1; 2; 3; 4; 5; 6; 7; 8; 9; 10] 16) = true));\n  (assert ((candidate list range 10 6) = true));\n  (assert ((candidate list range 10 9) = true));\n  (assert ((candidate list range 10 4) = true));\n  (assert ((candidate list range 100 10) = true));\n  (assert ((candidate [1; 2; 3; 4; 5] 7) = true));\n  (assert ((candidate list range 10 18) = true));\n  (assert ((candidate list range 10 21) = false));\n  (assert ((candidate list range 10 2) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_23499_get_years", "language": "ml", "prompt": "(**Get years contained in a time period.\nReturns the list of years contained in between the provided\nstart time and the stop time.\n:param start_time: Start time to determine list of years\n:type start_time: str\n:param stop_time: Stop time to determine list of years\n:type stop_time: str\n:return: Creation date\n:rtype: list of str\n*)\nlet get_years (start_time : string) (stop_time : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_23499_get_years.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_years in\n  (assert ((candidate \"1968-06-19T13:46:29.000Z\" \"2007-04-26T20:36:19.000Z\") = [\"1968\"; \"1969\"; \"1970\"; \"1971\"; \"1972\"; \"1973\"; \"1974\"; \"1975\"; \"1976\"; \"1977\"; \"1978\"; \"1979\"; \"1980\"; \"1981\"; \"1982\"; \"1983\"; \"1984\"; \"1985\"; \"1986\"; \"1987\"; \"1988\"; \"1989\"; \"1990\"; \"1991\"; \"1992\"; \"1993\"; \"1994\"; \"1995\"; \"1996\"; \"1997\"; \"1998\"; \"1999\"; \"2000\"; \"2001\"; \"2002\"; \"2003\"; \"2004\"; \"2005\"; \"2006\"; \"2007\"]));\n  (assert ((candidate \"2017-05-05\" \"2017-05-15\") = [\"2017\"]));\n  (assert ((candidate \"2017-05-05\" \"2017-05-05\") = [\"2017\"]));\n  (assert ((candidate \"2010-09-16T04:04:36.000Z\" \"2012-04-26T20:36:19.000Z\") = [\"2010\"; \"2011\"; \"2012\"]));\n  (assert ((candidate \"2017-05-05\" \"2016-05-05\") = []));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_235080_gen_color", "language": "ml", "prompt": "(**Generates a red color in 'dot' format, which tone is based in the number of elements of a cluster (more elements, more intense).\n@param num_elems: \n@param max_elems: \n@return:\n*)\nlet gen_color (num_elems : int) (max_elems : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_235080_gen_color.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = gen_color in\n  (assert ((candidate 3 5) = \"0.000 0.600 1.000\"));\n  (assert ((candidate 5 5) = \"0.000 1.000 1.000\"));\n  (assert ((candidate 200 200) = \"0.000 1.000 1.000\"));\n  (assert ((candidate 0 100) = \"0.000 0.000 1.000\"));\n  (assert ((candidate 50 100) = \"0.000 0.500 1.000\"));\n  (assert ((candidate 50 50) = \"0.000 1.000 1.000\"));\n  (assert ((candidate 1 10) = \"0.000 0.100 1.000\"));\n  (assert ((candidate 0 100) = \"0.000 0.000 1.000\"));\n  (assert ((candidate 1 1) = \"0.000 1.000 1.000\"));\n  (assert ((candidate 0 10) = \"0.000 0.000 1.000\"));\n  (assert ((candidate 100 100) = \"0.000 1.000 1.000\"));\n  (assert ((candidate 3 3) = \"0.000 1.000 1.000\"));\n  (assert ((candidate 0 5) = \"0.000 0.000 1.000\"));\n  (assert ((candidate 5 5) = \"0.000 1.000 1.000\"));\n  (assert ((candidate 1 1) = \"0.000 1.000 1.000\"));\n  (assert ((candidate 0 1) = \"0.000 0.000 1.000\"));\n  (assert ((candidate 10 20) = \"0.000 0.500 1.000\"));\n  (assert ((candidate 10 30) = \"0.000 0.333 1.000\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_236346__is_compliant_with_reference_json", "language": "ml", "prompt": "(**Validates if a json file contains the same metadata as provided in arguments.\n*)\nlet _is_compliant_with_reference_json (reference_problem_name : string) (reference_graph_type : string) (reference_p : int) (json : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_236346__is_compliant_with_reference_json.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _is_compliant_with_reference_json in\n  (assert ((candidate \"reference_problem_name\" \"reference_graph_type\" 2 [(\"problem_name\", \"reference_problem_name\"); (\"graph_type\", \"reference_graph_type\"); (\"p\", 2)]) = false));\n  (assert ((candidate \"reference_problem_name\" \"reference_graph_type\" 2 [(\"problem_name\", \"reference_problem_name\"); (\"graph_type\", \"reference_graph_type\"); (\"p\", 2); (\"foo\", \"bar\")]) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_236919_egcd", "language": "ml", "prompt": "(**SRC: https://en.wikibooks.org/wiki/Algorithm_Implementation/Mathematics/Extended_Euclidean_algorithm\nreturn (g, x, y) such that a*x + b*y = g = gcd(a, b)\n*)\nlet egcd (a : int) (b : int) :  int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_236919_egcd.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = egcd in\n  (assert ((candidate 1 0) = (1, 1, 0)));\n  (assert ((candidate 0 20) = (20, 0, 1)));\n  (assert ((candidate 4 5) = (1, (~1), 1)));\n  (assert ((candidate 10 0) = (10, 1, 0)));\n  (assert ((candidate 0 1) = (1, 0, 1)));\n  (assert ((candidate 0 0) = (0, 0, 1)));\n  (assert ((candidate 30 30) = (30, 1, 0)));\n  (assert ((candidate 5 4) = (1, 1, (~1))));\n  (assert ((candidate 200 200) = (200, 1, 0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_237220_setbit", "language": "ml", "prompt": "(**set n-th bit (i.e. set to 1) in an integer or array of integers\nArgs:\n * x: integer or :class:`numpy.ndarray` of integers\n * nth_bit: position of bit to be set (0, 1, 2, ..)\nReturns:\n * integer or array of integers where n-th bit is set while all other bits are kept as in input x\nExamples:\n * >>> setbit(0, 1)\n * 2\n * >>> setbit(3, 2)\n * 7\n*)\nlet setbit (x : int) (nth_bit : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_237220_setbit.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = setbit in\n  (assert ((candidate 0 6) = 64));\n  (assert ((candidate 2 1) = 2));\n  (assert ((candidate 1 4) = 17));\n  (assert ((candidate 7 0) = 7));\n  (assert ((candidate 3 2) = 7));\n  (assert ((candidate 0 5) = 32));\n  (assert ((candidate 0 2) = 4));\n  (assert ((candidate 0 1) = 2));\n  (assert ((candidate 0 3) = 8));\n  (assert ((candidate 0 0) = 1));\n  (assert ((candidate 0 4) = 16));\n  (assert ((candidate 0 8) = 256));\n  (assert ((candidate 0 7) = 128));\n  (assert ((candidate 1 0) = 1));\n  (assert ((candidate 1 2) = 5));\n  (assert ((candidate 1 1) = 3));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_237237_fix_indentation", "language": "ml", "prompt": "(**Replace tabs by spaces\n*)\nlet fix_indentation (text : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_237237_fix_indentation.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = fix_indentation in\n  (assert ((candidate \"if True:\n    print('The indentation is wrong!')\") = \"if True:\n    print('The indentation is wrong!')\"));\n  (assert ((candidate \"\nif x:\n    return 0\nelse:\n    return 1\n\") = \"\nif x:\n    return 0\nelse:\n    return 1\n\"));\n  (assert ((candidate \"\ndef func():\n    if x:\n        return 0\n    else:\n        return 1\n\") = \"\ndef func():\n    if x:\n        return 0\n    else:\n        return 1\n\"));\n  (assert ((candidate \"\nif x:\n    return 0\nelif y:\n    return 1\nelse:\n    return 2\n\") = \"\nif x:\n    return 0\nelif y:\n    return 1\nelse:\n    return 2\n\"));\n  (assert ((candidate \"\ndef func():\n    if x:\n        return 0\n    elif y:\n        return 1\n    elif z:\n        return 2\n    else:\n        return 3\n\") = \"\ndef func():\n    if x:\n        return 0\n    elif y:\n        return 1\n    elif z:\n        return 2\n    else:\n        return 3\n\"));\n  (assert ((candidate \"    I am indented by four spaces, or four tabs.\") = \"    I am indented by four spaces, or four tabs.\"));\n  (assert ((candidate \"if True:\n\tprint('The indentation is wrong!')\") = \"if True:\n    print('The indentation is wrong!')\"));\n  (assert ((candidate \"\ndef func():\n    if x:\n        return 0\n    elif y:\n        return 1\n    else:\n        return 2\n\") = \"\ndef func():\n    if x:\n        return 0\n    elif y:\n        return 1\n    else:\n        return 2\n\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_237242_normalize_archive_entry_name", "language": "ml", "prompt": "(**Get the normalized name of an archive file entry.\nArgs:\n * name (str): Name of the archive file entry.\nReturns:\n * str: The normalized name.\n*)\nlet normalize_archive_entry_name (name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_237242_normalize_archive_entry_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = normalize_archive_entry_name in\n  (assert ((candidate \"foo/bar/\") = \"foo/bar/\"));\n  (assert ((candidate \"foo\\bar\") = \"foo/bar\"));\n  (assert ((candidate \"..\") = \"..\"));\n  (assert ((candidate \"a/b\") = \"a/b\"));\n  (assert ((candidate \"../\") = \"../\"));\n  (assert ((candidate \".\") = \".\"));\n  (assert ((candidate \"a\") = \"a\"));\n  (assert ((candidate \"foo/bar\") = \"foo/bar\"));\n  (assert ((candidate \"foo\\bar\\baz\") = \"foo/bar/baz\"));\n  (assert ((candidate \"/\") = \"/\"));\n  (assert ((candidate \"a/b/\") = \"a/b/\"));\n  (assert ((candidate \"./\") = \"./\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"a/\") = \"a/\"));\n  (assert ((candidate \"foo\") = \"foo\"));\n  (assert ((candidate \"/a/\") = \"/a/\"));\n  (assert ((candidate \"/a\") = \"/a\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_237520_extended_gcd", "language": "ml", "prompt": "(**Returns a tuple (r, i, j) such that r = gcd(a, b) = ia + jb\n*)\nlet extended_gcd (a : int) (b : int) :  int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_237520_extended_gcd.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = extended_gcd in\n  (assert ((candidate 12 12) = (12, 0, 1)));\n  (assert ((candidate 1 12) = (1, 1, 0)));\n  (assert ((candidate 100 100) = (100, 0, 1)));\n  (assert ((candidate 12 1) = (1, 0, 1)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_238527_get_cluster", "language": "ml", "prompt": "(**get the real starting cluster\n*)\nlet get_cluster (startclust : int) (offset : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_238527_get_cluster.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_cluster in\n  (assert ((candidate 0 2) = 0));\n  (assert ((candidate 181 1) = 2));\n  (assert ((candidate 180 1) = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_238578_get_library_name", "language": "ml", "prompt": "(**Utility to split between the library name and version number when needed\n*)\nlet get_library_name (library_name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_238578_get_library_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_library_name in\n  (assert ((candidate \"django == 2.2.2\") = \"django\"));\n  (assert ((candidate \"Django >= 1.11\") = \"Django\"));\n  (assert ((candidate \"django\") = \"django\"));\n  (assert ((candidate \"os!=1.0\") = \"os\"));\n  (assert ((candidate \"os\") = \"os\"));\n  (assert ((candidate \"django ==1.11.6,>=1.8,>=1.4,<1.9\") = \"django\"));\n  (assert ((candidate \"django.utils\") = \"django.utils\"));\n  (assert ((candidate \"django ~=1.11,!=1.11.6,>=1.8,>=1.4,<1.9\") = \"django\"));\n  (assert ((candidate \"django\") = \"django\"));\n  (assert ((candidate \"django!=1.11,!=1.11.6\") = \"django\"));\n  (assert ((candidate \"django ==1.11.6,==1.11\") = \"django\"));\n  (assert ((candidate \"Django == 1.2.3,!=1.3.4.5, >=2.3.4\") = \"Django\"));\n  (assert ((candidate \"os==1.0!=1.0\") = \"os\"));\n  (assert ((candidate \"django.utils.log\") = \"django.utils.log\"));\n  (assert ((candidate \"django.utils.log.AdminEmailHandler\") = \"django.utils.log.AdminEmailHandler\"));\n  (assert ((candidate \"Django >= 1.11, == 2.3.4\") = \"Django\"));\n  (assert ((candidate \"Django == 2.2.2\") = \"Django\"));\n  (assert ((candidate \"os==1.0\") = \"os\"));\n  (assert ((candidate \"django!=1.11,!=1.11.6,>=1.8,>=1.4,<1.9\") = \"django\"));\n  (assert ((candidate \"os==1.0!=1.0>0.0\") = \"os\"));\n  (assert ((candidate \"os~=1.0\") = \"os\"));\n  (assert ((candidate \"django ==1.11.6\") = \"django\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_239032_remove_path_segments", "language": "ml", "prompt": "(**Removes the path segments of <remove> from the end of the path\nsegments <segments>.\nExamples:\n * # ('/a/b/c', 'b/c') -> '/a/'\n * remove_path_segments(['','a','b','c'], ['b','c']) == ['','a','']\n * # ('/a/b/c', '/b/c') -> '/a'\n * remove_path_segments(['','a','b','c'], ['','b','c']) == ['','a']\nReturns: The list of all remaining path segments after the segments\nin <remove> have been removed from the end of <segments>. If no\nsegments from <remove> were removed from <segments>, <segments> is\nreturned unmodified.\n*)\nlet remove_path_segments (segments : string list) (remove : string list) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_239032_remove_path_segments.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = remove_path_segments in\n  (assert ((candidate [\"\"; \"a\"] [\"\"; \"a\"; \"b\"]) = [\"\"; \"a\"]));\n  (assert ((candidate [\"\"; \"a\"] [\"\"; \"a\"]) = []));\n  (assert ((candidate [\"\"; \"a\"] [\"\"; \"b\"; \"c\"; \"d\"; \"e\"]) = [\"\"; \"a\"]));\n  (assert ((candidate [\"\"; \"a\"; \"b\"; \"c\"] [\"\"; \"b\"; \"c\"]) = [\"\"; \"a\"]));\n  (assert ((candidate [\"\"; \"a\"] [\"\"; \"b\"; \"a\"; \"c\"]) = [\"\"; \"a\"]));\n  (assert ((candidate [\"\"; \"a\"] [\"\"; \"b\"; \"c\"]) = [\"\"; \"a\"]));\n  (assert ((candidate [\"\"] [\"\"]) = []));\n  (assert ((candidate [\"\"; \"a\"; \"b\"; \"c\"] [\"a\"; \"b\"; \"d\"]) = [\"\"; \"a\"; \"b\"; \"c\"]));\n  (assert ((candidate [\"\"; \"a\"; \"b\"; \"c\"; \"d\"] [\"\"; \"b\"; \"c\"; \"d\"]) = [\"\"; \"a\"]));\n  (assert ((candidate [\"\"; \"a\"] [\"\"; \"b\"; \"c\"; \"a\"]) = [\"\"; \"a\"]));\n  (assert ((candidate [\"\"; \"a\"; \"b\"; \"c\"] [\"b\"; \"c\"]) = [\"\"; \"a\"; \"\"]));\n  (assert ((candidate [\"\"; \"a\"; \"b\"; \"c\"] [\"\"; \"b\"; \"c\"]) = [\"\"; \"a\"]));\n  (assert ((candidate [\"\"; \"a\"] [\"\"; \"b\"; \"a\"]) = [\"\"; \"a\"]));\n  (assert ((candidate [\"\"; \"a\"] []) = [\"\"; \"a\"]));\n  (assert ((candidate [\"\"; \"a\"; \"b\"; \"c\"] [\"c\"; \"d\"]) = [\"\"; \"a\"; \"b\"; \"c\"]));\n  (assert ((candidate [\"\"; \"a\"; \"b\"; \"c\"] [\"b\"; \"d\"]) = [\"\"; \"a\"; \"b\"; \"c\"]));\n  (assert ((candidate [\"\"; \"a\"] [\"\"; \"b\"; \"c\"; \"d\"]) = [\"\"; \"a\"]));\n  (assert ((candidate [\"\"; \"a\"; \"b\"; \"c\"] [\"b\"; \"c\"]) = [\"\"; \"a\"; \"\"]));\n  (assert ((candidate [\"\"; \"a\"] [\"\"]) = [\"\"; \"a\"]));\n  (assert ((candidate [\"\"; \"a\"] [\"\"; \"b\"]) = [\"\"; \"a\"]));\n  (assert ((candidate [\"\"; \"a\"] [\"\"; \"a\"; \"b\"; \"c\"]) = [\"\"; \"a\"]));\n  (assert ((candidate [\"\"; \"a\"; \"b\"; \"c\"] [\"d\"]) = [\"\"; \"a\"; \"b\"; \"c\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_23945_pre_text", "language": "ml", "prompt": "(**Encapsulate a string inside a Markdown <pre> container\n*)\nlet pre_text (string : string) (lang : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_23945_pre_text.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = pre_text in\n  (assert ((candidate \"test\ntest\" \"cpp\") = \"```cpp\ntest\ntest```\"));\n  (assert ((candidate \"test\" \"java\") = \"```java\ntest```\"));\n  (assert ((candidate \"test\" \"cpp\") = \"```cpp\ntest```\"));\n  (assert ((candidate \"test\") = \"```test```\"));\n  (assert ((candidate \"test\ntest\") = \"```test\ntest```\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_239754__extract_language", "language": "ml", "prompt": "(**Extracts language from locale string.\n:param locale_string: Something like language_COUNTRY.encoding\n:return: language\n*)\nlet _extract_language (locale_string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_239754__extract_language.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _extract_language in\n  (assert ((candidate \"en_GB\") = \"en\"));\n  (assert ((candidate \"sr_RS@latin\") = \"sr\"));\n  (assert ((candidate \"sr_RS@cyrillic\") = \"sr\"));\n  (assert ((candidate \"sr_ME\") = \"sr\"));\n  (assert ((candidate \"fr_FR\") = \"fr\"));\n  (assert ((candidate \"sr_RS\") = \"sr\"));\n  (assert ((candidate \"fr_CA\") = \"fr\"));\n  (assert ((candidate \"en_US\") = \"en\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_23979_hash_to_dir", "language": "ml", "prompt": "(**Transforms a given hash to a relative path and filename\nex: '002badb952000339cdcf1b61a3205b221766bf49' ->\n * '00/2badb952000339cdcf1b61a3205b221766bf49'\n:param hash: the hash to split\n:rtype: string\n*)\nlet hash_to_dir (hash : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_23979_hash_to_dir.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = hash_to_dir in\n  (assert ((candidate \"00\") = \"00/\"));\n  (assert ((candidate \"006061c77988c862085fc6c29c5357e3810822d3\") = \"00/6061c77988c862085fc6c29c5357e3810822d3\"));\n  (assert ((candidate \"007a90c0e00899f0596419a627d76f4256705188\") = \"00/7a90c0e00899f0596419a627d76f4256705188\"));\n  (assert ((candidate \"002badb952000339cdcf1b61a3205b221766bf49\") = \"00/2badb952000339cdcf1b61a3205b221766bf49\"));\n  (assert ((candidate \"0\") = \"0/\"));\n  (assert ((candidate \"002badb952000339cdcf1b61a3205b221766bf49\") = \"00/2badb952000339cdcf1b61a3205b221766bf49\"));\n  (assert ((candidate \"001426260e00059b5e5a401954d6071f19c74031\") = \"00/1426260e00059b5e5a401954d6071f19c74031\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_239937_convert2relative", "language": "ml", "prompt": "(**YOLO format use relative coordinates for annotation\n*)\nlet convert2relative (bbox :  int * int * int * int) (darknet_height : int) (darknet_width : int) :  int * int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_239937_convert2relative.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = convert2relative in\n  (assert ((candidate (0, 0, 10, 10) 10 10) = (0, 0, 1, 1)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_240045_caterpillar_sub_sequence", "language": "ml", "prompt": "(**Generate the steps for a given frame.\n*)\nlet caterpillar_sub_sequence (frame : int list) (new : int) (cat_length : int) : int list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_240045_caterpillar_sub_sequence.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = caterpillar_sub_sequence in\n  (assert ((candidate [0; 0; 0; 0; 0; 0; 0] 0 5) = [[0; 0; 0; 0; 0; 0; 0]]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_240081_compose_username", "language": "ml", "prompt": "(**@brief Compose the username\nThe username policy via openid is as follow:\n* Try to use the nick name\n* If not available fall back to email\n* Append the the openid provider as domain. Delimiter is % in order to \n * diferentiate from @ (if email is used)\n@param nick The nick name or None\n@param email The email or None\n@param provider the Authentication provider\n@return Non in case no user name was derived, otherwise the username\n*)\nlet compose_username (nick : string option) (email : string option) (provider : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_240081_compose_username.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = compose_username in\n  (assert ((candidate ) = \"<EMAIL>%provider\"));\n  (assert ((candidate Some(None) Some(\"<EMAIL>\") \"google\") = \"<EMAIL>%google\"));\n  (assert ((candidate Some(\"Peter\") Some(None) \"yahoo\") = \"Peter%yahoo\"));\n  (assert ((candidate ) = \"Nick%provider\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_241238_concatixnames", "language": "ml", "prompt": "(**Args:\nixname (str): 'ix'\nsource_suffix (str): 'left'\ntarget_suffix (str): 'right'\n * Returns:\nstr, str, list(): 'ix_source', 'ix_target', ['ix_source', 'ix_target']\n*)\nlet concatixnames (ixname : string) (source_suffix : string) (target_suffix : string) :  string * string * string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_241238_concatixnames.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = concatixnames in\n  (assert ((candidate \"ix\" \"source\" \"target\") = (\"ix_source\", \"ix_target\", [\"ix_source\"; \"ix_target\"])));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_24135_temp_commentary", "language": "ml", "prompt": "(**Gives temperature advice to the end user.\n*)\nlet temp_commentary (current_temp : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_24135_temp_commentary.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = temp_commentary in\n  (assert ((candidate 5) = \"It's Freezing Cold. Staying inside and a cup of Hot chocolate would be nice!\"));\n  (assert ((candidate 55) = \"It's cold right now. Make sure you keep yourself warm!\"));\n  (assert ((candidate 40) = \"It's cold right now. Make sure you keep yourself warm!\"));\n  (assert ((candidate 85) = \"It's hot and sunny right now. Don't forget that sunscreen!\"));\n  (assert ((candidate 69) = \"It's nice and warm right now. Time to flex those flip-flops!\"));\n  (assert ((candidate 25) = \"Brrrrrrr!!! Remember to wear your protective gear so you don't freeze!\"));\n  (assert ((candidate 75) = \"It's nice and warm right now. Time to flex those flip-flops!\"));\n  (assert ((candidate 59) = \"It's nice and cool right now. Go play outside in this great weather!\"));\n  (assert ((candidate 95) = \"It's scorching hot right now. Stay inside and be cool!\"));\n  (assert ((candidate 100) = \"It's scorching hot right now. Stay inside and be cool!\"));\n  (assert ((candidate (~15)) = \"It's Freezing Cold. Staying inside and a cup of Hot chocolate would be nice!\"));\n  (assert ((candidate 65) = \"It's nice and cool right now. Go play outside in this great weather!\"));\n  (assert ((candidate 6) = \"It's Freezing Cold. Staying inside and a cup of Hot chocolate would be nice!\"));\n  (assert ((candidate 80) = \"It's hot and sunny right now. Don't forget that sunscreen!\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_241380_sum_digits", "language": "ml", "prompt": "(**Sum all the digits of n.\n>>> sum_digits(10) # 1 + 0 = 1\n1\n>>> sum_digits(4224) # 4 + 2 + 2 + 4 = 12\n12\n>>> sum_digits(1234567890)\n45\n>>> x = sum_digits(123) # make sure that you are using return rather than print\n>>> x\n6\n*)\nlet sum_digits (n : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_241380_sum_digits.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sum_digits in\n  (assert ((candidate 4224) = 12));\n  (assert ((candidate 42) = 6));\n  (assert ((candidate 123) = 6));\n  (assert ((candidate 10) = 1));\n  (assert ((candidate 1234567890) = 45));\n  (assert ((candidate 1000) = 1));\n  (assert ((candidate 10000) = 1));\n  (assert ((candidate 10000000) = 1));\n  (assert ((candidate 123456789) = 45));\n  (assert ((candidate 0) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_241518_str_tags_to_list", "language": "ml", "prompt": "(**Convert string of comma separated tags to list, stripped of empty tags and whitespace.\n*)\nlet str_tags_to_list (tags : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_241518_str_tags_to_list.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = str_tags_to_list in\n  (assert ((candidate \"  hello ,   world   \") = [\"hello\"; \"world\"]));\n  (assert ((candidate \"hello, world\") = [\"hello\"; \"world\"]));\n  (assert ((candidate \",hello,,, world\") = [\"hello\"; \"world\"]));\n  (assert ((candidate \"hello\") = [\"hello\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_241903_datenum", "language": "ml", "prompt": "(**Return a date category with format\n*)\nlet datenum (name : string) (format : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_241903_datenum.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = datenum in\n  (assert ((candidate \"date\" \"'%Y-%m-%d'\") = \"candidate(date,'%Y-%m-%d')\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_242285_str_width", "language": "ml", "prompt": "(**calc string width, support cjk characters.\n*)\nlet str_width (unicode_text : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_242285_str_width.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = str_width in\n  (assert ((candidate \"      \") = 6));\n  (assert ((candidate \"abc     \") = 8));\n  (assert ((candidate \"abc    \") = 7));\n  (assert ((candidate \"A\u2000B\") = 3));\n  (assert ((candidate \"1234567890\") = 10));\n  (assert ((candidate \"abc  \") = 5));\n  (assert ((candidate \"hello\nworld\") = 11));\n  (assert ((candidate \"       \") = 7));\n  (assert ((candidate \"abc \") = 4));\n  (assert ((candidate \"ABC\") = 3));\n  (assert ((candidate \"   \") = 3));\n  (assert ((candidate \"abcdef\") = 6));\n  (assert ((candidate \"A\u0301B\") = 3));\n  (assert ((candidate \"abc\") = 3));\n  (assert ((candidate \"  \") = 2));\n  (assert ((candidate \"\uff41\uff42\uff43\") = 6));\n  (assert ((candidate \"hello world\") = 11));\n  (assert ((candidate \"\uff21\uff22\uff23\") = 6));\n  (assert ((candidate \"abc       \") = 10));\n  (assert ((candidate \"abcdefg\") = 7));\n  (assert ((candidate \" \") = 1));\n  (assert ((candidate \"abc   \") = 6));\n  (assert ((candidate \"hello\tworld\") = 11));\n  (assert ((candidate \"\uff71\uff71\uff71\uff71\") = 4));\n  (assert ((candidate \"abc      \") = 9));\n  (assert ((candidate \"abcde\") = 5));\n  (assert ((candidate \"\uff71\uff71\") = 2));\n  (assert ((candidate \"\uff71\uff71\uff71\") = 3));\n  (assert ((candidate \"        \") = 8));\n  (assert ((candidate \"     \") = 5));\n  (assert ((candidate \"    \") = 4));\n  (assert ((candidate \"abc        \") = 11));\n  (assert ((candidate \"A\") = 1));\n  (assert ((candidate \"\") = 0));\n  (assert ((candidate \"\uff71\") = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_242482_get_interval_unit", "language": "ml", "prompt": "(**Get interval unit.\n:param interval:\n:return:\n*)\nlet get_interval_unit (interval : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_242482_get_interval_unit.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_interval_unit in\n  (assert ((candidate 1000) = \"seconds\"));\n  (assert ((candidate -1.5) = \"seconds\"));\n  (assert ((candidate 10) = \"seconds\"));\n  (assert ((candidate 59) = \"seconds\"));\n  (assert ((candidate 0.5) = \"seconds\"));\n  (assert ((candidate 3) = \"seconds\"));\n  (assert ((candidate 1) = \"seconds\"));\n  (assert ((candidate -0.5) = \"seconds\"));\n  (assert ((candidate 61) = \"seconds\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_242504_LJ", "language": "ml", "prompt": "(**Lennard-Jones potential\n*)\nlet LJ (v : int) (epsilon : int) (sigma : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_242504_LJ.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = LJ in\n  (assert ((candidate 20 0 2) = 0));\n  (assert ((candidate 20 0 1) = 0));\n  (assert ((candidate 20 0 0) = 0));\n  (assert ((candidate 1 1 1) = 0));\n  (assert ((candidate 20 1 0) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_243078_check_origin", "language": "ml", "prompt": "(**Sorting function for origin\n*)\nlet check_origin (origin :  string * string) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_243078_check_origin.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = check_origin in\n  (assert ((candidate (\"XY\", \"Y\")) = Some(None)));\n  (assert ((candidate (\"X\", \"X\")) = Some(\"X\")));\n  (assert ((candidate (\"X\", \"X\")) = Some(\"X\")));\n  (assert ((candidate (\"XY\", \"\")) = Some(None)));\n  (assert ((candidate (\"Y\", \"XY\")) = Some(None)));\n  (assert ((candidate (\"\", \"XX\")) = Some(None)));\n  (assert ((candidate (\"XY\", \"XY\")) = Some(None)));\n  (assert ((candidate (\"XX\", \"\")) = Some(None)));\n  (assert ((candidate (\"Y\", \"Y\")) = Some(\"Y\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_243138_prepend_slash", "language": "ml", "prompt": "(**Prepend a slash to a URL fragment, checking if it already has one.\n*)\nlet prepend_slash (url : string) (prepend : bool) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_243138_prepend_slash.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = prepend_slash in\n  (assert ((candidate \"https://example.com\" false) = \"https://example.com\"));\n  (assert ((candidate \"https://example.com\" true) = \"/https://example.com\"));\n  (assert ((candidate \"/https://example.com/\" true) = \"/https://example.com/\"));\n  (assert ((candidate \"https://example.com/\" true) = \"/https://example.com/\"));\n  (assert ((candidate \"https://example.com/\" false) = \"https://example.com/\"));\n  (assert ((candidate \"/https://example.com\" true) = \"/https://example.com\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_243650__nf", "language": "ml", "prompt": "(**None Filter\n*)\nlet _nf (s : string) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_243650__nf.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _nf in\n  (assert ((candidate \"foo\") = Some(\"foo\")));\n  (assert ((candidate \"Hello World!\") = Some(\"Hello World!\")));\n  (assert ((candidate \"test\") = Some(\"test\")));\n  (assert ((candidate \"None\") = Some(None)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_24406_rearange_base_link_list", "language": "ml", "prompt": "(**Rarange base link to beginning of table\n*)\nlet rearange_base_link_list (table : int list) (base_link_index : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_24406_rearange_base_link_list.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = rearange_base_link_list in\n  (assert ((candidate [1] 0) = [1]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_244262_get_shard_range", "language": "ml", "prompt": "(**In case dataset_size is not evenly divided by world_size, we need to pad\none extra example in each shard\nshard_len = dataset_size // world_size + 1\nCase 1 rank < remainder: each shard start position is rank * shard_len\nCase 2 rank >= remainder: without padding, each shard start position is\nrank * (shard_len - 1) + remainder = rank * shard_len - (rank - remainder)\nBut to make sure all shard have same size, we need to pad one extra example\nwhen rank >= remainder, so start_position = start_position - 1\nFor example, dataset_size = 21, world_size = 8\nrank 0 to 4: [0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]\nrank 5 to 7: [14, 15, 16], [16, 17, 18], [18, 19, 20]\n*)\nlet get_shard_range (dataset_size : int) (rank : int) (world_size : int) :  int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_244262_get_shard_range.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_shard_range in\n  (assert ((candidate 10 0 3) = (0, 3)));\n  (assert ((candidate 11 1 3) = (4, 7)));\n  (assert ((candidate 3 0 2) = (0, 1)));\n  (assert ((candidate 3 1 2) = (1, 2)));\n  (assert ((candidate 11 0 4) = (0, 2)));\n  (assert ((candidate 11 2 3) = (7, 10)));\n  (assert ((candidate 4 1 2) = (2, 3)));\n  (assert ((candidate 10 0 1) = (0, 9)));\n  (assert ((candidate 7 0 3) = (0, 2)));\n  (assert ((candidate 10 0 4) = (0, 2)));\n  (assert ((candidate 3 0 1) = (0, 2)));\n  (assert ((candidate 4 0 1) = (0, 3)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_244748_get_3x3_translation", "language": "ml", "prompt": "(**return a matrix 3x3 for translation\n*)\nlet get_3x3_translation (x : int) (y : int) (z : int) : int list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_244748_get_3x3_translation.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_3x3_translation in\n  (assert ((candidate 2 3 4) = [[2; 0; 0]; [0; 3; 0]; [0; 0; 4]]));\n  (assert ((candidate 1 2 3) = [[1; 0; 0]; [0; 2; 0]; [0; 0; 3]]));\n  (assert ((candidate 1 1 1) = [[1; 0; 0]; [0; 1; 0]; [0; 0; 1]]));\n  (assert ((candidate 1 2 3) = candidate 1 2 3));\n  (assert ((candidate 3 1 2) = [[3; 0; 0]; [0; 1; 0]; [0; 0; 2]]));\n  (assert ((candidate 1 2 3) = [[1; 0; 0]; [0; 2; 0]; [0; 0; 3]]));\n  (assert ((candidate 0 0 0) = [[0; 0; 0]; [0; 0; 0]; [0; 0; 0]]));\n  (assert ((candidate 4 4 4) = [[4; 0; 0]; [0; 4; 0]; [0; 0; 4]]));\n  (assert ((candidate (~3) (~2) (~1)) = [[(~3); 0; 0]; [0; (~2); 0]; [0; 0; (~1)]]));\n  (assert ((candidate (~3) (~6) (~9)) = [[(~3); 0; 0]; [0; (~6); 0]; [0; 0; (~9)]]));\n  (assert ((candidate 1 2 3) = [[1; 0; 0]; [0; 2; 0]; [0; 0; 3]]));\n  (assert ((candidate 0 0 0) = [[0; 0; 0]; [0; 0; 0]; [0; 0; 0]]));\n  (assert ((candidate 3 2 1) = [[3; 0; 0]; [0; 2; 0]; [0; 0; 1]]));\n  (assert ((candidate (~1) 3 1) = [[(~1); 0; 0]; [0; 3; 0]; [0; 0; 1]]));\n  (assert ((candidate 5 10 15) = [[5; 0; 0]; [0; 10; 0]; [0; 0; 15]]));\n  (assert ((candidate 3 (~1) 2) = [[3; 0; 0]; [0; (~1); 0]; [0; 0; 2]]));\n  (assert ((candidate (~2) (~3) (~4)) = [[(~2); 0; 0]; [0; (~3); 0]; [0; 0; (~4)]]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_245061_decode_bert", "language": "ml", "prompt": "(**Decodes text that uses https://github.com/google/sentencepiece encoding.\nAssumes that pieces are separated by a space\n*)\nlet decode_bert (text : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_245061_decode_bert.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = decode_bert in\n  (assert ((candidate \"A long time ago in a galaxy far, far away\") = \"A long time ago in a galaxy far, far away\"));\n  (assert ((candidate \"I like cats and ## dogs \") = \"I like cats and dogs\"));\n  (assert ((candidate \"I like to go to the mall\") = \"I like to go to the mall\"));\n  (assert ((candidate \"long time ago in a galaxy far, far away\") = \"long time ago in a galaxy far, far away\"));\n  (assert ((candidate \"this is a test\") = \"this is a test\"));\n  (assert ((candidate \"I like to go to the m all\") = \"I like to go to the m all\"));\n  (assert ((candidate \"I like cats and dogs \") = \"I like cats and dogs\"));\n  (assert ((candidate \"I like cats and ## dogs\") = \"I like cats and dogs\"));\n  (assert ((candidate \"long time ago in a galaxy far ##, far away\") = \"long time ago in a galaxy far, far away\"));\n  (assert ((candidate \"I like cats and dogs  \") = \"I like cats and dogs\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_245144_get_dist_sq", "language": "ml", "prompt": "(**returns the distance squared between two points. Faster than the true euclidean dist\n*)\nlet get_dist_sq (point_a :  int * int) (point_b :  int * int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_245144_get_dist_sq.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_dist_sq in\n  (assert ((candidate (0, 0) (0, 0)) = 0));\n  (assert ((candidate (0, 0) (3, 4)) = 25));\n  (assert ((candidate (1, 1) (1, 1)) = 0));\n  (assert ((candidate ) = 1));\n  (assert ((candidate (0, 0) (0, 0)) = 0));\n  (assert ((candidate ((~3), (~4)) ((~3), (~4))) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_246231_parse_env", "language": "ml", "prompt": "(**Convert list of strings into dict object.\nDocker Inspect ENV is a list of strings. Env strings are\nin the form of KEY=VALUE. Split strings into key=value pairs\nand return dict object. Only return keys with \"good_stuff\".\n*)\nlet parse_env (Env : string list) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_246231_parse_env.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_env in\n  (assert ((candidate [\"USER=db_user\"; \"PASS=<PASSWORD>\"; \"EXTRA=1\"]) = [(\"USER\", \"db_user\"); (\"PASS\", \"<PASSWORD>\")]));\n  (assert ((candidate []) = []));\n  (assert ((candidate [\"USER=db_user\"; \"PASS=<PASSWORD>\"; \"_DB=db_name\"; \"EXTRA=1\"]) = [(\"USER\", \"db_user\"); (\"PASS\", \"<PASSWORD>\"); (\"_DB\", \"db_name\")]));\n  (assert ((candidate [\"_DB=foo\"; \"USER=bar\"]) = [(\"_DB\", \"foo\"); (\"USER\", \"bar\")]));\n  (assert ((candidate [\"USER=foo\"; \"_DB=bar\"]) = [(\"USER\", \"foo\"); (\"_DB\", \"bar\")]));\n  (assert ((candidate [\"USER=foo\"; \"PASS=<PASSWORD>\"; \"BAD_THING=bar\"]) = [(\"USER\", \"foo\"); (\"PASS\", \"<PASSWORD>\")]));\n  (assert ((candidate [\"USER=foo\"; \"USER=bar\"]) = [(\"USER\", \"bar\")]));\n  (assert ((candidate [\"USER=db_user\"; \"PASS=<PASSWORD>\"; \"_DB=db_name\"]) = [(\"USER\", \"db_user\"); (\"PASS\", \"<PASSWORD>\"); (\"_DB\", \"db_name\")]));\n  (assert ((candidate [\"USER=foo\"; \"PASS=<PASSWORD>\"; \"_DB=bar\"]) = [(\"USER\", \"foo\"); (\"PASS\", \"<PASSWORD>\"); (\"_DB\", \"bar\")]));\n  (assert ((candidate [\"USER=foo\"; \"PASS=bar\"; \"_DB=baz\"; \"USER=foo\"; \"PASS=bar\"; \"_DB=baz\"]) = [(\"USER\", \"foo\"); (\"PASS\", \"bar\"); (\"_DB\", \"baz\")]));\n  (assert ((candidate [\"USER=foo\"; \"PASS=<PASSWORD>\"]) = [(\"USER\", \"foo\"); (\"PASS\", \"<PASSWORD>\")]));\n  (assert ((candidate [\"USER=foo\"; \"PASS=bar\"; \"_DB=baz\"]) = [(\"USER\", \"foo\"); (\"PASS\", \"bar\"); (\"_DB\", \"baz\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_246717_version_get", "language": "ml", "prompt": "(**Check if version v1 is great or equal then version v2.\n*)\nlet version_get (v1 : string) (v2 : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_246717_version_get.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = version_get in\n  (assert ((candidate \"1.2.3.3\" \"1.2.3.4\") = false));\n  (assert ((candidate \"1.2.3a\" \"1.2.3\") = false));\n  (assert ((candidate \"1.1.0\" \"1.1.1\") = false));\n  (assert ((candidate \"1.1.3\" \"1.2\") = false));\n  (assert ((candidate \"1.2.3a\" \"1.2.3b\") = false));\n  (assert ((candidate \"1.2\" \"1.2.4\") = false));\n  (assert ((candidate \"1\" \"1.2\") = false));\n  (assert ((candidate \"1\" \"1.1.0\") = false));\n  (assert ((candidate \"1.2.4\" \"1.2.3\") = true));\n  (assert ((candidate \"1.1.1\" \"1.1.2\") = false));\n  (assert ((candidate \"1.1.1.0\" \"1.1.1.1\") = false));\n  (assert ((candidate \"1.2.3\" \"1.3.0\") = false));\n  (assert ((candidate \"1.2.3\" \"1.2.4\") = false));\n  (assert ((candidate \"1.1\" \"1.2\") = false));\n  (assert ((candidate \"1.2.2\" \"1.2\") = true));\n  (assert ((candidate \"1\" \"1.1.1\") = false));\n  (assert ((candidate \"1.1.1\" \"1.2.1\") = false));\n  (assert ((candidate \"1\" \"1.1\") = false));\n  (assert ((candidate \"1.1.0\" \"1.2.0\") = false));\n  (assert ((candidate \"1.2.3\" \"1.2\") = true));\n  (assert ((candidate \"1\" \"2.1.0\") = false));\n  (assert ((candidate \"1.1.1\" \"1.1.0\") = true));\n  (assert ((candidate \"1.2.3\" \"1.2.4\") = false));\n  (assert ((candidate \"1.3.0\" \"1.2.4\") = true));\n  (assert ((candidate \"1.2.3b\" \"1.2.3a\") = false));\n  (assert ((candidate \"1\" \"1.0\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_247246_is_prefix", "language": "ml", "prompt": "(**Return True if pre_path is a path-prefix of path.\n*)\nlet is_prefix (pre_path : string) (path : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_247246_is_prefix.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_prefix in\n  (assert ((candidate \"\" \"\") = true));\n  (assert ((candidate \"\" \"foo\") = true));\n  (assert ((candidate \"foo\" \"\") = false));\n  (assert ((candidate \"a.b.c\" \"a.b.c.d.e\") = true));\n  (assert ((candidate \"foo.bar\" \"foo\") = false));\n  (assert ((candidate \"\" \"foo.bar\") = true));\n  (assert ((candidate \"a.b.c.d\" \"a.b.c.d.e\") = true));\n  (assert ((candidate \"\" \"a.b.c.d.e\") = true));\n  (assert ((candidate \"a\" \"a.b.c.d.e\") = true));\n  (assert ((candidate \"foo.bar\" \"baz.foo.bar\") = false));\n  (assert ((candidate \"foo.bar\" \"\") = false));\n  (assert ((candidate \"foo.bar\" \"foo.bar.baz\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_247808_get_next_coin", "language": "ml", "prompt": "(**Return the next coin. \n>>> get_next_coin(1)\n5\n>>> get_next_coin(5)\n10\n>>> get_next_coin(10)\n25\n>>> get_next_coin(2) # Other values return None\n*)\nlet get_next_coin (coin : int) : int option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_247808_get_next_coin.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_next_coin in\n  (assert ((candidate 17) = Some(None)));\n  (assert ((candidate 3) = Some(None)));\n  (assert ((candidate 10) = Some(25)));\n  (assert ((candidate 1) = Some(5)));\n  (assert ((candidate 117) = Some(None)));\n  (assert ((candidate 2) = Some(None)));\n  (assert ((candidate 5) = Some(10)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_247936__full_license", "language": "ml", "prompt": "(**Get the full license from the image info\n:param image_info: the information about a particular image\n:return: the full license text for the image\n*)\nlet _full_license (image_info : (string, string) list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_247936__full_license.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _full_license in\n  (assert ((candidate [(\"license\", \"CC0\"); (\"license_version\", \"1.0\")]) = \"CC0 1.0\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_24798_p_a2", "language": "ml", "prompt": "(**Probability of selecting one input given ninputs and npsyns attempts. This\nuses a binomial distribution.\n@param npsyns: The number of proximal synapses.\n@param ninputs: The number of inputs.\n@return: The computed probability.\n*)\nlet p_a2 (npsyns : int) (ninputs : int) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_24798_p_a2.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = p_a2 in\n  (assert ((candidate 1 1) = 1.0));\n  (assert ((candidate 1 4) = 0.25));\n  (assert ((candidate 1 2) = 0.5));\n  (assert ((candidate 1 1) = 1.0));\n  (assert ((candidate 1 3) = 0.3333333333333333));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_248015_irshift", "language": "ml", "prompt": "(**Same as a >>= b.\n*)\nlet irshift (a : int) (b : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_248015_irshift.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = irshift in\n  (assert ((candidate 1 3) = 0));\n  (assert ((candidate (~1) 8) = (~1)));\n  (assert ((candidate 2 8) = 0));\n  (assert ((candidate 0 2) = 0));\n  (assert ((candidate 10 5) = 0));\n  (assert ((candidate 3 3) = 0));\n  (assert ((candidate (~1) 1) = (~1)));\n  (assert ((candidate (~1) 9) = (~1)));\n  (assert ((candidate 2 0) = 2));\n  (assert ((candidate 10 7) = 0));\n  (assert ((candidate 0 1) = 0));\n  (assert ((candidate 1 5) = 0));\n  (assert ((candidate 2 3) = 0));\n  (assert ((candidate (~1) 23) = (~1)));\n  (assert ((candidate (~2) 1) = (~1)));\n  (assert ((candidate (~1) 24) = (~1)));\n  (assert ((candidate 2 4) = 0));\n  (assert ((candidate (~1) 17) = (~1)));\n  (assert ((candidate (~1) 3) = (~1)));\n  (assert ((candidate (~1) 14) = (~1)));\n  (assert ((candidate (~1) 18) = (~1)));\n  (assert ((candidate 3 2) = 0));\n  (assert ((candidate (~1) 22) = (~1)));\n  (assert ((candidate (~1) 21) = (~1)));\n  (assert ((candidate 1 1) = 0));\n  (assert ((candidate (~1) 4) = (~1)));\n  (assert ((candidate 1 6) = 0));\n  (assert ((candidate (~1) 25) = (~1)));\n  (assert ((candidate 1 2) = 0));\n  (assert ((candidate (~1) 10) = (~1)));\n  (assert ((candidate (~1) 16) = (~1)));\n  (assert ((candidate 0 10) = 0));\n  (assert ((candidate 1 0) = 1));\n  (assert ((candidate 1 8) = 0));\n  (assert ((candidate (~1) 5) = (~1)));\n  (assert ((candidate (~1) 6) = (~1)));\n  (assert ((candidate 10 4) = 0));\n  (assert ((candidate 2 6) = 0));\n  (assert ((candidate 2 7) = 0));\n  (assert ((candidate 1 4) = 0));\n  (assert ((candidate 10 6) = 0));\n  (assert ((candidate (~1) 2) = (~1)));\n  (assert ((candidate 10 3) = 1));\n  (assert ((candidate (~1) 12) = (~1)));\n  (assert ((candidate (~1) 15) = (~1)));\n  (assert ((candidate 10 2) = 2));\n  (assert ((candidate (~1) 7) = (~1)));\n  (assert ((candidate (~1) 20) = (~1)));\n  (assert ((candidate 1 7) = 0));\n  (assert ((candidate (~1) 13) = (~1)));\n  (assert ((candidate 10 0) = 10));\n  (assert ((candidate 2 5) = 0));\n  (assert ((candidate 0 0) = 0));\n  (assert ((candidate 10 1) = 5));\n  (assert ((candidate 2 1) = 1));\n  (assert ((candidate (~1) 11) = (~1)));\n  (assert ((candidate (~1) 19) = (~1)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_248555_is_text_all_capital", "language": "ml", "prompt": "(**Returns true of the entire text is written with capitals. False otherwise.\n*)\nlet is_text_all_capital (text : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_248555_is_text_all_capital.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_text_all_capital in\n  (assert ((candidate \"abc\") = false));\n  (assert ((candidate \"\") = true));\n  (assert ((candidate \"ABC\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_249778_dist_modulus_to_distance", "language": "ml", "prompt": "(**Convert distance modulus -> distance (pc)\n: dm : distance modulus\n*)\nlet dist_modulus_to_distance (dm : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_249778_dist_modulus_to_distance.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = dist_modulus_to_distance in\n  (assert ((candidate (~10).0) = 0.1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_25003_stringquote", "language": "ml", "prompt": "(**escapes quotes as neccessary and returns a string representing\nthe text\n*)\nlet stringquote (text : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_25003_stringquote.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = stringquote in\n  (assert ((candidate \"\"one\"\") = \"'\"one\"'\"));\n  (assert ((candidate \"ab'c\") = \"\"ab'c\"\"));\n  (assert ((candidate \"'a\\nb\") = \"\"'a\\nb\"\"));\n  (assert ((candidate \"'\") = \"\"'\"\"));\n  (assert ((candidate \"a'b\") = \"\"a'b\"\"));\n  (assert ((candidate \"'one'\") = \"\"'one'\"\"));\n  (assert ((candidate \"ab\"c'\") = \"\"ab\"\"c'\"\"));\n  (assert ((candidate \"a\\nb'c\") = \"\"a\\nb'c\"\"));\n  (assert ((candidate \"one\") = \"'one'\"));\n  (assert ((candidate \"a\\\\'b\") = \"\"a\\\\'b\"\"));\n  (assert ((candidate \"\") = \"''\"));\n  (assert ((candidate \"abc\") = \"'abc'\"));\n  (assert ((candidate \"one\") = \"'one'\"));\n  (assert ((candidate \"ab\"c'd\") = \"\"ab\"\"c'd\"\"));\n  (assert ((candidate \"one' \") = \"\"one' \"\"));\n  (assert ((candidate \"a\") = \"'a'\"));\n  (assert ((candidate \"a\\'b\") = \"\"a\\'b\"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_250429_BitGet", "language": "ml", "prompt": "(**Gets bit value at position pos from the left of the length-N bit-representation of n\n*)\nlet BitGet (n : int) (N : int) (pos : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_250429_BitGet.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = BitGet in\n  (assert ((candidate 0 2 0) = 0));\n  (assert ((candidate 170 8 7) = 0));\n  (assert ((candidate 0 1 0) = 0));\n  (assert ((candidate 7 2 0) = 1));\n  (assert ((candidate 2 16 1) = 0));\n  (assert ((candidate 31 8 1) = 0));\n  (assert ((candidate 170 8 3) = 0));\n  (assert ((candidate 7 5 2) = 1));\n  (assert ((candidate 170 8 6) = 1));\n  (assert ((candidate 170 8 1) = 0));\n  (assert ((candidate 4 2 1) = 0));\n  (assert ((candidate 3 2 0) = 1));\n  (assert ((candidate 31 8 2) = 0));\n  (assert ((candidate 682 8 0) = 1));\n  (assert ((candidate 15 8 6) = 1));\n  (assert ((candidate 682 8 1) = 0));\n  (assert ((candidate 2 2 1) = 0));\n  (assert ((candidate 8 8 3) = 0));\n  (assert ((candidate 2 8 1) = 0));\n  (assert ((candidate 2147483648 32 0) = 1));\n  (assert ((candidate 64 16 6) = 0));\n  (assert ((candidate 15 8 5) = 1));\n  (assert ((candidate 170 8 5) = 0));\n  (assert ((candidate 8 16 3) = 0));\n  (assert ((candidate 128 16 7) = 0));\n  (assert ((candidate 682 8 2) = 1));\n  (assert ((candidate 3 2 1) = 1));\n  (assert ((candidate 0 2 1) = 0));\n  (assert ((candidate 31 8 3) = 1));\n  (assert ((candidate 15 8 7) = 1));\n  (assert ((candidate 4 2 0) = 0));\n  (assert ((candidate 170 8 4) = 1));\n  (assert ((candidate 31 8 0) = 0));\n  (assert ((candidate 7 5 0) = 0));\n  (assert ((candidate 0 3 0) = 0));\n  (assert ((candidate 1 2 0) = 0));\n  (assert ((candidate 170 8 2) = 1));\n  (assert ((candidate 4 16 2) = 0));\n  (assert ((candidate 682 8 3) = 0));\n  (assert ((candidate 15 8 4) = 1));\n  (assert ((candidate 170 8 0) = 1));\n  (assert ((candidate 32 16 5) = 0));\n  (assert ((candidate 7 2 1) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_250588_excel_col_name2int", "language": "ml", "prompt": "(**>>> excel_col_name2int('A')\n1\n>>> excel_col_name2int('AA')\n27\n>>> excel_col_name2int('AB')\n28\n*)\nlet excel_col_name2int (s : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_250588_excel_col_name2int.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = excel_col_name2int in\n  (assert ((candidate \"A\") = 1));\n  (assert ((candidate \"AA\") = 27));\n  (assert ((candidate \"B\") = 2));\n  (assert ((candidate \"J\") = 10));\n  (assert ((candidate \"H\") = 8));\n  (assert ((candidate \"Q\") = 17));\n  (assert ((candidate \"W\") = 23));\n  (assert ((candidate \"K\") = 11));\n  (assert ((candidate \"M\") = 13));\n  (assert ((candidate \"A\") = 1));\n  (assert ((candidate \"G\") = 7));\n  (assert ((candidate \"O\") = 15));\n  (assert ((candidate \"R\") = 18));\n  (assert ((candidate \"F\") = 6));\n  (assert ((candidate \"AA\") = 27));\n  (assert ((candidate \"T\") = 20));\n  (assert ((candidate \"X\") = 24));\n  (assert ((candidate \"I\") = 9));\n  (assert ((candidate \"C\") = 3));\n  (assert ((candidate \"S\") = 19));\n  (assert ((candidate \"V\") = 22));\n  (assert ((candidate \"E\") = 5));\n  (assert ((candidate \"P\") = 16));\n  (assert ((candidate \"N\") = 14));\n  (assert ((candidate \"L\") = 12));\n  (assert ((candidate \"D\") = 4));\n  (assert ((candidate \"U\") = 21));\n  (assert ((candidate \"AB\") = 28));\n  (assert ((candidate \"AB\") = 28));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_251103_hamming_with_n", "language": "ml", "prompt": "(**Hamming Distance without counting wildcard smbols.\nArgs:\n * s1: the first sequence for comparison.\n * s2: the second sequence for comparison.\nReturns:\n * the distance without accounting unrestricted sites.\n*)\nlet hamming_with_n (s1 : string) (s2 : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_251103_hamming_with_n.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = hamming_with_n in\n  (assert ((candidate \"AGT\" \"CCC\") = 3));\n  (assert ((candidate \"AGT\" \"AGC\") = 1));\n  (assert ((candidate \"AA\" \"AAA\") = 0));\n  (assert ((candidate \"AAA\" \"AA\") = 0));\n  (assert ((candidate \"AGT\" \"CCT\") = 2));\n  (assert ((candidate \"AGT\" \"AGT\") = 0));\n  (assert ((candidate \"AA\" \"AA\") = 0));\n  (assert ((candidate \"AGT\" \"AGG\") = 1));\n  (assert ((candidate \"A\" \"A\") = 0));\n  (assert ((candidate \"AGT\" \"GAT\") = 2));\n  (assert ((candidate \"\" \"\") = 0));\n  (assert ((candidate \"AGT\" \"GTT\") = 2));\n  (assert ((candidate \"AAA\" \"AAA\") = 0));\n  (assert ((candidate \"AGT\" \"TGG\") = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_251439_prefix_dict", "language": "ml", "prompt": "(**Add prefix_s to every key in dict\n:param di_:\n:param prefix_s:\n:return:\n*)\nlet prefix_dict (di_ : (string, int) list) (prefix_s : string) : (string, int) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_251439_prefix_dict.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = prefix_dict in\n  (assert ((candidate [(\"a\", 1); (\"b\", 2)] \"some_prefix_\") = [(\"some_prefix_a\", 1); (\"some_prefix_b\", 2)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_251602_match_link", "language": "ml", "prompt": "(**Diagnoses in app have substrings of how diagnosis named in desease list\n*)\nlet match_link (links : (string, string) list) (name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_251602_match_link.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = match_link in\n  (assert ((candidate [(\"pain\", \"Pain\")] \"pain in the joints\") = \"Pain\"));\n  (assert ((candidate [(\"pain\", \"Pain\")] \"pain in the hands and joints\") = \"Pain\"));\n  (assert ((candidate [(\"pain\", \"Pain\")] \"pain is located at the knee\") = \"Pain\"));\n  (assert ((candidate [(\"pain\", \"Pain\")] \"pain in the right shoulder\") = \"Pain\"));\n  (assert ((candidate [(\"pain\", \"Pain\")] \"pain in the right hip\") = \"Pain\"));\n  (assert ((candidate [(\"pain\", \"Pain\")] \"pain in the left knee\") = \"Pain\"));\n  (assert ((candidate [(\"pain\", \"Pain\")] \"pain in the hips\") = \"Pain\"));\n  (assert ((candidate [(\"pain\", \"Pain\")] \"pain in the leg\") = \"Pain\"));\n  (assert ((candidate [(\"pain\", \"Pain\")] \"pain in the shins\") = \"Pain\"));\n  (assert ((candidate [(\"pain\", \"Pain\")] \"pain in the legs\") = \"Pain\"));\n  (assert ((candidate [(\"pain\", \"Pain\")] \"pain in the right knee\") = \"Pain\"));\n  (assert ((candidate [(\"pain\", \"Pain\")] \"pain in the left hip\") = \"Pain\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_252412_is_up", "language": "ml", "prompt": "(**Returns True if the interface is up, False if it's down, and None if there\nis not enuough information present to determine whether it's up or down\n*)\nlet is_up (line : string) : bool option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_252412_is_up.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_up in\n  (assert ((candidate \"    eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\") = Some(true)));\n  (assert ((candidate \"UP\") = Some(true)));\n  (assert ((candidate \"state UP group default qlen 1000\") = Some(true)));\n  (assert ((candidate \"     UP    inet6 2001:db8::1/64  scope global  \") = Some(true)));\n  (assert ((candidate \"    lo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536\") = Some(true)));\n  (assert ((candidate \"    UP      inet 172.16.0.1/16  brd 172.16.0.255  mtu 1500\") = Some(true)));\n  (assert ((candidate \"state UP    group default qlen   1000\") = Some(true)));\n  (assert ((candidate \"state UNKNOWN group default qlen 1000\") = Some(None)));\n  (assert ((candidate \"state DOWN  group default qlen 1000\") = Some(false)));\n  (assert ((candidate \"    UP      inet 172.16.0.1/16  brd 172.16.0.255  mtu 1500\") = Some(true)));\n  (assert ((candidate \"eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\") = Some(true)));\n  (assert ((candidate \"state DOWN group default qlen 1000\") = Some(false)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_252535_last_blank", "language": "ml", "prompt": "(**Determine if the input source ends in a blank.\nA blank is either a newline or a line consisting of whitespace.\nParameters\n----------\nsrc : string\n * A single or multiline string.\n*)\nlet last_blank (src : string option) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_252535_last_blank.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = last_blank in\n  (assert ((candidate Some(\"  \\n  \")) = false));\n  (assert ((candidate Some(\" \")) = true));\n  (assert ((candidate Some(\" \n\")) = true));\n  (assert ((candidate Some(\"a\\nb\")) = false));\n  (assert ((candidate Some(\"   \n   foo\nbar\n   \")) = true));\n  (assert ((candidate Some(\"a\\n b\\nc\")) = false));\n  (assert ((candidate Some(None)) = false));\n  (assert ((candidate Some(\" \n \")) = true));\n  (assert ((candidate Some(\"foo\")) = false));\n  (assert ((candidate Some(\"  \\n  \\n  \")) = false));\n  (assert ((candidate Some(\"\n\")) = true));\n  (assert ((candidate Some(\"a\\n b\")) = false));\n  (assert ((candidate Some(\"\")) = false));\n  (assert ((candidate Some(\"a\n\")) = false));\n  (assert ((candidate Some(\"   foo   \")) = false));\n  (assert ((candidate Some(\"   foo\")) = false));\n  (assert ((candidate Some(\"a\")) = false));\n  (assert ((candidate Some(\" a\n b\")) = false));\n  (assert ((candidate Some(\" a\n\")) = false));\n  (assert ((candidate Some(\" a\n b\n \")) = true));\n  (assert ((candidate Some(\"foo\nbar\n   \")) = true));\n  (assert ((candidate Some(\"foo   \")) = false));\n  (assert ((candidate Some(\"\")) = false));\n  (assert ((candidate Some(\"\n\")) = true));\n  (assert ((candidate Some(\"   \n\")) = true));\n  (assert ((candidate Some(\"a\")) = false));\n  (assert ((candidate Some(\"a\n\n\")) = true));\n  (assert ((candidate Some(\"foo\nbar\")) = false));\n  (assert ((candidate Some(\"\")) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_253299_replace_slash", "language": "ml", "prompt": "(**Replaces slash with division slash symbol for CheckStyle Jenkins plugin\n*)\nlet replace_slash (name : string option) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_253299_replace_slash.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = replace_slash in\n  (assert ((candidate Some(\"x\")) = \"x\"));\n  (assert ((candidate Some(\"/foo/bar/\")) = \"\u2215foo\u2215bar\u2215\"));\n  (assert ((candidate Some(\"1\")) = \"1\"));\n  (assert ((candidate Some(\"hello/world\")) = \"hello\u2215world\"));\n  (assert ((candidate Some(\"hello/world/12345\")) = \"hello\u2215world\u221512345\"));\n  (assert ((candidate Some(\"/\")) = \"\u2215\"));\n  (assert ((candidate Some(\"123\")) = \"123\"));\n  (assert ((candidate Some(\"//hello\")) = \"\u2215\u2215hello\"));\n  (assert ((candidate Some(\"foo/bar//\")) = \"foo\u2215bar\u2215\u2215\"));\n  (assert ((candidate Some(\"foo//bar/baz\")) = \"foo\u2215\u2215bar\u2215baz\"));\n  (assert ((candidate Some(\"A/B\")) = \"A\u2215B\"));\n  (assert ((candidate Some(\"abc123\")) = \"abc123\"));\n  (assert ((candidate Some(\"//foo\")) = \"\u2215\u2215foo\"));\n  (assert ((candidate Some(\"hello\")) = \"hello\"));\n  (assert ((candidate Some(\"foo/bar/baz\")) = \"foo\u2215bar\u2215baz\"));\n  (assert ((candidate Some(\"A/B/C\")) = \"A\u2215B\u2215C\"));\n  (assert ((candidate Some(\"/A/B/C/\")) = \"\u2215A\u2215B\u2215C\u2215\"));\n  (assert ((candidate Some(\"//\")) = \"\u2215\u2215\"));\n  (assert ((candidate Some(\"foo//bar\")) = \"foo\u2215\u2215bar\"));\n  (assert ((candidate Some(\"bar\")) = \"bar\"));\n  (assert ((candidate Some(\"hello/world/12345/54321\")) = \"hello\u2215world\u221512345\u221554321\"));\n  (assert ((candidate Some(\"/A/B/\")) = \"\u2215A\u2215B\u2215\"));\n  (assert ((candidate Some(\"/A/B/C/D/\")) = \"\u2215A\u2215B\u2215C\u2215D\u2215\"));\n  (assert ((candidate Some(\"abc\")) = \"abc\"));\n  (assert ((candidate Some(\"foo/bar\")) = \"foo\u2215bar\"));\n  (assert ((candidate Some(\"\")) = \"\"));\n  (assert ((candidate Some(\"A/B/C/D\")) = \"A\u2215B\u2215C\u2215D\"));\n  (assert ((candidate Some(\"foo\")) = \"foo\"));\n  (assert ((candidate Some(None)) = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_253524_remove_block_hashtags", "language": "ml", "prompt": "(**attempt to remove hidden hashtags at the bottom of captions\n*)\nlet remove_block_hashtags (caption : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_253524_remove_block_hashtags.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = remove_block_hashtags in\n  (assert ((candidate \"a #simple #caption\n\n\u2022 #a hidden hashtag\n\n\u2022 another hidden hashtag\n\n\u2022 a third hidden hashtag\") = \"a #simple #caption\"));\n  (assert ((candidate \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\") = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\"));\n  (assert ((candidate \"Hey check out this #python #code\n\u2022 #programming #code #python #fun\") = \"Hey check out this #python #code\"));\n  (assert ((candidate \"#dogcatdog\") = \"#dogcatdog\"));\n  (assert ((candidate \"Hey check out this #python #code\n\u2022 #programming #code #python #fun\n\u2022 #python #coding #fun\n\u2022 #python #fun #code\n\u2022 #python #fun #code\n\u2022 #python #fun #code\") = \"Hey check out this #python #code\"));\n  (assert ((candidate \"Hey check out this #python #code\n\u2022 #programming #code #python #fun\n\u2022 #python #coding #fun\n\u2022 #python #fun #code\") = \"Hey check out this #python #code\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"a #simple #caption\n\n\u2022 #a hidden hashtag\n\n\u2022 #another hidden hashtag\") = \"a #simple #caption\"));\n  (assert ((candidate \"This is a caption with hashtags.\n\n###test ###hashtag ###hashtag\") = \"This is a caption with hashtags.\"));\n  (assert ((candidate \"Hello, Twitter! This is <NAME>, and today we're excited to introduce a brand new way to discover and share on Twitter. With the new Discover tab, you can find the content you love and follow people who love it!\") = \"Hello, Twitter! This is <NAME>, and today we're excited to introduce a brand new way to discover and share on Twitter. With the new Discover tab, you can find the content you love and follow people who love it!\"));\n  (assert ((candidate \"This is a caption with hashtags.\n\n#hello\n\n###test ###hashtag ###hashtag\n\n\") = \"This is a caption with hashtags.\"));\n  (assert ((candidate \"Hey check out this #python #code\n\u2022 #programming #code #python #fun\n\u2022 #python #coding #fun\") = \"Hey check out this #python #code\"));\n  (assert ((candidate \"A few days ago I had a very good feeling about the project because of how the community was and how active we were. I was also happy to see that the project was gaining momentum!\") = \"A few days ago I had a very good feeling about the project because of how the community was and how active we were. I was also happy to see that the project was gaining momentum!\"));\n  (assert ((candidate \"Today we're announcing a major new feature, which allows you to view who has liked your photos! You can now filter the photo grid by your liked photos to see who has liked your photos!\") = \"Today we're announcing a major new feature, which allows you to view who has liked your photos! You can now filter the photo grid by your liked photos to see who has liked your photos!\"));\n  (assert ((candidate \"a #simple #caption\n\n\u2022 #a hidden hashtag\n\n\u2022 another hidden hashtag\n\n\u2022 a third hidden hashtag\n\n\u2022 a fourth hidden hashtag\") = \"a #simple #caption\"));\n  (assert ((candidate \"a #simple #caption\n\n\u2022 #a hidden hashtag\") = \"a #simple #caption\"));\n  (assert ((candidate \"dogcatdogcatdogcat\") = \"dogcatdogcatdogcat\"));\n  (assert ((candidate \"hello world\") = \"hello world\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_253671__gen_bia_img_url", "language": "ml", "prompt": "(**Genarate BIA Image URL\n*)\nlet _gen_bia_img_url (imgname : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_253671__gen_bia_img_url.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _gen_bia_img_url in\n  (assert ((candidate \"4011225839_82f37d3a43_b.jpg\") = \"http://www.istartedsomething.com/bingimages/cache/4011225839_82f37d3a43_b.jpg\"));\n  (assert ((candidate \"4096.jpg\") = \"http://www.istartedsomething.com/bingimages/cache/4096.jpg\"));\n  (assert ((candidate \"1844c585d7706905996f70d34e6e88f4.jpg\") = \"http://www.istartedsomething.com/bingimages/cache/1844c585d7706905996f70d34e6e88f4.jpg\"));\n  (assert ((candidate \"16526562929_4a36810594_b.jpg\") = \"http://www.istartedsomething.com/bingimages/cache/16526562929_4a36810594_b.jpg\"));\n  (assert ((candidate \"test.jpg\") = \"http://www.istartedsomething.com/bingimages/cache/test.jpg\"));\n  (assert ((candidate ) = \"http://www.istartedsomething.com/bingimages/cache/mybiaimage.jpg\"));\n  (assert ((candidate \"13190.jpg\") = \"http://www.istartedsomething.com/bingimages/cache/13190.jpg\"));\n  (assert ((candidate \"542048039_d5e364672a_b.jpg\") = \"http://www.istartedsomething.com/bingimages/cache/542048039_d5e364672a_b.jpg\"));\n  (assert ((candidate \"12299423875_7e6178659f_b.jpg\") = \"http://www.istartedsomething.com/bingimages/cache/12299423875_7e6178659f_b.jpg\"));\n  (assert ((candidate \"25805.jpg\") = \"http://www.istartedsomething.com/bingimages/cache/25805.jpg\"));\n  (assert ((candidate \"test\") = \"http://www.istartedsomething.com/bingimages/cache/test\"));\n  (assert ((candidate \"foo.png\") = \"http://www.istartedsomething.com/bingimages/cache/foo.png\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_254264_sorted_items", "language": "ml", "prompt": "(**Return an iterator of the dict's items sorted by its keys.\n*)\nlet sorted_items (params : (string, int) list) :  string * int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_254264_sorted_items.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sorted_items in\n  (assert ((candidate [(\"a\", 1); (\"c\", 3); (\"b\", 2)]) = [(\"a\", 1); (\"b\", 2); (\"c\", 3)]));\n  (assert ((candidate dict ) = []));\n  (assert ((candidate [(\"a\", 1); (\"c\", 3); (\"b\", 2); (\"d\", 4)]) = [(\"a\", 1); (\"b\", 2); (\"c\", 3); (\"d\", 4)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_254385_parse_seat_to_binary", "language": "ml", "prompt": "(**Take a seat identifier BFFFBBFRRR and determine it's binary\nnumber\n*)\nlet parse_seat_to_binary (seat : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_254385_parse_seat_to_binary.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_seat_to_binary in\n  (assert ((candidate \"\") = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_254436__get_int_type_index", "language": "ml", "prompt": "(**Returns the index into the types array corresponding to this int\n*)\nlet _get_int_type_index (i : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_254436__get_int_type_index.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _get_int_type_index in\n  (assert ((candidate 12345) = 3));\n  (assert ((candidate 4294967295) = 2));\n  (assert ((candidate 2147483646) = 3));\n  (assert ((candidate 2147483648) = 2));\n  (assert ((candidate 10) = 3));\n  (assert ((candidate 1024) = 3));\n  (assert ((candidate 4) = 3));\n  (assert ((candidate (~2147483648)) = 3));\n  (assert ((candidate 1) = 3));\n  (assert ((candidate (~1)) = 3));\n  (assert ((candidate (~42)) = 3));\n  (assert ((candidate 42) = 3));\n  (assert ((candidate 2147483647) = 3));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_254770_key_int_to_str", "language": "ml", "prompt": "(**Convert spotify's 'pitch class notation' to\nand actual key value\n*)\nlet key_int_to_str (key : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_254770_key_int_to_str.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = key_int_to_str in\n  (assert ((candidate 8) = \"G#\"));\n  (assert ((candidate \"13\") = \"No key\"));\n  (assert ((candidate 9) = \"A\"));\n  (assert ((candidate 5) = \"F\"));\n  (assert ((candidate (~5)) = \"No key\"));\n  (assert ((candidate (~8)) = \"No key\"));\n  (assert ((candidate 15) = \"No key\"));\n  (assert ((candidate 3) = \"D#\"));\n  (assert ((candidate 1) = \"C#\"));\n  (assert ((candidate 4) = \"E\"));\n  (assert ((candidate (~1)) = \"No key\"));\n  (assert ((candidate 10) = \"A#\"));\n  (assert ((candidate 13) = \"No key\"));\n  (assert ((candidate (~3)) = \"No key\"));\n  (assert ((candidate \"12\") = \"No key\"));\n  (assert ((candidate (~2)) = \"No key\"));\n  (assert ((candidate 11) = \"B\"));\n  (assert ((candidate (~4)) = \"No key\"));\n  (assert ((candidate 14) = \"No key\"));\n  (assert ((candidate 2) = \"D\"));\n  (assert ((candidate 7) = \"G\"));\n  (assert ((candidate 12) = \"No key\"));\n  (assert ((candidate 0) = \"C\"));\n  (assert ((candidate (~6)) = \"No key\"));\n  (assert ((candidate 24) = \"No key\"));\n  (assert ((candidate (~7)) = \"No key\"));\n  (assert ((candidate 6) = \"F#\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_255070_average_best_three", "language": "ml", "prompt": "(**from input of four numbers average biggest three\naverage_best_three(1, 10, 20, 30)\n20\n*)\nlet average_best_three (grade1 : int) (grade2 : int) (grade3 : int) (grade4 : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_255070_average_best_three.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = average_best_three in\n  (assert ((candidate 3 3 3 3) = 3));\n  (assert ((candidate 10 10 10 10) = 10));\n  (assert ((candidate 1 10 20 30) = 20));\n  (assert ((candidate 10 1 30 20) = 20));\n  (assert ((candidate (~5) (~4) (~3) (~2)) = (~3)));\n  (assert ((candidate 10 20 10 30) = 20));\n  (assert ((candidate (~1) (~2) (~3) (~4)) = (~2)));\n  (assert ((candidate 10 1 20 30) = 20));\n  (assert ((candidate 1 1 1 1) = 1));\n  (assert ((candidate 5 5 5 5) = 5));\n  (assert ((candidate 100 100 100 100) = 100));\n  (assert ((candidate 0 0 0 0) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_255382_phex", "language": "ml", "prompt": "(**convert int to 2 characters hex string\nwhich not contain '0x' in begin or 'L' in end\n*)\nlet phex (num : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_255382_phex.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = phex in\n  (assert ((candidate 32) = \"20\"));\n  (assert ((candidate 31) = \"1F\"));\n  (assert ((candidate 42) = \"2A\"));\n  (assert ((candidate 129) = \"81\"));\n  (assert ((candidate 17) = \"11\"));\n  (assert ((candidate 65535) = \"FFFF\"));\n  (assert ((candidate 10) = \"0A\"));\n  (assert ((candidate 100) = \"64\"));\n  (assert ((candidate 4660) = \"1234\"));\n  (assert ((candidate 1) = \"01\"));\n  (assert ((candidate 256) = \"100\"));\n  (assert ((candidate 10000) = \"2710\"));\n  (assert ((candidate 255) = \"FF\"));\n  (assert ((candidate 1) = \"01\"));\n  (assert ((candidate 3) = \"03\"));\n  (assert ((candidate 1000) = \"3E8\"));\n  (assert ((candidate 0) = \"00\"));\n  (assert ((candidate 257) = \"101\"));\n  (assert ((candidate 16) = \"10\"));\n  (assert ((candidate 31) = \"1F\"));\n  (assert ((candidate 12) = \"0C\"));\n  (assert ((candidate 0) = \"00\"));\n  (assert ((candidate 128) = \"80\"));\n  (assert ((candidate 11) = \"0B\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_255677__prune_instance_label", "language": "ml", "prompt": "(**Deletes everything after the year, which ends in a closed parenthesis.\n*)\nlet _prune_instance_label (label : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_255677__prune_instance_label.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _prune_instance_label in\n  (assert ((candidate \"The Einstein Journal (1879-1934) (1944-1946) (1947-1948)\") = \"The Einstein Journal (1879-1934)\"));\n  (assert ((candidate \"n.d. (1827-04-17).???.\") = \"n.d. (1827-04-17)\"));\n  (assert ((candidate \"n.d. (1827-04-17)???\") = \"n.d. (1827-04-17)\"));\n  (assert ((candidate \"n.d. (1827-04-17).\") = \"n.d. (1827-04-17)\"));\n  (assert ((candidate \"n.d. (1827-04-17)\") = \"n.d. (1827-04-17)\"));\n  (assert ((candidate \"n.d. (1827-04-17)???.\") = \"n.d. (1827-04-17)\"));\n  (assert ((candidate \"The Einstein Journal (1879-1934) (1944-1946)\") = \"The Einstein Journal (1879-1934)\"));\n  (assert ((candidate \"n.d. (1827-04-17).???\") = \"n.d. (1827-04-17)\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_255721_hp_state_bit_english", "language": "ml", "prompt": "(**Convert derog bit flag to English\n*)\nlet hp_state_bit_english (raw_table : int list) (base_index : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_255721_hp_state_bit_english.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = hp_state_bit_english in\n  (assert ((candidate [255; 255; 255; 255; 255; 255; 255; 255] 0) = \"[Defrosting] [Boiler Pump Backup] [Boiler Backup] [HP Pump] [Backup 2] [Backup 1] [Compressor] \"));\n  (assert ((candidate [255; 255; 255; 255; 255; 255; 255; 255] 1) = \"[Defrosting] [Boiler Pump Backup] [Boiler Backup] [HP Pump] [Backup 2] [Backup 1] [Compressor] \"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_256372_is_mer", "language": "ml", "prompt": "(**Checks if the rectangle is a MER\nNOTE: exclusive ur\n*)\nlet is_mer (grid : int list list) (llx : int) (lly : int) (urx : int) (ury : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_256372_is_mer.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_mer in\n  (assert ((candidate [[1; 1; 1; 1; 1; 1; 0; 1]; [0; 0; 0; 1; 0; 1; 1; 1]; [0; 1; 1; 1; 0; 1; 1; 1]; [0; 0; 1; 1; 1; 1; 1; 1]] 0 0 7 7) = false));\n  (assert ((candidate [[1; 1; 1; 0; 1; 1; 1; 1]; [0; 0; 1; 1; 1; 1; 1; 1]; [0; 1; 1; 1; 0; 1; 1; 1]; [0; 0; 1; 1; 1; 1; 1; 1]] 0 0 7 7) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_257729_get_die_base_hazard_rate", "language": "ml", "prompt": "(**Retrieve the base hazard rate for a VHISC/VLSI die.\n:param type_id: the VHISC/VLSI type identifier.\n:return: _lambda_bd; the base die hazard rate.\n:rtype: float\n*)\nlet get_die_base_hazard_rate (type_id : int) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_257729_get_die_base_hazard_rate.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_die_base_hazard_rate in\n  (assert ((candidate 1) = 0.16));\n  (assert ((candidate 2) = 0.24));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_258216_parseMovie", "language": "ml", "prompt": "(**Parses a movie record in MovieLens format movieId::movieTitle .\n*)\nlet parseMovie (line : string) :  int * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_258216_parseMovie.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parseMovie in\n  (assert ((candidate \"6::Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\") = (6, \"Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\")));\n  (assert ((candidate \"1::Sully (1965)::http://us.imdb.com/M/title-exact?Sully%20(1965)\") = (1, \"Sully (1965)\")));\n  (assert ((candidate \"3::Grumpier Old Men (1995)::Comedy::Romance::8.0\") = (3, \"Grumpier Old Men (1995)\")));\n  (assert ((candidate \"1::Toy Story (1995)\") = (1, \"Toy Story (1995)\")));\n  (assert ((candidate \"1::Toy Story (1995)::Animation::Comedy::8.3\") = (1, \"Toy Story (1995)\")));\n  (assert ((candidate \"2::Jumanji (1995)::Adventure::Childhood::8.1\") = (2, \"Jumanji (1995)\")));\n  (assert ((candidate \"6::Heat (1995)::Action::Sci-Fi::7.9\") = (6, \"Heat (1995)\")));\n  (assert ((candidate \"8::Tom and Huck (1995)::Adventure::Children's::8.5\") = (8, \"Tom and Huck (1995)\")));\n  (assert ((candidate \"3::Three Billboards Outside Ebbing, Missouri (2017)::http://us.imdb.com/M/title-exact?Three%20Billboards%20Outside%20Ebbing,%20Missouri%20(2017)\") = (3, \"Three Billboards Outside Ebbing, Missouri (2017)\")));\n  (assert ((candidate \"2::Toy Story (1995)::http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)\") = (2, \"Toy Story (1995)\")));\n  (assert ((candidate \"4::Get Shorty (1995)\") = (4, \"Get Shorty (1995)\")));\n  (assert ((candidate \"3::Four Rooms (1995)\") = (3, \"Four Rooms (1995)\")));\n  (assert ((candidate \"5::Copycat (1995)\") = (5, \"Copycat (1995)\")));\n  (assert ((candidate \"5::Father of the Bride Part II (1995)::Comedy::Romance::8.5\") = (5, \"Father of the Bride Part II (1995)\")));\n  (assert ((candidate \"32::Clerks (1994)\") = (32, \"Clerks (1994)\")));\n  (assert ((candidate \"7::Sabrina (1995)::Comedy::Romance::8.3\") = (7, \"Sabrina (1995)\")));\n  (assert ((candidate \"4::Waiting to Exhale (1995)::Comedy::Romance::8.2\") = (4, \"Waiting to Exhale (1995)\")));\n  (assert ((candidate \"2::GoldenEye (1995)\") = (2, \"GoldenEye (1995)\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_258575_consolidate_paragraphs", "language": "ml", "prompt": "(**This takes the array of paragraphs and returns point at which paragraph begins. \nNOTE that  for purposes of paragraphs, headers are counted as being within the\nparagraph following it\n*)\nlet consolidate_paragraphs (paragraph_offsets :  int * int list) (header_offsets :  int * int list) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_258575_consolidate_paragraphs.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = consolidate_paragraphs in\n  (assert ((candidate [(0, 0); (2, 2); (3, 3); (4, 4); (8, 8)] [(0, 0)]) = [0; 2; 3; 4; 8]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_258727_cell_cube_coord", "language": "ml", "prompt": "(**Returns a tuple with the cube coordinates corresponding to the \ngiven axial coordinates.\n*)\nlet cell_cube_coord (c :  int * int) :  int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_258727_cell_cube_coord.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = cell_cube_coord in\n  (assert ((candidate (0, 2)) = (0, (~2), 2)));\n  (assert ((candidate (3, 0)) = (3, (~3), 0)));\n  (assert ((candidate (1, 1)) = (1, (~2), 1)));\n  (assert ((candidate (12, 12)) = (12, (~24), 12)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_258869_get_geo_url", "language": "ml", "prompt": "(**:param geo_list: list of (geo, geo_id) pair (smallest first)\ne.g. [(block%20group, *), (state, 01), (county, 02), (track, *), ]\n * :return: url for geo query\n*)\nlet get_geo_url (geo_list :  string * string list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_258869_get_geo_url.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_geo_url in\n  (assert ((candidate [(\"county\", \"02\"); (\"track\", \"*\")]) = \"&for=county:02&in=track:*\"));\n  (assert ((candidate [(\"state\", \"01\"); (\"county\", \"02\"); (\"track\", \"*\")]) = \"&for=state:01&in=county:02&in=track:*\"));\n  (assert ((candidate [(\"track\", \"*\")]) = \"&for=track:*\"));\n  (assert ((candidate [(\"state\", \"06\"); (\"county\", \"039\")]) = \"&for=state:06&in=county:039\"));\n  (assert ((candidate []) = \"\"));\n  (assert ((candidate [(\"state\", \"01\"); (\"county\", \"*\")]) = \"&for=state:01&in=county:*\"));\n  (assert ((candidate [(\"state\", \"01\"); (\"county\", \"053\"); (\"county\", \"005\"); (\"county\", \"*\")]) = \"&for=state:01&in=county:053&in=county:005&in=county:*\"));\n  (assert ((candidate [(\"state\", \"*\")]) = \"&for=state:*\"));\n  (assert ((candidate [(\"state\", \"01\")]) = \"&for=state:01\"));\n  (assert ((candidate [(\"state\", \"01\"); (\"county\", \"001\"); (\"tract\", \"001100\")]) = \"&for=state:01&in=county:001&in=tract:001100\"));\n  (assert ((candidate [(\"state\", \"06\"); (\"county\", \"031\")]) = \"&for=state:06&in=county:031\"));\n  (assert ((candidate [(\"state\", \"01\"); (\"county\", \"02\")]) = \"&for=state:01&in=county:02\"));\n  (assert ((candidate [(\"state\", \"*\"); (\"county\", \"*\")]) = \"&for=state:*&in=county:*\"));\n  (assert ((candidate [(\"state\", \"01\"); (\"county\", \"02\"); (\"track\", \"*\")]) = \"&for=state:01&in=county:02&in=track:*\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_259430_is_pkg_url", "language": "ml", "prompt": "(**Check to see if the url is for a pkg file\n*)\nlet is_pkg_url (munki_url : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_259430_is_pkg_url.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_pkg_url in\n  (assert ((candidate \"https://pkgs.foo.bar.com/product/foo/1.0/i386/Foo-1.0.dmg\") = true));\n  (assert ((candidate \"https://pkgs.foo.bar.com/product/foo/1.0/x86_64/Foo-1.0.dmg\") = true));\n  (assert ((candidate \"https://pkgs.foo.bar.com/product/foo/1.0/Foo-1.0.pkg\") = true));\n  (assert ((candidate \"https://my.munki.example.org/pkgs/foo-bar-1.0.pkg\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_25952_coalesce_dates", "language": "ml", "prompt": "(**Coalesces all date pairs into combined date pairs that makes it easy to find free time gaps.\n>>> from date_collapse import coalesce_dates\n>>> dates = [(1,4),(2,8),(12,16),(16,21)]\n>>> cdates = coalesce_dates(dates)\n>>> print(cdates)\n[(1, 8), (12, 21)]\n>>> dates = [(1,4),(2,8),(8,10),(12,16),(16,21),(21,31)]\n>>> cdates = coalesce_dates(dates)\n>>> print(cdates)\n[(1, 10), (12, 31)]\n*)\nlet coalesce_dates (dates :  int * int list) :  int * int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_25952_coalesce_dates.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = coalesce_dates in\n  (assert ((candidate [(1, 4); (2, 8); (8, 10); (12, 16); (16, 21); (21, 31)]) = [(1, 10); (12, 31)]));\n  (assert ((candidate [(1, 4); (2, 8); (12, 16); (16, 21)]) = [(1, 8); (12, 21)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_259671_conv_module_name_filter", "language": "ml", "prompt": "(**filter module name to have a short view\n*)\nlet conv_module_name_filter (name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_259671_conv_module_name_filter.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = conv_module_name_filter in\n  (assert ((candidate \"Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\") = \"Conv2d(3, 16, k=(1, 1), s=(1, 1), b=False)\"));\n  (assert ((candidate \"Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\") = \"Conv2d(3, 32, k=(5, 5), s=(1, 1), pad=(2, 2), b=False)\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_259733_IsVersionNewer", "language": "ml", "prompt": "(**Determines if new Chrome version is higher than the installed one.\nArgs:\n * cur_version: Current version of Chrome.\n * new_version: New version that will be installed.\nReturns:\n * True, if new version is higher, otherwise False.\n*)\nlet IsVersionNewer (cur_version : string) (new_version : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_259733_IsVersionNewer.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = IsVersionNewer in\n  (assert ((candidate \"1.2.3.4\" \"1.2.4.4\") = true));\n  (assert ((candidate \"1.2.3.4\" \"1.2.3.5\") = true));\n  (assert ((candidate \"1.2.3.4\" \"0.2.3.4\") = false));\n  (assert ((candidate \"1.2.3.4\" \"1.2.3.4\") = false));\n  (assert ((candidate \"1.2.3.4\" \"1.2.3.3\") = false));\n  (assert ((candidate \"1.2.3.4\" \"1.3.3.4\") = true));\n  (assert ((candidate \"1.2.3.4\" \"1.2.2.4\") = false));\n  (assert ((candidate \"1.2.3.4\" \"2.2.3.4\") = true));\n  (assert ((candidate \"1.2.3.4\" \"1.2.3.4\") = false));\n  (assert ((candidate \"1.0.0.0\" \"1.0.0.0\") = false));\n  (assert ((candidate \"1.2.3.4\" \"1.1.3.4\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_259839_interval_to_milliseconds", "language": "ml", "prompt": "(**Convert a Binance interval string to milliseconds\nFor clarification see document or mail d3dileep@gmail.com\n:param interval: Binance interval string 1m, 3m, 5m, 15m, 30m, 1h, 2h, 4h, 6h, 8h, 12h, 1d, 3d, 1w\n:type interval: str\n:return:\n * None if unit not one of m, h, d or w\n * None if string not in correct format\n * int value of interval in milliseconds\n*)\nlet interval_to_milliseconds (interval : string) : int option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_259839_interval_to_milliseconds.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = interval_to_milliseconds in\n  (assert ((candidate \"1h\") = Some(3600000)));\n  (assert ((candidate \"1M\") = Some(None)));\n  (assert ((candidate \"1m\") = Some(60000)));\n  (assert ((candidate \"30m\") = Some(1800000)));\n  (assert ((candidate \"4h\") = Some(14400000)));\n  (assert ((candidate \"3d\") = Some(259200000)));\n  (assert ((candidate \"2h\") = Some(7200000)));\n  (assert ((candidate \"6h\") = Some(21600000)));\n  (assert ((candidate \"1d\") = Some(86400000)));\n  (assert ((candidate \"1W\") = Some(None)));\n  (assert ((candidate \"1d\") = Some(86400000)));\n  (assert ((candidate \"1w\") = Some(604800000)));\n  (assert ((candidate \"15m\") = Some(900000)));\n  (assert ((candidate \"1w\") = Some(604800000)));\n  (assert ((candidate \"8h\") = Some(28800000)));\n  (assert ((candidate \"15m\") = Some(900000)));\n  (assert ((candidate \"4h\") = Some(14400000)));\n  (assert ((candidate \"1m\") = Some(60000)));\n  (assert ((candidate \"12h\") = Some(43200000)));\n  (assert ((candidate \"8h\") = Some(28800000)));\n  (assert ((candidate \"6h\") = Some(21600000)));\n  (assert ((candidate \"5m\") = Some(300000)));\n  (assert ((candidate \"2h\") = Some(7200000)));\n  (assert ((candidate \"3m\") = Some(180000)));\n  (assert ((candidate \"3m\") = Some(180000)));\n  (assert ((candidate \"12h\") = Some(43200000)));\n  (assert ((candidate \"1h\") = Some(3600000)));\n  (assert ((candidate \"3d\") = Some(259200000)));\n  (assert ((candidate \"5m\") = Some(300000)));\n  (assert ((candidate \"30m\") = Some(1800000)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_260814_str2bool", "language": "ml", "prompt": "(**Convert string to boolean.\n*)\nlet str2bool (string : string option) : bool option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_260814_str2bool.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = str2bool in\n  (assert ((candidate Some(\"1\")) = Some(true)));\n  (assert ((candidate Some(\"True\")) = Some(true)));\n  (assert ((candidate Some(\"True\")) = Some(true)));\n  (assert ((candidate Some(None)) = Some(None)));\n  (assert ((candidate Some(\"false\")) = Some(false)));\n  (assert ((candidate Some(\"false\")) = Some(false)));\n  (assert ((candidate Some(\"False\")) = Some(false)));\n  (assert ((candidate Some(\"yes\")) = Some(true)));\n  (assert ((candidate Some(\"0\")) = Some(false)));\n  (assert ((candidate Some(\"False\")) = Some(false)));\n  (assert ((candidate Some(\"no\")) = Some(false)));\n  (assert ((candidate Some(\"true\")) = Some(true)));\n  (assert ((candidate Some(\"true\")) = Some(true)));\n  (assert ((candidate Some(\"0\")) = Some(false)));\n  (assert ((candidate Some(\"1\")) = Some(true)));\n  (assert ((candidate Some(\"no\")) = Some(false)));\n  (assert ((candidate Some(\"yes\")) = Some(true)));\n  (assert ((candidate Some(\"\")) = Some(None)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_261308_get_eqn", "language": "ml", "prompt": "(**Returns the equation of a line in the form mx+b as a tuple of (m, b) for two points.\nDoes not check for vertical lines.\n*)\nlet get_eqn (p0 :  int * int) (p1 :  int * int) :  int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_261308_get_eqn.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_eqn in\n  (assert ((candidate (0, 0) (100, 0)) = (0, 0)));\n  (assert ((candidate (0, 0) (100, 100)) = (1, 0)));\n  (assert ((candidate (0, 0) (1, 2)) = (2, 0)));\n  (assert ((candidate (0, 0) (1, 1)) = (1, 0)));\n  (assert ((candidate (0, 0) ((~100), 100)) = ((~1), 0)));\n  (assert ((candidate (0, 0) ((~100), 0)) = (0, 0)));\n  (assert ((candidate (0, 0) ((~1), 1)) = ((~1), 0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_261555_write_output", "language": "ml", "prompt": "(**Make tsv format output file.\n*)\nlet write_output (final : string) (invcf : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_261555_write_output.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = write_output in\n  (assert ((candidate \"1\t10\tA\tG\n1\t12\tT\tC\n1\t15\tC\tT\n1\t18\tG\tA\n1\t20\tC\tT\n\" \"my_data.vcf\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_261763_get_package_type", "language": "ml", "prompt": "(**:returns the package type [\"pypy_package\"|\"git_package\"|\"weblink\"]\n>>> assert get_package_type('pip') == 'pypy_package'\n>>> assert get_package_type('https://github.com/pypa/pip.git') == 'git_package'\n>>> assert get_package_type('git+https://github.com/pypa/pip.git') == 'git_package'\n>>> assert get_package_type('https://github.com/pypa/archive/master.zip') == 'git_package'\n>>> assert get_package_type('https://some_link/pypa/archive/master.zip') == 'weblink'\n*)\nlet get_package_type (package_link : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_261763_get_package_type.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_package_type in\n  (assert ((candidate \"pip\") = \"pypy_package\"));\n  (assert ((candidate \"https://github.com/pypa/pip.git\") = \"git_package\"));\n  (assert ((candidate \"https://github.com/pypa/pip.git\") = \"git_package\"));\n  (assert ((candidate \"git+https://github.com/pypa/pip.git\") = \"git_package\"));\n  (assert ((candidate \"https://some_link/pypa/archive/master.zip\") = \"weblink\"));\n  (assert ((candidate \"https://github.com/pypa/archive/master.zip\") = \"git_package\"));\n  (assert ((candidate \"https://github.com/pypa/pip\") = \"git_package\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_262021_empty_columns", "language": "ml", "prompt": "(**Returns list of \"\" with length equal to length of expected column.\n>>> empty_columns(['***21**', '412453*', '423145*', '*543215', '*35214*', '*41532*', '*2*1***'])\n['', '', '', '', '', '', '']\n*)\nlet empty_columns (board : string list) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_262021_empty_columns.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = empty_columns in\n  (assert ((candidate [\"***21**\"; \"412553*\"; \"423145*\"; \"*543215\"; \"*35214*\"; \"*41232*\"; \"*2*1***\"]) = [\"\"; \"\"; \"\"; \"\"; \"\"; \"\"; \"\"]));\n  (assert ((candidate [\"*21**\"; \"412453*\"]) = [\"\"; \"\"; \"\"; \"\"; \"\"]));\n  (assert ((candidate [\"***22**\"; \"412453*\"; \"423145*\"; \"*543215\"; \"*35214*\"; \"*41532*\"; \"*2*1***\"]) = [\"\"; \"\"; \"\"; \"\"; \"\"; \"\"; \"\"]));\n  (assert ((candidate [\"***21**\"; \"412453*\"; \"423145*\"; \"*543215\"; \"*35214*\"; \"*41232*\"; \"*2*1***\"]) = [\"\"; \"\"; \"\"; \"\"; \"\"; \"\"; \"\"]));\n  (assert ((candidate [\"***22**\"; \"412453*\"; \"423145*\"; \"*543215\"; \"*35214*\"; \"*41232*\"; \"*2*1***\"]) = [\"\"; \"\"; \"\"; \"\"; \"\"; \"\"; \"\"]));\n  (assert ((candidate [\"***21**\"; \"412553*\"; \"423145*\"; \"*543215\"; \"*35214*\"; \"*41532*\"; \"*2*1***\"]) = [\"\"; \"\"; \"\"; \"\"; \"\"; \"\"; \"\"]));\n  (assert ((candidate [\"***21**\"; \"412453*\"; \"423145*\"; \"*543215\"; \"*35214*\"; \"*41532*\"; \"*2*1***\"]) = [\"\"; \"\"; \"\"; \"\"; \"\"; \"\"; \"\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_262051_remove_numbers", "language": "ml", "prompt": "(**Remove any number in a string\nArgs:\n * s (str): A string that need to remove number\nReturns:\n * A formatted string with no number\n*)\nlet remove_numbers (s : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_262051_remove_numbers.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = remove_numbers in\n  (assert ((candidate \"10101010\") = \"\"));\n  (assert ((candidate \"1234567890\") = \"\"));\n  (assert ((candidate \"abc12345\") = \"abc\"));\n  (assert ((candidate \"abc123abc\") = \"abcabc\"));\n  (assert ((candidate \"There are no numbers in this string\") = \"There are no numbers in this string\"));\n  (assert ((candidate \"Hello World\") = \"Hello World\"));\n  (assert ((candidate \"2021 isn't a year\") = \" isn't a year\"));\n  (assert ((candidate \"1234567890-\") = \"-\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"hello\") = \"hello\"));\n  (assert ((candidate \"Hello123World\") = \"HelloWorld\"));\n  (assert ((candidate \"Hi there! 23 is my favorite number.\") = \"Hi there!  is my favorite number.\"));\n  (assert ((candidate \"What is the weather like tomorrow?\") = \"What is the weather like tomorrow?\"));\n  (assert ((candidate \"The 5 boxing wizards jump quickly.\") = \"The  boxing wizards jump quickly.\"));\n  (assert ((candidate \"1234567890\") = \"\"));\n  (assert ((candidate \"abc 123 abc\") = \"abc  abc\"));\n  (assert ((candidate \"1234\") = \"\"));\n  (assert ((candidate \"No numbers here\") = \"No numbers here\"));\n  (assert ((candidate \"2021 is a year\") = \" is a year\"));\n  (assert ((candidate \"0123456789\") = \"\"));\n  (assert ((candidate \"1\") = \"\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"I am 20 years old.\") = \"I am  years old.\"));\n  (assert ((candidate \"123\") = \"\"));\n  (assert ((candidate \"I am 100 years old.\") = \"I am  years old.\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_262360_longest_substring", "language": "ml", "prompt": "(**Finds longest substring among list of strings\n:param str_list: strings to be searched\n:type str_list: list (of str)\n:rtype: str\n*)\nlet longest_substring (str_list : string list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_262360_longest_substring.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = longest_substring in\n  (assert ((candidate list \"   \") = \"\"));\n  (assert ((candidate [\"  \"]) = \"\"));\n  (assert ((candidate [\"   \"]) = \"\"));\n  (assert ((candidate [\"abc\"; \"abc\"]) = \"abc\"));\n  (assert ((candidate [\" \"]) = \"\"));\n  (assert ((candidate [\"a\"; \"a\"]) = \"a\"));\n  (assert ((candidate [\"abc\"; \"xyz\"]) = \"\"));\n  (assert ((candidate [\"apple\"; \"apple\"]) = \"apple\"));\n  (assert ((candidate list \"  \") = \"\"));\n  (assert ((candidate list \"\") = \"\"));\n  (assert ((candidate [\"\"]) = \"\"));\n  (assert ((candidate [\"\"; \"\"]) = \"\"));\n  (assert ((candidate [\"abc\"; \"xyz\"; \"123\"]) = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_26322_get_valid_step", "language": "ml", "prompt": "(**Checks if the current step is within boundaries and returns a corrected step.\n:param current_step: The current step to check.\n:param max_step: The maximum allowed step.\n:return: A corrected step between 1 and the maximum step.\n*)\nlet get_valid_step (current_step : int) (max_step : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_26322_get_valid_step.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_valid_step in\n  (assert ((candidate 4 1) = 1));\n  (assert ((candidate 1 5) = 1));\n  (assert ((candidate 0 3) = 1));\n  (assert ((candidate 2 3) = 2));\n  (assert ((candidate 5 1) = 1));\n  (assert ((candidate 11 10) = 10));\n  (assert ((candidate 6 5) = 5));\n  (assert ((candidate 1 2) = 1));\n  (assert ((candidate 7 2) = 2));\n  (assert ((candidate 5 3) = 3));\n  (assert ((candidate 1 3) = 1));\n  (assert ((candidate 1 1) = 1));\n  (assert ((candidate 4 2) = 2));\n  (assert ((candidate 5 5) = 5));\n  (assert ((candidate 7 3) = 3));\n  (assert ((candidate 6 1) = 1));\n  (assert ((candidate 2 2) = 2));\n  (assert ((candidate 7 1) = 1));\n  (assert ((candidate 5 10) = 5));\n  (assert ((candidate 3 3) = 3));\n  (assert ((candidate 6 3) = 3));\n  (assert ((candidate 4 3) = 3));\n  (assert ((candidate 5 2) = 2));\n  (assert ((candidate 100 10) = 10));\n  (assert ((candidate 2 1) = 1));\n  (assert ((candidate 3 2) = 2));\n  (assert ((candidate 0 10) = 1));\n  (assert ((candidate 6 2) = 2));\n  (assert ((candidate 0 5) = 1));\n  (assert ((candidate 3 1) = 1));\n  (assert ((candidate 3 5) = 3));\n  (assert ((candidate 0 2) = 1));\n  (assert ((candidate (~2) 5) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_263818_digit_count", "language": "ml", "prompt": "(**Returns the count of the digits (length) of the number\n*)\nlet digit_count (num : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_263818_digit_count.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = digit_count in\n  (assert ((candidate 0) = 1));\n  (assert ((candidate 1010) = 4));\n  (assert ((candidate 999) = 3));\n  (assert ((candidate 12) = 2));\n  (assert ((candidate 123456) = 6));\n  (assert ((candidate 25) = 2));\n  (assert ((candidate 1000) = 4));\n  (assert ((candidate 12345) = 5));\n  (assert ((candidate 12345678) = 8));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 100) = 3));\n  (assert ((candidate 100000000) = 9));\n  (assert ((candidate 123) = 3));\n  (assert ((candidate 2) = 1));\n  (assert ((candidate 1234) = 4));\n  (assert ((candidate 123456789) = 9));\n  (assert ((candidate 50) = 2));\n  (assert ((candidate 1234567) = 7));\n  (assert ((candidate 101) = 3));\n  (assert ((candidate 10000) = 5));\n  (assert ((candidate 10) = 2));\n  (assert ((candidate 1234567890) = 10));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_263912__split_kv", "language": "ml", "prompt": "(**Return dict for key=value.\n*)\nlet _split_kv (pair : string) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_263912__split_kv.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _split_kv in\n  (assert ((candidate \"foo=\") = [(\"foo\", \"\")]));\n  (assert ((candidate \"foo=bar=baz\") = [(\"foo\", \"bar=baz\")]));\n  (assert ((candidate \"a=b=c\") = [(\"a\", \"b=c\")]));\n  (assert ((candidate \"foo=bar\") = [(\"foo\", \"bar\")]));\n  (assert ((candidate \"a=b\") = [(\"a\", \"b\")]));\n  (assert ((candidate \"=bar\") = [(\"\", \"bar\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_264475_get_test", "language": "ml", "prompt": "(**get the file name of the test data\n*)\nlet get_test (date : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_264475_get_test.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_test in\n  (assert ((candidate \"2012010\") = \"2012010pred.csv\"));\n  (assert ((candidate \"20124010\") = \"20124010pred.csv\"));\n  (assert ((candidate \"2012010100\") = \"2012010100pred.csv\"));\n  (assert ((candidate \"201201020\") = \"201201020pred.csv\"));\n  (assert ((candidate ) = \"2013-05-27pred.csv\"));\n  (assert ((candidate ) = \"2013-05-29pred.csv\"));\n  (assert ((candidate ) = \"2013-05-28pred.csv\"));\n  (assert ((candidate \"20190103\") = \"20190103pred.csv\"));\n  (assert ((candidate \"20120103\") = \"20120103pred.csv\"));\n  (assert ((candidate \"20120132\") = \"20120132pred.csv\"));\n  (assert ((candidate \"20120140\") = \"20120140pred.csv\"));\n  (assert ((candidate \"201201010\") = \"201201010pred.csv\"));\n  (assert ((candidate \"20120100\") = \"20120100pred.csv\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_265233_parse_cookie_data", "language": "ml", "prompt": "(**Parse cookie data into key-value pairs\n*)\nlet parse_cookie_data (data : string) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_265233_parse_cookie_data.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_cookie_data in\n  (assert ((candidate \"CUSTOMER=WILE_E_COYOTE; PART_NUMBER=ROCKET_LAUNCHER_0001\") = [(\"CUSTOMER\", \"WILE_E_COYOTE\"); (\"PART_NUMBER\", \"ROCKET_LAUNCHER_0001\")]));\n  (assert ((candidate \"theme=light; sessionToken=<PASSWORD>; likes_python=true\") = [(\"theme\", \"light\"); (\"sessionToken\", \"<PASSWORD>\"); (\"likes_python\", \"true\")]));\n  (assert ((candidate \"\") = []));\n  (assert ((candidate \"a=b; c=d; e=f; g=h; i=j; k=l; m=n; o=p; q=r; s=t; u=v; w=x; y=z\") = [(\"a\", \"b\"); (\"c\", \"d\"); (\"e\", \"f\"); (\"g\", \"h\"); (\"i\", \"j\"); (\"k\", \"l\"); (\"m\", \"n\"); (\"o\", \"p\"); (\"q\", \"r\"); (\"s\", \"t\"); (\"u\", \"v\"); (\"w\", \"x\"); (\"y\", \"z\")]));\n  (assert ((candidate \"a=b; c=d; e=f\") = [(\"a\", \"b\"); (\"c\", \"d\"); (\"e\", \"f\")]));\n  (assert ((candidate \"a=b\") = [(\"a\", \"b\")]));\n  (assert ((candidate \"CUSTOMER=WILE_E_COYOTE; PART_NUMBER=ROCKET_LAUNCHER_0001; SHIPPING=FEDEX; CN=Ed\") = [(\"CUSTOMER\", \"WILE_E_COYOTE\"); (\"PART_NUMBER\", \"ROCKET_LAUNCHER_0001\"); (\"SHIPPING\", \"FEDEX\"); (\"CN\", \"Ed\")]));\n  (assert ((candidate \"k1=v1; k2=v2; k3=v3\") = [(\"k1\", \"v1\"); (\"k2\", \"v2\"); (\"k3\", \"v3\")]));\n  (assert ((candidate \"a=b; c=d\") = [(\"a\", \"b\"); (\"c\", \"d\")]));\n  (assert ((candidate \"cookie1=value1\") = [(\"cookie1\", \"value1\")]));\n  (assert ((candidate \"theme=light\") = [(\"theme\", \"light\")]));\n  (assert ((candidate \"k1=v1; k2=v2; k3=v3; k4=v4\") = [(\"k1\", \"v1\"); (\"k2\", \"v2\"); (\"k3\", \"v3\"); (\"k4\", \"v4\")]));\n  (assert ((candidate \"a=b; c=d; e=f; g=h; i=j; k=l; m=n; o=p; q=r; s=t; u=v; w=x; y=z\") = [(\"a\", \"b\"); (\"c\", \"d\"); (\"e\", \"f\"); (\"g\", \"h\"); (\"i\", \"j\"); (\"k\", \"l\"); (\"m\", \"n\"); (\"o\", \"p\"); (\"q\", \"r\"); (\"s\", \"t\"); (\"u\", \"v\"); (\"w\", \"x\"); (\"y\", \"z\")]));\n  (assert ((candidate \"cookie1=value1; cookie2=value2; cookie3=value3\") = [(\"cookie1\", \"value1\"); (\"cookie2\", \"value2\"); (\"cookie3\", \"value3\")]));\n  (assert ((candidate \"theme=light; likes_python=true\") = [(\"theme\", \"light\"); (\"likes_python\", \"true\")]));\n  (assert ((candidate \"theme=light; likes_python=true; sessionToken=<PASSWORD>\") = [(\"theme\", \"light\"); (\"likes_python\", \"true\"); (\"sessionToken\", \"<PASSWORD>\")]));\n  (assert ((candidate \"cookie1=value1; cookie2=value2\") = [(\"cookie1\", \"value1\"); (\"cookie2\", \"value2\")]));\n  (assert ((candidate \"likes_python=true\") = [(\"likes_python\", \"true\")]));\n  (assert ((candidate \"theme\") = []));\n  (assert ((candidate \"CUSTOMER=WILE_E_COYOTE\") = [(\"CUSTOMER\", \"WILE_E_COYOTE\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_265480_parseDbDummyFname", "language": "ml", "prompt": "(**given user data item which is dummy database name used for remesh and\nrestart purposes, pull out the base name (minus -s0002, -sXXXX, etc.)\nand return the base name and extension (extension in an empty string\nif appropriate)\n*)\nlet parseDbDummyFname (dbDummyFname : string) :  string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_265480_parseDbDummyFname.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parseDbDummyFname in\n  (assert ((candidate \"foo-s3\") = (\"foo\", \"-s3\")));\n  (assert ((candidate \"foo\") = (\"foo\", \"\")));\n  (assert ((candidate \"foo-s00003\") = (\"foo\", \"-s00003\")));\n  (assert ((candidate \"foo-s0002\") = (\"foo\", \"-s0002\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_265713_addContent", "language": "ml", "prompt": "(**Add html content together\n*)\nlet addContent (old_html : string) (raw_html : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_265713_addContent.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = addContent in\n  (assert ((candidate \"<h1>Test</h1>\" \"<p>Paragraph content.</p>\") = \"<h1>Test</h1><p>Paragraph content.</p>\"));\n  (assert ((candidate \"<div><span>Hello</span></div>\" \"<div><span>World</span></div>\") = \"<div><span>Hello</span></div><div><span>World</span></div>\"));\n  (assert ((candidate \"<p>The first paragraph.</p><p>The second paragraph.</p>\" \"<h3>This is a header.</h3>\") = \"<p>The first paragraph.</p><p>The second paragraph.</p><h3>This is a header.</h3>\"));\n  (assert ((candidate \"\" \"<div><span>World</span></div>\") = \"<div><span>World</span></div>\"));\n  (assert ((candidate \"<p>The first paragraph.</p>\" \"<p>The second paragraph.</p>\") = \"<p>The first paragraph.</p><p>The second paragraph.</p>\"));\n  (assert ((candidate \"<h1>Test</h1><h2>Subheading</h2>\" \"<h2>Another subheading</h2>\") = \"<h1>Test</h1><h2>Subheading</h2><h2>Another subheading</h2>\"));\n  (assert ((candidate \"<h3>This is a header.</h3>\" \"<p>This is a paragraph.</p>\") = \"<h3>This is a header.</h3><p>This is a paragraph.</p>\"));\n  (assert ((candidate \"<div><span>Hello</span></div>\" \"<div><span>World</span></div>\") = \"<div><span>Hello</span></div><div><span>World</span></div>\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_266228_scale_ticks_params", "language": "ml", "prompt": "(**Helper function for learning cureve plots.\nArgs:\n * tick_scale : available values are [linear, log2, log10]\n*)\nlet scale_ticks_params (tick_scale : string) :  int option * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_266228_scale_ticks_params.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = scale_ticks_params in\n  (assert ((candidate \"log2\") = (2, \"Log2 Scale\")));\n  (assert ((candidate \"log10\") = (10, \"Log10 Scale\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_266486_to_hex", "language": "ml", "prompt": "(**Given Image Id, return its hex value\n*)\nlet to_hex (image_id : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_266486_to_hex.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = to_hex in\n  (assert ((candidate 4095) = candidate 4095));\n  (assert ((candidate 16711680) = \"0000000000ff0000\"));\n  (assert ((candidate 4294967296) = \"0000000100000000\"));\n  (assert ((candidate 255) = \"00000000000000ff\"));\n  (assert ((candidate 15) = \"000000000000000f\"));\n  (assert ((candidate 255) = candidate 255));\n  (assert ((candidate 0) = \"0000000000000000\"));\n  (assert ((candidate 256) = \"0000000000000100\"));\n  (assert ((candidate 255) = \"00000000000000ff\"));\n  (assert ((candidate 256) = candidate 256));\n  (assert ((candidate 4294967295) = \"00000000ffffffff\"));\n  (assert ((candidate 16) = \"0000000000000010\"));\n  (assert ((candidate 65280) = \"000000000000ff00\"));\n  (assert ((candidate 18446744073709551615) = \"ffffffffffffffff\"));\n  (assert ((candidate 1) = \"0000000000000001\"));\n  (assert ((candidate 1) = \"0000000000000001\"));\n  (assert ((candidate 0) = \"0000000000000000\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_266488_create_local_cluster_name", "language": "ml", "prompt": "(**Create the local service-color cluster name.\n*)\nlet create_local_cluster_name (service : string) (color : string) (index : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_266488_create_local_cluster_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = create_local_cluster_name in\n  (assert ((candidate ) = \"local-foo-bar-0\"));\n  (assert ((candidate \"service\" \"color\" 1) = \"local-service-color-1\"));\n  (assert ((candidate \"service\" \"color\" \"1\") = \"local-service-color-1\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_266494_normalize_line", "language": "ml", "prompt": "(**Return line with fixed ending, if ending was present in line.\nOtherwise, does nothing.\n*)\nlet normalize_line (line : string) (newline : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_266494_normalize_line.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = normalize_line in\n  (assert ((candidate \"1234567890\n\" \"\") = \"1234567890\"));\n  (assert ((candidate \"1234567890\r\" \"\") = \"1234567890\"));\n  (assert ((candidate \"1234567890\r\n\" \"\n\") = \"1234567890\n\"));\n  (assert ((candidate \"1234567890\n\" \"\n\") = \"1234567890\n\"));\n  (assert ((candidate \"a\nb\n\" \"\n\") = \"a\nb\n\"));\n  (assert ((candidate \"1234567890\r\" \"\n\") = \"1234567890\n\"));\n  (assert ((candidate \"1234567890\n\" \"\r\n\") = \"1234567890\r\n\"));\n  (assert ((candidate \"1234567890\r\n\" \"\") = \"1234567890\"));\n  (assert ((candidate \"1234567890\" \"\") = \"1234567890\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_2664_fibonacci", "language": "ml", "prompt": "(**Get fibonacci sequence given it length.\nParameters\n----------\nlength : int\n * The length of the desired sequence.\nReturns\n-------\nsequence : list of int\n * The desired Fibonacci sequence\n*)\nlet fibonacci (length : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_2664_fibonacci.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = fibonacci in\n  (assert ((candidate 1) = [0]));\n  (assert ((candidate 7) = [0; 1; 1; 2; 3; 5; 8]));\n  (assert ((candidate 10) = [0; 1; 1; 2; 3; 5; 8; 13; 21; 34]));\n  (assert ((candidate 4) = [0; 1; 1; 2]));\n  (assert ((candidate 6) = [0; 1; 1; 2; 3; 5]));\n  (assert ((candidate 2) = [0; 1]));\n  (assert ((candidate 8) = [0; 1; 1; 2; 3; 5; 8; 13]));\n  (assert ((candidate 5) = [0; 1; 1; 2; 3]));\n  (assert ((candidate 3) = [0; 1; 1]));\n  (assert ((candidate 9) = [0; 1; 1; 2; 3; 5; 8; 13; 21]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_266766_re_remote_url", "language": "ml", "prompt": "(**Tests if a string is a \"remote\" URL, http, https, ftp.\n*)\nlet re_remote_url (s : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_266766_re_remote_url.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = re_remote_url in\n  (assert ((candidate \"https://foo.bar/baz\") = true));\n  (assert ((candidate \"https://foo.bar/baz#a?b=c\") = true));\n  (assert ((candidate \"https://foo.bar/baz?a=b\") = true));\n  (assert ((candidate \"http://foo.bar/baz\") = true));\n  (assert ((candidate \"ftp://foo.bar/baz\") = true));\n  (assert ((candidate \"https://foo.bar/baz\") = true));\n  (assert ((candidate \"https://foo.bar/baz#a\") = true));\n  (assert ((candidate \"foo.bar/baz\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_266834_sanitizeIOC", "language": "ml", "prompt": "(**Method to sanitize IOCs\n*)\nlet sanitizeIOC (ioc : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_266834_sanitizeIOC.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sanitizeIOC in\n  (assert ((candidate \"hxxp://example.com/path/to/file\") = \"http://example.com/path/to/file\"));\n  (assert ((candidate \"hxxp://test123.example.com\") = \"http://test123.example.com\"));\n  (assert ((candidate \"hxxp://example.com/test123\") = \"http://example.com/test123\"));\n  (assert ((candidate \"[.]abc.com\") = \".abc.com\"));\n  (assert ((candidate \"hxxp://google.com\") = \"http://google.com\"));\n  (assert ((candidate \"hxxp://example.com\") = \"http://example.com\"));\n  (assert ((candidate \"http://php.net/\") = \"http://php.net/\"));\n  (assert ((candidate \"hxxp://example.com\") = \"http://example.com\"));\n  (assert ((candidate \"hxxp://test.com\") = \"http://test.com\"));\n  (assert ((candidate \"[.]\") = \".\"));\n  (assert ((candidate \"\") = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_267008_get_sr", "language": "ml", "prompt": "(**\n*)\nlet get_sr (rij : int) (n : int) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_267008_get_sr.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_sr in\n  (assert ((candidate 1 100) = candidate 1 10000.0));\n  (assert ((candidate 1 100) = 0.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_267051_hook_with_extra_is_in_hooks", "language": "ml", "prompt": "(**Determine if the word given is the name of a valid hook, with extra data\nhanging off of it (e.g., `validhookname=extradata`).\n * hook_with_extra_is_in_hooks(\n * 'validhookname=stuff',\n * ['validhookname', 'other'])\n * #=> True\n * hook_with_extra_is_in_hooks(\n * 'invalidhookname=stuff',\n * ['validhookname', 'other'])\n * #=> False\n * hook_with_extra_is_in_hooks(\n * 'validhookname',\n * ['validhookname', 'other'])\n * #=> False\n*)\nlet hook_with_extra_is_in_hooks (word : string) (hooks : string list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_267051_hook_with_extra_is_in_hooks.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = hook_with_extra_is_in_hooks in\n  (assert ((candidate \"validhookname=other=stuff\" [\"validhookname\"; \"other\"; \"other=stuff\"]) = true));\n  (assert ((candidate \"validhookname=stuff\" [\"validhookname\"; \"other\"]) = true));\n  (assert ((candidate \"validhookname=other=\" [\"validhookname\"; \"other\"]) = true));\n  (assert ((candidate \"validhookname=other=stuff\" [\"validhookname\"; \"other\"; \"other=\"; \"other=stuff\"]) = true));\n  (assert ((candidate \"validhookname\" [\"validhookname\"; \"other\"]) = false));\n  (assert ((candidate \"invalidhookname=stuff\" [\"validhookname\"; \"other\"]) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_267064_format_time", "language": "ml", "prompt": "(**Function to format the time according to Mysql syntax\n*)\nlet format_time (time_string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_267064_format_time.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = format_time in\n  (assert ((candidate \"2020-04-26T00:00:01.000Z\") = \"2020-04-26 00:00:01\"));\n  (assert ((candidate \"2018-11-14T17:14:29.909Z\") = \"2018-11-14 17:14:29\"));\n  (assert ((candidate \"2008-01-01T00:00:01.000123456\") = \"2008-01-01 00:00:01\"));\n  (assert ((candidate \"2016-03-09T19:58:29.023000-05:00\") = \"2016-03-09 19:58:29\"));\n  (assert ((candidate \"1900-01-01T00:00:00.000Z\") = \"1900-01-01 00:00:00\"));\n  (assert ((candidate \"2008-01-01T00:00:00.000Z\") = \"2008-01-01 00:00:00\"));\n  (assert ((candidate \"2016-03-10T12:06:29.023000-05:00\") = \"2016-03-10 12:06:29\"));\n  (assert ((candidate \"2020-04-26T00:00:00.000Z\") = \"2020-04-26 00:00:00\"));\n  (assert ((candidate \"2020-04-25T23:59:59.909Z\") = \"2020-04-25 23:59:59\"));\n  (assert ((candidate \"2016-03-11T16:48:29.023000-05:00\") = \"2016-03-11 16:48:29\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_267473_subtract", "language": "ml", "prompt": "(**Subtract one 3-dimensional point from another\nParameters\n * coords1: coordinates of form [x,y,z]\n * coords2: coordinates of form [x,y,z]\nReturns\n * list:  List of coordinates equal to coords1 - coords2 (list)\n*)\nlet subtract (coords1 : int list) (coords2 : int list) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_267473_subtract.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = subtract in\n  (assert ((candidate [1; 2; 3] [4; 5; 6]) = [(~3); (~3); (~3)]));\n  (assert ((candidate [20; 30; 40] [10; 10; 10]) = [10; 20; 30]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_267485_check_none", "language": "ml", "prompt": "(**Return None if v is the empty string or the string 'None'.\n*)\nlet check_none (v : string option) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_267485_check_none.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = check_none in\n  (assert ((candidate Some(\"not none\")) = Some(\"not none\")));\n  (assert ((candidate Some(\"None\")) = Some(None)));\n  (assert ((candidate Some(\"abc\")) = Some(\"abc\")));\n  (assert ((candidate Some(\"\")) = Some(None)));\n  (assert ((candidate Some(None)) = Some(None)));\n  (assert ((candidate Some(\"some_string\")) = Some(\"some_string\")));\n  (assert ((candidate Some(\"foo\")) = Some(\"foo\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_268129_conflict", "language": "ml", "prompt": "(**Would putting two queens in (row1, col1) and (row2, col2) conflict?\n*)\nlet conflict (row1 : int) (col1 : int) (row2 : int) (col2 : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_268129_conflict.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = conflict in\n  (assert ((candidate 1 1 2 1) = true));\n  (assert ((candidate 0 0 2 3) = false));\n  (assert ((candidate 1 2 1 2) = true));\n  (assert ((candidate 0 0 8 8) = true));\n  (assert ((candidate 1 1 6 6) = true));\n  (assert ((candidate 0 0 7 7) = true));\n  (assert ((candidate 1 1 4 4) = true));\n  (assert ((candidate 0 0 9 9) = true));\n  (assert ((candidate 3 4 1 2) = true));\n  (assert ((candidate 0 0 5 5) = true));\n  (assert ((candidate 0 0 6 6) = true));\n  (assert ((candidate 0 0 0 1) = true));\n  (assert ((candidate 0 0 4 4) = true));\n  (assert ((candidate 0 0 2 1) = false));\n  (assert ((candidate 2 2 2 2) = true));\n  (assert ((candidate 0 0 3 3) = true));\n  (assert ((candidate 2 2 1 2) = true));\n  (assert ((candidate 2 1 1 1) = true));\n  (assert ((candidate 1 1 5 5) = true));\n  (assert ((candidate 1 1 3 3) = true));\n  (assert ((candidate 1 1 8 8) = true));\n  (assert ((candidate 2 2 1 1) = true));\n  (assert ((candidate 0 0 1 0) = true));\n  (assert ((candidate 1 1 2 2) = true));\n  (assert ((candidate 0 0 1 2) = false));\n  (assert ((candidate 0 1 2 2) = false));\n  (assert ((candidate 0 1 3 2) = false));\n  (assert ((candidate 1 2 2 1) = true));\n  (assert ((candidate 0 0 3 2) = false));\n  (assert ((candidate 1 1 1 1) = true));\n  (assert ((candidate 0 0 2 2) = true));\n  (assert ((candidate 1 1 7 7) = true));\n  (assert ((candidate 1 2 1 1) = true));\n  (assert ((candidate 2 3 3 2) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_268186_csv_addition", "language": "ml", "prompt": "(**Convert a csv string into ints and then add them.\n*)\nlet csv_addition (buf : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_268186_csv_addition.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = csv_addition in\n  (assert ((candidate \"1,2,3\") = 6));\n  (assert ((candidate \"5,10\") = 15));\n  (assert ((candidate \"1,2\") = 3));\n  (assert ((candidate \"2,1\") = 3));\n  (assert ((candidate \"1\") = 1));\n  (assert ((candidate \"1,2,3\") = 6));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_268347_is_before", "language": "ml", "prompt": "(**return True if ones turn is before twos,\nwhere one, two = [time_spent, last_move_number]\n*)\nlet is_before (one : int list) (two : int list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_268347_is_before.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_before in\n  (assert ((candidate [3; 3] [3; 3]) = false));\n  (assert ((candidate [1; 3] [1; 1]) = true));\n  (assert ((candidate [20; 200] [20; 200]) = false));\n  (assert ((candidate [20; 200] [10; 100]) = false));\n  (assert ((candidate [1; 2] [1; 2]) = false));\n  (assert ((candidate [3; 2] [3; 1]) = true));\n  (assert ((candidate [3; 1] [3; 2]) = false));\n  (assert ((candidate [10; 100] [10; 100]) = false));\n  (assert ((candidate [20; 200] [10; 200]) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_268388_words", "language": "ml", "prompt": "(**function that counts the number of word occurance in the input and return a dictionary\nthe dictionary contains the word as the key and the total number of occurance as the value\n*)\nlet words (word_statement : string) : (string, int) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_268388_words.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = words in\n  (assert ((candidate \"hello world  hello world\") = [(\"hello\", 2); (\"world\", 2)]));\n  (assert ((candidate \"Hello World!\") = [(\"Hello\", 1); (\"World!\", 1)]));\n  (assert ((candidate \"This is a test\") = [(\"This\", 1); (\"is\", 1); (\"a\", 1); (\"test\", 1)]));\n  (assert ((candidate \"hello world  hello world hello world\") = [(\"hello\", 3); (\"world\", 3)]));\n  (assert ((candidate \"hello world\") = [(\"hello\", 1); (\"world\", 1)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_268775_update_sum_squares", "language": "ml", "prompt": "(**Compute the update of sum of squares of differences from the current mean\nFrom the previously computed sum SUM_n-1, the new and old mean M_n and\nM_n-1 and the new measurement X_n, we compute an update value of the new\nsum of squares differences noted SUM_n using the formula:\nSUM_n = SUM_n-1 +(X_n - M_n)*(X_n - M_n-1)\nSee: https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance\nThis SUM can be use to compute the variance and sample variance:\nVn = SUM_n/n\nSn = SUM_n/(n+1)\nThis make the variance computation suffer less from floating point\ncomputation instabilities.\nParameters\n----------\nnew_data: int or decimal\n * The new measurement X_n\nold_sum_squares: int or decimal\n * The sum of squares SUM_n-1 computed previously\nnew_mean: int or decimal\n * The mean M_n computed on the current step n\nold_mean: int or decimal\n * The mean M_n-1 computed previously\nReturns\n-------\nfloat\n * The new sum of squares SUM_n updated with X_n, SUM_n-1, M_n and M_n-1\n*)\nlet update_sum_squares (new_data : int) (old_sum_squares : int) (new_mean : int) (old_mean : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_268775_update_sum_squares.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = update_sum_squares in\n  (assert ((candidate 5 4 2 2) = 13));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_270511_transform_boolean", "language": "ml", "prompt": "(**Transform boolean values that are blank into NULL so that they are not\nimported as empty strings.\n*)\nlet transform_boolean (value : string) : bool option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_270511_transform_boolean.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = transform_boolean in\n  (assert ((candidate \"F\") = Some(false)));\n  (assert ((candidate \"\") = Some(None)));\n  (assert ((candidate \"0   \") = Some(None)));\n  (assert ((candidate \"T\") = Some(true)));\n  (assert ((candidate \"True\") = Some(true)));\n  (assert ((candidate \"   \") = Some(None)));\n  (assert ((candidate \"0\") = Some(false)));\n  (assert ((candidate \"TRUE\") = Some(true)));\n  (assert ((candidate \"TRUE   \") = Some(None)));\n  (assert ((candidate \"1\") = Some(true)));\n  (assert ((candidate \"     \") = Some(None)));\n  (assert ((candidate \"f\") = Some(false)));\n  (assert ((candidate \"t\") = Some(true)));\n  (assert ((candidate \"FALSE   \") = Some(None)));\n  (assert ((candidate \"false\") = Some(false)));\n  (assert ((candidate \"False\") = Some(false)));\n  (assert ((candidate \" \") = Some(None)));\n  (assert ((candidate \"FALSE\") = Some(false)));\n  (assert ((candidate \"true\") = Some(true)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_271149_waiting_time", "language": "ml", "prompt": "(**Bus waiting time.\n*)\nlet waiting_time (timestamp : int) (bus : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_271149_waiting_time.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = waiting_time in\n  (assert ((candidate 0 1) = 1));\n  (assert ((candidate 100 15) = 5));\n  (assert ((candidate 10 5) = 5));\n  (assert ((candidate 11 5) = 4));\n  (assert ((candidate 939 59) = 5));\n  (assert ((candidate 10 3) = 2));\n  (assert ((candidate 14 5) = 1));\n  (assert ((candidate 12 5) = 3));\n  (assert ((candidate 13 5) = 2));\n  (assert ((candidate 11 3) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_271792_make_content_dict", "language": "ml", "prompt": "(**Method that takes an input string and returns a dict with characters as keys and occurrences as values\n*)\nlet make_content_dict (input_string : string) : (string, int) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_271792_make_content_dict.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = make_content_dict in\n  (assert ((candidate \"abc\") = [(\"a\", 1); (\"b\", 1); (\"c\", 1)]));\n  (assert ((candidate \"abcde\") = [(\"a\", 1); (\"b\", 1); (\"c\", 1); (\"d\", 1); (\"e\", 1)]));\n  (assert ((candidate \"abcb\") = [(\"a\", 1); (\"b\", 2); (\"c\", 1)]));\n  (assert ((candidate \"a\") = [(\"a\", 1)]));\n  (assert ((candidate \"aaaaaa\") = [(\"a\", 6)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_272497_count_saccades", "language": "ml", "prompt": "(**A Function that counts the number of distinct saccades\n:param saccades:    a list with values which indicate if the move from the previos is a saccade.\n:return:            a number of indicating the amount of different saccades\n*)\nlet count_saccades (saccades : int list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_272497_count_saccades.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = count_saccades in\n  (assert ((candidate []) = 0));\n  (assert ((candidate [1; 0; 0; 1; 1; 0; 0; 1; 0]) = 3));\n  (assert ((candidate [0; 0; 0; 0; 0; 0; 0; 0; 0; 0; 0]) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_272652_invert_injective", "language": "ml", "prompt": "(**invert a one-to-one map d\n*)\nlet invert_injective (d : (int, int) list) : (int, int) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_272652_invert_injective.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = invert_injective in\n  (assert ((candidate [(1, 1); (2, 2)]) = [(1, 1); (2, 2)]));\n  (assert ((candidate dict zip [1; 2] [2; 1]) = [(1, 2); (2, 1)]));\n  (assert ((candidate candidate [(1, 2); (2, 1); (3, 3)]) = [(1, 2); (2, 1); (3, 3)]));\n  (assert ((candidate [(1, 2); (2, 1)]) = [(1, 2); (2, 1)]));\n  (assert ((candidate [(1, 1); (2, 2)]) = [(1, 1); (2, 2)]));\n  (assert ((candidate []) = []));\n  (assert ((candidate [(1, 2); (3, 4); (5, 5); (6, 6)]) = [(2, 1); (4, 3); (5, 5); (6, 6)]));\n  (assert ((candidate [(1, 2); (3, 4); (5, 5)]) = [(2, 1); (4, 3); (5, 5)]));\n  (assert ((candidate [(1, 2); (3, 4); (5, 5); (6, 6); (7, 7)]) = [(2, 1); (4, 3); (5, 5); (6, 6); (7, 7)]));\n  (assert ((candidate dict ) = dict ));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_273233_write_group_author", "language": "ml", "prompt": "(**Given a string with a variable length of group author, insert into XML snippet, and return XML snippet\nNOTE: Group author does not require a primary key/unique ID\n:param group_authors: A string containing 1+ group authors, with multiple authors separated by || double pipes\n:return: XML snippet with group authors\n>>> write_group_author(\"Beauxbatons||Durmstrang\")   #doctest: +NORMALIZE_WHITESPACE\n'<v1:author>\n * <v1:role>author</v1:role>\n * <v1:groupAuthor>Beauxbatons</v1:groupAuthor>\n</v1:author>\n<v1:author>\n * <v1:role>author</v1:role>\n * <v1:groupAuthor>Durmstrang</v1:groupAuthor>\n</v1:author>'\n>>> write_group_author(\"Hogwarts School\")\n'<v1:author>\n * <v1:role>author</v1:role>\n * <v1:groupAuthor>Hogwarts School</v1:groupAuthor>\n * </v1:author>\n * '\n*)\nlet write_group_author (group_authors : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_273233_write_group_author.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = write_group_author in\n  (assert ((candidate \"Hogwarts School\") = \"<v1:author>\n            <v1:role>author</v1:role>\n            <v1:groupAuthor>Hogwarts School</v1:groupAuthor>\n        </v1:author>\n        \"));\n  (assert ((candidate \"Durmstrang\") = \"<v1:author>\n            <v1:role>author</v1:role>\n            <v1:groupAuthor>Durmstrang</v1:groupAuthor>\n        </v1:author>\n        \"));\n  (assert ((candidate \"Hogwarts School\") = \"<v1:author>\n            <v1:role>author</v1:role>\n            <v1:groupAuthor>Hogwarts School</v1:groupAuthor>\n        </v1:author>\n        \"));\n  (assert ((candidate \"Beauxbatons||Durmstrang\") = \"<v1:author>\n            <v1:role>author</v1:role>\n            <v1:groupAuthor>Beauxbatons</v1:groupAuthor>\n        </v1:author>\n        <v1:author>\n            <v1:role>author</v1:role>\n            <v1:groupAuthor>Durmstrang</v1:groupAuthor>\n        </v1:author>\n        \"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_273455_calc_order", "language": "ml", "prompt": "(**Returns the FP interferential order.\nParameters\n----------\nwavelength (float):\ngap_size (float):\nReturns\n-------\norder (float)\n*)\nlet calc_order (wavelength : float) (gap_size : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_273455_calc_order.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = calc_order in\n  (assert ((candidate 0.8 0.0) = 0.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_273577_calculate_polynomial", "language": "ml", "prompt": "(**Computes the value of the interpolating polynomial.\nParameters\n----------\ndegree : int\n * The degree of the interpolating polynomial.\nx_data : list\n * The values that were used when calculating the c of the interpolating polynomial.\ncoefficients : list\n * The coefficients of the interpolating polynomial, constant term first.\nx : int\n * The point at which the polynomial will be calculated\nReturns\n-------\nvalue : float\n * The value of the interpolating polynomial at point x.\n*)\nlet calculate_polynomial (degree : int) (x_data : int list) (coefficients : int list) (x : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_273577_calculate_polynomial.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = calculate_polynomial in\n  (assert ((candidate 3 [0; 1; 2] [1; 1; 1; 1; 1; 1] 0) = 1));\n  (assert ((candidate 3 [1; 3; 4] [0; 1; 2; 3; 4; 5] 1) = 0));\n  (assert ((candidate 0 [1; 2; 3] [1] 2) = 1));\n  (assert ((candidate 3 [0; 1; 2; 3] [1; 4; 1; 1] 0) = 1));\n  (assert ((candidate 3 [0; 1; 2] [1; 1; 1; 1; 1; 1] 1) = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_273749_norm_page_cnt", "language": "ml", "prompt": "(**Normalize a integer (page).\n* Ensure that it is greater than Zero, and is not None.\n * - If less than 1, or None, set it to 1\n* if max_number is None, then do not check for max_number\n * * if greater than max_number, reset it to be max_number\n*)\nlet norm_page_cnt (page : int option) (max_number : int option) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_273749_norm_page_cnt.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = norm_page_cnt in\n  (assert ((candidate Some(0) Some(200)) = 1));\n  (assert ((candidate Some(10) Some(100)) = 10));\n  (assert ((candidate Some(2) Some(200)) = 2));\n  (assert ((candidate Some(20) Some(10)) = 10));\n  (assert ((candidate Some(3) Some(3)) = 3));\n  (assert ((candidate Some(100) Some(100)) = 100));\n  (assert ((candidate Some(1)) = 1));\n  (assert ((candidate Some((~1)) Some(10)) = 1));\n  (assert ((candidate Some(1000) Some(100)) = 100));\n  (assert ((candidate Some(100)) = 100));\n  (assert ((candidate Some(1) Some(100)) = 1));\n  (assert ((candidate Some(100000) Some(100)) = 100));\n  (assert ((candidate Some((~5))) = 1));\n  (assert ((candidate Some((~3))) = 1));\n  (assert ((candidate Some(0) Some(3)) = 1));\n  (assert ((candidate Some(200) Some(200)) = 200));\n  (assert ((candidate Some(100000) Some(99)) = 99));\n  (assert ((candidate Some(0)) = 1));\n  (assert ((candidate Some(1) Some(10)) = 1));\n  (assert ((candidate Some(None) Some(10)) = 1));\n  (assert ((candidate Some(None)) = 1));\n  (assert ((candidate Some(101) Some(101)) = 101));\n  (assert ((candidate Some(1) Some(3)) = 1));\n  (assert ((candidate Some(None) Some(200)) = 1));\n  (assert ((candidate Some(101) Some(100)) = 100));\n  (assert ((candidate Some(1) Some(None)) = 1));\n  (assert ((candidate Some(1000) Some(99)) = 99));\n  (assert ((candidate Some((~3)) Some(3)) = 1));\n  (assert ((candidate Some((~1))) = 1));\n  (assert ((candidate Some(100) Some(10)) = 10));\n  (assert ((candidate Some((~100))) = 1));\n  (assert ((candidate Some(2) Some(3)) = 2));\n  (assert ((candidate Some(2)) = 2));\n  (assert ((candidate Some(10) Some(99)) = 10));\n  (assert ((candidate Some((~5)) Some(3)) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_273807_make_node_pairs_along_route", "language": "ml", "prompt": "(**Converts a list of nodes into a list of tuples for indexing edges along a route.\n*)\nlet make_node_pairs_along_route (route : string list) :  string * string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_273807_make_node_pairs_along_route.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = make_node_pairs_along_route in\n  (assert ((candidate list \"abcde\") = [(\"a\", \"b\"); (\"b\", \"c\"); (\"c\", \"d\"); (\"d\", \"e\")]));\n  (assert ((candidate list \"\") = []));\n  (assert ((candidate list \"abc\") = [(\"a\", \"b\"); (\"b\", \"c\")]));\n  (assert ((candidate list \"abcdef\") = [(\"a\", \"b\"); (\"b\", \"c\"); (\"c\", \"d\"); (\"d\", \"e\"); (\"e\", \"f\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_274415_str2bool", "language": "ml", "prompt": "(**Helper method to convert string to bool\n*)\nlet str2bool (val : string option) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_274415_str2bool.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = str2bool in\n  (assert ((candidate Some(\"False\")) = false));\n  (assert ((candidate Some(\"tRuE\")) = true));\n  (assert ((candidate Some(\"True\")) = true));\n  (assert ((candidate Some(\"FalSe\")) = false));\n  (assert ((candidate Some(\"oN\")) = true));\n  (assert ((candidate Some(\"y\")) = true));\n  (assert ((candidate Some(None)) = false));\n  (assert ((candidate Some(\"n\")) = false));\n  (assert ((candidate Some(\"yes\")) = true));\n  (assert ((candidate Some(\"oFf\")) = false));\n  (assert ((candidate Some(\"on\")) = true));\n  (assert ((candidate Some(\"false\")) = false));\n  (assert ((candidate Some(\"true\")) = true));\n  (assert ((candidate Some(\"off\")) = false));\n  (assert ((candidate Some(\"FALSE\")) = false));\n  (assert ((candidate Some(\"no\")) = false));\n  (assert ((candidate Some(\"1\")) = true));\n  (assert ((candidate Some(\"t\")) = true));\n  (assert ((candidate Some(\"f\")) = false));\n  (assert ((candidate Some(\"TRUE\")) = true));\n  (assert ((candidate Some(\"0\")) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_274793_pow", "language": "ml", "prompt": "(**Efficiently exponentiates an integer :math:`a^k (\\textrm{mod}\\ m)`.\nThe algorithm is more efficient than exponentiating first and then reducing modulo :math:`m`. This\nis the integer equivalent of :func:`galois.poly_pow`.\nNote\n----\nThis function is an alias of :func:`pow` in the standard library.\nParameters\n----------\nbase : int\n * The integer base :math:`a`.\nexp : int\n * The integer exponent :math:`k`.\nmod : int\n * The integer modulus :math:`m`.\nReturns\n-------\nint\n * The modular exponentiation :math:`a^k (\\textrm{mod}\\ m)`.\nExamples\n--------\n.. ipython:: python\n * galois.pow(3, 5, 7)\n * (3**5) % 7\n*)\nlet pow (base : int) (exp : int) (mod : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_274793_pow.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = pow in\n  (assert ((candidate 0 20 1) = 0));\n  (assert ((candidate 1 1 5) = 1));\n  (assert ((candidate 1 1 3) = 1));\n  (assert ((candidate 1 1 7) = 1));\n  (assert ((candidate 0 2 1) = 0));\n  (assert ((candidate 0 9 1) = 0));\n  (assert ((candidate 0 4 7) = 0));\n  (assert ((candidate 1 0 5) = 1));\n  (assert ((candidate 0 8 1) = 0));\n  (assert ((candidate 0 7 1) = 0));\n  (assert ((candidate 0 15 1) = 0));\n  (assert ((candidate 0 1 2) = 0));\n  (assert ((candidate 0 16 1) = 0));\n  (assert ((candidate 0 6 2) = 0));\n  (assert ((candidate 0 3 2) = 0));\n  (assert ((candidate 1 1 4) = 1));\n  (assert ((candidate 1 0 9) = 1));\n  (assert ((candidate 0 18 1) = 0));\n  (assert ((candidate 0 6 1) = 0));\n  (assert ((candidate 0 14 1) = 0));\n  (assert ((candidate 1 0 2) = 1));\n  (assert ((candidate 0 4 1) = 0));\n  (assert ((candidate 0 1 1) = 0));\n  (assert ((candidate 0 12 1) = 0));\n  (assert ((candidate 0 2 2) = 0));\n  (assert ((candidate 0 3 7) = 0));\n  (assert ((candidate 0 7 7) = 0));\n  (assert ((candidate 1 0 4) = 1));\n  (assert ((candidate 1 0 7) = 1));\n  (assert ((candidate 0 5 1) = 0));\n  (assert ((candidate 0 5 7) = 0));\n  (assert ((candidate 1 1 10) = 1));\n  (assert ((candidate 0 13 1) = 0));\n  (assert ((candidate 0 3 1) = 0));\n  (assert ((candidate 0 10 1) = 0));\n  (assert ((candidate 0 32 1) = 0));\n  (assert ((candidate 0 2 7) = 0));\n  (assert ((candidate 0 4 2) = 0));\n  (assert ((candidate 0 63 1) = 0));\n  (assert ((candidate 1 0 6) = 1));\n  (assert ((candidate 0 8 2) = 0));\n  (assert ((candidate 0 11 1) = 0));\n  (assert ((candidate 1 1 8) = 1));\n  (assert ((candidate 1 0 12) = 1));\n  (assert ((candidate 1 1 6) = 1));\n  (assert ((candidate 1 0 8) = 1));\n  (assert ((candidate 1 1 2) = 1));\n  (assert ((candidate 1 0 10) = 1));\n  (assert ((candidate 0 1 7) = 0));\n  (assert ((candidate 1 0 3) = 1));\n  (assert ((candidate 0 6 7) = 0));\n  (assert ((candidate 1 1 9) = 1));\n  (assert ((candidate 1 0 11) = 1));\n  (assert ((candidate 0 33 1) = 0));\n  (assert ((candidate 1 1 11) = 1));\n  (assert ((candidate 0 5 2) = 0));\n  (assert ((candidate 0 31 1) = 0));\n  (assert ((candidate 0 8 7) = 0));\n  (assert ((candidate 1 0 13) = 1));\n  (assert ((candidate 0 19 1) = 0));\n  (assert ((candidate 1 1 12) = 1));\n  (assert ((candidate 2 3 10) = 8));\n  (assert ((candidate 1 1 13) = 1));\n  (assert ((candidate 0 7 2) = 0));\n  (assert ((candidate 0 17 1) = 0));\n  (assert ((candidate 0 0 1) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_274795_column_index_to_integer", "language": "ml", "prompt": "(**Convert XLS-style column index into equivalent integer\nGiven a column index e.g. 'A', 'BZ' etc, converts it\nto the integer equivalent using zero-based counting\nsystem (so 'A' is equivalent to zero, 'B' to 1 etc).\n*)\nlet column_index_to_integer (col : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_274795_column_index_to_integer.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = column_index_to_integer in\n  (assert ((candidate \"A\") = 0));\n  (assert ((candidate \"AA\") = 26));\n  (assert ((candidate \"Z\") = 25));\n  (assert ((candidate \"BZ\") = 77));\n  (assert ((candidate \"AZ\") = 51));\n  (assert ((candidate \"BA\") = 52));\n  (assert ((candidate \"AB\") = 27));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_274982_NormalizeTargetPath", "language": "ml", "prompt": "(**Normalizes the target path.\nAdds leading slash if needed, strips ending slashes.\nArgs:\n * target: The target path (fusion db publish point).\nReturns:\n * Normalized target path.\n*)\nlet NormalizeTargetPath (target : string option) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_274982_NormalizeTargetPath.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = NormalizeTargetPath in\n  (assert ((candidate Some(\"  test  \")) = Some(\"/test\")));\n  (assert ((candidate Some(\"/test/\")) = Some(\"/test\")));\n  (assert ((candidate Some(\"  test\")) = Some(\"/test\")));\n  (assert ((candidate Some(None)) = Some(None)));\n  (assert ((candidate Some(\" \")) = Some(\"\")));\n  (assert ((candidate Some(\"test/\")) = Some(\"/test\")));\n  (assert ((candidate Some(\"test\")) = Some(\"/test\")));\n  (assert ((candidate Some(\"/foo\")) = Some(\"/foo\")));\n  (assert ((candidate Some(\"/foo/\")) = Some(\"/foo\")));\n  (assert ((candidate Some(\"foo\")) = Some(\"/foo\")));\n  (assert ((candidate Some(\"\")) = Some(\"\")));\n  (assert ((candidate Some(\"/test\")) = Some(\"/test\")));\n  (assert ((candidate Some(\"foo/\")) = Some(\"/foo\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_276253_sub_dir_source", "language": "ml", "prompt": "(**build out the source portion of the directory structure.\n:param dict d: A dictionary holding BIDS terms for path-building\n*)\nlet sub_dir_source (d : (string, string) list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_276253_sub_dir_source.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sub_dir_source in\n  (assert ((candidate [(\"sub\", \"02\"); (\"hem\", \"L\"); (\"samp\", \"1\"); (\"prob\", \"1\")]) = \"sub-02_hem-L_samp-1_prob-1\"));\n  (assert ((candidate [(\"sub\", \"01\"); (\"hem\", \"R\"); (\"samp\", \"1\"); (\"prob\", \"1\")]) = \"sub-01_hem-R_samp-1_prob-1\"));\n  (assert ((candidate [(\"sub\", \"01\"); (\"hem\", \"L\"); (\"samp\", \"2\"); (\"prob\", \"2\")]) = \"sub-01_hem-L_samp-2_prob-2\"));\n  (assert ((candidate [(\"sub\", \"01\"); (\"hem\", \"R\"); (\"samp\", \"2\"); (\"prob\", \"2\")]) = \"sub-01_hem-R_samp-2_prob-2\"));\n  (assert ((candidate [(\"sub\", \"02\"); (\"hem\", \"L\"); (\"samp\", \"2\"); (\"prob\", \"2\")]) = \"sub-02_hem-L_samp-2_prob-2\"));\n  (assert ((candidate [(\"sub\", \"01\"); (\"hem\", \"L\"); (\"samp\", \"1\"); (\"prob\", \"1\")]) = \"sub-01_hem-L_samp-1_prob-1\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_276589_make_key", "language": "ml", "prompt": "(**function to combine two coordinates into a valid dict key\n*)\nlet make_key (x : int) (y : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_276589_make_key.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = make_key in\n  (assert ((candidate 10 10) = \"10, 10\"));\n  (assert ((candidate 1 1) = \"1, 1\"));\n  (assert ((candidate 1 0) = \"1, 0\"));\n  (assert ((candidate 11 12) = \"11, 12\"));\n  (assert ((candidate 3 2) = \"3, 2\"));\n  (assert ((candidate 1 3) = \"1, 3\"));\n  (assert ((candidate (~3) 3) = \"-3, 3\"));\n  (assert ((candidate 50 50) = \"50, 50\"));\n  (assert ((candidate 0 1) = \"0, 1\"));\n  (assert ((candidate (~1) (~1)) = \"-1, -1\"));\n  (assert ((candidate 0 0) = \"0, 0\"));\n  (assert ((candidate 3 3) = \"3, 3\"));\n  (assert ((candidate 1 3) = \"1, 3\"));\n  (assert ((candidate 10 10) = \"10, 10\"));\n  (assert ((candidate (~20) 20) = \"-20, 20\"));\n  (assert ((candidate 1 2) = \"1, 2\"));\n  (assert ((candidate 10 1) = \"10, 1\"));\n  (assert ((candidate 3 4) = \"3, 4\"));\n  (assert ((candidate 0 0) = \"0, 0\"));\n  (assert ((candidate 2 3) = \"2, 3\"));\n  (assert ((candidate (~1) (~1)) = \"-1, -1\"));\n  (assert ((candidate 1 0) = \"1, 0\"));\n  (assert ((candidate 1 0) = \"1, 0\"));\n  (assert ((candidate (~10000) 10000) = \"-10000, 10000\"));\n  (assert ((candidate (~10000) (~10000)) = \"-10000, -10000\"));\n  (assert ((candidate (~3) (~3)) = \"-3, -3\"));\n  (assert ((candidate 1 1) = \"1, 1\"));\n  (assert ((candidate 2 1) = \"2, 1\"));\n  (assert ((candidate 0 1) = \"0, 1\"));\n  (assert ((candidate 10000 (~10000)) = \"10000, -10000\"));\n  (assert ((candidate 0 0) = \"0, 0\"));\n  (assert ((candidate 2 1) = \"2, 1\"));\n  (assert ((candidate 3 (~3)) = \"3, -3\"));\n  (assert ((candidate 3 4) = \"3, 4\"));\n  (assert ((candidate 10000 10000) = \"10000, 10000\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_276945_floatToString5", "language": "ml", "prompt": "(**Return float f as a string with five decimal places without trailing zeros\nand dot.\nIntended for places where five decimals are needed, e.g. transformations.\n*)\nlet floatToString5 (f : float) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_276945_floatToString5.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = floatToString5 in\n  (assert ((candidate 3.141592653589793) = \"3.14159\"));\n  (assert ((candidate 3.141592653589793) = \"3.14159\"));\n  (assert ((candidate -1.12345) = \"-1.12345\"));\n  (assert ((candidate 0.000123456789) = \"0.00012\"));\n  (assert ((candidate 12.3456789) = \"12.34568\"));\n  (assert ((candidate 1.23456789) = \"1.23457\"));\n  (assert ((candidate -1.2345e-05) = \"-0.00001\"));\n  (assert ((candidate 123.45678) = \"123.45678\"));\n  (assert ((candidate 1.12345) = \"1.12345\"));\n  (assert ((candidate -1.12345) = \"-1.12345\"));\n  (assert ((candidate 1.2345e-05) = \"0.00001\"));\n  (assert ((candidate 1.2345e-05) = \"0.00001\"));\n  (assert ((candidate 1.2345e-05) = \"0.00001\"));\n  (assert ((candidate 0.0) = \"0\"));\n  (assert ((candidate 0.00012345678900001) = \"0.00012\"));\n  (assert ((candidate 1.12345) = \"1.12345\"));\n  (assert ((candidate 123.456789) = \"123.45679\"));\n  (assert ((candidate 1.0) = \"1\"));\n  (assert ((candidate -1.2345e-05) = \"-0.00001\"));\n  (assert ((candidate -1.0) = \"-1\"));\n  (assert ((candidate -1.12345) = \"-1.12345\"));\n  (assert ((candidate (~1).0) = \"-1\"));\n  (assert ((candidate 1.0) = \"1\"));\n  (assert ((candidate 0.0) = \"0\"));\n  (assert ((candidate 1.12345) = \"1.12345\"));\n  (assert ((candidate 0.0) = \"0\"));\n  (assert ((candidate 1234.56789) = \"1234.56789\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_277039_urlify", "language": "ml", "prompt": "(**Question 3: Write a method to replace all spaces in a string with '%20'. You may\nassume that the string has suffcient space at the end to hold the additional characters,\nand that you are given the \"true\" length of the string.\nIn python I can use the replace method. string.replace(' ', '%20')\n*)\nlet urlify (string : string option) (length : int) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_277039_urlify.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = urlify in\n  (assert ((candidate Some(\"abc\") 10) = Some(\"abc\")));\n  (assert ((candidate Some(\"Hello, world\") 4) = Some(\"Hello\")));\n  (assert ((candidate Some(\"a bc\") 4) = Some(\"a%20bc\")));\n  (assert ((candidate Some(\"abc  def\") 10) = Some(\"abc%20def\")));\n  (assert ((candidate Some(\"hello\") 5) = Some(\"hello\")));\n  (assert ((candidate Some(\"abc def ghi\") 1000) = Some(\"abc%20def%20ghi\")));\n  (assert ((candidate Some(None) 0) = Some(None)));\n  (assert ((candidate Some(\"abc def ghi\") 10) = Some(\"abc%20def%20ghi\")));\n  (assert ((candidate Some(\"a b\") 2) = Some(\"a%20b\")));\n  (assert ((candidate Some(\"abcdefg\") 6) = Some(\"abcdefg\")));\n  (assert ((candidate Some(\"a\") 1) = Some(\"a\")));\n  (assert ((candidate Some(\"a bc\") 5) = Some(\"a%20bc\")));\n  (assert ((candidate Some(\"abcdefg \") 8) = Some(\"abcdefg%20\")));\n  (assert ((candidate Some(\"a b\") 4) = Some(\"a%20b\")));\n  (assert ((candidate Some(\"abcdefg\") 0) = Some(None)));\n  (assert ((candidate Some(\"abc defg \") 8) = Some(\"abc%20defg%20\")));\n  (assert ((candidate Some(\"a b\") 3) = Some(\"a%20b\")));\n  (assert ((candidate Some(\" \") 1) = Some(\"%20\")));\n  (assert ((candidate Some(\"hello world\") 11) = Some(\"hello%20world\")));\n  (assert ((candidate Some(\"hello world\") 13) = Some(\"hello%20world\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_277349_pingpong", "language": "ml", "prompt": "(**Return the nth element of the ping-pong sequence.\n>>> pingpong(8)\n8\n>>> pingpong(10)\n6\n>>> pingpong(15)\n1\n>>> pingpong(21)\n-1\n>>> pingpong(22)\n-2\n>>> pingpong(30)\n-2\n>>> pingpong(68)\n0\n>>> pingpong(69)\n-1\n>>> pingpong(80)\n0\n>>> pingpong(81)\n1\n>>> pingpong(82)\n0\n>>> pingpong(100)\n-6\n>>> from construct_check import check\n>>> # ban assignment statements\n>>> check(HW_SOURCE_FILE, 'pingpong',\n...       ['Assign', 'AnnAssign', 'AugAssign', 'NamedExpr'])\nTrue\n*)\nlet pingpong (n : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_277349_pingpong.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = pingpong in\n  (assert ((candidate 100) = (~6)));\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 81) = 1));\n  (assert ((candidate 14) = 2));\n  (assert ((candidate 19) = 1));\n  (assert ((candidate 69) = (~1)));\n  (assert ((candidate 21) = (~1)));\n  (assert ((candidate 22) = (~2)));\n  (assert ((candidate 10) = 6));\n  (assert ((candidate 17) = 1));\n  (assert ((candidate 80) = 0));\n  (assert ((candidate 15) = 1));\n  (assert ((candidate 18) = 2));\n  (assert ((candidate 82) = 0));\n  (assert ((candidate 68) = 0));\n  (assert ((candidate 8) = 8));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 30) = (~2)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_277573_covers_alphabet", "language": "ml", "prompt": "(**This function takes a string and returns if the given string contains all the alphabets\n*)\nlet covers_alphabet (sentence : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_277573_covers_alphabet.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = covers_alphabet in\n  (assert ((candidate \"Hello World\") = false));\n  (assert ((candidate \"1234567890\") = false));\n  (assert ((candidate \"This is a sentence. This is another sentence.\") = false));\n  (assert ((candidate \"abc def\") = false));\n  (assert ((candidate \"abcdefghijklmnopqrstuvwxyz\") = true));\n  (assert ((candidate \"The quick brown fox jumps over the lazy dog.\") = true));\n  (assert ((candidate \"abc def ghi\") = false));\n  (assert ((candidate \"This is a sentence.\") = false));\n  (assert ((candidate \"abc def ghi jkl\") = false));\n  (assert ((candidate \"The narwhal bacons at midnight.\") = false));\n  (assert ((candidate \"abc de\") = false));\n  (assert ((candidate \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\") = true));\n  (assert ((candidate \"The quick brown fox jumps over the lazy eog.\") = false));\n  (assert ((candidate \"a\") = false));\n  (assert ((candidate \"abc\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_278103_check_parens", "language": "ml", "prompt": "(**check_parens takes a string and:\nreturns 0 if the number of parentheses is balanced and matched.\nreturns 1 if more left parentheses than right.\nreturns -1 if string has broken (unmatched) parentheses.\n*)\nlet check_parens (str : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_278103_check_parens.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = check_parens in\n  (assert ((candidate \"())(())\") = (~1)));\n  (assert ((candidate \"((()))\") = 0));\n  (assert ((candidate \"(()()))\") = (~1)));\n  (assert ((candidate \"()\") = 0));\n  (assert ((candidate \")\") = (~1)));\n  (assert ((candidate \"(()()())\") = 0));\n  (assert ((candidate \"(()\") = 1));\n  (assert ((candidate \"((())\") = 1));\n  (assert ((candidate \"()()()()\") = 0));\n  (assert ((candidate \"((()())(())())\") = 0));\n  (assert ((candidate \")(\") = (~1)));\n  (assert ((candidate \")()(\") = (~1)));\n  (assert ((candidate \"())\") = (~1)));\n  (assert ((candidate \"()()())\") = (~1)));\n  (assert ((candidate \"()()()\") = 0));\n  (assert ((candidate \"())\") = (~1)));\n  (assert ((candidate \"(\") = 1));\n  (assert ((candidate \"(())\") = 0));\n  (assert ((candidate \"\") = 0));\n  (assert ((candidate \"(()())\") = 0));\n  (assert ((candidate \")()(())\") = (~1)));\n  (assert ((candidate \"(()))\") = (~1)));\n  (assert ((candidate \"()\") = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_278605_convert_mwh_bbtu", "language": "ml", "prompt": "(**converts energy in MWh to energy in billion btu.\n:param value:           value in megawatt-hours of energy\n:type value:            float\n:return:                value in bbtu\n*)\nlet convert_mwh_bbtu (value : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_278605_convert_mwh_bbtu.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = convert_mwh_bbtu in\n  (assert ((candidate 0.0) = 0.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_279010_prepare_url", "language": "ml", "prompt": "(**Prepare the URL\n*)\nlet prepare_url (valip : string) (valch : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_279010_prepare_url.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = prepare_url in\n  (assert ((candidate \"1.1.1.1\" \"ch1\") = \"http://1.1.1.1/api/v100/dali_devices.ssi?action=get&ch=ch1\"));\n  (assert ((candidate \"1\" \"1\") = \"http://1/api/v100/dali_devices.ssi?action=get&ch=1\"));\n  (assert ((candidate \"1.2.3.4\" \"1\") = \"http://1.2.3.4/api/v100/dali_devices.ssi?action=get&ch=1\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_279176_check_port", "language": "ml", "prompt": "(**return port value\n*)\nlet check_port (port : string option) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_279176_check_port.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = check_port in\n  (assert ((candidate Some(\"None\")) = \"-1\"));\n  (assert ((candidate Some(\"12345\")) = \"12345\"));\n  (assert ((candidate Some(\"1234\")) = \"1234\"));\n  (assert ((candidate Some(\"None\")) = \"-1\"));\n  (assert ((candidate Some(\"1\")) = \"1\"));\n  (assert ((candidate Some(None)) = \"-1\"));\n  (assert ((candidate Some(\"-1\")) = \"-1\"));\n  (assert ((candidate Some(\"0\")) = \"0\"));\n  (assert ((candidate Some(\"8080\")) = \"8080\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_279297_get_best_indexes", "language": "ml", "prompt": "(**Gets the indices of the n-best logits from a list.\n*)\nlet get_best_indexes (logits : float list) (n_best_size : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_279297_get_best_indexes.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_best_indexes in\n  (assert ((candidate [0.1; 0.2] 0) = []));\n  (assert ((candidate [0.1; 0.3; 0.2] 2) = [1; 2]));\n  (assert ((candidate [.0] 1) = []));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_279313_next_question_id", "language": "ml", "prompt": "(**Incrementally fetches the next question ID based on the base passage ID.\nSome questions have the same ID in the RACE dataset (if they are\nin the same file). We try to make those unique by appending an\nindex before the id. @q_ids is used to keep the counter for each\nquestion ID - it is essentially a map from the file name to the count.\nIt will generate ids as follows:\n1) 1-middle1548.txt\n2) 2-middle1548.txt\n3) 3-middle1548.txt\n4) ...\nUse this function to get incremental question IDs.\n*)\nlet next_question_id (next_ids : (string, int) list) (id_base : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_279313_next_question_id.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = next_question_id in\n  (assert ((candidate [(\"0-1-1548.txt\", 1); (\"0-2-1548.txt\", 1)] \"0-2-1548.txt\") = \"1-0-2-1548.txt\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_279421_hex_to_long", "language": "ml", "prompt": "(**Convert hex to long.\n*)\nlet hex_to_long (hex_string : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_279421_hex_to_long.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = hex_to_long in\n  (assert ((candidate \"0x4141\") = 16705));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_279964_enable_option", "language": "ml", "prompt": "(**Converts a boolean option to a CMake ON/OFF switch\n*)\nlet enable_option (value : bool) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_279964_enable_option.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = enable_option in\n  (assert ((candidate true) = \"ON\"));\n  (assert ((candidate false) = \"OFF\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_280016__get_by_path_kw", "language": "ml", "prompt": "(**Used by :meth:`get_by_path` to create the required kwargs for\nNode.objects.get(). Might be a starting point for more sophisticated\nqueries including paths. Example::\n * ifi = Node.objects.get(**Node._get_by_path_kw(['uio', 'ifi']))\n:param pathlist: A list of node-names, like ``['uio', 'ifi']``.\n*)\nlet _get_by_path_kw (pathlist : string list) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_280016__get_by_path_kw.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _get_by_path_kw in\n  (assert ((candidate [\"uio\"; \"ifi\"; \"studentservices\"; \"exams\"]) = [(\"short_name\", \"exams\"); (\"parentnode__short_name\", \"studentservices\"); (\"parentnode__parentnode__short_name\", \"ifi\"); (\"parentnode__parentnode__parentnode__short_name\", \"uio\")]));\n  (assert ((candidate [\"uio\"; \"ifi\"; \"studentservices\"; \"exams\"; \"test\"; \"blabla\"]) = [(\"short_name\", \"blabla\"); (\"parentnode__short_name\", \"test\"); (\"parentnode__parentnode__short_name\", \"exams\"); (\"parentnode__parentnode__parentnode__short_name\", \"studentservices\"); (\"parentnode__parentnode__parentnode__parentnode__short_name\", \"ifi\"); (\"parentnode__parentnode__parentnode__parentnode__parentnode__short_name\", \"uio\")]));\n  (assert ((candidate [\"uio\"; \"ifi\"; \"studentservices\"; \"exams\"; \"test\"]) = [(\"short_name\", \"test\"); (\"parentnode__short_name\", \"exams\"); (\"parentnode__parentnode__short_name\", \"studentservices\"); (\"parentnode__parentnode__parentnode__short_name\", \"ifi\"); (\"parentnode__parentnode__parentnode__parentnode__short_name\", \"uio\")]));\n  (assert ((candidate [\"uio\"; \"ifi\"; \"ifiok\"; \"test\"]) = [(\"short_name\", \"test\"); (\"parentnode__short_name\", \"ifiok\"); (\"parentnode__parentnode__short_name\", \"ifi\"); (\"parentnode__parentnode__parentnode__short_name\", \"uio\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_280991_str_to_dict", "language": "ml", "prompt": "(**Input example: \"{0: 214, 1: 224}\".\n*)\nlet str_to_dict (string : string) : (int, int) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_280991_str_to_dict.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = str_to_dict in\n  (assert ((candidate \"{0: 1, 1: 2}\") = [(0, 1); (1, 2)]));\n  (assert ((candidate \"{0: 214, 1: 224, 2: 253, 3: 254, 4: 255}\") = [(0, 214); (1, 224); (2, 253); (3, 254); (4, 255)]));\n  (assert ((candidate \"{0: 214, 1: 224}\") = [(0, 214); (1, 224)]));\n  (assert ((candidate \"{0: 1, 1: 2, 2: 3}\") = [(0, 1); (1, 2); (2, 3)]));\n  (assert ((candidate \"{0: 1}\") = [(0, 1)]));\n  (assert ((candidate \"{0: 1, 1: 2, 2: 3, 3: 4}\") = [(0, 1); (1, 2); (2, 3); (3, 4)]));\n  (assert ((candidate \"{1: 1, 2: 2}\") = [(1, 1); (2, 2)]));\n  (assert ((candidate \"{0: 214, 2: 253, 4: 255}\") = [(0, 214); (2, 253); (4, 255)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_282648_get_keywords_prefix", "language": "ml", "prompt": "(**Return the correct keyword's file prefix given the model\n:param model: name of the model\n:return: keyword's file prefix\n*)\nlet get_keywords_prefix (model : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_282648_get_keywords_prefix.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_keywords_prefix in\n  (assert ((candidate \"cyclerank\") = \"keywords_cyclerank\"));\n  (assert ((candidate \"pagerank_pageviews\") = \"keywords_pagerank\"));\n  (assert ((candidate \"pagerank\") = \"keywords_pagerank\"));\n  (assert ((candidate \"cyclerank_pageviews\") = \"keywords_cyclerank\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_282664_make_anagram_1", "language": "ml", "prompt": "(**Using a dictionary: O(n_a+n_b) time\n*)\nlet make_anagram_1 (a : string list) (b : string list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_282664_make_anagram_1.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = make_anagram_1 in\n  (assert ((candidate list \"codewars\" list \"code\") = 4));\n  (assert ((candidate list \"abcd\" list \"abcd\") = 0));\n  (assert ((candidate list \"code\" list \"code\") = 0));\n  (assert ((candidate list \"codewars\" list \"codewars\") = 0));\n  (assert ((candidate list \"aab\" list \"aab\") = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_282812_extract_bits", "language": "ml", "prompt": "(**Extract bits which is turend on (1).\nArgs:\n * bit (int): Bit to check.\n * bit_dict (dict): Correspondance dict of bit and status.\nReturn:\n * valid_bit (:obj:`list` of :obj:`str`): List of bit which is\n * turned on (1).\nExample:\n * >>> sample_dict = {\n * ...     \"S1\": 0b001,\n * ...     \"S2\": 0b010,\n * ...     \"S3\": 0b100,\n * ... }\n * >>> extract_bits(0b101, sample_dict)\n * [\"S1\", \"S3\"]\n*)\nlet extract_bits (bit : int) (bit_dict : (string, int) list) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_282812_extract_bits.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = extract_bits in\n  (assert ((candidate 7 [(\"S1\", 1); (\"S2\", 2); (\"S3\", 4)]) = [\"S1\"; \"S2\"; \"S3\"]));\n  (assert ((candidate 6 [(\"S1\", 1); (\"S2\", 2); (\"S3\", 4)]) = [\"S2\"; \"S3\"]));\n  (assert ((candidate 7 [(\"S1\", 1); (\"S2\", 2); (\"S3\", 4)]) = [\"S1\"; \"S2\"; \"S3\"]));\n  (assert ((candidate 6 [(\"S1\", 1); (\"S2\", 2); (\"S3\", 4)]) = [\"S2\"; \"S3\"]));\n  (assert ((candidate 3 [(\"S1\", 1); (\"S2\", 2); (\"S3\", 4)]) = [\"S1\"; \"S2\"]));\n  (assert ((candidate 2 [(\"S1\", 1); (\"S2\", 2); (\"S3\", 4)]) = [\"S2\"]));\n  (assert ((candidate 0 [(\"S1\", 1); (\"S2\", 2); (\"S3\", 4)]) = []));\n  (assert ((candidate 1 [(\"S1\", 1); (\"S2\", 2); (\"S3\", 4)]) = [\"S1\"]));\n  (assert ((candidate 4 [(\"S1\", 1); (\"S2\", 2); (\"S3\", 4)]) = [\"S3\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_283724__string_tolist", "language": "ml", "prompt": "(**Convert the authorization comma separated string to list\n*)\nlet _string_tolist (s : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_283724__string_tolist.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _string_tolist in\n  (assert ((candidate \"abc\ndef\") = [\"abc\ndef\"]));\n  (assert ((candidate \"foo,bar\") = [\"foo\"; \"bar\"]));\n  (assert ((candidate \" abc \") = [\"abc\"]));\n  (assert ((candidate \" a, b, c \") = [\"a\"; \"b\"; \"c\"]));\n  (assert ((candidate \"foo\") = [\"foo\"]));\n  (assert ((candidate \"a\") = [\"a\"]));\n  (assert ((candidate \" abc,def \") = [\"abc\"; \"def\"]));\n  (assert ((candidate \"a,b,c\") = [\"a\"; \"b\"; \"c\"]));\n  (assert ((candidate \" a,b,c \") = [\"a\"; \"b\"; \"c\"]));\n  (assert ((candidate \"a, b, c, d\") = [\"a\"; \"b\"; \"c\"; \"d\"]));\n  (assert ((candidate \",a,b,\") = [\"a\"; \"b\"]));\n  (assert ((candidate \"a b c\") = [\"a b c\"]));\n  (assert ((candidate \"a,,b\") = [\"a\"; \"b\"]));\n  (assert ((candidate \"a,\") = [\"a\"]));\n  (assert ((candidate \",a\") = [\"a\"]));\n  (assert ((candidate \"abc,def\") = [\"abc\"; \"def\"]));\n  (assert ((candidate \"\") = []));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_283945_to_bin", "language": "ml", "prompt": "(**convert number to binary\n*)\nlet to_bin (n : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_283945_to_bin.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = to_bin in\n  (assert ((candidate 2) = \"10\"));\n  (assert ((candidate 2) = \"10\"));\n  (assert ((candidate 6) = \"110\"));\n  (assert ((candidate 0) = \"0\"));\n  (assert ((candidate 3) = \"11\"));\n  (assert ((candidate 23) = \"10111\"));\n  (assert ((candidate 1) = \"1\"));\n  (assert ((candidate 5) = \"101\"));\n  (assert ((candidate 0) = \"0\"));\n  (assert ((candidate 42) = \"101010\"));\n  (assert ((candidate 1) = \"1\"));\n  (assert ((candidate 4) = \"100\"));\n  (assert ((candidate 42) = \"101010\"));\n  (assert ((candidate 3) = \"11\"));\n  (assert ((candidate 11) = \"1011\"));\n  (assert ((candidate 7) = \"111\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_284769_make_stat", "language": "ml", "prompt": "(**Called by loanpy.sanity.postprocess2.\nCalculates  statistics from optimum, max nr of guesses and length     of input data frame.\n:param opt_fp: The optimal false positive rate as a fraction of the     maximal false positive rate, i.e. last (=highest) element of     list passed to param <guesslist> in loanpy.sanity.eval_all.\n:type opt_fp: float\n:param opt_tp: The optimal true positive rate as a fraction of the     total number of input words for predictions, i.e. length of data frame.\n:type opt_tp: float\n:param max_fp: The maximal false positive rate is the     highest number of possible guesses, i.e. the last element of the list     passed to param <guesslist> in loanpy.sanity.eval_all.\n:type max_fp: int | float\n:param len_df: The total number of input words for predictions.\n:type len_df: int\n:returns: The optimal setting for param <howmany> in     loanpy.adrc.Adrc.adapt or loanpy.adrc.Adrc.reconstruct.\n:rtype: tuple of int, str, str\n:Example:\n>>> from loanpy.sanity import make_stat\n>>> make_stat(opt_fp=0.099, opt_tp=0.6, max_fp=1000, len_df=10)\n(100, \"6/10\", \"60%\")\n*)\nlet make_stat (opt_fp : float) (opt_tp : float) (max_fp : int) (len_df : int) :  int * string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_284769_make_stat.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = make_stat in\n  (assert ((candidate 0.099 0.9 1000 10) = (100, \"9/10\", \"90%\")));\n  (assert ((candidate 0.099 0.4 1000 10) = (100, \"4/10\", \"40%\")));\n  (assert ((candidate 0.099 0.0 1000 10) = (100, \"0/10\", \"0%\")));\n  (assert ((candidate 0.099 0.3 1000 10) = (100, \"3/10\", \"30%\")));\n  (assert ((candidate 0.099 0.8 1000 10) = (100, \"8/10\", \"80%\")));\n  (assert ((candidate 0.099 0.2 1000 10) = (100, \"2/10\", \"20%\")));\n  (assert ((candidate 0.099 0.7 1000 10) = (100, \"7/10\", \"70%\")));\n  (assert ((candidate 0.099 0.1 1000 10) = (100, \"1/10\", \"10%\")));\n  (assert ((candidate 0.099 0.6 1000 10) = (100, \"6/10\", \"60%\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_285975_get_alphas", "language": "ml", "prompt": "(**Return a tuple of the first non-digit characters of a revision (which\nmay be empty) and the remaining characters.\n*)\nlet get_alphas (revision_str : string) :  string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_285975_get_alphas.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_alphas in\n  (assert ((candidate \"b\") = (\"b\", \"\")));\n  (assert ((candidate \"a\") = (\"a\", \"\")));\n  (assert ((candidate \"None\") = (\"None\", \"\")));\n  (assert ((candidate \"abc\") = (\"abc\", \"\")));\n  (assert ((candidate \"abc-\") = (\"abc-\", \"\")));\n  (assert ((candidate \"\") = (\"\", \"\")));\n  (assert ((candidate \"34\") = (\"\", \"34\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_28615_split_instruction", "language": "ml", "prompt": "(**Split an assembly instruction into seperate parts.\n:param ins: The assembly line.\n:return: A list with the parts of the instruction.\n*)\nlet split_instruction (ins : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_28615_split_instruction.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = split_instruction in\n  (assert ((candidate \"addi $t1, $t2, 3\") = [\"addi\"; \"$t1\"; \"$t2\"; \"3\"]));\n  (assert ((candidate \"addi $10, $1, 1000,\") = [\"addi\"; \"$10\"; \"$1\"; \"1000\"]));\n  (assert ((candidate \" addi 3, 5, 7  \") = [\"addi\"; \"3\"; \"5\"; \"7\"]));\n  (assert ((candidate \"add    $t0,  $t1, $t2\") = [\"add\"; \"$t0\"; \"$t1\"; \"$t2\"]));\n  (assert ((candidate \"bltz $t1, 100000\") = [\"bltz\"; \"$t1\"; \"100000\"]));\n  (assert ((candidate \" slti $t7, $t8, -20\") = [\"slti\"; \"$t7\"; \"$t8\"; \"-20\"]));\n  (assert ((candidate \"add.d $f4, $f5, $f2\") = [\"add.d\"; \"$f4\"; \"$f5\"; \"$f2\"]));\n  (assert ((candidate \"lw $t1, 0($t2)\") = [\"lw\"; \"$t1\"; \"0($t2)\"]));\n  (assert ((candidate \"addi $10, $1, 1000, 123\") = [\"addi\"; \"$10\"; \"$1\"; \"1000\"; \"123\"]));\n  (assert ((candidate \"b 100000\") = [\"b\"; \"100000\"]));\n  (assert ((candidate \"bnez $t1, 100000\") = [\"bnez\"; \"$t1\"; \"100000\"]));\n  (assert ((candidate \"add $t0, $t1, $t2\") = [\"add\"; \"$t0\"; \"$t1\"; \"$t2\"]));\n  (assert ((candidate \" bltz  10, 12  \") = [\"bltz\"; \"10\"; \"12\"]));\n  (assert ((candidate \" jal  10  \") = [\"jal\"; \"10\"]));\n  (assert ((candidate \" jal  10, 12  \") = [\"jal\"; \"10\"; \"12\"]));\n  (assert ((candidate \"addi $10, $1, 1000, 123, 5\") = [\"addi\"; \"$10\"; \"$1\"; \"1000\"; \"123\"; \"5\"]));\n  (assert ((candidate \"add $t1, $t2, $t3\") = [\"add\"; \"$t1\"; \"$t2\"; \"$t3\"]));\n  (assert ((candidate \" move $s1, $s2\") = [\"move\"; \"$s1\"; \"$s2\"]));\n  (assert ((candidate \"   sub   $t3, $t4\") = [\"sub\"; \"$t3\"; \"$t4\"]));\n  (assert ((candidate \" move $t5, $t6\") = [\"move\"; \"$t5\"; \"$t6\"]));\n  (assert ((candidate \"add $t1, $t2, 0x10\") = [\"add\"; \"$t1\"; \"$t2\"; \"0x10\"]));\n  (assert ((candidate \"addi $10, $1, 1000\") = [\"addi\"; \"$10\"; \"$1\"; \"1000\"]));\n  (assert ((candidate \"add $t1, $t2\") = [\"add\"; \"$t1\"; \"$t2\"]));\n  (assert ((candidate \"add $t1, $t2, $zero\") = [\"add\"; \"$t1\"; \"$t2\"; \"$zero\"]));\n  (assert ((candidate \"j 0x10\") = [\"j\"; \"0x10\"]));\n  (assert ((candidate \"addi $10, $1, 1000, \") = [\"addi\"; \"$10\"; \"$1\"; \"1000\"]));\n  (assert ((candidate \"sw $t1, 0($t2)\") = [\"sw\"; \"$t1\"; \"0($t2)\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_287521_normalize_alef_maksura_hsb", "language": "ml", "prompt": "(**Normalize all occurences of Alef Maksura characters to a Yeh character\nin a Habash-Soudi-Buckwalter encoded string.\nArgs:\n * s (:obj:`str`): The string to be normalized.\nReturns:\n * :obj:`str`: The normalized string.\n*)\nlet normalize_alef_maksura_hsb (s : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_287521_normalize_alef_maksura_hsb.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = normalize_alef_maksura_hsb in\n  (assert ((candidate \"z\u00fd\") = \"zy\"));\n  (assert ((candidate \"z\u00fd\u00fd\") = \"zyy\"));\n  (assert ((candidate \"x\u00fd\u00fd\u00fd\") = \"xyyy\"));\n  (assert ((candidate \"\u00fd\") = \"y\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_287855_binary_combinations", "language": "ml", "prompt": "(**Returns all possible combinations of length n binary numbers as strings\n*)\nlet binary_combinations (n : int) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_287855_binary_combinations.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = binary_combinations in\n  (assert ((candidate 3) = [\"000\"; \"001\"; \"010\"; \"011\"; \"100\"; \"101\"; \"110\"; \"111\"]));\n  (assert ((candidate 2) = [\"00\"; \"01\"; \"10\"; \"11\"]));\n  (assert ((candidate 1) = [\"0\"; \"1\"]));\n  (assert ((candidate 1) = [\"0\"; \"1\"]));\n  (assert ((candidate 2) = [\"00\"; \"01\"; \"10\"; \"11\"]));\n  (assert ((candidate 3) = [\"000\"; \"001\"; \"010\"; \"011\"; \"100\"; \"101\"; \"110\"; \"111\"]));\n  (assert ((candidate 0) = [\"0\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_291839_format_hostmaster", "language": "ml", "prompt": "(**The DNS encodes the <local-part> as a single label, and encodes the\n<mail-domain> as a domain name.  The single label from the <local-part>\nis prefaced to the domain name from <mail-domain> to form the domain\nname corresponding to the mailbox.  Thus the mailbox HOSTMASTER@SRI-\nNIC.ARPA is mapped into the domain name HOSTMASTER.SRI-NIC.ARPA.  If the\n<local-part> contains dots or other special characters, its\nrepresentation in a master file will require the use of backslash\nquoting to ensure that the domain name is properly encoded.  For\nexample, the mailbox Action.domains@ISI.EDU would be represented as\nAction\\.domains.ISI.EDU.\nhttp://www.ietf.org/rfc/rfc1035.txt\n*)\nlet format_hostmaster (hostmaster : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_291839_format_hostmaster.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = format_hostmaster in\n  (assert ((candidate \"foo@bar\") = \"foo.bar.\"));\n  (assert ((candidate \"hostmaster@example.com\") = \"hostmaster.example.com.\"));\n  (assert ((candidate \"HOSTMASTER@SRI-NIC.ARPA\") = \"HOSTMASTER.SRI-NIC.ARPA.\"));\n  (assert ((candidate \"mail-hostmaster@example.com\") = \"mail-hostmaster.example.com.\"));\n  (assert ((candidate \"mailhostmaster@example.com\") = \"mailhostmaster.example.com.\"));\n  (assert ((candidate \"foo@bar.baz\") = \"foo.bar.baz.\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_291887_is_templated_secret", "language": "ml", "prompt": "(**Filters secrets that are shaped like: {secret}, <secret>, or ${secret}.\n*)\nlet is_templated_secret (secret : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_291887_is_templated_secret.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_templated_secret in\n  (assert ((candidate \"password}\") = false));\n  (assert ((candidate \"pass${\") = false));\n  (assert ((candidate \"${password}\") = true));\n  (assert ((candidate \"password\") = false));\n  (assert ((candidate \"<<PASSWORD>>\") = true));\n  (assert ((candidate \"{password\") = false));\n  (assert ((candidate \"}password\") = false));\n  (assert ((candidate \"pass<PASSWORD>\") = false));\n  (assert ((candidate \"${password\") = false));\n  (assert ((candidate \"$password}\") = false));\n  (assert ((candidate \"password{\") = false));\n  (assert ((candidate \"{password}\") = true));\n  (assert ((candidate \"pass$\") = false));\n  (assert ((candidate \"pass}\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_291988_virtual_temperature", "language": "ml", "prompt": "(**Convert temperature and mixing ratio to virtual temperature.\nArgs:\n * temperature_k: The temperature or potential temperature in units K.\n * mixing_ratio_kg_kg: The mixing ratio in units kg kg-1.\nReturns:\n * The virtual temperature in units K.\n*)\nlet virtual_temperature (temperature_k : float) (mixing_ratio_g_kg : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_291988_virtual_temperature.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = virtual_temperature in\n  (assert ((candidate 290.0 0.0) = 290.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_292668_rearrange_unsorted", "language": "ml", "prompt": "(**Solution to exercise C-4.20.\nGiven an unsorted sequence, S, of integers and an integer k, describe a\nrecursive algorithm for rearranging the elements in S so that all elements\nless than or equal to k come before any elements larger than k. What is\nthe running time of your algorithm on a sequence of n values?\n--------------------------------------------------------------------------\nSolution:\n--------------------------------------------------------------------------\nThe algorithm terminates when the start index equals the stop index.  That\nrequires n recursive calls.  Each recursive call will worst case swap two\nvalues in the list.  Replacing a value in a list is O(1) according to the\ntext (table 5.4), and so this algorithm is O(n).\n*)\nlet rearrange_unsorted (nums : int list) (k : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_292668_rearrange_unsorted.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = rearrange_unsorted in\n  (assert ((candidate [3; 1; 4; 2; 5] 6) = [3; 1; 4; 2; 5]));\n  (assert ((candidate [3; 1; 4; 2; 5] 4) = [3; 1; 4; 2; 5]));\n  (assert ((candidate [9; 8; 7; 6; 5; 4; 3; 2; 1; 0] 4) = [0; 1; 2; 3; 4; 5; 6; 7; 8; 9]));\n  (assert ((candidate list range 10 9) = list range 10));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_292769_get_board_columns", "language": "ml", "prompt": "(**Get board columns\n>>> get_board_columns(['***21**', '412453*', '423145*', '*543215',     '*35214*', '*41532*', '*2*1***'])\n['*125342', '*23451*', '2413251', '154213*', '*35142*']\n*)\nlet get_board_columns (board : string list) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_292769_get_board_columns.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_board_columns in\n  (assert ((candidate [\"***21**\"; \"412453*\"; \"423145*\"; \"*543215\"; \"*35214*\"; \"*41532*\"; \"*2*1***\"]) = [\"*125342\"; \"*23451*\"; \"2413251\"; \"154213*\"; \"*35142*\"]));\n  (assert ((candidate [\"***21**\"; \"412453*\"; \"423145*\"; \"*543215\"; \"*35214*\"; \"*41532*\"; \"*2*1***\"]) = [\"*125342\"; \"*23451*\"; \"2413251\"; \"154213*\"; \"*35142*\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_292929_edit_distance_dp", "language": "ml", "prompt": "(**Compute the Edit Distance between 2 strings.\n*)\nlet edit_distance_dp (str1 : string) (str2 : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_292929_edit_distance_dp.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = edit_distance_dp in\n  (assert ((candidate \"A\" \"B\") = 1));\n  (assert ((candidate \"gumbo\" \"gambol\") = 2));\n  (assert ((candidate \"Saturday\" \"Sunday\") = 3));\n  (assert ((candidate \"TCA\" \"TAAA\") = 2));\n  (assert ((candidate \"kitten\" \"kitten\") = 0));\n  (assert ((candidate \"GAGATTCTACGGA\" \"GAGCATTCTACGAG\") = 3));\n  (assert ((candidate \"\" \"\") = 0));\n  (assert ((candidate \"A\" \"A\") = 0));\n  (assert ((candidate \"GAGATTCTACGGA\" \"GAGATTCTACGGC\") = 1));\n  (assert ((candidate \"test\" \"text\") = 1));\n  (assert ((candidate \"GAGATTCTACGGA\" \"GAGCATTCTACGGC\") = 2));\n  (assert ((candidate \"foo\" \"bar\") = 3));\n  (assert ((candidate \"TCA\" \"TCAA\") = 1));\n  (assert ((candidate \"book\" \"back\") = 2));\n  (assert ((candidate \"GAGATTCTACGGA\" \"GAGATTCTACGGC\") = 1));\n  (assert ((candidate \"kitten\" \"sitting\") = 3));\n  (assert ((candidate \"A\" \"AG\") = 1));\n  (assert ((candidate \"AG\" \"A\") = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_293032_greatest_common_divisor_with_coefficient", "language": "ml", "prompt": "(**calc the greatest common divisor between a and b, and find two numbers x, y to fit formula:\na * x + b * y = the greatest common divisor.\n:param a: (int)\n:param b: (int)\n:return: (tuple) the greatest common divisor, x, y\n*)\nlet greatest_common_divisor_with_coefficient (a : int) (b : int) :  int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_293032_greatest_common_divisor_with_coefficient.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = greatest_common_divisor_with_coefficient in\n  (assert ((candidate 0 1) = (1, 0, 1)));\n  (assert ((candidate 4 2) = (2, 0, 1)));\n  (assert ((candidate 12 14) = (2, (~1), 1)));\n  (assert ((candidate 1 2) = (1, 1, 0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_294243_is_hidden", "language": "ml", "prompt": "(**Get boolean if a file (or a directory) is hidden or not, with linux based OS.\nRaises\n------\nTypeError\n * If the input data is not a string.\nParameters\n----------\nfile_name : String\n * Target file (required)\nReturns\n-------\nBoolean\n * True if a file is hidden, False elsewhere\n*)\nlet is_hidden (file_name : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_294243_is_hidden.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_hidden in\n  (assert ((candidate \"/.git/info/refs/remotes/origin/master/\") = false));\n  (assert ((candidate \"/.git/info/refs/remotes/origin\") = false));\n  (assert ((candidate \"a.\") = false));\n  (assert ((candidate \"/.git/info/refs/remotes/origin/\") = false));\n  (assert ((candidate \"/.git\") = false));\n  (assert ((candidate \"/.git/info/refs/heads/\") = false));\n  (assert ((candidate \"/.git/info/refs/remotes\") = false));\n  (assert ((candidate \"/..\") = false));\n  (assert ((candidate \"/.git/info/refs/remotes/\") = false));\n  (assert ((candidate \".\") = true));\n  (assert ((candidate \"/.git/info/\") = false));\n  (assert ((candidate \".test.py.swp\") = true));\n  (assert ((candidate \"test.py.swp\") = false));\n  (assert ((candidate \"/.\") = false));\n  (assert ((candidate \"/.git/HEAD\") = false));\n  (assert ((candidate \"/.git/info/refs\") = false));\n  (assert ((candidate \"/.git/\") = false));\n  (assert ((candidate \"/.git/info\") = false));\n  (assert ((candidate \"/.git/info/refs/heads/master/\") = false));\n  (assert ((candidate \" \") = false));\n  (assert ((candidate \"a.a.a\") = false));\n  (assert ((candidate \"..test.py\") = true));\n  (assert ((candidate \"/.git/info/refs/remotes/origin/master\") = false));\n  (assert ((candidate \"/.git/HEAD/master\") = false));\n  (assert ((candidate \".a\") = true));\n  (assert ((candidate \"/.git/info/refs/heads/master\") = false));\n  (assert ((candidate \"a.a.\") = false));\n  (assert ((candidate \"/.git/info/refs/\") = false));\n  (assert ((candidate \"a\") = false));\n  (assert ((candidate \"/.git/HEAD/\") = false));\n  (assert ((candidate \"Test.py\") = false));\n  (assert ((candidate \"\") = false));\n  (assert ((candidate \"a.a\") = false));\n  (assert ((candidate \"test.py\") = false));\n  (assert ((candidate \".test.py\") = true));\n  (assert ((candidate \"/.git/info/refs/heads\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_294425_signExp", "language": "ml", "prompt": "(**Opens the brackets, depending upon the Sign\n*)\nlet signExp (expression : string) (sign : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_294425_signExp.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = signExp in\n  (assert ((candidate \"-2 - 2 + 1\" \"+\") = \"-2 - 2 + 1\"));\n  (assert ((candidate \"a-b-c\" \"-\") = \"-a+b+c\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_295062_prime", "language": "ml", "prompt": "(**To Check If n Is Prime Or Not\n*)\nlet prime (n : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_295062_prime.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = prime in\n  (assert ((candidate 2) = 1));\n  (assert ((candidate 25) = 0));\n  (assert ((candidate 9) = 0));\n  (assert ((candidate 30) = 0));\n  (assert ((candidate 13) = 1));\n  (assert ((candidate 32) = 0));\n  (assert ((candidate 35) = 0));\n  (assert ((candidate 22) = 0));\n  (assert ((candidate 19) = 1));\n  (assert ((candidate 3) = 1));\n  (assert ((candidate 10000) = 0));\n  (assert ((candidate 200) = 0));\n  (assert ((candidate 17) = 1));\n  (assert ((candidate 4) = 0));\n  (assert ((candidate 12) = 0));\n  (assert ((candidate 28) = 0));\n  (assert ((candidate 24) = 0));\n  (assert ((candidate 5) = 1));\n  (assert ((candidate 18) = 0));\n  (assert ((candidate 34) = 0));\n  (assert ((candidate 36) = 0));\n  (assert ((candidate 37) = 1));\n  (assert ((candidate 10) = 0));\n  (assert ((candidate 7) = 1));\n  (assert ((candidate 40) = 0));\n  (assert ((candidate 8) = 0));\n  (assert ((candidate 11) = 1));\n  (assert ((candidate 6) = 0));\n  (assert ((candidate 31) = 1));\n  (assert ((candidate 16) = 0));\n  (assert ((candidate 38) = 0));\n  (assert ((candidate 341) = 0));\n  (assert ((candidate 15) = 0));\n  (assert ((candidate 14) = 0));\n  (assert ((candidate 26) = 0));\n  (assert ((candidate 4000) = 0));\n  (assert ((candidate 23) = 1));\n  (assert ((candidate 1000) = 0));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 29) = 1));\n  (assert ((candidate 199) = 1));\n  (assert ((candidate 2000) = 0));\n  (assert ((candidate 21) = 0));\n  (assert ((candidate 20) = 0));\n  (assert ((candidate 400) = 0));\n  (assert ((candidate 41) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_295233_char_count", "language": "ml", "prompt": "(**Function to return total character counts in a text,\npass the following parameter `ignore_spaces = False`\nto ignore whitespaces\n*)\nlet char_count (text : string) (ignore_spaces : bool) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_295233_char_count.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = char_count in\n  (assert ((candidate \"hello\") = 5));\n  (assert ((candidate \"abc\") = 3));\n  (assert ((candidate \"a \") = 1));\n  (assert ((candidate \"abc   \") = 3));\n  (assert ((candidate \"123 45\") = 5));\n  (assert ((candidate \"Hello world \" false) = 12));\n  (assert ((candidate \"hi 123\") = 5));\n  (assert ((candidate \"hi\") = 2));\n  (assert ((candidate \"123 456 7890\") = 10));\n  (assert ((candidate \"abc d e \") = 5));\n  (assert ((candidate \"Hello\") = 5));\n  (assert ((candidate \"12345\") = 5));\n  (assert ((candidate \"1234567890\") = 10));\n  (assert ((candidate \"abc d e\") = 5));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_295406_code_snippet", "language": "ml", "prompt": "(**Change a string-typed code snippet into Markdown-style code fence.\n# Argument\n * snippet: `str`. A code snippet.\n# Return\n * `str`: Markdown-style code fence.\n*)\nlet code_snippet (snippet : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_295406_code_snippet.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = code_snippet in\n  (assert ((candidate \"\") = \"```python\n\n```\"));\n  (assert ((candidate \"snippet\") = \"```python\nsnippet\n```\"));\n  (assert ((candidate \"2_snippet\") = \"```python\n2_snippet\n```\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_295538_unchunk", "language": "ml", "prompt": "(**Remove spaces in string.\n*)\nlet unchunk (string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_295538_unchunk.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = unchunk in\n  (assert ((candidate \"abc  def\") = \"abcdef\"));\n  (assert ((candidate \"Wonderful\") = \"Wonderful\"));\n  (assert ((candidate \"I   am   a    cat!\") = \"Iamacat!\"));\n  (assert ((candidate \"abc def\") = \"abcdef\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_295921_day_to_iso", "language": "ml", "prompt": "(**day to iso format\n*)\nlet day_to_iso (day : (string, int) list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_295921_day_to_iso.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = day_to_iso in\n  (assert ((candidate [(\"year\", 2020); (\"month\", 1); (\"day\", 1)]) = \"2020-1-1\"));\n  (assert ((candidate [(\"year\", 2020); (\"month\", 1); (\"day\", 31)]) = \"2020-1-31\"));\n  (assert ((candidate [(\"year\", 2016); (\"month\", 12); (\"day\", 31)]) = \"2016-12-31\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_296478__Indentation", "language": "ml", "prompt": "(**Returns the indentation string.\n*)\nlet _Indentation (indentation_level : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_296478__Indentation.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _Indentation in\n  (assert ((candidate (~2)) = \"\"));\n  (assert ((candidate 1) = \"    \"));\n  (assert ((candidate 6) = \"                        \"));\n  (assert ((candidate 8) = \"                                \"));\n  (assert ((candidate 10) = \"                                        \"));\n  (assert ((candidate 9) = \"                                    \"));\n  (assert ((candidate 4) = \"                \"));\n  (assert ((candidate 1) = candidate 1));\n  (assert ((candidate 7) = \"                            \"));\n  (assert ((candidate (~1)) = \"\"));\n  (assert ((candidate 2) = \"        \"));\n  (assert ((candidate 5) = \"                    \"));\n  (assert ((candidate 0) = \"\"));\n  (assert ((candidate (~4)) = \"\"));\n  (assert ((candidate 3) = \"            \"));\n  (assert ((candidate (~3)) = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_296667_lower_case", "language": "ml", "prompt": "(**Simple function to convert text to lowercase\nUsed in pipeline as workaround\n*)\nlet lower_case (text : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_296667_lower_case.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = lower_case in\n  (assert ((candidate \"lower case\") = \"lower case\"));\n  (assert ((candidate \"This is another sentence\") = \"this is another sentence\"));\n  (assert ((candidate \"THIS IS A MIXED CASE STRING\") = \"this is a mixed case string\"));\n  (assert ((candidate \"This is a sentence\") = \"this is a sentence\"));\n  (assert ((candidate \"A new sentence.\") = \"a new sentence.\"));\n  (assert ((candidate \"ANOTHER STRING\") = \"another string\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_29671_get_node_flow", "language": "ml", "prompt": "(**Returns the sum of the flow into minus the sum of the flow out from the\nnode.\nIn a maximum flow network, this function returns 0 for all nodes except\nfor the source (wich returns -max_flow) and drain (wich returns max_flow).\n*)\nlet get_node_flow (flow_net : int list list) (node : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_29671_get_node_flow.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_node_flow in\n  (assert ((candidate [[0; 1; 1; 0]; [0; 0; 1; 0]; [0; 0; 0; 1]; [0; 0; 0; 0]] 2) = 1));\n  (assert ((candidate [[0; 0; 0; 0; 0; 0]; [0; 0; 0; 1; 0; 0]; [0; 0; 1; 1; 1; 0]; [0; 0; 1; 0; 1; 0]; [0; 0; 0; 0; 0; 0]; [0; 0; 0; 0; 0; 0]] 0) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_296818_multistep_lr", "language": "ml", "prompt": "(**MultiStep learning rate\n*)\nlet multistep_lr (lr : float) (milestones : int list) (gamma : float) (iters : int) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_296818_multistep_lr.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = multistep_lr in\n  (assert ((candidate 0.5 [2; 3] 0.1 1) = 0.5));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_298293_url_to_repo_org", "language": "ml", "prompt": "(**Extract owner and repository from GitHub url.\n*)\nlet url_to_repo_org (url : string) :  string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_298293_url_to_repo_org.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = url_to_repo_org in\n  (assert ((candidate \"https://github.com/lsst-sqre/templatekit\") = (\"lsst-sqre\", \"templatekit\")));\n  (assert ((candidate \"https://github.com/lsst-sqre/nbreport\") = (\"lsst-sqre\", \"nbreport\")));\n  (assert ((candidate \"https://github.com/pytorch/pytorch\") = (\"pytorch\", \"pytorch\")));\n  (assert ((candidate \"https://github.com/pytorch/vision\") = (\"pytorch\", \"vision\")));\n  (assert ((candidate \"https://github.com/pytorch/vision/\") = (\"pytorch\", \"vision\")));\n  (assert ((candidate \"https://github.com/fairlearn/fairlearn/blob/master/README.md\") = (\"fairlearn\", \"fairlearn\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_298370_timestamp_seconds", "language": "ml", "prompt": "(**Returns seconds float from value generated by `timestamp`.\n*)\nlet timestamp_seconds (ts : int) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_298370_timestamp_seconds.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = timestamp_seconds in\n  (assert ((candidate 0) = 0.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_298424_is_sane_slack_webhook", "language": "ml", "prompt": "(**Really basic sanity checking.\n*)\nlet is_sane_slack_webhook (url : string option) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_298424_is_sane_slack_webhook.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_sane_slack_webhook in\n  (assert ((candidate Some(\"\")) = false));\n  (assert ((candidate Some(\"   \")) = false));\n  (assert ((candidate Some(\"http://hooks.slack.com\")) = false));\n  (assert ((candidate Some(\"https://hooks.slack/A/B/C\")) = false));\n  (assert ((candidate Some(None)) = false));\n  (assert ((candidate Some(\"https://hooks.com/A/B/C\")) = false));\n  (assert ((candidate Some(\"not a url\")) = false));\n  (assert ((candidate Some(\"https://hooks.slack.com/services/ABC123/ABC123/ABC123\")) = true));\n  (assert ((candidate Some(\"https://hooks.com/A/B/C/D\")) = false));\n  (assert ((candidate Some(\"https://hooks.slack.com/services/A/B/C\")) = true));\n  (assert ((candidate Some(\"https://hooks.slack/A/B/C/D\")) = false));\n  (assert ((candidate Some(\"https://hooks.slack.com/services/ABC123/DEF456/XYZ789\")) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_299447_any", "language": "ml", "prompt": "(**Return True if at least one element is set to True.\nThis function does not support predicates explicitely,\nbut this behaviour can be simulated easily using\nlist comprehension.\n>>> any( [False, False, False] )\nFalse\n>>> any( [False, True, False] )\nTrue\n>>> any( [ x % 2 == 1 for x in [2, 6, 8] ] )\nFalse\n>>> any( [ x % 2 == 1 for x in [2, 6, 7] ] )\nTrue\nNOTE: Starting from Python 2.5 this a built-in.\n*)\nlet any (iterable : bool list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_299447_any.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = any in\n  (assert ((candidate [false; false; false]) = false));\n  (assert ((candidate [false; true; false]) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_299708_get_command_from_argument", "language": "ml", "prompt": "(**extract command from the command line arguments\n*)\nlet get_command_from_argument (argv : string list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_299708_get_command_from_argument.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_command_from_argument in\n  (assert ((candidate [\"foo\"; \"bar\"]) = \"bar\"));\n  (assert ((candidate [\"prog\"; \"subcommand\"]) = \"subcommand\"));\n  (assert ((candidate [\"prog\"; \"subcommand\"; \"argument\"]) = \"subcommand\"));\n  (assert ((candidate [\"/path/to/cli\"; \"list\"]) = \"list\"));\n  (assert ((candidate [\"/path/to/cli\"; \"list\"; \"foo\"]) = \"list\"));\n  (assert ((candidate [\"foo\"; \"bar\"; \"-abc\"]) = \"bar\"));\n  (assert ((candidate [\"foo\"; \"-abc\"; \"bar\"; \"baz\"]) = \"bar\"));\n  (assert ((candidate [\"prog\"; \"subcommand\"; \"--flag\"]) = \"subcommand\"));\n  (assert ((candidate [\"/path/to/cli\"; \"list\"; \"foo\"; \"--bar\"]) = \"list\"));\n  (assert ((candidate [\"/path/to/cli\"; \"list\"; \"--foo\"; \"foo\"]) = \"list\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_300012_solution", "language": "ml", "prompt": "(**Write a function to find the longest common prefix string amongst an array of strings.\nIf there is no common prefix, return an empty string \"\".\n>>> solution(['flower', 'flow', 'flight'])\n'fl'\n>>> solution(['dog', 'racecar', 'car'])\n''\n>>> solution(['amazing', 'amazingly', 'amazing'])\n'amazing'\n>>> solution([])\n''\n*)\nlet solution (strs : string list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_300012_solution.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = solution in\n  (assert ((candidate []) = \"\"));\n  (assert ((candidate [\"dog\"; \"racecar\"; \"car\"]) = \"\"));\n  (assert ((candidate [\"amazing\"; \"amazingly\"; \"amazing\"]) = \"amazing\"));\n  (assert ((candidate [\"amazing\"; \"amazingly\"; \"amazing\"]) = \"amazing\"));\n  (assert ((candidate [\"flower\"; \"flow\"; \"flight\"]) = \"fl\"));\n  (assert ((candidate [\"dog\"; \"racecar\"; \"car\"]) = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_300495_previous_month", "language": "ml", "prompt": "(**Returns a tuple of the month prior to the year and month provided.\n*)\nlet previous_month (year : int) (month : int) :  int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_300495_previous_month.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = previous_month in\n  (assert ((candidate 2017 12) = (2017, 11)));\n  (assert ((candidate 2018 1) = (2017, 12)));\n  (assert ((candidate 1999 1) = (1998, 12)));\n  (assert ((candidate 2018 12) = (2018, 11)));\n  (assert ((candidate 2017 1) = (2016, 12)));\n  (assert ((candidate 2020 7) = (2020, 6)));\n  (assert ((candidate 2019 2) = (2019, 1)));\n  (assert ((candidate 2000 2) = (2000, 1)));\n  (assert ((candidate 1999 2) = (1999, 1)));\n  (assert ((candidate 2021 11) = (2021, 10)));\n  (assert ((candidate 2016 1) = (2015, 12)));\n  (assert ((candidate 2017 2) = (2017, 1)));\n  (assert ((candidate 2017 3) = (2017, 2)));\n  (assert ((candidate 2012 12) = (2012, 11)));\n  (assert ((candidate 2018 2) = (2018, 1)));\n  (assert ((candidate 2012 2) = (2012, 1)));\n  (assert ((candidate 2016 12) = (2016, 11)));\n  (assert ((candidate 2018 10) = (2018, 9)));\n  (assert ((candidate 2000 1) = (1999, 12)));\n  (assert ((candidate 2020 1) = (2019, 12)));\n  (assert ((candidate 2012 1) = (2011, 12)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_300533_difference_p", "language": "ml", "prompt": "(**Calculate difference between 2 values in percent\n*)\nlet difference_p (first : int) (second : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_300533_difference_p.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = difference_p in\n  (assert ((candidate 10 10) = 0));\n  (assert ((candidate 2 1) = 100));\n  (assert ((candidate 10 10) = 0));\n  (assert ((candidate 30 30) = 0));\n  (assert ((candidate 1 1) = 0));\n  (assert ((candidate 2 10) = 80));\n  (assert ((candidate 5 10) = 50));\n  (assert ((candidate 1000 1000) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_300987_cu_mask_to_int", "language": "ml", "prompt": "(**A utility function that takes an array of booleans and returns an\ninteger with 1s wherever there was a \"True\" in the array. The value at\nindex 0 is the least significant bit.\n*)\nlet cu_mask_to_int (cu_mask : bool list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_300987_cu_mask_to_int.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = cu_mask_to_int in\n  (assert ((candidate [true; true; true; true]) = 15));\n  (assert ((candidate [false; false; false; false]) = 0));\n  (assert ((candidate [true; true; true; false; false; false; false; false]) = 7));\n  (assert ((candidate [true; true; true; true]) = 15));\n  (assert ((candidate [true; false; true; false; false; false; false; false]) = 5));\n  (assert ((candidate [true; true; false; false; false; false; false; false]) = 3));\n  (assert ((candidate [false; false; false; false; false; false; false; false]) = 0));\n  (assert ((candidate [false; false; false; false]) = 0));\n  (assert ((candidate [true; false; false; false; false; false; false; false]) = 1));\n  (assert ((candidate [true; false; false; true]) = 9));\n  (assert ((candidate [true; true; true; true; false; false; false; false]) = 15));\n  (assert ((candidate [true; true; true; true; true; false; false; false]) = 31));\n  (assert ((candidate [true; true; true; true; true; true; false; false]) = 63));\n  (assert ((candidate [false; true; true; false]) = 6));\n  (assert ((candidate [true; true; true; true; true; true; true; false]) = 127));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_301359_shift_leftward", "language": "ml", "prompt": "(**Shift positive left, or negative right.  Same as n * 2**nbits\n*)\nlet shift_leftward (n : int) (nbits : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_301359_shift_leftward.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = shift_leftward in\n  (assert ((candidate 1024 (~2)) = 256));\n  (assert ((candidate 16 5) = 512));\n  (assert ((candidate (~1) 2) = (~4)));\n  (assert ((candidate 128 4) = 2048));\n  (assert ((candidate 16 0) = 16));\n  (assert ((candidate 0 0) = 0));\n  (assert ((candidate 127 6) = 8128));\n  (assert ((candidate 0 1) = 0));\n  (assert ((candidate 1024 0) = 1024));\n  (assert ((candidate 16 1) = 32));\n  (assert ((candidate 2 4) = 32));\n  (assert ((candidate 2 (~1)) = 1));\n  (assert ((candidate 1 6) = 64));\n  (assert ((candidate 16 6) = 1024));\n  (assert ((candidate 19088743 32) = 81985526906748928));\n  (assert ((candidate (~1) 31) = (~2147483648)));\n  (assert ((candidate 127 1) = 254));\n  (assert ((candidate (~1) 7) = (~128)));\n  (assert ((candidate 0 31) = 0));\n  (assert ((candidate 1 1) = 2));\n  (assert ((candidate 5 0) = 5));\n  (assert ((candidate 128 3) = 1024));\n  (assert ((candidate 16 9) = 8192));\n  (assert ((candidate (~1) 20) = (~1048576)));\n  (assert ((candidate (~2) 1) = (~4)));\n  (assert ((candidate 256 0) = 256));\n  (assert ((candidate 31 1) = 62));\n  (assert ((candidate 0 5) = 0));\n  (assert ((candidate 1 32) = 4294967296));\n  (assert ((candidate 1 7) = 128));\n  (assert ((candidate 16 3) = 128));\n  (assert ((candidate 128 5) = 4096));\n  (assert ((candidate 1 5) = 32));\n  (assert ((candidate 1 63) = 9223372036854775808));\n  (assert ((candidate 256 2) = 1024));\n  (assert ((candidate 256 3) = 2048));\n  (assert ((candidate 128 0) = 128));\n  (assert ((candidate 0 64) = 0));\n  (assert ((candidate 16 2) = 64));\n  (assert ((candidate (~2) 0) = (~2)));\n  (assert ((candidate 2 7) = 256));\n  (assert ((candidate 128 2) = 512));\n  (assert ((candidate 2 0) = 2));\n  (assert ((candidate (~1) 32) = (~4294967296)));\n  (assert ((candidate 16 (~1)) = 8));\n  (assert ((candidate 1 3) = 8));\n  (assert ((candidate 5 2) = 20));\n  (assert ((candidate 31 2) = 124));\n  (assert ((candidate 2 3) = 16));\n  (assert ((candidate (~31) 2) = (~124)));\n  (assert ((candidate 128 1) = 256));\n  (assert ((candidate 127 2) = 508));\n  (assert ((candidate 1 (~20)) = 0));\n  (assert ((candidate 1024 10) = 1048576));\n  (assert ((candidate 16 4) = 256));\n  (assert ((candidate 1 4) = 16));\n  (assert ((candidate 255 (~1)) = 127));\n  (assert ((candidate 0 63) = 0));\n  (assert ((candidate 0 (~4)) = 0));\n  (assert ((candidate 31 0) = 31));\n  (assert ((candidate 127 3) = 1016));\n  (assert ((candidate (~1) (~20)) = (~1)));\n  (assert ((candidate 1024 (~1)) = 512));\n  (assert ((candidate 2 5) = 64));\n  (assert ((candidate 255 1) = 510));\n  (assert ((candidate 255 3) = 2040));\n  (assert ((candidate (~1) 5) = (~32)));\n  (assert ((candidate 1 1) = 2));\n  (assert ((candidate 1 20) = 1048576));\n  (assert ((candidate 1 0) = 1));\n  (assert ((candidate 0 32) = 0));\n  (assert ((candidate 0 3) = 0));\n  (assert ((candidate (~128) 0) = (~128)));\n  (assert ((candidate (~1) 1) = (~2)));\n  (assert ((candidate 0 4) = 0));\n  (assert ((candidate 0 4) = 0));\n  (assert ((candidate (~1) 0) = (~1)));\n  (assert ((candidate (~1) 63) = (~9223372036854775808)));\n  (assert ((candidate 16 10) = 16384));\n  (assert ((candidate 2 2) = 8));\n  (assert ((candidate 1024 (~3)) = 128));\n  (assert ((candidate (~1) 4) = (~16)));\n  (assert ((candidate 255 0) = 255));\n  (assert ((candidate 125 0) = 125));\n  (assert ((candidate 2 6) = 128));\n  (assert ((candidate 0 2) = 0));\n  (assert ((candidate 2 0) = 2));\n  (assert ((candidate 127 4) = 2032));\n  (assert ((candidate 10 4) = 160));\n  (assert ((candidate 16 7) = 2048));\n  (assert ((candidate 0 (~3)) = 0));\n  (assert ((candidate 15 0) = 15));\n  (assert ((candidate 1 64) = 18446744073709551616));\n  (assert ((candidate 16 8) = 4096));\n  (assert ((candidate 127 5) = 4064));\n  (assert ((candidate 1024 1) = 2048));\n  (assert ((candidate (~1) 6) = (~64)));\n  (assert ((candidate 1 0) = 1));\n  (assert ((candidate (~31) 0) = (~31)));\n  (assert ((candidate 1 2) = 4));\n  (assert ((candidate 0 0) = 0));\n  (assert ((candidate 1 4) = 16));\n  (assert ((candidate 0 1) = 0));\n  (assert ((candidate 1 31) = 2147483648));\n  (assert ((candidate 255 2) = 1020));\n  (assert ((candidate (~2) 2) = (~8)));\n  (assert ((candidate (~125) 0) = (~125)));\n  (assert ((candidate 2 1) = 4));\n  (assert ((candidate (~31) 1) = (~62)));\n  (assert ((candidate 31 3) = 248));\n  (assert ((candidate 256 1) = 512));\n  (assert ((candidate 1 (~1)) = 0));\n  (assert ((candidate 2 1) = 4));\n  (assert ((candidate (~31) 3) = (~248)));\n  (assert ((candidate 2 4) = 32));\n  (assert ((candidate 128 6) = 8192));\n  (assert ((candidate 16 (~2)) = 4));\n  (assert ((candidate (~1) 3) = (~8)));\n  (assert ((candidate 127 0) = 127));\n  (assert ((candidate 128 (~1)) = 64));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_301474__string_lower", "language": "ml", "prompt": "(**Convenience function to lowercase a string.\n:param string:\n * The string which will be lower-cased.\n:returns:\n * Lower-cased copy of string s.\n*)\nlet _string_lower (string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_301474__string_lower.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _string_lower in\n  (assert ((candidate \"HELLO\") = \"hello\"));\n  (assert ((candidate \"Hello\") = \"hello\"));\n  (assert ((candidate \"HELLO WORLD\") = \"hello world\"));\n  (assert ((candidate \"hello world\") = \"hello world\"));\n  (assert ((candidate \"hello     world\") = \"hello     world\"));\n  (assert ((candidate \"HeLlO wOrLd\") = \"hello world\"));\n  (assert ((candidate \"hello\") = \"hello\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_301724_suffixer", "language": "ml", "prompt": "(**Provides the suffix for printing out a podium spot based on the spot number.\n*)\nlet suffixer (n : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_301724_suffixer.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = suffixer in\n  (assert ((candidate 1113) = \"th\"));\n  (assert ((candidate 3) = \"rd\"));\n  (assert ((candidate 14) = \"th\"));\n  (assert ((candidate 30) = \"th\"));\n  (assert ((candidate 6) = \"th\"));\n  (assert ((candidate 9) = \"th\"));\n  (assert ((candidate 10) = \"th\"));\n  (assert ((candidate 111) = \"th\"));\n  (assert ((candidate 28) = \"th\"));\n  (assert ((candidate 1115) = \"th\"));\n  (assert ((candidate 1114) = \"th\"));\n  (assert ((candidate 11) = \"th\"));\n  (assert ((candidate 4) = \"th\"));\n  (assert ((candidate 12) = \"th\"));\n  (assert ((candidate 16) = \"th\"));\n  (assert ((candidate 18) = \"th\"));\n  (assert ((candidate 1112) = \"th\"));\n  (assert ((candidate 25) = \"th\"));\n  (assert ((candidate 17) = \"th\"));\n  (assert ((candidate 27) = \"th\"));\n  (assert ((candidate 1) = \"st\"));\n  (assert ((candidate 15) = \"th\"));\n  (assert ((candidate 2) = \"nd\"));\n  (assert ((candidate 7) = \"th\"));\n  (assert ((candidate 29) = \"th\"));\n  (assert ((candidate 1011) = \"th\"));\n  (assert ((candidate 8) = \"th\"));\n  (assert ((candidate 1111) = \"th\"));\n  (assert ((candidate 19) = \"th\"));\n  (assert ((candidate 24) = \"th\"));\n  (assert ((candidate 34) = \"th\"));\n  (assert ((candidate 20) = \"th\"));\n  (assert ((candidate 5) = \"th\"));\n  (assert ((candidate 13) = \"th\"));\n  (assert ((candidate 26) = \"th\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_303347_fake_headers", "language": "ml", "prompt": "(**Bricklink does referrer and user-agent checks so we need to fake those.\n*)\nlet fake_headers (url : string) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_303347_fake_headers.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = fake_headers in\n  (assert ((candidate \"https://www.bricklink.com/catalogPG.asp?catID=25&colorID=5&page=4\") = [(\"referrer\", \"https://www.bricklink.com/catalogPG.asp?catID=25&colorID=5&page=4\"); (\"User-agent\", \"Mozilla/5.0\")]));\n  (assert ((candidate \"https://www.bricklink.com/v2/api/register_consumer.page\") = [(\"referrer\", \"https://www.bricklink.com/v2/api/register_consumer.page\"); (\"User-agent\", \"Mozilla/5.0\")]));\n  (assert ((candidate \"\") = [(\"referrer\", \"\"); (\"User-agent\", \"Mozilla/5.0\")]));\n  (assert ((candidate \"https://www.bricklink.com/catalogPG.asp?catID=25&colorID=5&page=1\") = [(\"referrer\", \"https://www.bricklink.com/catalogPG.asp?catID=25&colorID=5&page=1\"); (\"User-agent\", \"Mozilla/5.0\")]));\n  (assert ((candidate \"https://www.bricklink.com/catalogPG.asp?catID=25&colorID=5&page=3\") = [(\"referrer\", \"https://www.bricklink.com/catalogPG.asp?catID=25&colorID=5&page=3\"); (\"User-agent\", \"Mozilla/5.0\")]));\n  (assert ((candidate \"https://example.com\") = [(\"referrer\", \"https://example.com\"); (\"User-agent\", \"Mozilla/5.0\")]));\n  (assert ((candidate \"https://www.bricklink.com/catalogPG.asp?catID=25&colorID=5&page=2\") = [(\"referrer\", \"https://www.bricklink.com/catalogPG.asp?catID=25&colorID=5&page=2\"); (\"User-agent\", \"Mozilla/5.0\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_303816__ps", "language": "ml", "prompt": "(**Convenience function for score printing\n*)\nlet _ps (score : float) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_303816__ps.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _ps in\n  (assert ((candidate 0.0) = \"0.000\"));\n  (assert ((candidate 0.001234) = \"0.001\"));\n  (assert ((candidate 0.0012349) = \"0.001\"));\n  (assert ((candidate 0.0012345) = \"0.001\"));\n  (assert ((candidate 0.1234) = \"0.123\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_304953_common_prefix_length", "language": "ml", "prompt": "(**Determine the common prefix of two strings.\nArgs:\n * text1: First string.\n * text2: Second string.\nReturns:\n * The number of characters common to the start of each string.\n*)\nlet common_prefix_length (text1 : string) (text2 : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_304953_common_prefix_length.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = common_prefix_length in\n  (assert ((candidate \"abc\" \"abc\") = 3));\n  (assert ((candidate \"ab\" \"abc\") = 2));\n  (assert ((candidate \"aa\" \"a\") = 1));\n  (assert ((candidate \"abc\" \"abcabc\") = 3));\n  (assert ((candidate \"abc\" \"a\") = 1));\n  (assert ((candidate \"\" \"\") = 0));\n  (assert ((candidate \"\" \"\") = 0));\n  (assert ((candidate \"abc\" \"ab\") = 2));\n  (assert ((candidate \"abc\" \"ab\") = 2));\n  (assert ((candidate \"abc\" \"xabc\") = 0));\n  (assert ((candidate \"abc\" \"ab\") = 2));\n  (assert ((candidate \"abc\" \"abc\") = 3));\n  (assert ((candidate \"a\" \"b\") = 0));\n  (assert ((candidate \"abc\" \"abd\") = 2));\n  (assert ((candidate \"a\" \"aa\") = 1));\n  (assert ((candidate \"abc\" \"\") = 0));\n  (assert ((candidate \"aaa\" \"aaa\") = 3));\n  (assert ((candidate \"aaaa\" \"aaaa\") = 4));\n  (assert ((candidate \"\" \"\") = 0));\n  (assert ((candidate \"abcd\" \"abc\") = 3));\n  (assert ((candidate \"a\" \"a\") = 1));\n  (assert ((candidate \"a\" \"abc\") = 1));\n  (assert ((candidate \"abc\" \"abbc\") = 2));\n  (assert ((candidate \"xabc\" \"abc\") = 0));\n  (assert ((candidate \"abc\" \"abcx\") = 3));\n  (assert ((candidate \"abc\" \"\") = 0));\n  (assert ((candidate \"ab\" \"abc\") = 2));\n  (assert ((candidate \"aaa\" \"a\") = 1));\n  (assert ((candidate \"abc\" \"abcd\") = 3));\n  (assert ((candidate \"a\" \"a\") = 1));\n  (assert ((candidate \"abc\" \"abcd\") = 3));\n  (assert ((candidate \"a\" \"aaa\") = 1));\n  (assert ((candidate \"abc\" \"abc\") = 3));\n  (assert ((candidate \"abc\" \"abcx\") = 3));\n  (assert ((candidate \"ab\" \"abc\") = 2));\n  (assert ((candidate \"abc\" \"a\") = 1));\n  (assert ((candidate \"abcx\" \"abc\") = 3));\n  (assert ((candidate \"\" \"abc\") = 0));\n  (assert ((candidate \"abc\" \"xabc\") = 0));\n  (assert ((candidate \"\" \"abc\") = 0));\n  (assert ((candidate \"ab\" \"ab\") = 2));\n  (assert ((candidate \"abc\" \"abcd\") = 3));\n  (assert ((candidate \"a\" \"abc\") = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_305196_count_words", "language": "ml", "prompt": "(**dirty code for count word\n*)\nlet count_words (content : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_305196_count_words.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = count_words in\n  (assert ((candidate \"Python is a programming language and is fun to learn\") = 10));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_305323_string_to_ascii_html", "language": "ml", "prompt": "(**Convert unicode chars of str to HTML entities if chars are not ASCII.\n*)\nlet string_to_ascii_html (string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_305323_string_to_ascii_html.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = string_to_ascii_html in\n  (assert ((candidate \"abc\") = \"abc\"));\n  (assert ((candidate \"hello world\") = \"hello world\"));\n  (assert ((candidate \"123\") = \"123\"));\n  (assert ((candidate \"Hello \u4f60\u597d World\") = \"Hello &#20320;&#22909; World\"));\n  (assert ((candidate \"\ud83d\udc18\") = \"&#128024;\"));\n  (assert ((candidate \"123 abc ABC\") = \"123 abc ABC\"));\n  (assert ((candidate \"Hello World\") = \"Hello World\"));\n  (assert ((candidate \"ABC\") = \"ABC\"));\n  (assert ((candidate \"This is a test.\") = \"This is a test.\"));\n  (assert ((candidate \"ABC 123\") = \"ABC 123\"));\n  (assert ((candidate \"123 abc ABC 123\") = \"123 abc ABC 123\"));\n  (assert ((candidate \"a\") = \"a\"));\n  (assert ((candidate \"Hello World!\") = \"Hello World!\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_305496__hex_to_char", "language": "ml", "prompt": "(**'61' => 'a'\n*)\nlet _hex_to_char (chr_pair : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_305496__hex_to_char.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _hex_to_char in\n  (assert ((candidate \"7e\") = \"~\"));\n  (assert ((candidate \"01\") = \"\u0001\"));\n  (assert ((candidate \"00\") = \"\u0000\"));\n  (assert ((candidate \"61\") = \"a\"));\n  (assert ((candidate \"02\") = \"\u0002\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_305558_make_shard_files", "language": "ml", "prompt": "(**Make sharding files when shard_equal_rows is False.\n*)\nlet make_shard_files (dataset_files : string list) (num_shards : int) (shard_id : int) :  string * int * int * bool list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_305558_make_shard_files.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = make_shard_files in\n  (assert ((candidate [\"dataset_file1.csv\"; \"dataset_file2.csv\"; \"dataset_file3.csv\"] 2 1) = [(\"dataset_file2.csv\", (~1), (~1), true)]));\n  (assert ((candidate [\"dataset_file1.csv\"; \"dataset_file2.csv\"; \"dataset_file3.csv\"] 3 2) = [(\"dataset_file3.csv\", (~1), (~1), true)]));\n  (assert ((candidate [\"dataset_file1.csv\"; \"dataset_file2.csv\"; \"dataset_file3.csv\"] 3 0) = [(\"dataset_file1.csv\", (~1), (~1), true)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_305605_idx2off", "language": "ml", "prompt": "(**Produces [0, 32, 64,   88, 120, 152,   176, 208, 240,   264, 296, 328]\nThese are the byte offsets when dividing into 44-coeff chunks\n*)\nlet idx2off (i : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_305605_idx2off.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = idx2off in\n  (assert ((candidate 13) = 384));\n  (assert ((candidate 1) = 32));\n  (assert ((candidate 14) = 416));\n  (assert ((candidate 9) = 264));\n  (assert ((candidate 10) = 296));\n  (assert ((candidate 3) = 88));\n  (assert ((candidate 12) = 352));\n  (assert ((candidate 11) = 328));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 5) = 152));\n  (assert ((candidate 4) = 120));\n  (assert ((candidate 7) = 208));\n  (assert ((candidate 6) = 176));\n  (assert ((candidate 2) = 64));\n  (assert ((candidate 8) = 240));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_305774_translate", "language": "ml", "prompt": "(**Translate vector(x,y) by (dx,dy).\n*)\nlet translate (x : int) (y : int) (dx : int) (dy : int) :  int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_305774_translate.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = translate in\n  (assert ((candidate 100 200 10 (~10)) = (110, 190)));\n  (assert ((candidate (~100) 200 10 (~10)) = ((~90), 190)));\n  (assert ((candidate 2 2 1 0) = (3, 2)));\n  (assert ((candidate 100 200 (~10) 10) = (90, 210)));\n  (assert ((candidate 2 2 1 1) = (3, 3)));\n  (assert ((candidate (~1) (~2) 2 (~2)) = (1, (~4))));\n  (assert ((candidate 0 0 1 1) = (1, 1)));\n  (assert ((candidate 1 1 1 0) = (2, 1)));\n  (assert ((candidate 0 0 10 (~10)) = (10, (~10))));\n  (assert ((candidate 0 0 (~10) 10) = ((~10), 10)));\n  (assert ((candidate 1 1 0 0) = (1, 1)));\n  (assert ((candidate 100 200 10 10) = (110, 210)));\n  (assert ((candidate 0 0 0 0) = (0, 0)));\n  (assert ((candidate 0 0 10 10) = (10, 10)));\n  (assert ((candidate 0 1 0 0) = (0, 1)));\n  (assert ((candidate 0 1 0 2) = (0, 3)));\n  (assert ((candidate 0 0 0 0) = (0, 0)));\n  (assert ((candidate 1 0 0 2) = (1, 2)));\n  (assert ((candidate 100 200 (~10) (~10)) = (90, 190)));\n  (assert ((candidate (~100) 200 10 10) = ((~90), 210)));\n  (assert ((candidate 1 0 2 0) = (3, 0)));\n  (assert ((candidate (~1) (~1) 1 1) = (0, 0)));\n  (assert ((candidate 2 2 0 1) = (2, 3)));\n  (assert ((candidate 1 2 0 0) = (1, 2)));\n  (assert ((candidate 1 2 3 4) = (4, 6)));\n  (assert ((candidate 0 1 2 0) = (2, 1)));\n  (assert ((candidate 0 0 (~10) (~10)) = ((~10), (~10))));\n  (assert ((candidate 1 2 2 (~2)) = (3, 0)));\n  (assert ((candidate (~100) 200 (~10) 10) = ((~110), 210)));\n  (assert ((candidate 2 2 0 0) = (2, 2)));\n  (assert ((candidate 1 1 1 1) = (2, 2)));\n  (assert ((candidate (~100) 200 (~10) (~10)) = ((~110), 190)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_306162_get_target_delta", "language": "ml", "prompt": "(**Generate target delta given the size of a dataset. Delta should be\nless than the inverse of the datasize.\nParameters\n----------\ndata_size : int\n * The size of the dataset.\nReturns\n-------\nfloat\n * The target delta value.\n*)\nlet get_target_delta (data_size : int) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_306162_get_target_delta.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_target_delta in\n  (assert ((candidate 10000000) = 1e-08.0));\n  (assert ((candidate 1) = 0.1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_306499_getKmers", "language": "ml", "prompt": "(**Generate k-mers of size k\n*)\nlet getKmers (k : int) (bases : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_306499_getKmers.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = getKmers in\n  (assert ((candidate 1 \"ACGT\") = [\"A\"; \"C\"; \"G\"; \"T\"]));\n  (assert ((candidate 2 \"ACGT\") = [\"AA\"; \"AC\"; \"AG\"; \"AT\"; \"CA\"; \"CC\"; \"CG\"; \"CT\"; \"GA\"; \"GC\"; \"GG\"; \"GT\"; \"TA\"; \"TC\"; \"TG\"; \"TT\"]));\n  (assert ((candidate 3 \"ACGT\") = [\"AAA\"; \"AAC\"; \"AAG\"; \"AAT\"; \"ACA\"; \"ACC\"; \"ACG\"; \"ACT\"; \"AGA\"; \"AGC\"; \"AGG\"; \"AGT\"; \"ATA\"; \"ATC\"; \"ATG\"; \"ATT\"; \"CAA\"; \"CAC\"; \"CAG\"; \"CAT\"; \"CCA\"; \"CCC\"; \"CCG\"; \"CCT\"; \"CGA\"; \"CGC\"; \"CGG\"; \"CGT\"; \"CTA\"; \"CTC\"; \"CTG\"; \"CTT\"; \"GAA\"; \"GAC\"; \"GAG\"; \"GAT\"; \"GCA\"; \"GCC\"; \"GCG\"; \"GCT\"; \"GGA\"; \"GGC\"; \"GGG\"; \"GGT\"; \"GTA\"; \"GTC\"; \"GTG\"; \"GTT\"; \"TAA\"; \"TAC\"; \"TAG\"; \"TAT\"; \"TCA\"; \"TCC\"; \"TCG\"; \"TCT\"; \"TGA\"; \"TGC\"; \"TGG\"; \"TGT\"; \"TTA\"; \"TTC\"; \"TTG\"; \"TTT\"]));\n  (assert ((candidate 2 \"ACGT\") = [\"AA\"; \"AC\"; \"AG\"; \"AT\"; \"CA\"; \"CC\"; \"CG\"; \"CT\"; \"GA\"; \"GC\"; \"GG\"; \"GT\"; \"TA\"; \"TC\"; \"TG\"; \"TT\"]));\n  (assert ((candidate 1 \"A\") = [\"A\"]));\n  (assert ((candidate 1 \"ATCGT\") = [\"A\"; \"T\"; \"C\"; \"G\"; \"T\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_306534_alphabetical", "language": "ml", "prompt": "(**Sorts a list of tuples in reverse alphabetical order by the first key\nin the tuple.\nArguments:\nlst -- the list to sort\nReturns:\nthe sorted list\n*)\nlet alphabetical (lst :  string * int list) :  string * int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_306534_alphabetical.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = alphabetical in\n  (assert ((candidate [(\"a\", 1); (\"a\", 2); (\"a\", 3); (\"a\", 4); (\"a\", 5); (\"a\", 6); (\"a\", 7); (\"a\", 8); (\"a\", 9); (\"a\", 10)]) = [(\"a\", 10); (\"a\", 9); (\"a\", 8); (\"a\", 7); (\"a\", 6); (\"a\", 5); (\"a\", 4); (\"a\", 3); (\"a\", 2); (\"a\", 1)]));\n  (assert ((candidate list ) = list ));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3); (\"d\", 4); (\"e\", 5); (\"f\", 6); (\"g\", 7); (\"h\", 8); (\"i\", 9); (\"j\", 10)]) = [(\"j\", 10); (\"i\", 9); (\"h\", 8); (\"g\", 7); (\"f\", 6); (\"e\", 5); (\"d\", 4); (\"c\", 3); (\"b\", 2); (\"a\", 1)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_307233_toWidthHeightInverse", "language": "ml", "prompt": "(**Transforms from [w, h, x, y] to [x0,y0,x1,y1] format\n*)\nlet toWidthHeightInverse (wh : int list) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_307233_toWidthHeightInverse.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = toWidthHeightInverse in\n  (assert ((candidate [2; 2; 1; 1]) = [0; 0; 1; 1]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_307309_binV2_to_A2", "language": "ml", "prompt": "(**Used to convert SII(t)[bin_V**2] to SII(t)[A**2]\n*)\nlet binV2_to_A2 (S2 : int) (R_acq : int) (mv_per_bin : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_307309_binV2_to_A2.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = binV2_to_A2 in\n  (assert ((candidate 0 1 1) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_307930_find_all", "language": "ml", "prompt": "(**returns a list of locations where substr occurs in searchin\nlocations are not allowed to overlap\n*)\nlet find_all (searchin : string) (substr : string) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_307930_find_all.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = find_all in\n  (assert ((candidate \"aa\" \"aaaa\") = []));\n  (assert ((candidate \"abracadabra\" \"bra\") = [1; 8]));\n  (assert ((candidate \"a a a a a a a a a\" \"b\") = []));\n  (assert ((candidate \"aa\" \"a\") = [0; 1]));\n  (assert ((candidate \"a\" \"a\") = [0]));\n  (assert ((candidate \"\" \"a\") = []));\n  (assert ((candidate \"aaa\" \"aaaaaaa\") = []));\n  (assert ((candidate \"abcdefghijklmnopqrstuvwxyz\" \"xyz\") = [23]));\n  (assert ((candidate \"aa\" \"aabbaa\") = []));\n  (assert ((candidate \"aaaa\" \"aa\") = [0; 2]));\n  (assert ((candidate \"\" \"x\") = []));\n  (assert ((candidate \"a\" \"aa\") = []));\n  (assert ((candidate \"abcde\" \"cde\") = [2]));\n  (assert ((candidate \"123456\" \"0\") = []));\n  (assert ((candidate \"aaa\" \"a\") = [0; 1; 2]));\n  (assert ((candidate \"a\" \"aaa\") = []));\n  (assert ((candidate \"x    y\" \"x\") = [0]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_308818_event_independence_check", "language": "ml", "prompt": "(**Checks if two events are independent.\nThis function accepts the probability of 2 events and their joint probability.\nAnd prints if the events are independent or not.\nKeyword arguments:\nprob_event1 -- probability of event1\nprob_event2 -- probability of event2\nprob_event1_event2 -- probability of event1 and event2\n*)\nlet event_independence_check (prob_event1 : float) (prob_event2 : float) (prob_event1_event2 : float) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_308818_event_independence_check.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = event_independence_check in\n  (assert ((candidate 0.33 0.67 0.19) = false));\n  (assert ((candidate 0.3 0.6 0.132) = false));\n  (assert ((candidate 0.2 0.8 0.08) = false));\n  (assert ((candidate 0.25 0.75 0.2) = false));\n  (assert ((candidate 0.5 0.5 0.25) = true));\n  (assert ((candidate 0.3 0.6 0.054) = false));\n  (assert ((candidate 0.9 0.7 0.635) = false));\n  (assert ((candidate 0.6 0.6 0.36) = true));\n  (assert ((candidate 0.2 0.6 0.096) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_309108_deserialize_sanitizer_options", "language": "ml", "prompt": "(**Read options from a variable like ASAN_OPTIONS into a dict.\n*)\nlet deserialize_sanitizer_options (options : string) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_309108_deserialize_sanitizer_options.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = deserialize_sanitizer_options in\n  (assert ((candidate \"handle_segv=1\") = [(\"handle_segv\", \"1\")]));\n  (assert ((candidate \"handle_segv=1:detect_stack_use_after_return=1\") = [(\"handle_segv\", \"1\"); (\"detect_stack_use_after_return\", \"1\")]));\n  (assert ((candidate \"foo=bar:baz=123\") = [(\"foo\", \"bar\"); (\"baz\", \"123\")]));\n  (assert ((candidate \"allocator_may_return_null=1\") = [(\"allocator_may_return_null\", \"1\")]));\n  (assert ((candidate \"detect_leaks=0\") = [(\"detect_leaks\", \"0\")]));\n  (assert ((candidate \"handle_segv=1\") = [(\"handle_segv\", \"1\")]));\n  (assert ((candidate \"detect_odr_violation=0\") = [(\"detect_odr_violation\", \"0\")]));\n  (assert ((candidate \"strict_memcmp=1:detect_leaks=0:allocator_may_return_null=1\") = [(\"strict_memcmp\", \"1\"); (\"detect_leaks\", \"0\"); (\"allocator_may_return_null\", \"1\")]));\n  (assert ((candidate \"allow_user_segv_handler=0\") = [(\"allow_user_segv_handler\", \"0\")]));\n  (assert ((candidate \"detect_leaks=0:allocator_may_return_null=1\") = [(\"detect_leaks\", \"0\"); (\"allocator_may_return_null\", \"1\")]));\n  (assert ((candidate \"allocator_may_return_null=1\") = [(\"allocator_may_return_null\", \"1\")]));\n  (assert ((candidate \"detect_stack_use_after_return=1\") = [(\"detect_stack_use_after_return\", \"1\")]));\n  (assert ((candidate \"detect_leaks=0:handle_segv=1\") = [(\"detect_leaks\", \"0\"); (\"handle_segv\", \"1\")]));\n  (assert ((candidate \"print_suppressions=1\") = [(\"print_suppressions\", \"1\")]));\n  (assert ((candidate \"detect_stack_use_after_return=1:handle_segv=1\") = [(\"detect_stack_use_after_return\", \"1\"); (\"handle_segv\", \"1\")]));\n  (assert ((candidate \"detect_leaks=0\") = [(\"detect_leaks\", \"0\")]));\n  (assert ((candidate \"detect_leaks=0\") = [(\"detect_leaks\", \"0\")]));\n  (assert ((candidate \"detect_leaks=1\") = [(\"detect_leaks\", \"1\")]));\n  (assert ((candidate \"detect_leaks=1:allocator_may_return_null=0\") = [(\"detect_leaks\", \"1\"); (\"allocator_may_return_null\", \"0\")]));\n  (assert ((candidate \"coverage=1:coverage_dir=/somewhere\") = [(\"coverage\", \"1\"); (\"coverage_dir\", \"/somewhere\")]));\n  (assert ((candidate \"print_suppressions=0\") = [(\"print_suppressions\", \"0\")]));\n  (assert ((candidate \"detect_leaks=0:handle_segv=1:detect_stack_use_after_return=1\") = [(\"detect_leaks\", \"0\"); (\"handle_segv\", \"1\"); (\"detect_stack_use_after_return\", \"1\")]));\n  (assert ((candidate \"handle_sigbus=1\") = [(\"handle_sigbus\", \"1\")]));\n  (assert ((candidate \"detect_leaks=0:detect_leaks=1\") = [(\"detect_leaks\", \"1\")]));\n  (assert ((candidate \"allocator_may_return_null=0\") = [(\"allocator_may_return_null\", \"0\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_310088_indentation_value", "language": "ml", "prompt": "(**Given an indentation string of spaces and tabs,\nreturns the equivalent number of spaces per Python\nindentation rule.\n*)\nlet indentation_value (spaces : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_310088_indentation_value.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = indentation_value in\n  (assert ((candidate \"      \") = 6));\n  (assert ((candidate \"        \") = 8));\n  (assert ((candidate \"    \") = 4));\n  (assert ((candidate \"\t\") = 8));\n  (assert ((candidate \"\") = 0));\n  (assert ((candidate \"\") = 0));\n  (assert ((candidate \"        \") = 8));\n  (assert ((candidate \"  \") = 2));\n  (assert ((candidate \"  \") = 2));\n  (assert ((candidate \"    \") = 4));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_3108_lines_in_file", "language": "ml", "prompt": "(**Count the number of lines in a file\n:param filename: A string containing the relative or absolute path to a file\n:returns: The number of lines in the file\n*)\nlet lines_in_file (filename : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_3108_lines_in_file.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = lines_in_file in\n  (assert ((candidate \"no_such_file\") = 0));\n  (assert ((candidate \"no_such_file\") = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_312017_deserialize_datetime", "language": "ml", "prompt": "(**Deserializes string to datetime.\nThe string should be in iso8601 datetime format.\n:param string: str.\n:type string: str\n:return: datetime.\n:rtype: datetime\n*)\nlet deserialize_datetime (string : string option) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_312017_deserialize_datetime.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = deserialize_datetime in\n  (assert ((candidate Some(\"2018-01-01T12:34:56\")) = Some(\"2018-01-01T12:34:56\")));\n  (assert ((candidate Some(\"2018-01-01T12:34:56.123456-01:00\")) = Some(\"2018-01-01T12:34:56.123456-01:00\")));\n  (assert ((candidate Some(\"2018-01-01T12:34:56.123456Z\")) = Some(\"2018-01-01T12:34:56.123456Z\")));\n  (assert ((candidate Some(\"2018-01-01T12:34:56Z\")) = Some(\"2018-01-01T12:34:56Z\")));\n  (assert ((candidate Some(\"2018-01-01T12:34:56.123456\")) = Some(\"2018-01-01T12:34:56.123456\")));\n  (assert ((candidate Some(\"2018-01-01T12:34:56.123456-01:00Z\")) = Some(\"2018-01-01T12:34:56.123456-01:00Z\")));\n  (assert ((candidate Some(None)) = Some(None)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_312491_unsignedIntegerToBytes", "language": "ml", "prompt": "(**Converts an unsigned integer into a sequence of bytes, LSB first.\ninteger -- the number to be converted\nnumbytes -- the number of bytes to be used in representing the integer\n*)\nlet unsignedIntegerToBytes (integer : int) (numbytes : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_312491_unsignedIntegerToBytes.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = unsignedIntegerToBytes in\n  (assert ((candidate 0 2) = [0; 0]));\n  (assert ((candidate 65535 3) = [255; 255; 0]));\n  (assert ((candidate 0 3) = [0; 0; 0]));\n  (assert ((candidate 255 1) = [255]));\n  (assert ((candidate 0 4) = [0; 0; 0; 0]));\n  (assert ((candidate 0 1) = [0]));\n  (assert ((candidate 1 1) = [1]));\n  (assert ((candidate 257 2) = [1; 1]));\n  (assert ((candidate 256 4) = [0; 1; 0; 0]));\n  (assert ((candidate 1 2) = [1; 0]));\n  (assert ((candidate 257 4) = [1; 1; 0; 0]));\n  (assert ((candidate 42 2) = [42; 0]));\n  (assert ((candidate 4294967295 4) = [255; 255; 255; 255]));\n  (assert ((candidate 256 3) = [0; 1; 0]));\n  (assert ((candidate 256 2) = [0; 1]));\n  (assert ((candidate 65536 4) = [0; 0; 1; 0]));\n  (assert ((candidate 257 3) = [1; 1; 0]));\n  (assert ((candidate 1 3) = [1; 0; 0]));\n  (assert ((candidate 65537 4) = [1; 0; 1; 0]));\n  (assert ((candidate 65535 2) = [255; 255]));\n  (assert ((candidate 1 4) = [1; 0; 0; 0]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_314698_is_non_negative", "language": "ml", "prompt": "(**Check if the input dictionary values are non negative.\nArgs:\n * input_dict (dict): dictionary.\nReturns:\n * bool: boolean variable indicating whether dict values are non negative or not.\n*)\nlet is_non_negative (input_dict : (int, int) list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_314698_is_non_negative.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_non_negative in\n  (assert ((candidate [(1, 1); (2, 2)]) = true));\n  (assert ((candidate [(1, 1); (2, 2); (3, (~3)); (4, 4)]) = false));\n  (assert ((candidate [(1, 1); (2, 2); (3, (~3))]) = false));\n  (assert ((candidate []) = true));\n  (assert ((candidate [(1, 1)]) = true));\n  (assert ((candidate [(1, 1); (2, 2); (3, 3)]) = true));\n  (assert ((candidate [(1, 1); (2, 2); (3, (~3)); (4, (~4))]) = false));\n  (assert ((candidate [(1, 1); (2, 2); (3, 3); (4, 4)]) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_315387_num_desc_seq_given_total_and_head", "language": "ml", "prompt": "(**Subproblem in dynamic programming.\nCount the number of descending sequences given a total and the head.\nNote that a one-term sequence is also considered a sequence.\n*)\nlet num_desc_seq_given_total_and_head (total : int) (head : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_315387_num_desc_seq_given_total_and_head.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = num_desc_seq_given_total_and_head in\n  (assert ((candidate 5 25) = 0));\n  (assert ((candidate 10 10) = 1));\n  (assert ((candidate 2 3) = 0));\n  (assert ((candidate 4 3) = 1));\n  (assert ((candidate 2 1) = 1));\n  (assert ((candidate 5 3) = 2));\n  (assert ((candidate 4 30) = 0));\n  (assert ((candidate 1 1) = 1));\n  (assert ((candidate 4 7) = 0));\n  (assert ((candidate 1 2) = 0));\n  (assert ((candidate 4 2) = 2));\n  (assert ((candidate 3 2) = 1));\n  (assert ((candidate 10 100) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_316104_fontname", "language": "ml", "prompt": "(**Sets the current font used when drawing text.\n*)\nlet fontname (name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_316104_fontname.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = fontname in\n  (assert ((candidate \"Arial\") = \"Arial\"));\n  (assert ((candidate \"Helvetica\") = \"Helvetica\"));\n  (assert ((candidate \"Arial\") = \"Arial\"));\n  (assert ((candidate \"Courier\") = \"Courier\"));\n  (assert ((candidate \"Times-Roman\") = \"Times-Roman\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_316766_get_flowcell_name_from_desc", "language": "ml", "prompt": "(**Get the flowcell name from the description\nParameters\n----------\ndescription_dict: dict\n * A parsed dictionary created from the description from the fastq record\nuser_run_name: str\n * The user run name that we have been given on the command line\nReturns\n-------\nflowcell_name: str\n * The flowcell name that we are gonna be using\n*)\nlet get_flowcell_name_from_desc (description_dict : (string, string) list) (user_run_name : string option) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_316766_get_flowcell_name_from_desc.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_flowcell_name_from_desc in\n  (assert ((candidate [] Some(\"my_run\")) = \"my_run\"));\n  (assert ((candidate [] Some(\"foo\")) = \"foo\"));\n  (assert ((candidate [(\"sampleid\", \"ABCD1234\")] Some(\"ignored\")) = \"ABCD1234\"));\n  (assert ((candidate [(\"flow_cell_id\", \"1234\")] Some(\"ignored\")) = \"1234\"));\n  (assert ((candidate [(\"sampleid\", \"foo\")] Some(\"bar\")) = \"foo\"));\n  (assert ((candidate [(\"flow_cell_id\", \"AB12345\")] Some(None)) = \"AB12345\"));\n  (assert ((candidate [(\"sample_id\", \"ABCD1234\")] Some(\"ignored\")) = \"ABCD1234\"));\n  (assert ((candidate [(\"flow_cell_id\", \"12345\"); (\"sample_id\", \"54321\"); (\"sampleid\", \"55555\")] Some(\"user_run_name\")) = \"12345\"));\n  (assert ((candidate [] Some(\"user_run_name\")) = \"user_run_name\"));\n  (assert ((candidate [(\"flow_cell_id\", \"foo\")] Some(\"bar\")) = \"foo\"));\n  (assert ((candidate [(\"sample_id\", \"AB12345\")] Some(None)) = \"AB12345\"));\n  (assert ((candidate [(\"sampleid\", \"AB12345\")] Some(\"user_run_name\")) = \"AB12345\"));\n  (assert ((candidate [(\"flow_cell_id\", \"1234\")] Some(\"1111\")) = \"1234\"));\n  (assert ((candidate [] Some(\"1234\")) = \"1234\"));\n  (assert ((candidate [(\"flow_cell_id\", \"AB12345\")] Some(\"user_run_name\")) = \"AB12345\"));\n  (assert ((candidate [(\"sampleid\", \"1234\")] Some(\"1111\")) = \"1234\"));\n  (assert ((candidate [(\"sample_id\", \"1234\")] Some(\"1111\")) = \"1234\"));\n  (assert ((candidate [(\"sample_id\", \"54321\"); (\"sampleid\", \"55555\")] Some(\"user_run_name\")) = \"54321\"));\n  (assert ((candidate [(\"sample_id\", \"AB12345\")] Some(\"user_run_name\")) = \"AB12345\"));\n  (assert ((candidate [(\"sample_id\", \"foo\")] Some(\"bar\")) = \"foo\"));\n  (assert ((candidate [(\"flow_cell_id\", \"12345\"); (\"sample_id\", \"54321\")] Some(\"user_run_name\")) = \"12345\"));\n  (assert ((candidate [(\"sample_id\", \"54321\"); (\"sampleid\", \"555555\")] Some(\"user_run_name\")) = \"54321\"));\n  (assert ((candidate [] Some(\"bar\")) = \"bar\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_316829_pretty_print_ec2_res_id", "language": "ml", "prompt": "(**Pretty-print the EC2 reservation ID\n*)\nlet pretty_print_ec2_res_id (res : (string, string) list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_316829_pretty_print_ec2_res_id.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = pretty_print_ec2_res_id in\n  (assert ((candidate [(\"ReservedInstancesId\", \"73599745-9067-4a6c-8629-99a4154e1606\")]) = \"73599745...\"));\n  (assert ((candidate [(\"ReservedInstancesId\", \"4a928483-9067-4a6c-8629-99a4154e1606\")]) = \"4a928483...\"));\n  (assert ((candidate [(\"ReservedInstancesId\", \"89599745-9067-4a6c-8629-99a4154e1606\")]) = \"89599745...\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_316883_code_to_name", "language": "ml", "prompt": "(**returns a country name if the given dictionary contains a code for it\nif the code is not in the dictionary it will return an empty string\nArgs:\n * code (str):         country code\n * code_dict (dict):   dictionary with code as key and name as value\nReturns:\n * geo_name (str):     name of country\n*)\nlet code_to_name (code : string) (code_dict : (string, string) list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_316883_code_to_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = code_to_name in\n  (assert ((candidate \"XY\" [(\"AL\", \"Albania\")]) = \"\"));\n  (assert ((candidate \"AL\" [(\"AL\", \"Albania\")]) = \"Albania\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_317662_delete_keys_from_dict", "language": "ml", "prompt": "(**Utility to remove specific keys from a dictionary.\nParameters\n----------\ndictionary : dict\n * Input dictionary.\nkeys_to_remove : list\n * list of keys to remove from the dictionary. If this list is\n * non-unique (i.e. has repeats), then there will be an error. Also, if\n * any element in this list is not a key in the dictionary, there will\n * be an error as well.\nReturns\n-------\ndictionary : dict\n * Dictionary with keys removed.\n*)\nlet delete_keys_from_dict (dictionary : (string, int) list) (keys_to_remove : string list) : (string, int) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_317662_delete_keys_from_dict.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = delete_keys_from_dict in\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3)] []) = [(\"a\", 1); (\"b\", 2); (\"c\", 3)]));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3)] [\"a\"; \"c\"; \"b\"]) = []));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3)] [\"a\"; \"c\"]) = [(\"b\", 2)]));\n  (assert ((candidate [(\"a\", 0); (\"b\", 1); (\"c\", 2)] [\"a\"]) = [(\"b\", 1); (\"c\", 2)]));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3)] [\"a\"; \"b\"]) = [(\"c\", 3)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_317743_wordCount", "language": "ml", "prompt": "(**This function counts words from a text and returns a dictionary. \nDoes not fix for punctuation and special characters, so for example 'why' and 'why?' will be counted as two different words. This doesn't matter in the case of youtube subtitles.\nINPUT: string\nOUTPUT: dictionary where keys are words, and the values are counts.\n*)\nlet wordCount (cleantext : string) : (string, int) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_317743_wordCount.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = wordCount in\n  (assert ((candidate \"\") = []));\n  (assert ((candidate \" \") = []));\n  (assert ((candidate \"It was a bright cold day in April, and the clocks were striking thirteen.\") = [(\"It\", 1); (\"was\", 1); (\"a\", 1); (\"bright\", 1); (\"cold\", 1); (\"day\", 1); (\"in\", 1); (\"April,\", 1); (\"and\", 1); (\"the\", 1); (\"clocks\", 1); (\"were\", 1); (\"striking\", 1); (\"thirteen.\", 1)]));\n  (assert ((candidate \"Hello world\") = [(\"Hello\", 1); (\"world\", 1)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_317929_get_split_parts", "language": "ml", "prompt": "(**get split parts\n*)\nlet get_split_parts (num : int) (num_part : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_317929_get_split_parts.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_split_parts in\n  (assert ((candidate 26 2) = [13; 13]));\n  (assert ((candidate 1000 10) = [100; 100; 100; 100; 100; 100; 100; 100; 100; 100]));\n  (assert ((candidate 10 2) = [5; 5]));\n  (assert ((candidate 10 5) = [2; 2; 2; 2; 2]));\n  (assert ((candidate 100 1) = [100]));\n  (assert ((candidate 12 1) = [12]));\n  (assert ((candidate 11 1) = [11]));\n  (assert ((candidate 12 3) = [4; 4; 4]));\n  (assert ((candidate 26 1) = [26]));\n  (assert ((candidate 10 1) = [10]));\n  (assert ((candidate 13 1) = [13]));\n  (assert ((candidate 100 5) = [20; 20; 20; 20; 20]));\n  (assert ((candidate 100 4) = [25; 25; 25; 25]));\n  (assert ((candidate 15 3) = [5; 5; 5]));\n  (assert ((candidate 25 1) = [25]));\n  (assert ((candidate 100 2) = [50; 50]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_318311__safe_parse", "language": "ml", "prompt": "(**Parse an irc message.\nArgs:\n * msg (str): raw message\nReturn:\n * dict: {'user': user, 'msg': message}\n*)\nlet _safe_parse (msg : string) : (string, string) list option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_318311__safe_parse.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _safe_parse in\n  (assert ((candidate \"PRIVMSG 12345!@#$%^&*()\") = Some(None)));\n  (assert ((candidate \"PRIVMSG!@#$%^&*()!@#$%^&*()\") = Some(None)));\n  (assert ((candidate \"PRIVMSG 12345 12345\") = Some(None)));\n  (assert ((candidate \":nick!<EMAIL> PRIVMSG\") = Some(None)));\n  (assert ((candidate \"PRIVMSG\") = Some(None)));\n  (assert ((candidate \"PRIVMSG\") = Some(None)));\n  (assert ((candidate \":nick!<EMAIL> PRIVMSG #chan :I have a message\") = Some([(\"user\", \"nick\"); (\"msg\", \"I have a message\")])));\n  (assert ((candidate \"PRIVMSG!@#$%^&*() 12345\") = Some(None)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_319216_sum_digits", "language": "ml", "prompt": "(**assumes s a string\nReturns an int that is the sum of all of the digits in s.\nIf there are no digits in s it raises a ValueError exception.\n*)\nlet sum_digits (s : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_319216_sum_digits.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sum_digits in\n  (assert ((candidate \"-123\") = 6));\n  (assert ((candidate str (~123)) = 6));\n  (assert ((candidate str 123) = 6));\n  (assert ((candidate \"a0123456789b\") = 45));\n  (assert ((candidate \"123\") = 6));\n  (assert ((candidate \"987\") = 24));\n  (assert ((candidate \"abc123\") = 6));\n  (assert ((candidate \"123abc\") = 6));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_319388_bit_len", "language": "ml", "prompt": "(**Helper function returning the number of bits required to binary encode an integer.\n*)\nlet bit_len (int_type : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_319388_bit_len.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = bit_len in\n  (assert ((candidate 5) = 3));\n  (assert ((candidate 7) = 3));\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 127) = 7));\n  (assert ((candidate 6) = 3));\n  (assert ((candidate 23) = 5));\n  (assert ((candidate 30) = 5));\n  (assert ((candidate 26) = 5));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 29) = 5));\n  (assert ((candidate 19) = 5));\n  (assert ((candidate 13) = 4));\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 3) = 2));\n  (assert ((candidate 20) = 5));\n  (assert ((candidate 128) = 8));\n  (assert ((candidate 4) = 3));\n  (assert ((candidate 24) = 5));\n  (assert ((candidate 63) = 6));\n  (assert ((candidate 25) = 5));\n  (assert ((candidate 16383) = 14));\n  (assert ((candidate 17) = 5));\n  (assert ((candidate 511) = 9));\n  (assert ((candidate 512) = 10));\n  (assert ((candidate 4) = 3));\n  (assert ((candidate 2048) = 12));\n  (assert ((candidate 31) = 5));\n  (assert ((candidate 21) = 5));\n  (assert ((candidate 25) = 5));\n  (assert ((candidate 64) = 7));\n  (assert ((candidate 33) = 6));\n  (assert ((candidate 7) = 3));\n  (assert ((candidate 16) = 5));\n  (assert ((candidate 21) = 5));\n  (assert ((candidate 8) = 4));\n  (assert ((candidate 11) = 4));\n  (assert ((candidate 15) = 4));\n  (assert ((candidate 5) = 3));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 100) = 7));\n  (assert ((candidate 28) = 5));\n  (assert ((candidate 16) = 5));\n  (assert ((candidate 18) = 5));\n  (assert ((candidate 10) = 4));\n  (assert ((candidate 8191) = 13));\n  (assert ((candidate 19) = 5));\n  (assert ((candidate 14) = 4));\n  (assert ((candidate 255) = 8));\n  (assert ((candidate 1023) = 10));\n  (assert ((candidate 14) = 4));\n  (assert ((candidate 12) = 4));\n  (assert ((candidate 27) = 5));\n  (assert ((candidate 256) = 9));\n  (assert ((candidate 22) = 5));\n  (assert ((candidate 22) = 5));\n  (assert ((candidate 4096) = 13));\n  (assert ((candidate 12) = 4));\n  (assert ((candidate 9) = 4));\n  (assert ((candidate 2047) = 11));\n  (assert ((candidate 34) = 6));\n  (assert ((candidate 3) = 2));\n  (assert ((candidate 17) = 5));\n  (assert ((candidate 16384) = 15));\n  (assert ((candidate 32) = 6));\n  (assert ((candidate 28) = 5));\n  (assert ((candidate 4095) = 12));\n  (assert ((candidate 20) = 5));\n  (assert ((candidate 10) = 4));\n  (assert ((candidate 13) = 4));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 6) = 3));\n  (assert ((candidate 26) = 5));\n  (assert ((candidate 8) = 4));\n  (assert ((candidate 24) = 5));\n  (assert ((candidate 27) = 5));\n  (assert ((candidate 23) = 5));\n  (assert ((candidate 18) = 5));\n  (assert ((candidate 8192) = 14));\n  (assert ((candidate 15) = 4));\n  (assert ((candidate 1024) = 11));\n  (assert ((candidate 11) = 4));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 9) = 4));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_320259_bitInBitmap", "language": "ml", "prompt": "(**bit map decoding\n*)\nlet bitInBitmap (bitmap : int) (bit : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_320259_bitInBitmap.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = bitInBitmap in\n  (assert ((candidate 23 10) = false));\n  (assert ((candidate 10 100) = false));\n  (assert ((candidate 255 128) = true));\n  (assert ((candidate 13 100) = false));\n  (assert ((candidate 42 7) = false));\n  (assert ((candidate 0 1) = false));\n  (assert ((candidate 2 1) = false));\n  (assert ((candidate 2047 128) = true));\n  (assert ((candidate 0 0) = false));\n  (assert ((candidate 128 128) = true));\n  (assert ((candidate 1 1) = true));\n  (assert ((candidate 8 1) = false));\n  (assert ((candidate 256 128) = false));\n  (assert ((candidate 42 4) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_320360_get_rounds", "language": "ml", "prompt": "(**Get list of current and next rounds\n:param number: int - current round number.\n:return: list - current round and the two that follow.\n*)\nlet get_rounds (number : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_320360_get_rounds.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_rounds in\n  (assert ((candidate 3) = [3; 4; 5]));\n  (assert ((candidate 12) = [12; 13; 14]));\n  (assert ((candidate 0) = [0; 1; 2]));\n  (assert ((candidate 2) = [2; 3; 4]));\n  (assert ((candidate 25) = [25; 26; 27]));\n  (assert ((candidate 1) = [1; 2; 3]));\n  (assert ((candidate 7) = [7; 8; 9]));\n  (assert ((candidate 5) = [5; 6; 7]));\n  (assert ((candidate 20) = [20; 21; 22]));\n  (assert ((candidate 100) = [100; 101; 102]));\n  (assert ((candidate 17) = [17; 18; 19]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_32048_color_str_yellow", "language": "ml", "prompt": "(**Color string YELLOW for writing to STDIN.\n*)\nlet color_str_yellow (s : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_32048_color_str_yellow.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = color_str_yellow in\n  (assert ((candidate \"hello\") = \"\u001b[93mhello\u001b[00m\"));\n  (assert ((candidate \"foo\") = \"\u001b[93mfoo\u001b[00m\"));\n  (assert ((candidate \"hello\") = \"\u001b[93mhello\u001b[00m\"));\n  (assert ((candidate \"\u2603\") = \"\u001b[93m\u2603\u001b[00m\"));\n  (assert ((candidate str 1) = \"\u001b[93m1\u001b[00m\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_321019_decompose_dateint", "language": "ml", "prompt": "(**Decomposes the given dateint into its year, month and day components.\nArguments\n---------\ndateint : int\n * An integer object decipting a specific calendaric day; e.g. 20161225.\nReturns\n-------\nyear : int\n * The year component of the given dateint.\nmonth : int\n * The month component of the given dateint.\nday : int\n * The day component of the given dateint.\n*)\nlet decompose_dateint (dateint : int) :  int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_321019_decompose_dateint.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = decompose_dateint in\n  (assert ((candidate 20161225) = (2016, 12, 25)));\n  (assert ((candidate 19860915) = (1986, 9, 15)));\n  (assert ((candidate 19000101) = (1900, 1, 1)));\n  (assert ((candidate 20120229) = (2012, 2, 29)));\n  (assert ((candidate 20160229) = (2016, 2, 29)));\n  (assert ((candidate 19130814) = (1913, 8, 14)));\n  (assert ((candidate 10102030) = (1010, 20, 30)));\n  (assert ((candidate 20101231) = (2010, 12, 31)));\n  (assert ((candidate 20210615) = (2021, 6, 15)));\n  (assert ((candidate 20110101) = (2011, 1, 1)));\n  (assert ((candidate 19000229) = (1900, 2, 29)));\n  (assert ((candidate 20000229) = (2000, 2, 29)));\n  (assert ((candidate 21000229) = (2100, 2, 29)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_321523_get_voxel_coord", "language": "ml", "prompt": "(**Based on provided integer voxel index and lateral size of the 3D neighborhood, determines the coordinates of the\nvoxel in the neighborhood\n:type index: int\n:param index:\n:type s: int\n:param s:\n:return:\n*)\nlet get_voxel_coord (index : int) (s : int) :  int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_321523_get_voxel_coord.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_voxel_coord in\n  (assert ((candidate 14 4) = (2, 3, 0)));\n  (assert ((candidate 16 3) = (1, 2, 1)));\n  (assert ((candidate 2 4) = (2, 0, 0)));\n  (assert ((candidate 4 3) = (1, 1, 0)));\n  (assert ((candidate 14 3) = (2, 1, 1)));\n  (assert ((candidate 7 3) = (1, 2, 0)));\n  (assert ((candidate 15 3) = (0, 2, 1)));\n  (assert ((candidate 11 3) = (2, 0, 1)));\n  (assert ((candidate 8 3) = (2, 2, 0)));\n  (assert ((candidate 5 3) = (2, 1, 0)));\n  (assert ((candidate 10 3) = (1, 0, 1)));\n  (assert ((candidate 6 4) = (2, 1, 0)));\n  (assert ((candidate 1 3) = (1, 0, 0)));\n  (assert ((candidate 1 4) = (1, 0, 0)));\n  (assert ((candidate 0 3) = (0, 0, 0)));\n  (assert ((candidate 3 4) = (3, 0, 0)));\n  (assert ((candidate 0 4) = (0, 0, 0)));\n  (assert ((candidate 10 4) = (2, 2, 0)));\n  (assert ((candidate 5 4) = (1, 1, 0)));\n  (assert ((candidate 3 3) = (0, 1, 0)));\n  (assert ((candidate 12 3) = (0, 1, 1)));\n  (assert ((candidate 9 4) = (1, 2, 0)));\n  (assert ((candidate 3 2) = (1, 1, 0)));\n  (assert ((candidate 2 3) = (2, 0, 0)));\n  (assert ((candidate 13 3) = (1, 1, 1)));\n  (assert ((candidate 16 4) = (0, 0, 1)));\n  (assert ((candidate 4 4) = (0, 1, 0)));\n  (assert ((candidate 12 4) = (0, 3, 0)));\n  (assert ((candidate 7 4) = (3, 1, 0)));\n  (assert ((candidate 9 3) = (0, 0, 1)));\n  (assert ((candidate 11 4) = (3, 2, 0)));\n  (assert ((candidate 8 4) = (0, 2, 0)));\n  (assert ((candidate 13 4) = (1, 3, 0)));\n  (assert ((candidate 6 3) = (0, 2, 0)));\n  (assert ((candidate 15 4) = (3, 3, 0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_321626_truncate_string", "language": "ml", "prompt": "(**Truncate a string.\nParams:\n- in_string: (type: string) string to truncate.\n- length: (type: int) length of output string.\nReturns:\n- result: (type: string) truncated string.\n*)\nlet truncate_string (input_string : string) (length : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_321626_truncate_string.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = truncate_string in\n  (assert ((candidate \"1234567890\" 10) = \"1234567890\"));\n  (assert ((candidate \"12345678901\" 11) = \"12345678901\"));\n  (assert ((candidate \"12345678901\" 12) = \"12345678901\"));\n  (assert ((candidate \"a\" 1) = \"a\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_321996_join_env", "language": "ml", "prompt": "(**Convert a single intercepted environment variable from dictionary to envs.txt line.\n*)\nlet join_env (env : (string, string) list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_321996_join_env.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = join_env in\n  (assert ((candidate [(\"a\", \"b\")]) = \"a=b\"));\n  (assert ((candidate [(\"USER\", \"root\")]) = \"USER=root\"));\n  (assert ((candidate [(\"a\", \"1\")]) = \"a=1\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_322935_isNarcissistic", "language": "ml", "prompt": "(**Returns whether or not a given number is Narcissistic.\nA positive integer is called a narcissistic number if it\nis equal to the sum of its own digits each raised to the\npower of the number of digits.\nExample: 153 is narcissistic because 1^3 + 5^3 + 3^3 = 1 + 125 + 27 = 153.\nNote that by this definition all single digit numbers are narcissistic.\n*)\nlet isNarcissistic (x : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_322935_isNarcissistic.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = isNarcissistic in\n  (assert ((candidate 1) = true));\n  (assert ((candidate 10000000) = false));\n  (assert ((candidate 9926315) = true));\n  (assert ((candidate 0) = true));\n  (assert ((candidate 370) = true));\n  (assert ((candidate 153) = true));\n  (assert ((candidate 122) = false));\n  (assert ((candidate 409) = false));\n  (assert ((candidate 4888) = false));\n  (assert ((candidate 88) = false));\n  (assert ((candidate 371) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_323207_validate_color", "language": "ml", "prompt": "(**Check whether or not an RGB tuple is acceptable.\n*)\nlet validate_color (color :  int * int * int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_323207_validate_color.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = validate_color in\n  (assert ((candidate (0, 0, 255)) = true));\n  (assert ((candidate (255, 255, 0)) = true));\n  (assert ((candidate ((~10), 255, 255)) = false));\n  (assert ((candidate (1, 2, 3)) = true));\n  (assert ((candidate (10, 10, 255)) = true));\n  (assert ((candidate (0, (~20), 0)) = false));\n  (assert ((candidate (255, 256, 255)) = false));\n  (assert ((candidate (255, 255, 255)) = true));\n  (assert ((candidate (255, 10, 10)) = true));\n  (assert ((candidate (254, 253, 252)) = true));\n  (assert ((candidate (0, 255, 0)) = true));\n  (assert ((candidate (10, 0, 255)) = true));\n  (assert ((candidate (0, 10, 0)) = true));\n  (assert ((candidate (255, 255, (~10))) = false));\n  (assert ((candidate (255, 0, 0)) = true));\n  (assert ((candidate (10, 255, 10)) = true));\n  (assert ((candidate (255, 10, 255)) = true));\n  (assert ((candidate (10, 255, 255)) = true));\n  (assert ((candidate (10, 255, 0)) = true));\n  (assert ((candidate (255, 255, 254)) = true));\n  (assert ((candidate (0, 255, 255)) = true));\n  (assert ((candidate (10, 10, 10)) = true));\n  (assert ((candidate (255, 0, 255)) = true));\n  (assert ((candidate (0, 255, 10)) = true));\n  (assert ((candidate (0, 10, 255)) = true));\n  (assert ((candidate (0, 0, 0)) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_323236_int2signed", "language": "ml", "prompt": "(**Given a Python integer, return its 2s complement \nword representation.\n*)\nlet int2signed (num : int) (nbits : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_323236_int2signed.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = int2signed in\n  (assert ((candidate (~20)) = 4294967276));\n  (assert ((candidate (~1) 2) = 3));\n  (assert ((candidate 1 2) = 1));\n  (assert ((candidate 2 2) = 2));\n  (assert ((candidate 32767) = 32767));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 65535) = 65535));\n  (assert ((candidate 2147483647) = 2147483647));\n  (assert ((candidate (~2147483648)) = 2147483648));\n  (assert ((candidate 42) = 42));\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 0 3) = 0));\n  (assert ((candidate 1 3) = 1));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate (~1) 3) = 7));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_323414_urlstring", "language": "ml", "prompt": "(**Forms a string with the full url from a filename and base url.\nKeyword arguments:\nf - filename\nbaseUrl - address of the root of the website\n*)\nlet urlstring (f : string) (baseUrl : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_323414_urlstring.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = urlstring in\n  (assert ((candidate \"/images/google.png\" \"http://code.google.com\") = \"http://code.google.com/images/google.png\"));\n  (assert ((candidate \"./images/google.png\" \"http://code.google.com/\") = \"http://code.google.com/images/google.png\"));\n  (assert ((candidate \"images/google.png\" \"http://code.google.com/\") = \"http://code.google.com/images/google.png\"));\n  (assert ((candidate \"about.html\" \"http://code.google.com\") = \"http://code.google.com/about.html\"));\n  (assert ((candidate \"./my_page.html\" \"http://codeskulptor.org/\") = \"http://codeskulptor.org/my_page.html\"));\n  (assert ((candidate \"/my_page.html\" \"http://codeskulptor.org\") = \"http://codeskulptor.org/my_page.html\"));\n  (assert ((candidate \"./a/b/c/\" \"http://example.com\") = \"http://example.com/a/b/c/\"));\n  (assert ((candidate \"my_page.html\" \"http://codeskulptor.org/\") = \"http://codeskulptor.org/my_page.html\"));\n  (assert ((candidate \"a/b/c/index.html\" \"http://example.com/\") = \"http://example.com/a/b/c/\"));\n  (assert ((candidate \"images/google.png\" \"http://code.google.com\") = \"http://code.google.com/images/google.png\"));\n  (assert ((candidate \"./about.html\" \"http://code.google.com\") = \"http://code.google.com/about.html\"));\n  (assert ((candidate \"./a/b/c/\" \"http://example.com/\") = \"http://example.com/a/b/c/\"));\n  (assert ((candidate \"./images/google.png\" \"http://code.google.com\") = \"http://code.google.com/images/google.png\"));\n  (assert ((candidate \"index.html\" \"http://example.com/\") = \"http://example.com/\"));\n  (assert ((candidate \"./my_page.html\" \"http://codeskulptor.org\") = \"http://codeskulptor.org/my_page.html\"));\n  (assert ((candidate \"my_page.html\" \"http://codeskulptor.org\") = \"http://codeskulptor.org/my_page.html\"));\n  (assert ((candidate \"/images/google.png\" \"http://code.google.com/\") = \"http://code.google.com/images/google.png\"));\n  (assert ((candidate \"./a/b/c/index.html\" \"http://example.com/\") = \"http://example.com/a/b/c/\"));\n  (assert ((candidate \"/my_page.html\" \"http://codeskulptor.org/\") = \"http://codeskulptor.org/my_page.html\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_323665_ini_value", "language": "ml", "prompt": "(**Strips key= from key=value from ini configuration data\n*)\nlet ini_value (key_value : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_323665_ini_value.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = ini_value in\n  (assert ((candidate \"key=value with spaces and\nnewlines\") = \"value with spaces and\nnewlines\"));\n  (assert ((candidate \"key=value with spaces and\ttabs\") = \"value with spaces and\ttabs\"));\n  (assert ((candidate \"key=value\twith\ttabs\") = \"value\twith\ttabs\"));\n  (assert ((candidate \"key=value\") = \"value\"));\n  (assert ((candidate \"key=value\n\nwith\n\nnewlines\n\n\") = \"value\n\nwith\n\nnewlines\n\n\"));\n  (assert ((candidate \"key=value with spaces\") = \"value with spaces\"));\n  (assert ((candidate \"key=value\nwith\nnewlines\") = \"value\nwith\nnewlines\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_325056_toggle_collapse", "language": "ml", "prompt": "(**collapse the side bar\n*)\nlet toggle_collapse (n : int) (is_open : bool) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_325056_toggle_collapse.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = toggle_collapse in\n  (assert ((candidate 3 false) = true));\n  (assert ((candidate 5 false) = true));\n  (assert ((candidate 2 true) = false));\n  (assert ((candidate 1 true) = false));\n  (assert ((candidate 0 false) = false));\n  (assert ((candidate 4 false) = true));\n  (assert ((candidate 1 false) = true));\n  (assert ((candidate 3 true) = false));\n  (assert ((candidate 2 false) = true));\n  (assert ((candidate 4 true) = false));\n  (assert ((candidate 5 true) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_325573_format_data", "language": "ml", "prompt": "(**Takes the account data and returns in a printable format.\n*)\nlet format_data (account : (string, string) list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_325573_format_data.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = format_data in\n  (assert ((candidate [(\"name\", \"John\"); (\"description\", \"Doctor\"); (\"country\", \"USA\")]) = \"John, a Doctor, from USA\"));\n  (assert ((candidate [(\"name\", \"Alice\"); (\"description\", \"A normal account\"); (\"country\", \"Canada\")]) = \"Alice, a A normal account, from Canada\"));\n  (assert ((candidate [(\"name\", \"Bob\"); (\"description\", \"The bad account\"); (\"country\", \"France\")]) = \"Bob, a The bad account, from France\"));\n  (assert ((candidate [(\"name\", \"Charlie\"); (\"description\", \"An alright account\"); (\"country\", \"Mexico\")]) = \"Charlie, a An alright account, from Mexico\"));\n  (assert ((candidate [(\"name\", \"\"); (\"description\", \"Doctor\"); (\"country\", \"USA\")]) = \", a Doctor, from USA\"));\n  (assert ((candidate [(\"name\", \"John\"); (\"description\", \"Doctor\"); (\"country\", \"\")]) = \"John, a Doctor, from \"));\n  (assert ((candidate [(\"name\", \"<NAME>\"); (\"description\", \"Super Mario Maker 2\"); (\"country\", \"Japan\")]) = \"<NAME>, a Super Mario Maker 2, from Japan\"));\n  (assert ((candidate [(\"name\", \"Bob\"); (\"description\", \"The bad account\"); (\"country\", \"France\")]) = \"Bob, a The bad account, from France\"));\n  (assert ((candidate [(\"name\", \"Alice\"); (\"description\", \"A normal account\"); (\"country\", \"Canada\")]) = \"Alice, a A normal account, from Canada\"));\n  (assert ((candidate [(\"name\", \"Charlie\"); (\"description\", \"An alright account\"); (\"country\", \"Mexico\")]) = \"Charlie, a An alright account, from Mexico\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_325906_strQ2B", "language": "ml", "prompt": "(**Converting full-width characters to half-width characters\n*)\nlet strQ2B (ustring : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_325906_strQ2B.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = strQ2B in\n  (assert ((candidate \"\uff54\uff45\uff53\uff54\") = \"test\"));\n  (assert ((candidate \"\uff21\uff22\uff23\") = \"ABC\"));\n  (assert ((candidate \"\uff41\uff42\uff43\uff21\uff22\uff23\") = \"abcABC\"));\n  (assert ((candidate \"\uff11\uff12\uff13456\") = \"123456\"));\n  (assert ((candidate \"\uff10\uff11\uff12\uff13\") = \"0123\"));\n  (assert ((candidate candidate \"abc\") = \"abc\"));\n  (assert ((candidate \"\uff05\uff41\uff42\uff43\uff44\uff45\uff46\uff47\uff48\uff49\uff4a\uff4b\uff4c\uff4d\uff4e\uff4f\uff50\uff51\uff52\uff53\uff54\uff55\uff56\uff57\uff58\uff59\uff5a\") = \"%abcdefghijklmnopqrstuvwxyz\"));\n  (assert ((candidate \"\uff11\uff12\uff13\") = \"123\"));\n  (assert ((candidate \"\uff21\uff22\uff23\uff10\uff11\uff12\uff13\") = \"ABC0123\"));\n  (assert ((candidate \"123\") = \"123\"));\n  (assert ((candidate \"\uff21\uff22\uff23\") = \"ABC\"));\n  (assert ((candidate \"\uff41\uff42\uff43\uff41\uff42\uff43\uff21\uff22\uff23\uff21\uff22\uff23\") = \"abcabcABCABC\"));\n  (assert ((candidate \"abc\") = \"abc\"));\n  (assert ((candidate \"\u554a\u9f44\u4e02\u72db\u72dc\") = \"\u554a\u9f44\u4e02\u72db\u72dc\"));\n  (assert ((candidate \"\uff41\uff42\uff43\") = \"abc\"));\n  (assert ((candidate \"\uff3a\uff41\uff42\uff43\uff11\uff12\uff13\") = \"Zabc123\"));\n  (assert ((candidate \"abc\") = \"abc\"));\n  (assert ((candidate \"\u4f60\u597d\") = \"\u4f60\u597d\"));\n  (assert ((candidate \"\uff21\uff22\uff23\") = \"ABC\"));\n  (assert ((candidate \"\uff41\uff42\uff43\uff41\uff42\uff43\") = \"abcabc\"));\n  (assert ((candidate \"\uff41\uff42\uff43\") = \"abc\"));\n  (assert ((candidate \"\uff41\uff42\uff43\uff10\uff11\uff12\uff13\") = \"abc0123\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_326010_job_id_from_reponse", "language": "ml", "prompt": "(**Return a string representation of integer job id from the qsub response to stdout\n*)\nlet job_id_from_reponse (text : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_326010_job_id_from_reponse.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = job_id_from_reponse in\n  (assert ((candidate \"Your job-array 4321.1-3:1 (\"wrfpost\") has been submitted\") = \"4321\"));\n  (assert ((candidate \"Your job-array 4321.1-3:1 ('wrfpost') has been submitted\") = \"4321\"));\n  (assert ((candidate \"Your job 4321.1 (\"wrfpost\") has been submitted\") = \"4321\"));\n  (assert ((candidate \"Your job 3681 (\"TEST\") has been submitted\") = \"3681\"));\n  (assert ((candidate \"Your job-array 4321.1-3:1 (\"wrfpost\") has been submitted\") = \"4321\"));\n  (assert ((candidate \"Your job 3681 () has been submitted\") = \"3681\"));\n  (assert ((candidate \"Your job 3681 (\"TEST\") has been submitted\") = \"3681\"));\n  (assert ((candidate \"Your job 3681 ('TEST') has been submitted\") = \"3681\"));\n  (assert ((candidate \"Your job 4321 (\"wrfpost\") has been submitted\") = \"4321\"));\n  (assert ((candidate \"Your job-array 4321.1-3:1 (\"wrfpost\") has been submitted\") = \"4321\"));\n  (assert ((candidate \"Your job 3681 (\"TEST\") has been submitted\") = \"3681\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_326484_vectorize", "language": "ml", "prompt": "(**Converts a list of words into a list of frequency position numbers.\nArgs:\n * dictionary(dict): Dictionary containing the words in the vocabulary together\n * with their frequency position.\n * words(list): List of words that are to be converted.\nReturns:\n * A list of frequency position numbers in place of the actual words in the list.\n*)\nlet vectorize (dictionary : (string, int) list) (words : string list) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_326484_vectorize.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = vectorize in\n  (assert ((candidate dict [(\"first\", 1); (\"second\", 2)] [\"first\"; \"second\"; \"third\"]) = [1; 2; 0]));\n  (assert ((candidate dict [(\"first\", 0); (\"second\", 0)] [\"first\"; \"second\"]) = [0; 0]));\n  (assert ((candidate dict [(\"first\", 0); (\"second\", 0)] [\"first\"; \"second\"; \"third\"]) = [0; 0; 0]));\n  (assert ((candidate dict [(\"first\", 1); (\"second\", 2)] []) = []));\n  (assert ((candidate dict  []) = []));\n  (assert ((candidate dict [(\"first\", 1); (\"second\", 2)] [\"first\"; \"first\"]) = [1; 1]));\n  (assert ((candidate dict  [\"first\"; \"second\"]) = [0; 0]));\n  (assert ((candidate dict [(\"first\", 0)] []) = []));\n  (assert ((candidate dict [(\"first\", 1); (\"second\", 2)] [\"first\"; \"first\"; \"third\"]) = [1; 1; 0]));\n  (assert ((candidate dict [(\"first\", 1); (\"second\", 2)] [\"first\"; \"second\"]) = [1; 2]));\n  (assert ((candidate dict [(\"first\", 0)] [\"first\"; \"second\"]) = [0; 0]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_327793_encode_pdf", "language": "ml", "prompt": "(**Encode the probability density function.\n*)\nlet encode_pdf (pdf :  int * int list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_327793_encode_pdf.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = encode_pdf in\n  (assert ((candidate [(1, 1)]) = \"[(1, 1)]\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_327885_is_between_strict", "language": "ml", "prompt": "(**Shorthand for `(lo < val < hi) or (lo > val > hi)`.\n*)\nlet is_between_strict (lo : int) (val : int) (hi : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_327885_is_between_strict.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_between_strict in\n  (assert ((candidate 2 3 2) = false));\n  (assert ((candidate 3 2 3) = false));\n  (assert ((candidate 5 10 10) = false));\n  (assert ((candidate 2 1 2) = false));\n  (assert ((candidate 1 3 2) = false));\n  (assert ((candidate 3 3 1) = false));\n  (assert ((candidate 3 1 3) = false));\n  (assert ((candidate 0 1 2) = true));\n  (assert ((candidate 3 2 5) = false));\n  (assert ((candidate 2 2 3) = false));\n  (assert ((candidate 3 3 5) = false));\n  (assert ((candidate 3 4 5) = true));\n  (assert ((candidate 1 3 3) = false));\n  (assert ((candidate 0 1 (~1)) = false));\n  (assert ((candidate 3 1 1) = false));\n  (assert ((candidate 1 2 3) = true));\n  (assert ((candidate 10 10 15) = false));\n  (assert ((candidate 3 6 5) = false));\n  (assert ((candidate 1 3 1) = false));\n  (assert ((candidate 1 2 2) = false));\n  (assert ((candidate 5 6 3) = false));\n  (assert ((candidate 1 4 3) = false));\n  (assert ((candidate 5 10 5) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_328378_parse_line", "language": "ml", "prompt": "(**Takes a line of space seperated values, returns the values in a list.\n*)\nlet parse_line (line : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_328378_parse_line.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_line in\n  (assert ((candidate \"1111 22\") = [\"1111\"; \"22\"]));\n  (assert ((candidate \"1111 22 3\") = [\"1111\"; \"22\"; \"3\"]));\n  (assert ((candidate \"   This is a line with 10 spaces in front of it.   \") = [\"This\"; \"is\"; \"a\"; \"line\"; \"with\"; \"10\"; \"spaces\"; \"in\"; \"front\"; \"of\"; \"it.\"]));\n  (assert ((candidate \"This is a line without spaces.\") = [\"This\"; \"is\"; \"a\"; \"line\"; \"without\"; \"spaces.\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_328945_loop_add", "language": "ml", "prompt": "(**An imperative implementation using a loop and in-place mutation.\n*)\nlet loop_add (x : int) (y : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_328945_loop_add.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = loop_add in\n  (assert ((candidate 123 456) = 579));\n  (assert ((candidate 2 2) = 4));\n  (assert ((candidate (~700) 300) = (~400)));\n  (assert ((candidate (~123) 456) = 333));\n  (assert ((candidate 0 100) = 100));\n  (assert ((candidate 3 2) = 5));\n  (assert ((candidate 1 1) = 2));\n  (assert ((candidate 0 1) = 1));\n  (assert ((candidate 10 0) = 10));\n  (assert ((candidate 1 2) = 3));\n  (assert ((candidate 2 3) = 5));\n  (assert ((candidate 1000 0) = 1000));\n  (assert ((candidate (~10) 0) = (~10)));\n  (assert ((candidate (~10) 1) = (~9)));\n  (assert ((candidate 0 1000) = 1000));\n  (assert ((candidate 1 0) = 1));\n  (assert ((candidate 0 0) = 0));\n  (assert ((candidate 100 20) = 120));\n  (assert ((candidate (~1) 1000) = 999));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_329540_invertEvent", "language": "ml", "prompt": "(**Return the inverted event.\n*)\nlet invertEvent (e : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_329540_invertEvent.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = invertEvent in\n  (assert ((candidate 0) = 1));\n  (assert ((candidate 1) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_33050_check_event_attrs", "language": "ml", "prompt": "(**Verify the event has the expected attributes for Flog Apache logs and custom app logs\n*)\nlet check_event_attrs (attrs : (string, string) list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_33050_check_event_attrs.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = check_event_attrs in\n  (assert ((candidate [(\"id\", \"1\"); (\"source_component\", \"1.2.3.4\")]) = false));\n  (assert ((candidate [(\"app\", \"customApp\"); (\"id\", \"99999\"); (\"activity_type\", \"ssh\"); (\"categories\", \"auth, ssh\"); (\"dest_country\", \"US\"); (\"dest_ip\", \"192.168.1.1\"); (\"dest_port\", \"3389\"); (\"device_type\", \"desktop\"); (\"domain\", \"myDomain.com\"); (\"forwarder\", \"my.forwarder.net\"); (\"is_phishing_domain\", \"False\"); (\"is_ransomware_dest_ip\", \"False\"); (\"is_ransomware_src_ip\", \"False\"); (\"is_threat_dest_ip\", \"False\"); (\"is_threat_src_ip\", \"False\"); (\"outcome\", \"failure\"); (\"source_component\", \"ssh-desktop\"); (\"src_country\", \"US\"); (\"src_ip\", \"192.168.1.2\"); (\"src_port\", \"53269\"); (\"subcategory\", \"auth, ssh\"); (\"username\", \"joeuser\"); (\"version\", \"0.1.0\")]) = true));\n  (assert ((candidate [(\"app\", \"customApp\"); (\"activity_type\", \"activity\"); (\"categories\", \"cat1\"); (\"dest_country\", \"US\"); (\"dest_ip\", \"172.16.17.32\"); (\"dest_port\", \"35084\"); (\"device_type\", \"Laptop\"); (\"domain\", \"example.com\"); (\"forwarder\", \"forwarder1\"); (\"id\", \"123\"); (\"is_phishing_domain\", \"False\"); (\"is_ransomware_dest_ip\", \"False\"); (\"is_ransomware_src_ip\", \"False\"); (\"is_threat_dest_ip\", \"False\"); (\"is_threat_src_ip\", \"False\"); (\"outcome\", \"success\"); (\"source_component\", \"source_component1\"); (\"src_country\", \"US\"); (\"src_ip\", \"172.16.17.32\"); (\"src_port\", \"443\"); (\"subcategory\", \"subcategory1\"); (\"username\", \"username1\"); (\"version\", \"version1\")]) = true));\n  (assert ((candidate [(\"dataset\", \"accesslog\"); (\"agent\", \"client\"); (\"authUser\", \"joeuser\"); (\"bytes\", \"1234\"); (\"ip\", \"192.168.1.1\"); (\"protocol\", \"http\"); (\"referrer\", \"http://myDomain.com/login\"); (\"status\", \"404\"); (\"uriPath\", \"/login\"); (\"user\", \"joeuser\")]) = true));\n  (assert ((candidate [(\"app\", \"customApp\"); (\"activity_type\", \"fileDownload\"); (\"categories\", \"fileDownload\"); (\"dest_country\", \"US\"); (\"dest_ip\", \"1.2.3.4\"); (\"dest_port\", \"80\"); (\"device_type\", \"server\"); (\"domain\", \"example.com\"); (\"forwarder\", \"filebeat-8.0.0-darwin-x86_64\"); (\"id\", \"80071\"); (\"is_phishing_domain\", \"no\"); (\"is_ransomware_dest_ip\", \"no\"); (\"is_ransomware_src_ip\", \"no\"); (\"is_threat_dest_ip\", \"no\"); (\"is_threat_src_ip\", \"no\"); (\"outcome\", \"success\"); (\"source_component\", \"Falcon\"); (\"src_country\", \"US\"); (\"src_ip\", \"1.2.3.4\"); (\"src_port\", \"5672\"); (\"subcategory\", \"File Downloads\"); (\"username\", \"user\"); (\"version\", \"20.2.0.19344\")]) = true));\n  (assert ((candidate [(\"id\", \"1\"); (\"app\", \"customApp\"); (\"source_component\", \"1.2.3.4\"); (\"outcome\", \"succeded\")]) = false));\n  (assert ((candidate [(\"id\", \"1\"); (\"source_component\", \"1.2.3.4\"); (\"outcome\", \"succeded\")]) = false));\n  (assert ((candidate [(\"id\", \"1\"); (\"app\", \"customApp\"); (\"outcome\", \"succeded\")]) = false));\n  (assert ((candidate [(\"id\", \"1\"); (\"app\", \"customApp\")]) = false));\n  (assert ((candidate [(\"id\", \"1\"); (\"outcome\", \"succeded\")]) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_330601_makeHtmlText", "language": "ml", "prompt": "(**add formatting for an html textarea to a string\n*)\nlet makeHtmlText (str_in : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_330601_makeHtmlText.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = makeHtmlText in\n  (assert ((candidate \"I eat\ncats.\") = \"<textarea rows=\"2\" cols=\"100\" style=\"border:double 2px blue;\">I eat\ncats.</textarea>\"));\n  (assert ((candidate \"I eat cats!\") = \"<textarea rows=\"2\" cols=\"100\" style=\"border:double 2px blue;\">I eat cats!</textarea>\"));\n  (assert ((candidate \"hello world\") = \"<textarea rows=\"2\" cols=\"100\" style=\"border:double 2px blue;\">hello world</textarea>\"));\n  (assert ((candidate \"It was the best of times, it was the worst of times. It was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way \u2013 in short, the period was so far like the present period, that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only...\") = \"<textarea rows=\"2\" cols=\"100\" style=\"border:double 2px blue;\">It was the best of times, it was the worst of times. It was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way \u2013 in short, the period was so far like the present period, that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only...</textarea>\"));\n  (assert ((candidate \"hello world\") = \"<textarea rows=\"2\" cols=\"100\" style=\"border:double 2px blue;\">hello world</textarea>\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_331914_is_tracked_zone", "language": "ml", "prompt": "(**Is the root domain for the provided cname one of the known domains?\n*)\nlet is_tracked_zone (cname : string) (zones : string list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_331914_is_tracked_zone.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_tracked_zone in\n  (assert ((candidate \"example.gov\" [\"example.org\"; \"example.net\"; \"example.biz\"; \"example.gov\"]) = true));\n  (assert ((candidate \"example.net\" [\"example.org\"; \"example.net\"; \"example.biz\"; \"example.gov\"]) = true));\n  (assert ((candidate \"example.com\" [\"example.org\"; \"example.net\"; \"example.biz\"; \"example.gov\"]) = false));\n  (assert ((candidate \"example.com\" [\"example.org\"; \"example.net\"; \"example.biz\"]) = false));\n  (assert ((candidate \"example.com\" [\"example.com\"; \"example.org\"; \"example.net\"; \"example.biz\"]) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_332162_dict_bool", "language": "ml", "prompt": "(**Implementation of `dict_bool`.\n*)\nlet dict_bool (x : (string, int) list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_332162_dict_bool.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = dict_bool in\n  (assert ((candidate dict ) = false));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3)]) = true));\n  (assert ((candidate [(\"a\", 1)]) = true));\n  (assert ((candidate [(\"a\", 1)]) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_332746_month_str", "language": "ml", "prompt": "(**Returns the string e.g. 'JAN' corresponding to month\n*)\nlet month_str (month : int) (upper : bool) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_332746_month_str.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = month_str in\n  (assert ((candidate 5 false) = \"may\"));\n  (assert ((candidate 8) = \"AUG\"));\n  (assert ((candidate 1) = \"JAN\"));\n  (assert ((candidate 6) = \"JUN\"));\n  (assert ((candidate 4 false) = \"apr\"));\n  (assert ((candidate 10 false) = \"oct\"));\n  (assert ((candidate 12) = \"DEC\"));\n  (assert ((candidate 9 true) = \"SEP\"));\n  (assert ((candidate 3 false) = \"mar\"));\n  (assert ((candidate 6 false) = \"jun\"));\n  (assert ((candidate 7) = \"JUL\"));\n  (assert ((candidate 3 true) = \"MAR\"));\n  (assert ((candidate 1 true) = \"JAN\"));\n  (assert ((candidate 6 true) = \"JUN\"));\n  (assert ((candidate 3) = \"MAR\"));\n  (assert ((candidate 2 false) = \"feb\"));\n  (assert ((candidate 6) = \"JUN\"));\n  (assert ((candidate 9 false) = \"sep\"));\n  (assert ((candidate 11) = \"NOV\"));\n  (assert ((candidate 1 false) = \"jan\"));\n  (assert ((candidate 9) = \"SEP\"));\n  (assert ((candidate 10) = \"OCT\"));\n  (assert ((candidate 11 false) = \"nov\"));\n  (assert ((candidate 7 true) = \"JUL\"));\n  (assert ((candidate 2) = \"FEB\"));\n  (assert ((candidate 12 false) = \"dec\"));\n  (assert ((candidate 8 false) = \"aug\"));\n  (assert ((candidate 4) = \"APR\"));\n  (assert ((candidate 7 false) = \"jul\"));\n  (assert ((candidate 5) = \"MAY\"));\n  (assert ((candidate 12) = \"DEC\"));\n  (assert ((candidate 8 true) = \"AUG\"));\n  (assert ((candidate 5 true) = \"MAY\"));\n  (assert ((candidate 1) = \"JAN\"));\n  (assert ((candidate 4 true) = \"APR\"));\n  (assert ((candidate 7) = \"JUL\"));\n  (assert ((candidate 2 true) = \"FEB\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_333098_to_bool", "language": "ml", "prompt": "(**Helper function for translating strings into booleans\n@see test/TestReadConfig.py\n*)\nlet to_bool (value : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_333098_to_bool.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = to_bool in\n  (assert ((candidate \"f\") = false));\n  (assert ((candidate \"y\") = true));\n  (assert ((candidate \"TRUE\") = true));\n  (assert ((candidate \"true\") = true));\n  (assert ((candidate \"false\") = false));\n  (assert ((candidate \"n\") = false));\n  (assert ((candidate \"N\") = false));\n  (assert ((candidate \"0\") = false));\n  (assert ((candidate \"true\") = true));\n  (assert ((candidate \"f\") = false));\n  (assert ((candidate \"N\") = false));\n  (assert ((candidate \"y\") = true));\n  (assert ((candidate \"T\") = true));\n  (assert ((candidate \"t\") = true));\n  (assert ((candidate \"1\") = true));\n  (assert ((candidate \"n\") = false));\n  (assert ((candidate \"F\") = false));\n  (assert ((candidate \"1\") = true));\n  (assert ((candidate \"Y\") = true));\n  (assert ((candidate \"f\") = false));\n  (assert ((candidate \"1\") = true));\n  (assert ((candidate \"0\") = false));\n  (assert ((candidate \"y\") = true));\n  (assert ((candidate \"1\") = true));\n  (assert ((candidate \"FALSE\") = false));\n  (assert ((candidate \"T\") = true));\n  (assert ((candidate \"y\") = true));\n  (assert ((candidate \"t\") = true));\n  (assert ((candidate \"t\") = true));\n  (assert ((candidate \"n\") = false));\n  (assert ((candidate \"false\") = false));\n  (assert ((candidate \"Y\") = true));\n  (assert ((candidate \"F\") = false));\n  (assert ((candidate \"t\") = true));\n  (assert ((candidate \"true\") = true));\n  (assert ((candidate \"0\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_333149_manhattan_distance", "language": "ml", "prompt": "(**Number of steps between two squares allowing only\nup, down, left and right steps.\n*)\nlet manhattan_distance (xy_a :  int * int) (xy_b :  int * int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_333149_manhattan_distance.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = manhattan_distance in\n  (assert ((candidate (0, 0) (1, 0)) = 1));\n  (assert ((candidate (0, 0) (1, 1)) = 2));\n  (assert ((candidate (0, 0) (0, (~1))) = 1));\n  (assert ((candidate (3, 2) (2, 3)) = 2));\n  (assert ((candidate (0, 0) (1, 0)) = 1));\n  (assert ((candidate (0, 0) (0, 0)) = 0));\n  (assert ((candidate (0, 0) (0, 1)) = 1));\n  (assert ((candidate (3, 4) (2, 3)) = 2));\n  (assert ((candidate (0, 0) (1, (~1))) = 2));\n  (assert ((candidate (0, 0) (1, 1)) = 2));\n  (assert ((candidate (1, 1) (2, 2)) = 2));\n  (assert ((candidate (2, 2) (2, 2)) = 0));\n  (assert ((candidate ((~2), 2) ((~4), (~2))) = 6));\n  (assert ((candidate (0, 0) (2, 2)) = 4));\n  (assert ((candidate (0, 0) (0, 0)) = 0));\n  (assert ((candidate (2, 3) (3, 4)) = 2));\n  (assert ((candidate (0, 0) (2, 2)) = 4));\n  (assert ((candidate (0, 0) (0, 1)) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_333447_urlsafe_address", "language": "ml", "prompt": "(**Make an address safe to use in a URL.\nArgs:\n * address: A tuple of address information.\nReturns:\n * A 2-tuple of url-safe (address, port)\n*)\nlet urlsafe_address (address :  string * int) :  string * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_333447_urlsafe_address.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = urlsafe_address in\n  (assert ((candidate (\"localhost\", 80)) = (\"localhost\", 80)));\n  (assert ((candidate (\"localhost\", 8080)) = (\"localhost\", 8080)));\n  (assert ((candidate (\"example.com\", 8080)) = (\"example.com\", 8080)));\n  (assert ((candidate (\"::1\", 80)) = (\"::1\", 80)));\n  (assert ((candidate (\"127.0.0.1\", 80)) = (\"127.0.0.1\", 80)));\n  (assert ((candidate (\"example.com\", 80)) = (\"example.com\", 80)));\n  (assert ((candidate (\"127.0.0.1\", 8080)) = (\"127.0.0.1\", 8080)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_333685_get_name", "language": "ml", "prompt": "(**get name from idx2name\n*)\nlet get_name (idx2name : (string, string) list) (info : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_333685_get_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_name in\n  (assert ((candidate ) = \"a#b#c\"));\n  (assert ((candidate ) = \"a\"));\n  (assert ((candidate [(\"3\", \"3\"); (\"4\", \"4\")] \"3\") = \"3\"));\n  (assert ((candidate [(\"1\", \"tom\"); (\"2\", \"dick\"); (\"3\", \"harry\")] \"3\") = \"harry\"));\n  (assert ((candidate [(\"1\", \"1\"); (\"2\", \"2\"); (\"3\", \"3\"); (\"4\", \"4\")] \"1#2#3#4#5\") = \"1#2#3#4#5\"));\n  (assert ((candidate [(\"1\", \"Alice\"); (\"2\", \"Bob\"); (\"3\", \"Charlie\"); (\"4\", \"David\"); (\"5\", \"Eve\"); (\"6\", \"Fred\"); (\"7\", \"Ginny\"); (\"8\", \"Harriet\"); (\"9\", \"Ileana\"); (\"10\", \"Joseph\"); (\"11\", \"Kincaid\"); (\"12\", \"Larry\")] \"12\") = \"Larry\"));\n  (assert ((candidate [(\"1\", \"tom\"); (\"2\", \"dick\"); (\"3\", \"harry\")] \"1\") = \"tom\"));\n  (assert ((candidate [(\"1\", \"1\"); (\"2\", \"2\"); (\"3\", \"3\"); (\"4\", \"4\")] \"3#4\") = \"3#4\"));\n  (assert ((candidate [(\"1\", \"1\"); (\"2\", \"2\"); (\"3\", \"3\"); (\"4\", \"4\")] \"1#2#3\") = \"1#2#3\"));\n  (assert ((candidate [(\"1\", \"1\"); (\"2\", \"2\"); (\"3\", \"3\"); (\"4\", \"4\")] \"2#3#4\") = \"2#3#4\"));\n  (assert ((candidate [(\"1\", \"1\"); (\"2\", \"2\"); (\"3\", \"3\"); (\"4\", \"4\")] \"1#2#3#4\") = \"1#2#3#4\"));\n  (assert ((candidate [(\"1\", \"tom\"); (\"2\", \"dick\"); (\"3\", \"harry\")] \"5\") = \"5\"));\n  (assert ((candidate ) = \"a#a#a#b#c\"));\n  (assert ((candidate [(\"3\", \"3\"); (\"4\", \"4\")] \"4\") = \"4\"));\n  (assert ((candidate [(\"1\", \"1\"); (\"2\", \"2\"); (\"3\", \"3\"); (\"4\", \"4\"); (\"5\", \"5\"); (\"6\", \"6\"); (\"7\", \"7\"); (\"8\", \"8\"); (\"9\", \"9\"); (\"10\", \"10\")] \"1\") = \"1\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_334071_prepend_scheme", "language": "ml", "prompt": "(**Prepend scheme to a remote path.\nScheme is only prepended if not already present\nParameters\n----------\nscheme: str\n * a scheme like 'file', 's3' or 'gs'\npath: str\n * path which will possibly get a scheme prepended\nReturns\n-------\nfull_path: str\n*)\nlet prepend_scheme (scheme : string) (path : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_334071_prepend_scheme.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = prepend_scheme in\n  (assert ((candidate \"gs\" \"/tmp/test_folder/file.txt\") = \"gs://tmp/test_folder/file.txt\"));\n  (assert ((candidate \"\" \"/test/test.txt\") = \"file://test/test.txt\"));\n  (assert ((candidate \"file\" \"tmp/test_folder/file.txt\") = \"file://tmp/test_folder/file.txt\"));\n  (assert ((candidate \"gs\" \"tmp/test_folder/file.txt\") = \"gs://tmp/test_folder/file.txt\"));\n  (assert ((candidate \"s3\" \"/tmp/test_folder/file.txt\") = \"s3://tmp/test_folder/file.txt\"));\n  (assert ((candidate \"file\" \"/tmp/test_folder/\") = \"file://tmp/test_folder/\"));\n  (assert ((candidate \"gs\" \"/tmp/test_folder/\") = \"gs://tmp/test_folder/\"));\n  (assert ((candidate \"s3\" \"tmp/test_folder/file.txt\") = \"s3://tmp/test_folder/file.txt\"));\n  (assert ((candidate \"\" \"test.txt\") = \"file://test.txt\"));\n  (assert ((candidate \"file\" \"/tmp/test_folder/file.txt\") = \"file://tmp/test_folder/file.txt\"));\n  (assert ((candidate \"file\" \"tmp/test_folder/\") = \"file://tmp/test_folder/\"));\n  (assert ((candidate \"s3\" \"/tmp/test_folder/\") = \"s3://tmp/test_folder/\"));\n  (assert ((candidate \"s3\" \"tmp/test_folder/\") = \"s3://tmp/test_folder/\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_3342_parse_cigar", "language": "ml", "prompt": "(**for a specific operation (mismach, match, insertion, deletion... see above)\nreturn occurences and index in the alignment\n*)\nlet parse_cigar (cigarlist :  int * int list) (ope : int) : int list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_3342_parse_cigar.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_cigar in\n  (assert ((candidate [(2, 100)] 1) = []));\n  (assert ((candidate candidate [(\"M\", 5); (\"M\", 3); (\"I\", 5)] \"D\" \"D\") = []));\n  (assert ((candidate [(0, 100)] 2) = []));\n  (assert ((candidate [(1, 100)] 1) = [[100; 0]]));\n  (assert ((candidate [(1, 100)] 0) = []));\n  (assert ((candidate [(0, 100)] 8) = []));\n  (assert ((candidate [(1, 100)] 2) = []));\n  (assert ((candidate [(2, 100)] 0) = []));\n  (assert ((candidate [(1, 100)] 7) = []));\n  (assert ((candidate [(2, 100)] 8) = []));\n  (assert ((candidate [(0, 100)] 1) = []));\n  (assert ((candidate candidate [(\"M\", 5); (\"M\", 3); (\"I\", 5)] \"N\" \"N\") = []));\n  (assert ((candidate [(2, 100)] 7) = []));\n  (assert ((candidate [(0, 100)] 0) = [[100; 0]]));\n  (assert ((candidate [(7, 100)] 0) = []));\n  (assert ((candidate [(0, 100)] 7) = []));\n  (assert ((candidate [(7, 100)] 2) = []));\n  (assert ((candidate [(2, 100)] 2) = [[100; 0]]));\n  (assert ((candidate [(7, 100)] 1) = []));\n  (assert ((candidate [(1, 100)] 8) = []));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_33486_is_int_type_malicious_score", "language": "ml", "prompt": "(**determine if integer type confidence score is malicious in reputation_params\n*)\nlet is_int_type_malicious_score (confidence_score : int) (params : (string, int) list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_33486_is_int_type_malicious_score.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_int_type_malicious_score in\n  (assert ((candidate 100 [(\"override_confidence_score_malicious_threshold\", 100000)]) = false));\n  (assert ((candidate 0 [(\"override_confidence_score_malicious_threshold\", 100000)]) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_335015_base10_to_7", "language": "ml", "prompt": "(**Take a base 10 number and convert it to an ASCII string.\n:param num: the base 10 number\n:return: the ASCII string\n*)\nlet base10_to_7 (num : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_335015_base10_to_7.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = base10_to_7 in\n  (assert ((candidate 0) = \"\"));\n  (assert ((candidate 0) = \"\"));\n  (assert ((candidate 127) = \"\u007f\"));\n  (assert ((candidate 1) = \"\u0001\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_335336_gcd_by_subtracting", "language": "ml", "prompt": "(**Computes the greatest common divisor of two numbers by continuously subtracting the smaller\nnumber from the bigger one till they became equal.\n:param int m: First number.\n:param int n: Second number.\n:returns: GCD as a number.\n*)\nlet gcd_by_subtracting (m : int) (n : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_335336_gcd_by_subtracting.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = gcd_by_subtracting in\n  (assert ((candidate 1 7) = 1));\n  (assert ((candidate 18 12) = 6));\n  (assert ((candidate 200 100) = 100));\n  (assert ((candidate 6 90) = 6));\n  (assert ((candidate 24 36) = 12));\n  (assert ((candidate 42 42) = 42));\n  (assert ((candidate 6 12) = 6));\n  (assert ((candidate 252 105) = 21));\n  (assert ((candidate 100 10) = 10));\n  (assert ((candidate 12 16) = 4));\n  (assert ((candidate 1 1) = 1));\n  (assert ((candidate 12 28) = 4));\n  (assert ((candidate 10 100) = 10));\n  (assert ((candidate 6 24) = 6));\n  (assert ((candidate 13 27) = 1));\n  (assert ((candidate 7 1) = 1));\n  (assert ((candidate 10 20) = 10));\n  (assert ((candidate 6 8) = 2));\n  (assert ((candidate 12 18) = 6));\n  (assert ((candidate 5 125) = 5));\n  (assert ((candidate 6 14) = 2));\n  (assert ((candidate 22 13) = 1));\n  (assert ((candidate 6 18) = 6));\n  (assert ((candidate 10000000000 123456789) = 1));\n  (assert ((candidate 6 30) = 6));\n  (assert ((candidate 3 5) = 1));\n  (assert ((candidate 24 8) = 8));\n  (assert ((candidate 9 6) = 3));\n  (assert ((candidate 12 6) = 6));\n  (assert ((candidate 2000 1000) = 1000));\n  (assert ((candidate 999 1) = 1));\n  (assert ((candidate 2 10) = 2));\n  (assert ((candidate 20 10) = 10));\n  (assert ((candidate 1000 2000) = 1000));\n  (assert ((candidate 125 5) = 5));\n  (assert ((candidate 5 3) = 1));\n  (assert ((candidate 6 15) = 3));\n  (assert ((candidate 12 20) = 4));\n  (assert ((candidate 100 200) = 100));\n  (assert ((candidate 20 25) = 5));\n  (assert ((candidate 25 20) = 5));\n  (assert ((candidate 6 4) = 2));\n  (assert ((candidate 23456789 123456789) = 1));\n  (assert ((candidate 6 10) = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_336336_format_role_order", "language": "ml", "prompt": "(**Given roles, returns them in the format: role_arn,principal_arn.\nThe format of the attribute value should be role_arn,principal_arn\nbut lots of blogs list it as principal_arn,role_arn so let's reverse\nthem if needed.\nArgs:\n * roles: List of roles.\nReturns:\n * List of roles in the format: role_arn,principal_arn\n*)\nlet format_role_order (roles : string list) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_336336_format_role_order.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = format_role_order in\n  (assert ((candidate [\"role1,principal1\"; \"role2,principal2\"]) = [\"role1,principal1\"; \"role2,principal2\"]));\n  (assert ((candidate [\"role1,principal1\"; \"role2,principal2\"; \"role3,principal3\"; \"role4,principal4\"]) = [\"role1,principal1\"; \"role2,principal2\"; \"role3,principal3\"; \"role4,principal4\"]));\n  (assert ((candidate [\"role1\"; \"role2\"]) = [\"role1\"; \"role2\"]));\n  (assert ((candidate [\"arn:aws:iam::123456789012:saml-provider/ADFS,arn:aws:iam::123456789012:role/Admin\"]) = [\"arn:aws:iam::123456789012:role/Admin,arn:aws:iam::123456789012:saml-provider/ADFS\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_337003_power", "language": "ml", "prompt": "(**Compute x to the power of n (with n>=0)\n*)\nlet power (x : int) (n : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_337003_power.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = power in\n  (assert ((candidate 2 4) = 16));\n  (assert ((candidate 2 6) = 64));\n  (assert ((candidate 5 2) = 25));\n  (assert ((candidate 2 5) = 32));\n  (assert ((candidate 5 3) = 125));\n  (assert ((candidate 5 5) = 3125));\n  (assert ((candidate 10 1) = 10));\n  (assert ((candidate 2 0) = 1));\n  (assert ((candidate 3 0) = 1));\n  (assert ((candidate 3 4) = 81));\n  (assert ((candidate 2 1) = 2));\n  (assert ((candidate 2 2) = 4));\n  (assert ((candidate 5 4) = 625));\n  (assert ((candidate 10 0) = 1));\n  (assert ((candidate 5 0) = 1));\n  (assert ((candidate 2 3) = 8));\n  (assert ((candidate 10 2) = 100));\n  (assert ((candidate 3 5) = 243));\n  (assert ((candidate 3 3) = 27));\n  (assert ((candidate 3 1) = 3));\n  (assert ((candidate 10 4) = 10000));\n  (assert ((candidate 1 0) = 1));\n  (assert ((candidate 3 6) = 729));\n  (assert ((candidate 10 3) = 1000));\n  (assert ((candidate 5 1) = 5));\n  (assert ((candidate 3 2) = 9));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_338620_get_distance", "language": "ml", "prompt": "(**Get distance between two point in a tore space.\nParameters\n----------\ncoord1: coordinate of the first point (tupe(int, int)).\ncoord2: coordinate of the second point (tupe(int, int)).\nsize: size of the tore (tupe(int, int))\nReturn\n------\nDistance: distance between the two points (int).\nVersion\n-------\nSpecification: Alisson Leist, Bayron Mahy, Nicolas Van Bossuyt (v1. 10/02/17)\n * Bayron Mahy (v2. 19/03/17)\nImplementation: Nicolas Van Bossuyt, Alisson Leist (v1. 14/02/17)\n * Nicolas Van Bossuyt (v2. 09/03/17)\n * Nicolas Van Bossuyt (v3. 03/05/17)\n*)\nlet get_distance (coord1 :  int * int) (coord2 :  int * int) (size :  int * int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_338620_get_distance.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_distance in\n  (assert ((candidate (0, 1) (1, 0) (2, 3)) = 2));\n  (assert ((candidate (0, 0) (3, 7) (10, 10)) = 6));\n  (assert ((candidate (1, 0) (0, 0) (2, 1)) = 1));\n  (assert ((candidate (0, 1) (1, 0) (2, 2)) = 2));\n  (assert ((candidate (0, 0) (0, 0) (10, 10)) = 0));\n  (assert ((candidate (0, 0) (7, 3) (10, 10)) = 6));\n  (assert ((candidate (0, 0) (1, 0) (2, 1)) = 1));\n  (assert ((candidate (0, 0) (1, 0) (2, 2)) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_338738_power", "language": "ml", "prompt": "(**Raise term to exponent.\nThis function raises ``term`` to ``exponent``.\nParameters\n----------\nterm : Number\n * Term to be raised.\nexponent : int\n * Exponent.\nReturns\n-------\nresult : Number\n * Result of the operation.\nRaises\n------\nValueError\n * If exponent is not an integer.\nSee Also\n--------\nadd : Addition\nsubtract : Subtraction\nmultiply : Multiplication\ndivide : Division\nExamples\n--------\n>>> power(1, 1)\n1\n>>> power(2, 2)\n4\n>>> power(4, 2)\n16\n>>> power(10, 2)\n100\n>>> power(100, 1)\n100\n>>> power(10, 3)\n1000\n*)\nlet power (term : int) (exponent : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_338738_power.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = power in\n  (assert ((candidate 10 2) = 100));\n  (assert ((candidate 2 0) = 1));\n  (assert ((candidate (~2) 3) = (~8)));\n  (assert ((candidate 5 4) = 625));\n  (assert ((candidate 2 2) = 4));\n  (assert ((candidate 100 1) = 100));\n  (assert ((candidate 2 3) = 8));\n  (assert ((candidate 10 3) = 1000));\n  (assert ((candidate 0 0) = 1));\n  (assert ((candidate 4 2) = 16));\n  (assert ((candidate 1 1) = 1));\n  (assert ((candidate 5 2) = 25));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_339249_urlsplit", "language": "ml", "prompt": "(**Split an arbitrary url into protocol, host, rest\nThe standard urlsplit does not want to provide 'netloc' for arbitrary\nprotocols, this works around that.\n:param url: The url to split into component parts\n*)\nlet urlsplit (url : string) :  string * string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_339249_urlsplit.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = urlsplit in\n  (assert ((candidate \"http://www.python.org/doc/2.5.2/lib/module-time.html\") = (\"http\", \"www.python.org\", \"/doc/2.5.2/lib/module-time.html\")));\n  (assert ((candidate \"http://www.example.com/a/b/c\") = (\"http\", \"www.example.com\", \"/a/b/c\")));\n  (assert ((candidate \"https://127.0.0.1/foo/bar\") = (\"https\", \"127.0.0.1\", \"/foo/bar\")));\n  (assert ((candidate \"http://www.example.com/\") = (\"http\", \"www.example.com\", \"/\")));\n  (assert ((candidate \"http://www.example.com/foo\") = (\"http\", \"www.example.com\", \"/foo\")));\n  (assert ((candidate \"http://www.example.com/a/b/c?a=1&b=2\") = (\"http\", \"www.example.com\", \"/a/b/c?a=1&b=2\")));\n  (assert ((candidate \"http://www.example.com/a/b/c?a=1&b=2#frag\") = (\"http\", \"www.example.com\", \"/a/b/c?a=1&b=2#frag\")));\n  (assert ((candidate \"http://www.python.org/\") = (\"http\", \"www.python.org\", \"/\")));\n  (assert ((candidate \"http://www.example.com/?a=1&b=2\") = (\"http\", \"www.example.com\", \"/?a=1&b=2\")));\n  (assert ((candidate \"ftp://ftp.debian.org/debian/README\") = (\"ftp\", \"ftp.debian.org\", \"/debian/README\")));\n  (assert ((candidate \"http://www.python.org:80/\") = (\"http\", \"www.python.org:80\", \"/\")));\n  (assert ((candidate \"https://localhost/foo/bar\") = (\"https\", \"localhost\", \"/foo/bar\")));\n  (assert ((candidate \"file:///foo/bar/baz.html\") = (\"file\", \"\", \"/foo/bar/baz.html\")));\n  (assert ((candidate \"http://localhost/foo/bar\") = (\"http\", \"localhost\", \"/foo/bar\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_339342__extract_prop_option", "language": "ml", "prompt": "(**Extract the (key,value)-tuple from a string like:\n>>> \"option foobar 123\"\n:param line:\n:return: tuple (key, value)\n*)\nlet _extract_prop_option (line : string) :  string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_339342__extract_prop_option.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _extract_prop_option in\n  (assert ((candidate \"option foobar:baz 123\") = (\"foobar:baz\", \"123\")));\n  (assert ((candidate \"option foobar 123\") = (\"foobar\", \"123\")));\n  (assert ((candidate \"option foobar -123\") = (\"foobar\", \"-123\")));\n  (assert ((candidate \"option foobar 123\") = (\"foobar\", \"123\")));\n  (assert ((candidate \"option foobar 123.4e5_0\") = (\"foobar\", \"123.4e5_0\")));\n  (assert ((candidate \"option foobar 123\") = (\"foobar\", \"123\")));\n  (assert ((candidate \"option foobar 123.4e5\") = (\"foobar\", \"123.4e5\")));\n  (assert ((candidate \"option foobar:baz 123 123 123\") = (\"foobar:baz\", \"123 123 123\")));\n  (assert ((candidate \"option foobar 123\") = (\"foobar\", \"123\")));\n  (assert ((candidate \"option foobar 123 123 123\") = (\"foobar\", \"123 123 123\")));\n  (assert ((candidate \"option foobar +123.4\") = (\"foobar\", \"+123.4\")));\n  (assert ((candidate \"option foobar 123\") = (\"foobar\", \"123\")));\n  (assert ((candidate \"option foobar -123.4\") = (\"foobar\", \"-123.4\")));\n  (assert ((candidate \"option foobar 123 456\") = (\"foobar\", \"123 456\")));\n  (assert ((candidate \"option foobar 123.4e-5\") = (\"foobar\", \"123.4e-5\")));\n  (assert ((candidate \"option foobar 123.4\") = (\"foobar\", \"123.4\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_340491_int_with_radix", "language": "ml", "prompt": "(**Parse integer with or without a base prefix\n:param string: String representation of integer\n:type string: str\n:return: Parsed integer\n:rtype: int\n:raise ValueError: If string is no valid integer representation\n*)\nlet int_with_radix (string : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_340491_int_with_radix.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = int_with_radix in\n  (assert ((candidate \"0xFF\") = 255));\n  (assert ((candidate \"0b10\") = 2));\n  (assert ((candidate \"-0b00011011\") = (~27)));\n  (assert ((candidate \"0\") = 0));\n  (assert ((candidate \"1010101\") = 1010101));\n  (assert ((candidate \"0x10\") = 16));\n  (assert ((candidate \"0x0000\") = 0));\n  (assert ((candidate \"1\") = 1));\n  (assert ((candidate \"0x100\") = 256));\n  (assert ((candidate \"0x100\") = 256));\n  (assert ((candidate \"0x00\") = 0));\n  (assert ((candidate \"0x0\") = 0));\n  (assert ((candidate \"10\") = 10));\n  (assert ((candidate \"0x000\") = 0));\n  (assert ((candidate \"-0x1234\") = (~4660)));\n  (assert ((candidate \"0x1234\") = 4660));\n  (assert ((candidate \"0b00011011\") = 27));\n  (assert ((candidate \"-0o1234\") = (~668)));\n  (assert ((candidate \"0o1234\") = 668));\n  (assert ((candidate \"0b10101010\") = 170));\n  (assert ((candidate \"0x1234\") = 4660));\n  (assert ((candidate \"-1\") = (~1)));\n  (assert ((candidate \"0x10\") = 16));\n  (assert ((candidate \"0o77\") = 63));\n  (assert ((candidate \"1\") = 1));\n  (assert ((candidate \"0o10\") = 8));\n  (assert ((candidate \"0x1234567890abcdefabcdef\") = 22007822917795467892608495));\n  (assert ((candidate \"1234\") = 1234));\n  (assert ((candidate \"0x1234567890abcdef\") = 1311768467294899695));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_34192_parse_envs", "language": "ml", "prompt": "(**Parse environment configs as a dict.\nSupport format 'k1=v1,k2=v2,k3=v3..'. Note that comma is supported\nin value field.\n*)\nlet parse_envs (arg : string option) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_34192_parse_envs.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_envs in\n  (assert ((candidate Some(\"key\")) = []));\n  (assert ((candidate Some(\"k1=v1,,\")) = [(\"k1\", \"v1,,\")]));\n  (assert ((candidate Some(\"a=1\")) = [(\"a\", \"1\")]));\n  (assert ((candidate Some(\"x=y,z=z\")) = [(\"x\", \"y\"); (\"z\", \"z\")]));\n  (assert ((candidate Some(\"a=a,b=b,c=c,d=d,e=e\")) = [(\"a\", \"a\"); (\"b\", \"b\"); (\"c\", \"c\"); (\"d\", \"d\"); (\"e\", \"e\")]));\n  (assert ((candidate Some(\"A=B,C=D,E=F,G=H\")) = [(\"A\", \"B\"); (\"C\", \"D\"); (\"E\", \"F\"); (\"G\", \"H\")]));\n  (assert ((candidate Some(\"foo=bar\")) = [(\"foo\", \"bar\")]));\n  (assert ((candidate Some(\"k1=v1\")) = [(\"k1\", \"v1\")]));\n  (assert ((candidate Some(\"key=value,key1=value1,key2=value2\")) = [(\"key\", \"value\"); (\"key1\", \"value1\"); (\"key2\", \"value2\")]));\n  (assert ((candidate Some(\"key=value\")) = [(\"key\", \"value\")]));\n  (assert ((candidate Some(\"a=\")) = [(\"a\", \"\")]));\n  (assert ((candidate Some(\"a=1,b=2,c=3,d=a,b,c\")) = [(\"a\", \"1\"); (\"b\", \"2\"); (\"c\", \"3\"); (\"d\", \"a,b,c\")]));\n  (assert ((candidate Some(\"key=value1,value2\")) = [(\"key\", \"value1,value2\")]));\n  (assert ((candidate Some(\"k1=v1,k2=v2,k3=\")) = [(\"k1\", \"v1\"); (\"k2\", \"v2\"); (\"k3\", \"\")]));\n  (assert ((candidate Some(\"key1=\")) = [(\"key1\", \"\")]));\n  (assert ((candidate Some(\"a=1,b=2\")) = [(\"a\", \"1\"); (\"b\", \"2\")]));\n  (assert ((candidate Some(\"a=b,c=d,e=f,g=h\")) = [(\"a\", \"b\"); (\"c\", \"d\"); (\"e\", \"f\"); (\"g\", \"h\")]));\n  (assert ((candidate Some(\"foo=bar,baz=qux,quux=corge\")) = [(\"foo\", \"bar\"); (\"baz\", \"qux\"); (\"quux\", \"corge\")]));\n  (assert ((candidate Some(\" a \")) = []));\n  (assert ((candidate Some(\"abc\")) = []));\n  (assert ((candidate Some(\"\")) = []));\n  (assert ((candidate Some(\"key1=value1,key2=value2\")) = [(\"key1\", \"value1\"); (\"key2\", \"value2\")]));\n  (assert ((candidate Some(\"A=B,C=D,E=F,G=H,I=J,K=L,M=N\")) = [(\"A\", \"B\"); (\"C\", \"D\"); (\"E\", \"F\"); (\"G\", \"H\"); (\"I\", \"J\"); (\"K\", \"L\"); (\"M\", \"N\")]));\n  (assert ((candidate Some(\" \")) = []));\n  (assert ((candidate Some(\"A=B\")) = [(\"A\", \"B\")]));\n  (assert ((candidate Some(\"a=a,b=b,c=c,d=d\")) = [(\"a\", \"a\"); (\"b\", \"b\"); (\"c\", \"c\"); (\"d\", \"d\")]));\n  (assert ((candidate Some(\"A=B,C=D,E=F,G=H,I=J,K=L,M=N,O=P\")) = [(\"A\", \"B\"); (\"C\", \"D\"); (\"E\", \"F\"); (\"G\", \"H\"); (\"I\", \"J\"); (\"K\", \"L\"); (\"M\", \"N\"); (\"O\", \"P\")]));\n  (assert ((candidate Some(\"a=b\")) = [(\"a\", \"b\")]));\n  (assert ((candidate Some(\" a b \")) = []));\n  (assert ((candidate Some(\"A=B,C=D\")) = [(\"A\", \"B\"); (\"C\", \"D\")]));\n  (assert ((candidate Some(\"key=value,key2=value2\")) = [(\"key\", \"value\"); (\"key2\", \"value2\")]));\n  (assert ((candidate Some(\"a=b,c=d,e=f\")) = [(\"a\", \"b\"); (\"c\", \"d\"); (\"e\", \"f\")]));\n  (assert ((candidate Some(\"a=a\")) = [(\"a\", \"a\")]));\n  (assert ((candidate Some(\"a=b,c=d,e=f,g=h,i=j,k=l,m=n\")) = [(\"a\", \"b\"); (\"c\", \"d\"); (\"e\", \"f\"); (\"g\", \"h\"); (\"i\", \"j\"); (\"k\", \"l\"); (\"m\", \"n\")]));\n  (assert ((candidate Some(\"A=B,C=D,E=F\")) = [(\"A\", \"B\"); (\"C\", \"D\"); (\"E\", \"F\")]));\n  (assert ((candidate Some(\"hello=world\")) = [(\"hello\", \"world\")]));\n  (assert ((candidate Some(\"a=a,b=b\")) = [(\"a\", \"a\"); (\"b\", \"b\")]));\n  (assert ((candidate Some(\"A=B,C=D,E=F,G=H,I=J\")) = [(\"A\", \"B\"); (\"C\", \"D\"); (\"E\", \"F\"); (\"G\", \"H\"); (\"I\", \"J\")]));\n  (assert ((candidate Some(\"k1=v1,k2=v2,k3=v3\")) = [(\"k1\", \"v1\"); (\"k2\", \"v2\"); (\"k3\", \"v3\")]));\n  (assert ((candidate Some(\"k1=v1,k2=v2,k3=v3\")) = [(\"k1\", \"v1\"); (\"k2\", \"v2\"); (\"k3\", \"v3\")]));\n  (assert ((candidate Some(\"k1=,k2=v3\")) = [(\"k1\", \"\"); (\"k2\", \"v3\")]));\n  (assert ((candidate Some(\"key1=value1\")) = [(\"key1\", \"value1\")]));\n  (assert ((candidate Some(\"a=a,b=b,c=c\")) = [(\"a\", \"a\"); (\"b\", \"b\"); (\"c\", \"c\")]));\n  (assert ((candidate Some(\"key=value,key2=value2,key3=value3\")) = [(\"key\", \"value\"); (\"key2\", \"value2\"); (\"key3\", \"value3\")]));\n  (assert ((candidate Some(\"k1=v1,k2=v2,k3=v3,k4=v4\")) = [(\"k1\", \"v1\"); (\"k2\", \"v2\"); (\"k3\", \"v3\"); (\"k4\", \"v4\")]));\n  (assert ((candidate Some(\"k1=v1,k2=v2\")) = [(\"k1\", \"v1\"); (\"k2\", \"v2\")]));\n  (assert ((candidate Some(\" a b c \")) = []));\n  (assert ((candidate Some(\"a=b,c=d,e=f,g=h,i=j,k=l,m=n,o=p,q=r,s=t,u=v,w=x,y=z\")) = [(\"a\", \"b\"); (\"c\", \"d\"); (\"e\", \"f\"); (\"g\", \"h\"); (\"i\", \"j\"); (\"k\", \"l\"); (\"m\", \"n\"); (\"o\", \"p\"); (\"q\", \"r\"); (\"s\", \"t\"); (\"u\", \"v\"); (\"w\", \"x\"); (\"y\", \"z\")]));\n  (assert ((candidate Some(\"a=b\")) = [(\"a\", \"b\")]));\n  (assert ((candidate Some(\"x=y\")) = [(\"x\", \"y\")]));\n  (assert ((candidate Some(None)) = []));\n  (assert ((candidate Some(\"k1=v1,k2=v2,k3=v3,k4=v4,k5=v5\")) = [(\"k1\", \"v1\"); (\"k2\", \"v2\"); (\"k3\", \"v3\"); (\"k4\", \"v4\"); (\"k5\", \"v5\")]));\n  (assert ((candidate Some(\"a=b,c=d,e=f,g=h,i=j\")) = [(\"a\", \"b\"); (\"c\", \"d\"); (\"e\", \"f\"); (\"g\", \"h\"); (\"i\", \"j\")]));\n  (assert ((candidate Some(\"a=1,b=2,c=3\")) = [(\"a\", \"1\"); (\"b\", \"2\"); (\"c\", \"3\")]));\n  (assert ((candidate Some(\"a=b,c=d\")) = [(\"a\", \"b\"); (\"c\", \"d\")]));\n  (assert ((candidate Some(\"k1=,k2=\")) = [(\"k1\", \"\"); (\"k2\", \"\")]));\n  (assert ((candidate Some(\"hello\")) = []));\n  (assert ((candidate Some(\"hello=world,foo=bar,baz=qux\")) = [(\"hello\", \"world\"); (\"foo\", \"bar\"); (\"baz\", \"qux\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_342149_checkpid", "language": "ml", "prompt": "(**return the pid of the engine\n*)\nlet checkpid (pid : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_342149_checkpid.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = checkpid in\n  (assert ((candidate 12345) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_342437_problem48", "language": "ml", "prompt": "(**Problem 48 - Self powers\n*)\nlet problem48 (limit : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_342437_problem48.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = problem48 in\n  (assert ((candidate 1000) = 9110846700));\n  (assert ((candidate 10) = 405071317));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_342875_naive_add", "language": "ml", "prompt": "(**A naive implementation which can blow the call stack.\n*)\nlet naive_add (x : int) (y : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_342875_naive_add.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = naive_add in\n  (assert ((candidate 1000 0) = 1000));\n  (assert ((candidate 3 10) = 13));\n  (assert ((candidate 100 100) = 200));\n  (assert ((candidate 1 10) = 11));\n  (assert ((candidate 1 1) = 2));\n  (assert ((candidate 100 500) = 600));\n  (assert ((candidate 2 0) = 2));\n  (assert ((candidate 2 3) = 5));\n  (assert ((candidate 10 100) = 110));\n  (assert ((candidate 1 0) = 1));\n  (assert ((candidate 0 0) = 0));\n  (assert ((candidate 1 2) = 3));\n  (assert ((candidate 5 100) = 105));\n  (assert ((candidate 0 100) = 100));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_344339__estim_determ_p", "language": "ml", "prompt": "(**An estimator that beliefs just in\ndeterministic memory-less models.\n*)\nlet _estim_determ_p (num_zeros : int) (num_ones : int) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_344339__estim_determ_p.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _estim_determ_p in\n  (assert ((candidate 1 0) = 0.5));\n  (assert ((candidate 0 1) = 0.5));\n  (assert ((candidate 1 1) = 0.0));\n  (assert ((candidate 2 2) = 0.0));\n  (assert ((candidate 2 1) = 0.0));\n  (assert ((candidate 0 2) = 0.5));\n  (assert ((candidate 0 3) = 0.5));\n  (assert ((candidate 3 0) = 0.5));\n  (assert ((candidate 1 2) = 0.0));\n  (assert ((candidate 2 0) = 0.5));\n  (assert ((candidate 0 0) = 1.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_345591_categorizeClass", "language": "ml", "prompt": "(**Greeble classification with respect to horns [0 down, 1 up]\nh1  |h2     |class\n0   |0      |1\n0   |1      |2\n1   |0      |3\n1   |1      |4\n*)\nlet categorizeClass (h1 : int) (h2 : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_345591_categorizeClass.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = categorizeClass in\n  (assert ((candidate 0 0) = 0));\n  (assert ((candidate 0 1) = 1));\n  (assert ((candidate 1 1) = 3));\n  (assert ((candidate 1 0) = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_346321_reverse_int", "language": "ml", "prompt": "(**Late to the party, but here's a good one.\nInteger Reverse:\nGiven: Any random integer in decimal.\nChallenge: Reverse it, without using any of the obvious toString tricks, or transient conversions to a data type other than an int.\n*)\nlet reverse_int (n : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_346321_reverse_int.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = reverse_int in\n  (assert ((candidate 88888888) = 88888888));\n  (assert ((candidate 1000) = 1));\n  (assert ((candidate 987654321) = 123456789));\n  (assert ((candidate 10) = 1));\n  (assert ((candidate 123456789) = 987654321));\n  (assert ((candidate 987) = 789));\n  (assert ((candidate 4) = 4));\n  (assert ((candidate 4321) = 1234));\n  (assert ((candidate 4560) = 654));\n  (assert ((candidate 12345) = 54321));\n  (assert ((candidate 123) = 321));\n  (assert ((candidate 321) = 123));\n  (assert ((candidate 123) = 321));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 0) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_34678_url", "language": "ml", "prompt": "(**Url\nArgs:\n * text (str): text for url.\n * url (str): url for text.\nReturns:\n * str: url.\n*)\nlet url (text : string) (url_ : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_34678_url.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = url in\n  (assert ((candidate \"title\" \"candidate\") = \"[title](candidate)\"));\n  (assert ((candidate \"title with underscore\" \"candidate\") = \"[title with underscore](candidate)\"));\n  (assert ((candidate \"title with space\" \"candidate\") = \"[title with space](candidate)\"));\n  (assert ((candidate \"title with underscore and space\" \"candidate\") = \"[title with underscore and space](candidate)\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_348306_is_allowed_conference", "language": "ml", "prompt": "(**Return True if at least one of c1/c2 is an allowed_conference\nconf_names is a list of all defined conferences (used to group things into an \"other\" category)\n*)\nlet is_allowed_conference (c1 : int) (c2 : int) (conf_names : string list) (allowed_confs : string list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_348306_is_allowed_conference.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_allowed_conference in\n  (assert ((candidate 1 2 [\"a\"; \"b\"] []) = false));\n  (assert ((candidate 1 2 [\"a\"; \"b\"] [\"other\"; \"a\"]) = true));\n  (assert ((candidate 1 2 [\"a\"; \"b\"] [\"other\"; \"a\"; \"b\"]) = true));\n  (assert ((candidate 1 2 [\"a\"; \"b\"] [\"a\"; \"other\"]) = true));\n  (assert ((candidate 1 2 [\"a\"; \"b\"] [\"other\"; \"b\"; \"c\"]) = true));\n  (assert ((candidate 1 2 [\"a\"; \"b\"] [\"a\"]) = false));\n  (assert ((candidate 1 2 [\"a\"; \"b\"] [\"c\"]) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_349011_mml_namelist", "language": "ml", "prompt": "(**padding to be same length\n*)\nlet mml_namelist (namelist : string list) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_349011_mml_namelist.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = mml_namelist in\n  (assert ((candidate [\"a\"; \"b\"]) = [\"'a'\"; \"'b'\"]));\n  (assert ((candidate [\"foo\"; \"bar\"; \"baz\"]) = [\"'foo'\"; \"'bar'\"; \"'baz'\"]));\n  (assert ((candidate [\"a\"; \"bbbb\"; \"ccccc\"]) = [\"'a    '\"; \"'bbbb '\"; \"'ccccc'\"]));\n  (assert ((candidate [\"foo\"; \"bar\"]) = [\"'foo'\"; \"'bar'\"]));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"]) = [\"'a'\"; \"'b'\"; \"'c'\"]));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"; \"d\"]) = [\"'a'\"; \"'b'\"; \"'c'\"; \"'d'\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_350170_welcome", "language": "ml", "prompt": "(**Welcome to API Star. Personalized for name\n*)\nlet welcome (name : string option) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_350170_welcome.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = welcome in\n  (assert ((candidate Some(\"Michael\")) = [(\"message\", \"Welcome to API Star, Michael!\")]));\n  (assert ((candidate Some(None)) = [(\"message\", \"Welcome to API Star!\")]));\n  (assert ((candidate Some(\"Python\")) = [(\"message\", \"Welcome to API Star, Python!\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_350340__get_acl_username", "language": "ml", "prompt": "(**Port of ``copyAclUserName`` from ``dumputils.c``\n*)\nlet _get_acl_username (acl : string) :  int * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_350340__get_acl_username.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _get_acl_username in\n  (assert ((candidate \"foo\") = (3, \"foo\")));\n  (assert ((candidate \"=\") = (0, \"\")));\n  (assert ((candidate \"\"foo\"\") = (5, \"foo\")));\n  (assert ((candidate \"\"a\"\") = (3, \"a\")));\n  (assert ((candidate \"\"foo\"\"=bar\"\") = (11, \"foo\"=bar\")));\n  (assert ((candidate \"a\") = (1, \"a\")));\n  (assert ((candidate \"\") = (0, \"\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_350862_count_values", "language": "ml", "prompt": "(**:param input_dict:\n:return:\nTakes a dict and counts the unique values in that dict.\n*)\nlet count_values (input_dict : (string, int) list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_350862_count_values.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = count_values in\n  (assert ((candidate [(\"a\", 1); (\"b\", 1); (\"c\", 1); (\"d\", 2); (\"e\", 2); (\"f\", 3)]) = 3));\n  (assert ((candidate [(\"a\", 1); (\"b\", 1); (\"c\", 1)]) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_351488_hexToBytes", "language": "ml", "prompt": "(**Provide hex sting in format 'ab ab ab...'\nReturns the byte values\n*)\nlet hexToBytes (hexStr : string) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_351488_hexToBytes.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = hexToBytes in\n  (assert ((candidate \"123\") = [18]));\n  (assert ((candidate \"\") = []));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_351618_substring_edit_distance", "language": "ml", "prompt": "(**The minimum number of edits required to make t a substring of s.\nAn edit is the addition, deletion, or replacement of a character.\n*)\nlet substring_edit_distance (s : string) (t : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_351618_substring_edit_distance.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = substring_edit_distance in\n  (assert ((candidate \"abcd\" \"abcdef\") = 2));\n  (assert ((candidate \"abcd\" \"abcd\") = 0));\n  (assert ((candidate \"abcdefghij\" \"abcdefghijk\") = 1));\n  (assert ((candidate \"abcde\" \"abcde\") = 0));\n  (assert ((candidate \"abcdefghijklmnopqrstuvwxyz\" \"abcdefghijklmnopqrstuvwxyza\") = 1));\n  (assert ((candidate \"abc\" \"def\") = 3));\n  (assert ((candidate \"abc\" \"abc\") = 0));\n  (assert ((candidate \"abcdefghij\" \"abcdefghij\") = 0));\n  (assert ((candidate \"\" \"abcd\") = 4));\n  (assert ((candidate \"abcd\" \"abc\") = 0));\n  (assert ((candidate \"a\" \"abcdef\") = 5));\n  (assert ((candidate \"abcdef\" \"abccef\") = 1));\n  (assert ((candidate \"abc\" \"abcd\") = 1));\n  (assert ((candidate \"abc\" \"abc\") = 0));\n  (assert ((candidate \"abc\" \"abcde\") = 2));\n  (assert ((candidate \"abcdefghijklmnop\" \"abcdefghijklmnopq\") = 1));\n  (assert ((candidate \"abc\" \"abcdef\") = 3));\n  (assert ((candidate \"abcdefghijklmnopqrstuvwxyz\" \"abcdefghijklmnopqrstuvwxyzab\") = 2));\n  (assert ((candidate \"abcdefghijklmnopqrstuvwxyz\" \"abcdefghijklmnopqrstuvwxyz\") = 0));\n  (assert ((candidate \"\" \"\") = 0));\n  (assert ((candidate \"\" \"abc\") = 3));\n  (assert ((candidate \"abc\" \"abcxyz\") = 3));\n  (assert ((candidate \"abcdef\" \"abcdef\") = 0));\n  (assert ((candidate \"abcd\" \"abcde\") = 1));\n  (assert ((candidate \"abc\" \"xyz\") = 3));\n  (assert ((candidate \"\" \"abcdef\") = 6));\n  (assert ((candidate \"abcd\" \"ac\") = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_351752_xyminmax_to_xywh", "language": "ml", "prompt": "(**convert box coordinates from (xmin, ymin, xmax, ymax) form to (x, y, w , h) form\n*)\nlet xyminmax_to_xywh (xmin : int) (ymin : int) (xmax : int) (ymax : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_351752_xyminmax_to_xywh.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = xyminmax_to_xywh in\n  (assert ((candidate 1 2 1 2) = [1; 2; 0; 0]));\n  (assert ((candidate 1 2 3 3) = [1; 2; 2; 1]));\n  (assert ((candidate (~1) (~1) 1 1) = [(~1); (~1); 2; 2]));\n  (assert ((candidate 1 1 3 5) = [1; 1; 2; 4]));\n  (assert ((candidate 1 1 3 4) = [1; 1; 2; 3]));\n  (assert ((candidate 1 2 3 4) = [1; 2; 2; 2]));\n  (assert ((candidate 1 2 3 2) = [1; 2; 2; 0]));\n  (assert ((candidate 1 2 1 4) = [1; 2; 0; 2]));\n  (assert ((candidate 0 0 1 1) = [0; 0; 1; 1]));\n  (assert ((candidate 3 7 5 9) = [3; 7; 2; 2]));\n  (assert ((candidate 1 1 3 3) = [1; 1; 2; 2]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_351898_lat_to_km", "language": "ml", "prompt": "(**Expresses given latitude in kilometers to the north\nArgs:\n * latitude (float): Latitude in degrees.\nReturns:\n * float: Latitude expressed in kilometers to the north\n*)\nlet lat_to_km (latitude : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_351898_lat_to_km.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = lat_to_km in\n  (assert ((candidate 0.0) = 0.0));\n  (assert ((candidate 0.0) = 0.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_35240_int_to_str", "language": "ml", "prompt": "(**Formats integer to string.\nThis function is used for operating with image names.\nExample: int_to_str(2) -> '02'\n*)\nlet int_to_str (number : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_35240_int_to_str.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = int_to_str in\n  (assert ((candidate 8) = \"08\"));\n  (assert ((candidate 2) = \"02\"));\n  (assert ((candidate 99) = \"99\"));\n  (assert ((candidate 13) = \"13\"));\n  (assert ((candidate 18) = \"18\"));\n  (assert ((candidate 7) = \"07\"));\n  (assert ((candidate 40) = \"40\"));\n  (assert ((candidate 1) = \"01\"));\n  (assert ((candidate 9) = \"09\"));\n  (assert ((candidate 16) = \"16\"));\n  (assert ((candidate 20) = \"20\"));\n  (assert ((candidate 1000) = \"1000\"));\n  (assert ((candidate 11) = \"11\"));\n  (assert ((candidate 14) = \"14\"));\n  (assert ((candidate 30) = \"30\"));\n  (assert ((candidate 50) = \"50\"));\n  (assert ((candidate 6) = \"06\"));\n  (assert ((candidate 19) = \"19\"));\n  (assert ((candidate 4) = \"04\"));\n  (assert ((candidate 38) = \"38\"));\n  (assert ((candidate 100) = \"100\"));\n  (assert ((candidate 0) = \"00\"));\n  (assert ((candidate 5) = \"05\"));\n  (assert ((candidate 15) = \"15\"));\n  (assert ((candidate 3) = \"03\"));\n  (assert ((candidate 12) = \"12\"));\n  (assert ((candidate 10) = \"10\"));\n  (assert ((candidate 17) = \"17\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_352460_mat_mul", "language": "ml", "prompt": "(**Function to performs matrix multiplication\nReturns the a new matrix\n*)\nlet mat_mul (mat1 : int list list) (mat2 : int list list) : int list list option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_352460_mat_mul.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = mat_mul in\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]; [7; 8; 9]] [[1; 2]; [3; 4]; [5; 6]]) = Some([[22; 28]; [49; 64]; [76; 100]])));\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]] [[7; 8]; [9; 10]]) = Some(None)));\n  (assert ((candidate [[1; 2]; [3; 4]] [[5; 6]; [7; 8]]) = Some([[19; 22]; [43; 50]])));\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]] [[1; 2]; [3; 4]; [5; 6]]) = Some([[22; 28]; [49; 64]])));\n  (assert ((candidate [[1; 2; 3; 4]; [5; 6; 7; 8]] [[1; 2; 3]; [4; 5; 6]]) = Some(None)));\n  (assert ((candidate [[1; 2]; [3; 4]] [[1; 2]; [3; 4]]) = Some([[7; 10]; [15; 22]])));\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]] [[7; 8]; [9; 10]; [11; 12]; [13; 14]]) = Some(None)));\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]] [[1]; [2]; [3]]) = Some([[14]; [32]])));\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]] [[7; 8]; [9; 10]; [11; 12]]) = Some([[58; 64]; [139; 154]])));\n  (assert ((candidate [[1; 2]; [3; 4]] [[1; 2]; [3; 4]; [5; 6]]) = Some(None)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_353572_name_cleanup", "language": "ml", "prompt": "(**cleanup a register name\n*)\nlet name_cleanup (s : string option) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_353572_name_cleanup.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = name_cleanup in\n  (assert ((candidate Some(\"a\")) = Some(\"a\")));\n  (assert ((candidate Some(\"a\")) = Some(\"a\")));\n  (assert ((candidate Some(None)) = Some(None)));\n  (assert ((candidate Some(\"Foo\")) = Some(\"Foo\")));\n  (assert ((candidate Some(\"r1\")) = Some(\"r1\")));\n  (assert ((candidate Some(\"reg\")) = Some(\"reg\")));\n  (assert ((candidate Some(\"[%s]\")) = Some(\"%s\")));\n  (assert ((candidate Some(\"\")) = Some(\"\")));\n  (assert ((candidate Some(\"foo\")) = Some(\"foo\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_354029_get_full_path_file_name", "language": "ml", "prompt": "(**Build full path to file given folder and file name\n*)\nlet get_full_path_file_name (folder_name : string) (file_name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_354029_get_full_path_file_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_full_path_file_name in\n  (assert ((candidate \"my_folder\" \"my_file.txt\") = \"my_folder/my_file.txt\"));\n  (assert ((candidate \"test_folder\" \"test_file\") = \"test_folder/test_file\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_354107__version2int", "language": "ml", "prompt": "(**X.X.X => X0X0X\n*)\nlet _version2int (v : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_354107__version2int.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _version2int in\n  (assert ((candidate \"1.0.2\") = 10002));\n  (assert ((candidate \"1.1.3\") = 10103));\n  (assert ((candidate \"0.0.*\") = 0));\n  (assert ((candidate \"1.2.3-dev\") = 10203));\n  (assert ((candidate \"1.0.12\") = 10012));\n  (assert ((candidate \"1.2.3\") = 10203));\n  (assert ((candidate \"0.0.0\") = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_354564_enforce_key_consistency", "language": "ml", "prompt": "(**Forces all keys to lowercase and replaces spaces with underscores\n*)\nlet enforce_key_consistency (key : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_354564_enforce_key_consistency.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = enforce_key_consistency in\n  (assert ((candidate \"snake case\") = \"snake_case\"));\n  (assert ((candidate \"Test\") = \"test\"));\n  (assert ((candidate \"UPPERCASE\") = \"uppercase\"));\n  (assert ((candidate \"FOO\") = \"foo\"));\n  (assert ((candidate \"snake_Case\") = \"snake_case\"));\n  (assert ((candidate \" 100\") = \"_100\"));\n  (assert ((candidate \"Test Test\") = \"test_test\"));\n  (assert ((candidate \"snake_case\") = \"snake_case\"));\n  (assert ((candidate \"lowercase\") = \"lowercase\"));\n  (assert ((candidate \"Foo\") = \"foo\"));\n  (assert ((candidate \"foo\") = \"foo\"));\n  (assert ((candidate \"UPPER SNAKE CASE\") = \"upper_snake_case\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_35470_rgb_to_tk", "language": "ml", "prompt": "(**Converts rgb values to tkinter color codes.\n:param rgb: Tuple of 3 ints.\n:return: tk color code string\n*)\nlet rgb_to_tk (rgb :  int * int * int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_35470_rgb_to_tk.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = rgb_to_tk in\n  (assert ((candidate (0, 128, 255)) = \"#0080ff\"));\n  (assert ((candidate (255, 0, 0)) = \"#ff0000\"));\n  (assert ((candidate (255, 255, 255)) = \"#ffffff\"));\n  (assert ((candidate (0, 0, 0)) = \"#000000\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_355601_g_speed", "language": "ml", "prompt": "(**returns a speed from a g-code\n*)\nlet g_speed (parameters : string) (actual_speed : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_355601_g_speed.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = g_speed in\n  (assert ((candidate \"f1000 x0 y0 z0\" 1000) = 1000));\n  (assert ((candidate \"x0 y0 z0\" 1000) = 1000));\n  (assert ((candidate \"f500\" 200) = 500));\n  (assert ((candidate \"f200\" 500) = 200));\n  (assert ((candidate \"f1000\" 1000) = 1000));\n  (assert ((candidate \"f2000 x0 y0 z0\" 1000) = 2000));\n  (assert ((candidate \"f2000\" 1000) = 2000));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_356550_substitute_file_extension", "language": "ml", "prompt": "(**Substitutes file extension, respecting known shader extensions.\nfoo.vert -> foo.vert.[extension] [similarly for .frag, .comp, etc.]\nfoo.glsl -> foo.[extension]\nfoo.unknown -> foo.[extension]\nfoo -> foo.[extension]\n*)\nlet substitute_file_extension (filename : string) (extension : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_356550_substitute_file_extension.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = substitute_file_extension in\n  (assert ((candidate \"foo\" \"frag\") = \"foo.frag\"));\n  (assert ((candidate \"foo.vert.frag\" \"frag\") = \"foo.vert.frag.frag\"));\n  (assert ((candidate \"foo.vert.frag.frag\" \"frag\") = \"foo.vert.frag.frag.frag\"));\n  (assert ((candidate \"foo.vert\" \"spvasm\") = \"foo.vert.spvasm\"));\n  (assert ((candidate \"foo.vert\" \"frag\") = \"foo.vert.frag\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_356733_strip_article_title_word", "language": "ml", "prompt": "(**Used when tokenizing the titles of articles\nin order to index them for search\n*)\nlet strip_article_title_word (word : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_356733_strip_article_title_word.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = strip_article_title_word in\n  (assert ((candidate \"\"\"\") = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_356963_FunList", "language": "ml", "prompt": "(**[Takes list and prints it vertically assigning each item its index number on CLI]\nArgs:\n * List ([string]): [The items to be displayed]\nReturns:\n * [string]: [a string displaying entries vertically with its indexes]\n*)\nlet FunList (List : string list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_356963_FunList.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = FunList in\n  (assert ((candidate [\"a\"; \"b\"; \"c\"; \"d\"; \"e\"; \"f\"; \"g\"; \"h\"]) = \"\n1 - a\n2 - b\n3 - c\n4 - d\n5 - e\n6 - f\n7 - g\n8 - h\n\"));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"]) = \"\n1 - a\n2 - b\n3 - c\n\"));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"; \"d\"; \"e\"; \"f\"; \"g\"]) = \"\n1 - a\n2 - b\n3 - c\n4 - d\n5 - e\n6 - f\n7 - g\n\"));\n  (assert ((candidate [\"a\"]) = \"\n1 - a\n\"));\n  (assert ((candidate []) = \"\n\"));\n  (assert ((candidate []) = \"\n\"));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"; \"d\"; \"e\"; \"f\"; \"g\"; \"h\"; \"i\"]) = \"\n1 - a\n2 - b\n3 - c\n4 - d\n5 - e\n6 - f\n7 - g\n8 - h\n9 - i\n\"));\n  (assert ((candidate []) = \"\n\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_357580_ld_to_m", "language": "ml", "prompt": "(**Converts the input distance (or velocity) of the input from Lunar distances to meters.\n*)\nlet ld_to_m (ld : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_357580_ld_to_m.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = ld_to_m in\n  (assert ((candidate (~1)) = (~384402000)));\n  (assert ((candidate 0) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_357625_phase", "language": "ml", "prompt": "(**Returns the layer thermodynamical phase, as identified from the\nfeature classification flag\n0 = unknown / not determined 1 = randomly oriented ice\n2 = water\n3 = horizontally oriented ice\n*)\nlet phase (flags : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_357625_phase.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = phase in\n  (assert ((candidate 63) = 1));\n  (assert ((candidate 18) = 0));\n  (assert ((candidate 29) = 0));\n  (assert ((candidate 4) = 0));\n  (assert ((candidate 255) = 3));\n  (assert ((candidate 11) = 0));\n  (assert ((candidate 5) = 0));\n  (assert ((candidate 17) = 0));\n  (assert ((candidate 9) = 0));\n  (assert ((candidate 22) = 0));\n  (assert ((candidate 10) = 0));\n  (assert ((candidate 21) = 0));\n  (assert ((candidate 31) = 0));\n  (assert ((candidate 6) = 0));\n  (assert ((candidate 27) = 0));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 23) = 0));\n  (assert ((candidate 112) = 3));\n  (assert ((candidate 48) = 1));\n  (assert ((candidate 19) = 0));\n  (assert ((candidate 26) = 0));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 12) = 0));\n  (assert ((candidate 208) = 2));\n  (assert ((candidate 208) = 2));\n  (assert ((candidate 8) = 0));\n  (assert ((candidate 7) = 0));\n  (assert ((candidate 28) = 0));\n  (assert ((candidate 24) = 0));\n  (assert ((candidate 20) = 0));\n  (assert ((candidate 256) = 0));\n  (assert ((candidate 64) = 2));\n  (assert ((candidate 14) = 0));\n  (assert ((candidate 1) = 0));\n  (assert ((candidate 25) = 0));\n  (assert ((candidate 2124414975) = 3));\n  (assert ((candidate 16) = 0));\n  (assert ((candidate 13) = 0));\n  (assert ((candidate 30) = 0));\n  (assert ((candidate 15) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_357773_new_mean_temperature", "language": "ml", "prompt": "(**Calculates a new mean temperature for the volume.\n:param area: in m^2\n:param height_external: in m\n:param temperature_external: in K\n:param heat: in J\n:return: temperature in K\n*)\nlet new_mean_temperature (area : int) (height_external : int) (temperature_external : float) (heat : int) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_357773_new_mean_temperature.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = new_mean_temperature in\n  (assert ((candidate 1 1 273.15 0) = 273.15));\n  (assert ((candidate 1 1 274.15 0) = 274.15));\n  (assert ((candidate 1 1 373.15 0) = 373.15));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_358759_pep8_to_camel_case", "language": "ml", "prompt": "(**Convert a PEP8 style name to camel case.\n*)\nlet pep8_to_camel_case (name : string) (initial : bool) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_358759_pep8_to_camel_case.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = pep8_to_camel_case in\n  (assert ((candidate \"the_quick_brown_fox_jumps_over_the_lazy_dog\" false) = \"theQuickBrownFoxJumpsOverTheLazyDog\"));\n  (assert ((candidate \"the_quick_brown_fox_jumps_over_the_lazy_dog\" true) = \"TheQuickBrownFoxJumpsOverTheLazyDog\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_35877__if_unmodified_since_passes", "language": "ml", "prompt": "(**Test the If-Unmodified-Since comparison as defined in section 3.4 of\nRFC 7232.\n*)\nlet _if_unmodified_since_passes (last_modified : int) (if_unmodified_since : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_35877__if_unmodified_since_passes.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _if_unmodified_since_passes in\n  (assert ((candidate 0 1) = false));\n  (assert ((candidate 1 1) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_359341_rfact", "language": "ml", "prompt": "(**Recursive\n*)\nlet rfact (n : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_359341_rfact.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = rfact in\n  (assert ((candidate 17) = 355687428096000));\n  (assert ((candidate 10) = 3628800));\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 19) = 121645100408832000));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 16) = 20922789888000));\n  (assert ((candidate 11) = 39916800));\n  (assert ((candidate 14) = 87178291200));\n  (assert ((candidate 12) = 479001600));\n  (assert ((candidate 6) = 720));\n  (assert ((candidate 7) = 5040));\n  (assert ((candidate 5) = 120));\n  (assert ((candidate 4) = 24));\n  (assert ((candidate 18) = 6402373705728000));\n  (assert ((candidate 3) = 6));\n  (assert ((candidate 0) = 1));\n  (assert ((candidate 9) = 362880));\n  (assert ((candidate 15) = 1307674368000));\n  (assert ((candidate 8) = 40320));\n  (assert ((candidate 13) = 6227020800));\n  (assert ((candidate 20) = 2432902008176640000));\n  (assert ((candidate 21) = 51090942171709440000));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_35954_trunc32", "language": "ml", "prompt": "(**Return the bottom 32 bits of w as a Python int.\nThis creates longs temporarily, but returns an int.\n*)\nlet trunc32 (w : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_35954_trunc32.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = trunc32 in\n  (assert ((candidate candidate 19088743) = 19088743));\n  (assert ((candidate 4294967295) = (~1)));\n  (assert ((candidate 18446744073709551615) = (~1)));\n  (assert ((candidate 4294967297) = 1));\n  (assert ((candidate (~1)) = (~1)));\n  (assert ((candidate 123456789) = 123456789));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 2147483647) = 2147483647));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 2147483648) = (~2147483648)));\n  (assert ((candidate 4294967295) = (~1)));\n  (assert ((candidate 4294967296) = 0));\n  (assert ((candidate (~17)) = (~17)));\n  (assert ((candidate candidate 0) = 0));\n  (assert ((candidate 19088743) = 19088743));\n  (assert ((candidate 87112285931760246646623899502532662132736) = 0));\n  (assert ((candidate 2147483647) = 2147483647));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate candidate 2147483647) = 2147483647));\n  (assert ((candidate 147573952589676412928) = 0));\n  (assert ((candidate 18446744073709551616) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_359972_add_to_whitelist", "language": "ml", "prompt": "(**Given a fingerprint, add to the whitelist\n*)\nlet add_to_whitelist (fingerprint :  (string, string) list * string * string) (additions : (string, string) list) :  (string, string) list * string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_359972_add_to_whitelist.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = add_to_whitelist in\n  (assert ((candidate ([(\"1\", \"1\"); (\"2\", \"2\"); (\"3\", \"3\")], \"2012-12-13T12:12:12Z\", \"2012-12-13T12:12:12Z\") [(\"4\", \"4\"); (\"5\", \"5\"); (\"6\", \"6\")]) = ([(\"1\", \"1\"); (\"2\", \"2\"); (\"3\", \"3\"); (\"4\", \"4\"); (\"5\", \"5\"); (\"6\", \"6\")], \"2012-12-13T12:12:12Z\", \"2012-12-13T12:12:12Z\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_360740_subtractFrom", "language": "ml", "prompt": "(**Subtraction formatter\n*)\nlet subtractFrom (acc : int) (curr : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_360740_subtractFrom.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = subtractFrom in\n  (assert ((candidate 5 6) = \"5 - 6\"));\n  (assert ((candidate 12 (~5)) = \"12 - -5\"));\n  (assert ((candidate 5 3) = \"5 - 3\"));\n  (assert ((candidate 0 0) = \"0 - 0\"));\n  (assert ((candidate 0 5) = \"0 - 5\"));\n  (assert ((candidate 3 2) = \"3 - 2\"));\n  (assert ((candidate 12 5) = \"12 - 5\"));\n  (assert ((candidate 5 0) = \"5 - 0\"));\n  (assert ((candidate (~5) (~5)) = \"-5 - -5\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_361436_get_actual_objname", "language": "ml", "prompt": "(**Given a object string full name (e.g 0&0&DEFINING_ORIGIN), returns\nits name (e.g DEFINING_ORIGIN).\n*)\nlet get_actual_objname (full_object_name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_361436_get_actual_objname.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_actual_objname in\n  (assert ((candidate \"0&0&DEFINING_ORIGIN&0\") = \"DEFINING_ORIGIN\"));\n  (assert ((candidate \"0&0&DEFINING_ORIGIN\") = \"DEFINING_ORIGIN\"));\n  (assert ((candidate \"0&0&DEFINING_ORIGIN\") = \"DEFINING_ORIGIN\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_362047_make_divisible", "language": "ml", "prompt": "(**This function is taken from the original tf repo.\nIt ensures that all layers have a channel number that is divisible by 8\nIt can be seen here:\nhttps://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n:param v:\n:param divisor:\n:param min_value:\n:return:\n*)\nlet make_divisible (v : int) (divisor : int) (min_value : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_362047_make_divisible.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = make_divisible in\n  (assert ((candidate 12 2) = 12));\n  (assert ((candidate 3 4) = 4));\n  (assert ((candidate 64 4) = 64));\n  (assert ((candidate 13 4) = 12));\n  (assert ((candidate 17 8) = 16));\n  (assert ((candidate 5 2) = 6));\n  (assert ((candidate 18 2) = 18));\n  (assert ((candidate 12 8) = 16));\n  (assert ((candidate 13 8) = 16));\n  (assert ((candidate 24 8) = 24));\n  (assert ((candidate 3 3) = 3));\n  (assert ((candidate 256 8) = 256));\n  (assert ((candidate 8 2) = 8));\n  (assert ((candidate 33 8) = 32));\n  (assert ((candidate 256 32) = 256));\n  (assert ((candidate 7 4) = 8));\n  (assert ((candidate 23 8) = 24));\n  (assert ((candidate 20 2) = 20));\n  (assert ((candidate 22 8) = 24));\n  (assert ((candidate 100 128) = 128));\n  (assert ((candidate 21 4) = 20));\n  (assert ((candidate 15 16) = 16));\n  (assert ((candidate 32 4) = 32));\n  (assert ((candidate 17 32) = 32));\n  (assert ((candidate 512 32) = 512));\n  (assert ((candidate 25 16) = 32));\n  (assert ((candidate 17 3) = 18));\n  (assert ((candidate 10 2) = 10));\n  (assert ((candidate 32 8) = 32));\n  (assert ((candidate 16 16) = 16));\n  (assert ((candidate 100 64) = 128));\n  (assert ((candidate 6 2) = 6));\n  (assert ((candidate 14 2) = 14));\n  (assert ((candidate 14 8) = 16));\n  (assert ((candidate 14 4) = 16));\n  (assert ((candidate 5 4) = 8));\n  (assert ((candidate 128 8) = 128));\n  (assert ((candidate 4 8) = 8));\n  (assert ((candidate 7 2) = 8));\n  (assert ((candidate 256 16) = 256));\n  (assert ((candidate 25 4) = 24));\n  (assert ((candidate 4 2) = 4));\n  (assert ((candidate 25 8) = 24));\n  (assert ((candidate 21 2) = 22));\n  (assert ((candidate 16 4) = 16));\n  (assert ((candidate 16 8) = 16));\n  (assert ((candidate 5 3) = 6));\n  (assert ((candidate 40 16) = 48));\n  (assert ((candidate 12 4) = 12));\n  (assert ((candidate 4 4) = 4));\n  (assert ((candidate 8 8) = 8));\n  (assert ((candidate 21 8) = 24));\n  (assert ((candidate 8 3) = 9));\n  (assert ((candidate 15 8) = 16));\n  (assert ((candidate 15 4) = 16));\n  (assert ((candidate 6 4) = 8));\n  (assert ((candidate 15 2) = 16));\n  (assert ((candidate 3 2) = 4));\n  (assert ((candidate 24 4) = 24));\n  (assert ((candidate 128 4) = 128));\n  (assert ((candidate 11 2) = 12));\n  (assert ((candidate 23 4) = 24));\n  (assert ((candidate 8 4) = 8));\n  (assert ((candidate 512 4) = 512));\n  (assert ((candidate 5 8) = 8));\n  (assert ((candidate 100 128 256) = 256));\n  (assert ((candidate 512 16) = 512));\n  (assert ((candidate 512 8) = 512));\n  (assert ((candidate 3 8) = 8));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_362264_compute_padding", "language": "ml", "prompt": "(**Computes the padding to be added on the left and on the right\nof the signal.\nIt should hold that 2**J_pad >= N\nParameters\n----------\nJ_pad : int\n * 2**J_pad is the support of the padded signal\nN : int\n * original signal support size\nReturns\n-------\npad_left: amount to pad on the left (\"beginning\" of the support)\npad_right: amount to pad on the right (\"end\" of the support)\nReferences\n----------\nThis is a modification of\nhttps://github.com/kymatio/kymatio/blob/master/kymatio/scattering1d/utils.py\nKymatio, (C) 2018-present. The Kymatio developers.\n*)\nlet compute_padding (J_pad : int) (N : int) :  int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_362264_compute_padding.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = compute_padding in\n  (assert ((candidate 1 2) = (0, 0)));\n  (assert ((candidate 12 2048) = (1024, 1024)));\n  (assert ((candidate 5 16) = (8, 8)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_362650_scale_100_to_10", "language": "ml", "prompt": "(**Convert a value from 0-100 range to 0-10 range.\nArgs:\n * value: an integer from 0 to 100.\nReturns:\n * an integer from 0 to 10\n*)\nlet scale_100_to_10 (value : int option) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_362650_scale_100_to_10.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = scale_100_to_10 in\n  (assert ((candidate ) = 10));\n  (assert ((candidate Some(None)) = 0));\n  (assert ((candidate Some(100)) = 10));\n  (assert ((candidate Some(10)) = 1));\n  (assert ((candidate Some(1000)) = 10));\n  (assert ((candidate Some(0)) = 0));\n  (assert ((candidate ) = 0));\n  (assert ((candidate ) = 0));\n  (assert ((candidate Some(50)) = 5));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_36313_I_form", "language": "ml", "prompt": "(**returns Identity matrix of order n\n*)\nlet I_form (n : int) : int list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_36313_I_form.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = I_form in\n  (assert ((candidate 0) = []));\n  (assert ((candidate 4) = [[1; 0; 0; 0]; [0; 1; 0; 0]; [0; 0; 1; 0]; [0; 0; 0; 1]]));\n  (assert ((candidate 2) = [[1; 0]; [0; 1]]));\n  (assert ((candidate 3) = [[1; 0; 0]; [0; 1; 0]; [0; 0; 1]]));\n  (assert ((candidate 3) = [[1; 0; 0]; [0; 1; 0]; [0; 0; 1]]));\n  (assert ((candidate 1) = [[1]]));\n  (assert ((candidate 5) = [[1; 0; 0; 0; 0]; [0; 1; 0; 0; 0]; [0; 0; 1; 0; 0]; [0; 0; 0; 1; 0]; [0; 0; 0; 0; 1]]));\n  (assert ((candidate 2) = [[1; 0]; [0; 1]]));\n  (assert ((candidate 2) = [[1; 0]; [0; 1]]));\n  (assert ((candidate 2) = [[1; 0]; [0; 1]]));\n  (assert ((candidate 3) = [[1; 0; 0]; [0; 1; 0]; [0; 0; 1]]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_363184_process", "language": "ml", "prompt": "(**Search the container for the element.\n:param container_: The list of elements\n:param search_element_: The element to search\n:return: return position of the element.\n*)\nlet process (container_ : int list) (search_element_ : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_363184_process.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = process in\n  (assert ((candidate [0; 1; 2; 3; 4; 5; 6; 7; 8; 9] 8) = 8));\n  (assert ((candidate [0; 1; 2; 3; 4; 5; 6; 7; 8; 9] 20) = (~1)));\n  (assert ((candidate [0; 1; 2; 3; 4; 5; 6; 7; 8; 9] 3) = 3));\n  (assert ((candidate [0; 1; 2; 3; 4; 5; 6; 7; 8; 9] 6) = 6));\n  (assert ((candidate [0; 1; 2; 3; 4; 5; 6; 7; 8; 9] 9) = 9));\n  (assert ((candidate [0; 1; 2; 3; 4; 5; 6; 7; 8; 9] 0) = 0));\n  (assert ((candidate [0; 1; 2; 3; 4; 5; 6; 7; 8; 9] 4) = 4));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_363888_escape_string", "language": "ml", "prompt": "(**Escape a string for command line use.\n*)\nlet escape_string (value : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_363888_escape_string.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = escape_string in\n  (assert ((candidate \"foo\\nbar\") = \"foo\\nbar\"));\n  (assert ((candidate \"\"\") = \"\\\"\"));\n  (assert ((candidate \"abc\") = \"abc\"));\n  (assert ((candidate \"foo\") = \"foo\"));\n  (assert ((candidate \"foo\") = \"foo\"));\n  (assert ((candidate \"foo\") = \"foo\"));\n  (assert ((candidate \"a\") = \"a\"));\n  (assert ((candidate \"{'a': 'b'}\") = \"{'a': 'b'}\"));\n  (assert ((candidate \"abc\") = \"abc\"));\n  (assert ((candidate \"abc\") = \"abc\"));\n  (assert ((candidate \"x\") = \"x\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_364333__ConvertBoxToCOCOFormat", "language": "ml", "prompt": "(**Converts a box in [ymin, xmin, ymax, xmax] format to COCO format.\nThis is a utility function for converting from our internal\n[ymin, xmin, ymax, xmax] convention to the convention used by the COCO API\ni.e., [xmin, ymin, width, height].\nArgs:\n * box: a [ymin, xmin, ymax, xmax] numpy array\nReturns:\n * a list of floats representing [xmin, ymin, width, height]\n*)\nlet _ConvertBoxToCOCOFormat (box : int list) : float list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_364333__ConvertBoxToCOCOFormat.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _ConvertBoxToCOCOFormat in\n  (assert ((candidate [0; 0; 100; 100]) = [0.0; 0.0; 100.0; 100.0]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_364399_allowed_file_models", "language": "ml", "prompt": "(**Check whether the type is allowed for a bpmn model file.\n:param filename: name of the file\n:return: True or False\n*)\nlet allowed_file_models (filename : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_364399_allowed_file_models.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = allowed_file_models in\n  (assert ((candidate \"my_filename.xml\") = false));\n  (assert ((candidate \"my_filename.jpeg\") = false));\n  (assert ((candidate \"my_filename.yaml\") = false));\n  (assert ((candidate \"my_filename.txt\") = false));\n  (assert ((candidate \"my_filename.png\") = false));\n  (assert ((candidate \"my_filename.bpmn\") = true));\n  (assert ((candidate \"my_filename.bpn\") = false));\n  (assert ((candidate \"my_filename.jpg\") = false));\n  (assert ((candidate \"my_filename.bpnm\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_364462_maybe_scream", "language": "ml", "prompt": "(**Returns given text input as caps lock text, if do_scream is true.\nArgs:\n * text (str): Some input text\n * do_scream (bool): Decide, whether to scream or not\nReturns:\n * str: May be in caps lock\n*)\nlet maybe_scream (text : string) (do_scream : bool) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_364462_maybe_scream.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = maybe_scream in\n  (assert ((candidate \"hello\" true) = \"HELLO\"));\n  (assert ((candidate \"Some text\" true) = \"SOME TEXT\"));\n  (assert ((candidate \"hello\" false) = \"hello\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_3645_wizard_active", "language": "ml", "prompt": "(**Return the proper classname for the step div in the badge wizard.\nThe current step needs a 'selected' class while the following step needs a\n'next-selected' class to color the tip of the arrow properly.\n*)\nlet wizard_active (step : int) (current : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_3645_wizard_active.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = wizard_active in\n  (assert ((candidate 4 4) = \"selected\"));\n  (assert ((candidate 3 2) = \"next-selected\"));\n  (assert ((candidate 3 3) = \"selected\"));\n  (assert ((candidate 2 1) = \"next-selected\"));\n  (assert ((candidate 5 4) = \"next-selected\"));\n  (assert ((candidate 2 2) = \"selected\"));\n  (assert ((candidate 1 1) = \"selected\"));\n  (assert ((candidate 4 3) = \"next-selected\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_364777_intervalsIntersect", "language": "ml", "prompt": "(**Returns True if the specified half-closed intervals [a1, b1)\nand [a2, b2) intersect.\n*)\nlet intervalsIntersect (a1 : int) (b1 : int) (a2 : int) (b2 : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_364777_intervalsIntersect.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = intervalsIntersect in\n  (assert ((candidate 1 2 2 3) = false));\n  (assert ((candidate 0 10 11 20) = false));\n  (assert ((candidate 1 3 1 3) = true));\n  (assert ((candidate 0 10 (~1) 0) = false));\n  (assert ((candidate 1 3 1 2) = true));\n  (assert ((candidate 2 3 2 2) = false));\n  (assert ((candidate 1 3 2 4) = true));\n  (assert ((candidate 0 10 5 20) = true));\n  (assert ((candidate 1 2 1 3) = true));\n  (assert ((candidate 1 2 1 2) = true));\n  (assert ((candidate 0 10 10 100) = false));\n  (assert ((candidate 0 10 10 20) = false));\n  (assert ((candidate 1 3 2 3) = true));\n  (assert ((candidate 2 3 1 2) = false));\n  (assert ((candidate 3 4 2 3) = false));\n  (assert ((candidate 1 2 2 2) = false));\n  (assert ((candidate 1 1 1 2) = false));\n  (assert ((candidate 1 2 3 4) = false));\n  (assert ((candidate 0 10 0 10) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_364905_pick_username", "language": "ml", "prompt": "(**>>> pick_username([\"JonaThan TanoTo\", \"WeiYue Li\"])\n'JonaThan TanoTo'\n>>> pick_username([\"JonaThan TanoTo\", \"WeiYue Li\", \"ShuBham KauShal\"])\n'ShuBham KauShal'\n>>> pick_username([\"JonaThan TanoTo\", \"WeiYue Li\", \"ShuBham KauShal\", \"MARINA\"])\n'MARINA'\n*)\nlet pick_username (names : string list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_364905_pick_username.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = pick_username in\n  (assert ((candidate [\"<NAME>\"; \"<NAME>\"; \"<NAME>\"; \"MARINA\"]) = \"MARINA\"));\n  (assert ((candidate [\"JonaThan TanoTo\"; \"WeiYue Li\"]) = \"JonaThan TanoTo\"));\n  (assert ((candidate [\"JonaThan TanoTo\"; \"WeiYue Li\"; \"ShuBham KauShal\"; \"MARINA\"]) = \"MARINA\"));\n  (assert ((candidate [\"<NAME>\"; \"<NAME>\"; \"<NAME>\"]) = \"<NAME>\"));\n  (assert ((candidate [\"JonaThan TanoTo\"; \"WeiYue Li\"; \"ShuBham KauShal\"]) = \"ShuBham KauShal\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_365886_sanitize_phone_field", "language": "ml", "prompt": "(**Phone Number Format\nAAAEEENNNNXXXX, where\nAAA = Area Code\nEEE = Exchange\nNNNN = Number\nXXXX = Extension\n*)\nlet sanitize_phone_field (s : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_365886_sanitize_phone_field.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sanitize_phone_field in\n  (assert ((candidate \"5551212\") = \"5551212\"));\n  (assert ((candidate \"800-555-1212\") = \"8005551212\"));\n  (assert ((candidate \"(800)555-3211\") = \"8005553211\"));\n  (assert ((candidate \"800-555-3535\") = \"8005553535\"));\n  (assert ((candidate \"912-456-7890\") = \"9124567890\"));\n  (assert ((candidate \"912.456.7890\") = \"9124567890\"));\n  (assert ((candidate \"800-555-3211\") = \"8005553211\"));\n  (assert ((candidate \"(123)456-7890\") = \"1234567890\"));\n  (assert ((candidate \"123.456.7890\") = \"1234567890\"));\n  (assert ((candidate \"8005551212\") = \"8005551212\"));\n  (assert ((candidate \"800(555)3535\") = \"8005553535\"));\n  (assert ((candidate \"555-1212\") = \"5551212\"));\n  (assert ((candidate \"(800)555-3535\") = \"8005553535\"));\n  (assert ((candidate \"123-456-7890\") = \"1234567890\"));\n  (assert ((candidate \"546-234-8900\") = \"5462348900\"));\n  (assert ((candidate \"800.555.3535\") = \"8005553535\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_366538_find_stem", "language": "ml", "prompt": "(**Find longest common substring in array of strings.\nFrom https://www.geeksforgeeks.org/longest-common-substring-array-strings/\n*)\nlet find_stem (arr : string list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_366538_find_stem.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = find_stem in\n  (assert ((candidate [\"Python\"; \"is\"; \"the\"; \"best\"; \"language\"]) = \"\"));\n  (assert ((candidate [\"Geeks\"; \"Geeks\"]) = \"Geeks\"));\n  (assert ((candidate [\"Python\"; \"Python\"; \"Python\"]) = \"Python\"));\n  (assert ((candidate [\"geek\"; \"gee\"; \"gee\"; \"geeksforgeeks\"]) = \"gee\"));\n  (assert ((candidate [\"geeks\"; \"geeksforgeeks\"; \"geek\"]) = \"geeks\"));\n  (assert ((candidate [\"geeksforgeeks\"; \"geeks\"; \"geek\"]) = \"geeks\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_366835_convertosides", "language": "ml", "prompt": "(**Takes polypoints describing the corners of a polygon and returns list of quadruples describing sides of polygon \nInput:\npolypointsx (list of float): corners of the polygon in a consecutive order, any format, x\npolypointsy (list of float): corners of the polygon in a consecutive order, any format, y\nOutput will be [[x1,x2,y1,y2], ...]\n*)\nlet convertosides (polypointsx : int list) (polypointsy : int list) : int list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_366835_convertosides.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = convertosides in\n  (assert ((candidate [1; 2; 3; 4] [5; 6; 7; 8; 9]) = [[1; 2; 5; 6]; [2; 3; 6; 7]; [3; 4; 7; 8]; [4; 1; 8; 5]]));\n  (assert ((candidate [1; 2; 3; 4; 5; 6] [7; 8; 9; 10; 11; 12]) = [[1; 2; 7; 8]; [2; 3; 8; 9]; [3; 4; 9; 10]; [4; 5; 10; 11]; [5; 6; 11; 12]; [6; 1; 12; 7]]));\n  (assert ((candidate [1; 2; 3; 4; 5] [6; 7; 8; 9; 10]) = [[1; 2; 6; 7]; [2; 3; 7; 8]; [3; 4; 8; 9]; [4; 5; 9; 10]; [5; 1; 10; 6]]));\n  (assert ((candidate [1; 2; 3; 4] [5; 6; 7; 8]) = [[1; 2; 5; 6]; [2; 3; 6; 7]; [3; 4; 7; 8]; [4; 1; 8; 5]]));\n  (assert ((candidate [1; 2; 3; 4; 5; 6] [7; 8; 9; 10; 11; 12]) = [[1; 2; 7; 8]; [2; 3; 8; 9]; [3; 4; 9; 10]; [4; 5; 10; 11]; [5; 6; 11; 12]; [6; 1; 12; 7]]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_366856_normalize_format", "language": "ml", "prompt": "(**Turns common shortenings into full format names.\n*)\nlet normalize_format (fmt : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_366856_normalize_format.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = normalize_format in\n  (assert ((candidate \"html\") = \"html\"));\n  (assert ((candidate \"html\") = \"html\"));\n  (assert ((candidate \"md\") = \"markdown\"));\n  (assert ((candidate \"markdown\") = \"markdown\"));\n  (assert ((candidate \"md\") = \"markdown\"));\n  (assert ((candidate \"mm\") = \"moinmoin\"));\n  (assert ((candidate \"rst\") = \"rst\"));\n  (assert ((candidate \"markdown\") = \"markdown\"));\n  (assert ((candidate \"mm\") = \"moinmoin\"));\n  (assert ((candidate \"txt\") = \"txt\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_368353_GetComplimentaryHex", "language": "ml", "prompt": "(**:param color:\n*)\nlet GetComplimentaryHex (color : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_368353_GetComplimentaryHex.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = GetComplimentaryHex in\n  (assert ((candidate \"#0000000\") = \"#FFFFFF\"));\n  (assert ((candidate \"#00000000000000\") = \"#FFFFFF\"));\n  (assert ((candidate \"#000000000\") = \"#FFFFFF\"));\n  (assert ((candidate \"#0000000000000\") = \"#FFFFFF\"));\n  (assert ((candidate \"#FFFFFF\") = \"#000000\"));\n  (assert ((candidate \"#00000000\") = \"#FFFFFF\"));\n  (assert ((candidate \"#000000000000000\") = \"#FFFFFF\"));\n  (assert ((candidate \"#00000000000\") = \"#FFFFFF\"));\n  (assert ((candidate \"#0000000000\") = \"#FFFFFF\"));\n  (assert ((candidate \"#000000000000\") = \"#FFFFFF\"));\n  (assert ((candidate \"#000000\") = \"#FFFFFF\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_369037_levenshtein_distance", "language": "ml", "prompt": "(**The minimum amount of edits needed to make s2 into s1.\nArgs:\n * s1: string\n * s2: string\nReturns:\n * int\n*)\nlet levenshtein_distance (s1 : string) (s2 : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_369037_levenshtein_distance.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = levenshtein_distance in\n  (assert ((candidate \"kitten\" \"sittingtt\") = 5));\n  (assert ((candidate \"abc\" \"def\") = 3));\n  (assert ((candidate \"123456789\" \"123456789\") = 0));\n  (assert ((candidate \"abcd\" \"abcd\") = 0));\n  (assert ((candidate \"kitten\" \"sitting\") = 3));\n  (assert ((candidate \"abc\" \"\") = 3));\n  (assert ((candidate \"kitten\" \"sitting\") = 3));\n  (assert ((candidate \"abcd\" \"abc\") = 1));\n  (assert ((candidate \"abc\" \"abcd\") = 1));\n  (assert ((candidate \"\" \"abc\") = 3));\n  (assert ((candidate \"abc\" \"abc\") = 0));\n  (assert ((candidate \"kitten\" \"sitttnn\") = 3));\n  (assert ((candidate \"kitten\" \"sitttn\") = 2));\n  (assert ((candidate \"\" \"kitten\") = 6));\n  (assert ((candidate \"kitten\" \"mittens\") = 2));\n  (assert ((candidate \"kitten\" \"kitten\") = 0));\n  (assert ((candidate \"kitten\" \"sittttttttnnn\") = 9));\n  (assert ((candidate \"one two three four\" \"one two three five\") = 3));\n  (assert ((candidate \"hello\" \"hello\") = 0));\n  (assert ((candidate \"kitten\" \"kitten\") = 0));\n  (assert ((candidate \"kitten\" \"sitting\") = 3));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_37035_remove_cations", "language": "ml", "prompt": "(**Removes periodic table group 1 and 7 counterions from the SMILES\nstrings.\n * Args:\n * -----\nSMILES (str) -- the SMILES string representation of the\n * molecule.\n * Returns:\n * --------\nSMILES (str) -- the string representation of the molecule with\n * the counterions omitted.\n*)\nlet remove_cations (SMILES : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_37035_remove_cations.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = remove_cations in\n  (assert ((candidate \"N1CC(N=c2c(C(C)C)n(C(C)(C)C)c(=O)c2C)CC1\") = \"N1CC(N=c2c(C(C)C)n(C(C)(C)C)c(=O)c2C)CC1\"));\n  (assert ((candidate \"NC1=CC(=O)C(C(C)(C)C)=C1C(N)=O\") = \"NC1=CC(=O)C(C(C)(C)C)=C1C(N)=O\"));\n  (assert ((candidate \"CC(=O)N1CCC(C(=O)c2c(C)n(C(C)(C)C)c(=O)c2C(N)=O)CC1\") = \"CC(=O)N1CCC(C(=O)c2c(C)n(C(C)(C)C)c(=O)c2C(N)=O)CC1\"));\n  (assert ((candidate \"N[N+]1(CCCC1)C\") = \"N[N+]1(CCCC1)C\"));\n  (assert ((candidate \"CN1CCC(C(=O)c2c(C)n(C(C)(C)C)c(=O)c2C(N)=O)CC1\") = \"CN1CCC(C(=O)c2c(C)n(C(C)(C)C)c(=O)c2C(N)=O)CC1\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_370597_inline_code", "language": "ml", "prompt": "(**Covert code to inline code\nArgs:\n * code (str) : code to be converted to inline code\nReturns:\n * str: inline code\n*)\nlet inline_code (code : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_370597_inline_code.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = inline_code in\n  (assert ((candidate \"print('Hello, World!')\") = \"`print('Hello, World!')`\"));\n  (assert ((candidate \"print('Hello, World!')\") = \"`print('Hello, World!')`\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_370651_set_paths_chemkin_files", "language": "ml", "prompt": "(**Set the absolute path to required files on the current machine.\n*** only required if using chemkin files****\nParameters\n-------\nmy_path                 : str\n * path where all the imput files are located\nReturns\n-------\nthermo_path            : str\n * path to the chemkin thermo file\nsmile_path             : str\n * path to the file `species_smiles.dat`\nreactionlist_path      : str\n * path to the chemkin reaction file\n*)\nlet set_paths_chemkin_files (my_path : string) :  string * string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_370651_set_paths_chemkin_files.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = set_paths_chemkin_files in\n  (assert ((candidate \"path/to/data/directory\") = (\"path/to/data/directory/data/thermo.dat\", \"path/to/data/directory/data/species_smiles.dat\", \"path/to/data/directory/data/reaction.dat\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_37129_compare_log_to_resp", "language": "ml", "prompt": "(**Search the log list for the responses in the response list\nSearch through the log list for the lines in the response list. The\nresponse list may contain substrings found in the log list lines. The\nresponse list lines must be found in the log list in the order they\nare specified in the response list (the log list may have extra lines\nwhich are ignored).\nReturns None if all the strings in the response list were found in the\nlog list. Otherwise, returns the first missing response line.\n*)\nlet compare_log_to_resp (log : string list) (resp : string list) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_37129_compare_log_to_resp.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = compare_log_to_resp in\n  (assert ((candidate [\"The quick brown fox jumps over the lazy dog\"] [\"The quick brown fox jumps over the lazy dog\"; \" \"; \" \"]) = Some(None)));\n  (assert ((candidate [\"The quick brown fox jumps over the lazy dog\"] [\"The quick brown fox jumps over the lazy dog\"]) = Some(None)));\n  (assert ((candidate [\"The quick brown fox jumps over the lazy dog\"] [\"The quick brown fox jumps over the lazy dog\"; \" \"; \" \"; \" \"; \" \"]) = Some(None)));\n  (assert ((candidate [\"A\"; \"B\"; \"C\"; \"D\"; \"E\"; \"F\"; \"G\"; \"H\"] [\"A\"; \"B\"; \"C\"; \"D\"; \"E\"; \"F\"; \"G\"; \"H\"]) = Some(None)));\n  (assert ((candidate [\"The quick brown fox jumps over the lazy dog\"] [\"The quick brown fox jumps over the lazy dog\"; \" \"; \" \"; \" \"]) = Some(None)));\n  (assert ((candidate [\"This is a test\"; \"This is another test\"] [\"This is a test\"; \"This is another test\"]) = Some(None)));\n  (assert ((candidate [\"The quick brown fox jumps over the lazy dog\"; \"The quick brown fox jumps over the lazy dog\"] [\"The quick brown fox jumps over the lazy dog\"; \"The quick brown fox jumps over the lazy dog\"]) = Some(None)));\n  (assert ((candidate [\"This is a test\"; \"This is another test\"] [\"This is a test\"; \"This is yet another test\"]) = Some(\"This is yet another test\")));\n  (assert ((candidate [\"The quick brown fox jumps over the lazy dog\"] [\"The quick brown fox jumps over the lazy dog\"; \"\"]) = Some(None)));\n  (assert ((candidate [\"The quick brown fox jumps over the lazy dog\"; \"The quick brown fox jumps over the lazy dog\"] [\"The quick brown fox jumps over the lazy dog\"]) = Some(None)));\n  (assert ((candidate [\"A\"; \"B\"; \"C\"; \"D\"; \"E\"; \"F\"; \"G\"; \"H\"] [\"A\"; \"B\"; \"C\"; \"D\"; \"E\"; \"G\"; \"F\"]) = Some(\"F\")));\n  (assert ((candidate [\"This is a test\"; \"This is another test\"] [\"This is a test\"; \"This is yet another test\"; \"\"]) = Some(\"This is yet another test\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_371762_query_delete_table", "language": "ml", "prompt": "(**Generate table delete query for table with name 'table'\n*)\nlet query_delete_table (table : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_371762_query_delete_table.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = query_delete_table in\n  (assert ((candidate \"books\") = \"DROP TABLE IF EXISTS books\"));\n  (assert ((candidate ) = \"DROP TABLE IF EXISTS students\"));\n  (assert ((candidate \"students\") = \"DROP TABLE IF EXISTS students\"));\n  (assert ((candidate \"my_table\") = \"DROP TABLE IF EXISTS my_table\"));\n  (assert ((candidate \"Users\") = \"DROP TABLE IF EXISTS Users\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_372605_boolean_to_xml", "language": "ml", "prompt": "(**serialize a boolean to XML\n:param obj: boolean\n:return: string in the XML accepted form\n*)\nlet boolean_to_xml (obj : bool) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_372605_boolean_to_xml.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = boolean_to_xml in\n  (assert ((candidate true) = \"true\"));\n  (assert ((candidate false) = \"false\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_372626_find_integer", "language": "ml", "prompt": "(**:params array: [[]]\n:params target: int\n:return bool\n*)\nlet find_integer (array : int list list) (target : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_372626_find_integer.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = find_integer in\n  (assert ((candidate [[1; 4]; [2; 3]; [3; 4]] 5) = false));\n  (assert ((candidate [[1; 4]; [2; 3]; [3; 4]] 7) = false));\n  (assert ((candidate [[1; 3; 5; 7; 9]; [10; 11; 16; 20]; [23; 30; 34; 50]] 24) = false));\n  (assert ((candidate [[1; 3; 5]; [7; 9; 11]; [20; 21]] 21) = true));\n  (assert ((candidate [[1; 2; 8; 9]; [2; 4; 9; 12]; [4; 7; 10; 13]; [6; 8; 11; 15]] 7) = true));\n  (assert ((candidate [[1; 4; 5; 8; 9]; [10; 11; 16; 20]; [23; 30; 34; 50]] 15) = false));\n  (assert ((candidate [[1; 3; 8; 9]; [2; 4; 9; 12]; [4; 7; 10; 13]; [6; 8; 11; 15]] 12) = true));\n  (assert ((candidate [] 1) = false));\n  (assert ((candidate [[1; 3; 5; 7; 9]; [10; 11; 16; 20]; [23; 30; 34; 50]] 20) = true));\n  (assert ((candidate [[1; 3; 8; 9]; [2; 4; 9; 12]; [4; 7; 10; 13]; [6; 8; 11; 15]] 13) = true));\n  (assert ((candidate [] 100) = false));\n  (assert ((candidate [[1; 3; 5]; [7; 9; 11]] 15) = false));\n  (assert ((candidate [[1; 3; 5; 7; 9]; [10; 11; 16; 20]; [23; 30; 34; 50]] 10) = true));\n  (assert ((candidate [[1; 3; 5; 7; 9]; [10; 11; 16; 20]; [23; 30; 34; 50]] 3) = true));\n  (assert ((candidate [[1; 4]; [2; 3]; [3; 4]] 0) = false));\n  (assert ((candidate [[1; 3; 8; 9]; [2; 4; 9; 12]; [4; 7; 10; 13]; [6; 8; 11; 15]] 200) = false));\n  (assert ((candidate [[1; 3; 5; 7; 9]; [10; 11; 16; 20]; [23; 30; 34; 50]] 3) = true));\n  (assert ((candidate [[1; 4]; [2; 3]; [3; 4]] 4) = true));\n  (assert ((candidate [[1; 4; 5; 8; 9]; [10; 11; 16; 20]; [23; 30; 34; 50]] 45) = false));\n  (assert ((candidate [[1; 3; 5; 7; 9]; [10; 11; 16; 20]; [23; 30; 34; 50]] 20) = true));\n  (assert ((candidate [[1; 4]; [2; 3]; [3; 4]] 3) = true));\n  (assert ((candidate [[1; 3; 5]; [7; 9; 11]] 3) = true));\n  (assert ((candidate [] 10) = false));\n  (assert ((candidate [[1; 3; 5; 7; 9]; [10; 11; 16; 20]; [23; 30; 34; 50]] 4) = false));\n  (assert ((candidate [[1; 3; 5; 7; 9]; [10; 11; 16; 20]; [23; 30; 34; 50]] 23) = true));\n  (assert ((candidate [[1; 3; 5]; [7; 9; 11]; [20; 21]] 22) = false));\n  (assert ((candidate [[1; 3; 8; 9]; [2; 4; 9; 12]; [4; 7; 10; 13]; [6; 8; 11; 15]] 100) = false));\n  (assert ((candidate [[1; 3; 8; 9]; [2; 4; 9; 12]; [4; 7; 10; 13]; [6; 8; 11; 15]] 2) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_373273_merge_usage_periods", "language": "ml", "prompt": "(**Merge a time period into an existing set of usage periods\n*)\nlet merge_usage_periods (periods : int list list) (new_period : int list) : int list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_373273_merge_usage_periods.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = merge_usage_periods in\n  (assert ((candidate [[1; 2]; [3; 4]] [2; 5]) = [[1; 5]]));\n  (assert ((candidate [[10; 20]; [30; 40]; [50; 60]] [1; 100]) = [[1; 100]]));\n  (assert ((candidate [[1; 2]; [3; 4]] [1; 3]) = [[1; 4]]));\n  (assert ((candidate [[1; 2]; [3; 4]] [1; 5]) = [[1; 5]]));\n  (assert ((candidate [[1; 2]] [3; 4]) = [[1; 2]; [3; 4]]));\n  (assert ((candidate [[1; 2]; [3; 4]] [2; 4]) = [[1; 4]]));\n  (assert ((candidate [[1; 2]; [3; 4]] [1; 4]) = [[1; 4]]));\n  (assert ((candidate [[1; 2]; [3; 4]] [2; 3]) = [[1; 4]]));\n  (assert ((candidate [[1; 2]; [3; 4]] [5; 6]) = [[1; 2]; [3; 4]; [5; 6]]));\n  (assert ((candidate [[10; 20]; [30; 40]] [10; 30]) = [[10; 40]]));\n  (assert ((candidate [[10; 20]; [30; 40]; [50; 60]] [30; 50]) = [[10; 20]; [30; 60]]));\n  (assert ((candidate [] [1; 2]) = [[1; 2]]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_373677_S_VAR_ASSIGN", "language": "ml", "prompt": "(**Evaluates an S_STATEMENT node\n*)\nlet S_VAR_ASSIGN (vardec : string) (assign : string) (data : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_373677_S_VAR_ASSIGN.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = S_VAR_ASSIGN in\n  (assert ((candidate \"v3\" \"=\" \"4\") = \"v3=4\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_373751_sort_array_for_min_number", "language": "ml", "prompt": "(**:param nums: int list\n:return: min number string\n*)\nlet sort_array_for_min_number (nums : int list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_373751_sort_array_for_min_number.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sort_array_for_min_number in\n  (assert ((candidate [1; 2; 4; 5; 3]) = \"12345\"));\n  (assert ((candidate [5; 4; 3; 2; 1]) = \"12345\"));\n  (assert ((candidate [1; 2; 3; 5; 4]) = \"12345\"));\n  (assert ((candidate [5; 1; 2; 3; 4]) = \"12345\"));\n  (assert ((candidate [1; 2; 3; 4; 5]) = \"12345\"));\n  (assert ((candidate [1; 2; 5; 4; 3]) = \"12345\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_373808_parse_time_cmd", "language": "ml", "prompt": "(**Convert timing info from `time` into float seconds.\t\nE.g. parse_time('0m0.000s') -> 0.0\n*)\nlet parse_time_cmd (s : string) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_373808_parse_time_cmd.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_time_cmd in\n  (assert ((candidate \"10m0.000s\") = 600.0));\n  (assert ((candidate \"0m0.010s\") = 0.01));\n  (assert ((candidate \"0m0.000s\") = 0.0));\n  (assert ((candidate \"1m0.000s\") = 60.0));\n  (assert ((candidate \"0m0.001s\") = 0.001));\n  (assert ((candidate \"0m10.000s\") = 10.0));\n  (assert ((candidate \"0m0.010s\") = 0.01));\n  (assert ((candidate \"0m2.000s\") = 2.0));\n  (assert ((candidate \"0m0.100s\") = 0.1));\n  (assert ((candidate \"1m0.000s\") = 60.0));\n  (assert ((candidate \"100m0.000s\") = 6000.0));\n  (assert ((candidate \"0m0.000s\") = 0.0));\n  (assert ((candidate \"0m0.001s\") = 0.001));\n  (assert ((candidate \"0m0.100s\") = 0.1));\n  (assert ((candidate \"0m0.000s\") = 0.0));\n  (assert ((candidate \"0m1.000s\") = 1.0));\n  (assert ((candidate \"0m0.001s\") = 0.001));\n  (assert ((candidate \"0m1.000s\") = 1.0));\n  (assert ((candidate \"1000m0.000s\") = 60000.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_374512__convert_ratio_to_int", "language": "ml", "prompt": "(**Round the ratio to 2 decimal places, multiply by 100, and take the integer part.\n*)\nlet _convert_ratio_to_int (ratio : float) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_374512__convert_ratio_to_int.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _convert_ratio_to_int in\n  (assert ((candidate 0.03) = 3));\n  (assert ((candidate 0.41) = 41));\n  (assert ((candidate 0.19) = 19));\n  (assert ((candidate 0.39) = 39));\n  (assert ((candidate 0.49) = 49));\n  (assert ((candidate 0.5) = 50));\n  (assert ((candidate 1.01) = 101));\n  (assert ((candidate 0.11) = 11));\n  (assert ((candidate 0.5) = 50));\n  (assert ((candidate 1.234567891234568) = 123));\n  (assert ((candidate 0.51) = 51));\n  (assert ((candidate 0.2) = 20));\n  (assert ((candidate 0.125) = 12));\n  (assert ((candidate 0.1) = 10));\n  (assert ((candidate 0.3) = 30));\n  (assert ((candidate 0.75) = 75));\n  (assert ((candidate 1.0) = 100));\n  (assert ((candidate 0.4) = 40));\n  (assert ((candidate 0.6) = 60));\n  (assert ((candidate 0.01) = 1));\n  (assert ((candidate 0.31) = 31));\n  (assert ((candidate 0.99) = 99));\n  (assert ((candidate 0.1) = 10));\n  (assert ((candidate 0.21) = 21));\n  (assert ((candidate 0.61) = 61));\n  (assert ((candidate 0.59) = 59));\n  (assert ((candidate 1.23456789) = 123));\n  (assert ((candidate 0.1234) = 12));\n  (assert ((candidate 0.0) = 0));\n  (assert ((candidate 0.0) = 0));\n  (assert ((candidate 0.09) = 9));\n  (assert ((candidate 0.25) = 25));\n  (assert ((candidate 0.02) = 2));\n  (assert ((candidate 1.2345678912345) = 123));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_374778_str2float", "language": "ml", "prompt": "(**Converts a string to a float.\n*)\nlet str2float (string : string) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_374778_str2float.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = str2float in\n  (assert ((candidate 1.0) = 1.0));\n  (assert ((candidate \"1.0/1.0\") = 1.0));\n  (assert ((candidate \"10\") = 10.0));\n  (assert ((candidate \"0\") = 0.0));\n  (assert ((candidate \"1/2\") = 0.5));\n  (assert ((candidate \"1\") = 1.0));\n  (assert ((candidate \"1/4\") = 0.25));\n  (assert ((candidate \"10.0\") = 10.0));\n  (assert ((candidate \"0.0/1.0\") = 0.0));\n  (assert ((candidate 1) = 1.0));\n  (assert ((candidate \"1/1\") = 1.0));\n  (assert ((candidate \"1/2.0\") = 0.5));\n  (assert ((candidate \"0.0\") = 0.0));\n  (assert ((candidate \"0/1\") = 0.0));\n  (assert ((candidate \"1.0/2.0\") = 0.5));\n  (assert ((candidate \"1.0\") = 1.0));\n  (assert ((candidate \"1/1.0\") = 1.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_375173_format_sequence", "language": "ml", "prompt": "(**Places the replacement character everywhere there is a False in the\ntemplate list\ninput: list list string\nreturns: string\n*)\nlet format_sequence (template : string list) (sequence : string list) (repl_char : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_375173_format_sequence.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = format_sequence in\n  (assert ((candidate list \"00000\" list \"10011\" \"?\") = \"10011\"));\n  (assert ((candidate list \"000\" list \"011\" \"?\") = \"011\"));\n  (assert ((candidate list \"0000\" list \"1011\" \"?\") = \"1011\"));\n  (assert ((candidate list \"000000\" list \"100110\" \"?\") = \"100110\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_375564_sort_list", "language": "ml", "prompt": "(**index: int number, according to it to sort data_list\n*)\nlet sort_list (data_list :  string * int list) (index : int) (reverse : bool) :  string * int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_375564_sort_list.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sort_list in\n  (assert ((candidate [(\"oranges\", 5); (\"apples\", 2); (\"bananas\", 1)] 1) = [(\"oranges\", 5); (\"apples\", 2); (\"bananas\", 1)]));\n  (assert ((candidate [(\"oranges\", 5); (\"apples\", 2); (\"bananas\", 1)] 0 false) = [(\"apples\", 2); (\"bananas\", 1); (\"oranges\", 5)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_375823_hreflang_formatter", "language": "ml", "prompt": "(**sitemap hreflang should follow correct format.\nUse hyphen instead of underscore in language and country value.\n * ref: https://en.wikipedia.org/wiki/Hreflang#Common_Mistakes\n * source: https://github.com/readthedocs/readthedocs.org/pull/5638\n*)\nlet hreflang_formatter (lang : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_375823_hreflang_formatter.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = hreflang_formatter in\n  (assert ((candidate \"en_GB\") = \"en-GB\"));\n  (assert ((candidate \"en_us\") = \"en-us\"));\n  (assert ((candidate \"zh-CN\") = \"zh-CN\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"zh_CN\") = \"zh-CN\"));\n  (assert ((candidate \"zh-TW\") = \"zh-TW\"));\n  (assert ((candidate \"zh_TW\") = \"zh-TW\"));\n  (assert ((candidate \"zh_tw\") = \"zh-tw\"));\n  (assert ((candidate \"zh_cn\") = \"zh-cn\"));\n  (assert ((candidate \"en\") = \"en\"));\n  (assert ((candidate \"zh-tw\") = \"zh-tw\"));\n  (assert ((candidate \"zh-cn\") = \"zh-cn\"));\n  (assert ((candidate \"en\") = \"en\"));\n  (assert ((candidate \"en_US\") = \"en-US\"));\n  (assert ((candidate \"en-US\") = \"en-US\"));\n  (assert ((candidate \"en_gb\") = \"en-gb\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_376349__to_swarming_dimensions", "language": "ml", "prompt": "(**Converts dimensions from buildbucket format to swarming format.\n*)\nlet _to_swarming_dimensions (dims : string list) : (string, string) list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_376349__to_swarming_dimensions.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _to_swarming_dimensions in\n  (assert ((candidate [\"os:mac\"; \"cpu:x86\"]) = [[(\"key\", \"os\"); (\"value\", \"mac\")]; [(\"key\", \"cpu\"); (\"value\", \"x86\")]]));\n  (assert ((candidate [\"pool:default\"; \"os:Ubuntu\"; \"cpu:x86-64\"; \"gce-vm:1\"; \"gpu:none\"]) = [[(\"key\", \"pool\"); (\"value\", \"default\")]; [(\"key\", \"os\"); (\"value\", \"Ubuntu\")]; [(\"key\", \"cpu\"); (\"value\", \"x86-64\")]; [(\"key\", \"gce-vm\"); (\"value\", \"1\")]; [(\"key\", \"gpu\"); (\"value\", \"none\")]]));\n  (assert ((candidate [\"os:OS\"; \"cpu:arm\"; \"pool:Chrome\"; \"gpu:GTX660\"; \"device_type:tablet\"]) = [[(\"key\", \"os\"); (\"value\", \"OS\")]; [(\"key\", \"cpu\"); (\"value\", \"arm\")]; [(\"key\", \"pool\"); (\"value\", \"Chrome\")]; [(\"key\", \"gpu\"); (\"value\", \"GTX660\")]; [(\"key\", \"device_type\"); (\"value\", \"tablet\")]]));\n  (assert ((candidate [\"os:mac\"; \"cpu:x86\"; \"pool:\"]) = [[(\"key\", \"os\"); (\"value\", \"mac\")]; [(\"key\", \"cpu\"); (\"value\", \"x86\")]; [(\"key\", \"pool\"); (\"value\", \"\")]]));\n  (assert ((candidate [\"os:Mac-10.9\"; \"pool:Chrome-perf\"; \"cpu:x86-64\"]) = [[(\"key\", \"os\"); (\"value\", \"Mac-10.9\")]; [(\"key\", \"pool\"); (\"value\", \"Chrome-perf\")]; [(\"key\", \"cpu\"); (\"value\", \"x86-64\")]]));\n  (assert ((candidate [\"os:Mac-10.9\"; \"pool:Chrome\"; \"cpu:x86-64\"]) = [[(\"key\", \"os\"); (\"value\", \"Mac-10.9\")]; [(\"key\", \"pool\"); (\"value\", \"Chrome\")]; [(\"key\", \"cpu\"); (\"value\", \"x86-64\")]]));\n  (assert ((candidate [\"os:mac\"; \"cpu:x86\"; \"pool:default\"]) = [[(\"key\", \"os\"); (\"value\", \"mac\")]; [(\"key\", \"cpu\"); (\"value\", \"x86\")]; [(\"key\", \"pool\"); (\"value\", \"default\")]]));\n  (assert ((candidate [\"os:Mac\"; \"pool:Chrome-perf\"]) = [[(\"key\", \"os\"); (\"value\", \"Mac\")]; [(\"key\", \"pool\"); (\"value\", \"Chrome-perf\")]]));\n  (assert ((candidate [\"os:Windows\"; \"pool:Chrome-perf\"]) = [[(\"key\", \"os\"); (\"value\", \"Windows\")]; [(\"key\", \"pool\"); (\"value\", \"Chrome-perf\")]]));\n  (assert ((candidate [\"os:mac\"; \"cpu:x86\"; \"pool:default:\"]) = [[(\"key\", \"os\"); (\"value\", \"mac\")]; [(\"key\", \"cpu\"); (\"value\", \"x86\")]; [(\"key\", \"pool\"); (\"value\", \"default:\")]]));\n  (assert ((candidate [\"os:Debian\"; \"cpu:x86-64\"; \"gce-vm:1\"; \"gpu:none\"]) = [[(\"key\", \"os\"); (\"value\", \"Debian\")]; [(\"key\", \"cpu\"); (\"value\", \"x86-64\")]; [(\"key\", \"gce-vm\"); (\"value\", \"1\")]; [(\"key\", \"gpu\"); (\"value\", \"none\")]]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_376708_build_matrix_row", "language": "ml", "prompt": "(**Populate row given all possible hits, accepted hits and an optional score\n:param all_vfs: a list of all virulence factor ids\n:param accepted_hits: a list of a hits that passed the cutoof\n:param score: the value to fill the matrix with (default = None which\n * implies 0.5)\n:type all_vfs: list\n:type accepted_hits: list\n:type score: float\n:rtype: a list of floats\n*)\nlet build_matrix_row (all_vfs : string list) (accepted_hits : string list) (score : float) : float list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_376708_build_matrix_row.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = build_matrix_row in\n  (assert ((candidate [\"10001\"; \"10002\"; \"10003\"; \"10004\"; \"10005\"] [\"10001\"; \"10002\"] 1.0) = [1.0; 1.0; 0.5; 0.5; 0.5]));\n  (assert ((candidate [\"10001\"; \"10002\"; \"10003\"; \"10004\"; \"10005\"] [\"10001\"; \"10002\"] 0.0) = [0.0; 0.0; 0.5; 0.5; 0.5]));\n  (assert ((candidate [] []) = [.0]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_376729_hosoya", "language": "ml", "prompt": "(**Calculates the hosoya triangle\nheight -- height of the triangle\n*)\nlet hosoya (height : int) (width : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_376729_hosoya.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = hosoya in\n  (assert ((candidate 3 1) = 2));\n  (assert ((candidate 1 1) = 1));\n  (assert ((candidate 1 3) = 0));\n  (assert ((candidate 5 5) = 8));\n  (assert ((candidate 5 4) = 5));\n  (assert ((candidate 0 2) = 0));\n  (assert ((candidate 0 2) = 0));\n  (assert ((candidate 3 2) = 2));\n  (assert ((candidate 4 4) = 5));\n  (assert ((candidate 1 1) = 1));\n  (assert ((candidate 2 1) = 1));\n  (assert ((candidate 1 0) = 1));\n  (assert ((candidate 1 3) = 0));\n  (assert ((candidate 3 3) = 3));\n  (assert ((candidate 1 0) = 1));\n  (assert ((candidate 0 0) = 1));\n  (assert ((candidate 2 1) = 1));\n  (assert ((candidate 0 0) = 1));\n  (assert ((candidate 0 3) = 0));\n  (assert ((candidate 0 3) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_37718_how_many_days", "language": "ml", "prompt": "(**Returns the number of days in a month.\nWARNING: This function doesn't account for leap years!\n*)\nlet how_many_days (month_number : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_37718_how_many_days.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = how_many_days in\n  (assert ((candidate 5) = 31));\n  (assert ((candidate 2) = 28));\n  (assert ((candidate 9) = 30));\n  (assert ((candidate 12) = 31));\n  (assert ((candidate 11) = 30));\n  (assert ((candidate 4) = 30));\n  (assert ((candidate 8) = 31));\n  (assert ((candidate 10) = 31));\n  (assert ((candidate 6) = 30));\n  (assert ((candidate 7) = 31));\n  (assert ((candidate 1) = 31));\n  (assert ((candidate 3) = 31));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_379101_line_parameters_xy", "language": "ml", "prompt": "(**Used in lines_intersection\nfrom:\nhttps://stackoverflow.com/questions/20677795/how-do-i-compute-the-intersection-point-of-two-lines-in-python\n*)\nlet line_parameters_xy (pt_1 :  int * int) (pt_2 :  int * int) :  int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_379101_line_parameters_xy.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = line_parameters_xy in\n  (assert ((candidate (0, 0) (1, 1)) = ((~1), 1, 0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_379304_countBits", "language": "ml", "prompt": "(**Count number of bits needed to store a (positive) integer number.\n>>> countBits(0)\n1\n>>> countBits(1000)\n10\n>>> countBits(44100)\n16\n>>> countBits(18446744073709551615)\n64\n*)\nlet countBits (value : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_379304_countBits.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = countBits in\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 3) = 2));\n  (assert ((candidate 10) = 4));\n  (assert ((candidate 44100) = 16));\n  (assert ((candidate 100) = 7));\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 6) = 3));\n  (assert ((candidate 8) = 4));\n  (assert ((candidate 1000) = 10));\n  (assert ((candidate 0) = 1));\n  (assert ((candidate 4) = 3));\n  (assert ((candidate 9) = 4));\n  (assert ((candidate 7) = 3));\n  (assert ((candidate 5) = 3));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_379324_int_max_value", "language": "ml", "prompt": "(**Returns the maximum int value of a signed or unsigned integer\nbased on used bits.\nArguments:\nbits -- How many bits, e.g., 16\nsigned -- True if a signed int\nReturns:\nmax_value -- The maximum int value based on given parameters\n*)\nlet int_max_value (bits : int) (signed : bool) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_379324_int_max_value.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = int_max_value in\n  (assert ((candidate 8 true) = 127));\n  (assert ((candidate 16 true) = 32767));\n  (assert ((candidate 8 false) = 255));\n  (assert ((candidate 8) = 127));\n  (assert ((candidate 16 false) = 65535));\n  (assert ((candidate 32 false) = 4294967295));\n  (assert ((candidate 64 false) = 18446744073709551615));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_379765_sum_numbers", "language": "ml", "prompt": "(**Calculate the sum of integers less than upper.\n*)\nlet sum_numbers (upper : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_379765_sum_numbers.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sum_numbers in\n  (assert ((candidate 3) = 3));\n  (assert ((candidate 5) = 10));\n  (assert ((candidate 2) = 1));\n  (assert ((candidate 1001) = 500500));\n  (assert ((candidate 1) = 0));\n  (assert ((candidate 101) = 5050));\n  (assert ((candidate 10) = 45));\n  (assert ((candidate 100) = 4950));\n  (assert ((candidate 0) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_380059_comment_lines", "language": "ml", "prompt": "(**Return commented lines\n*)\nlet comment_lines (lines : string list) (prefix : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_380059_comment_lines.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = comment_lines in\n  (assert ((candidate [\"This is a short comment.\"] \"#\") = [\"# This is a short comment.\"]));\n  (assert ((candidate [\"This is the first line.\"; \"This is the second line.\"] \"\") = [\"This is the first line.\"; \"This is the second line.\"]));\n  (assert ((candidate [\"\"] \"\") = [\"\"]));\n  (assert ((candidate [] \"#\") = []));\n  (assert ((candidate [\"This is the first line.\"; \"This is the second line.\"] \"#\") = [\"# This is the first line.\"; \"# This is the second line.\"]));\n  (assert ((candidate [\"This is a long comment\"; \"that contains multiple lines.\"] \"#\") = [\"# This is a long comment\"; \"# that contains multiple lines.\"]));\n  (assert ((candidate [\"\"] \"#\") = [\"#\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_380282_dict_item", "language": "ml", "prompt": "(**'Template filter to allow accessing dictionary value by variable key.\nExample use::\n * {{ mydict|dict_item:keyvar }}\n*)\nlet dict_item (dictionary : (string, string) list) (key : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_380282_dict_item.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = dict_item in\n  (assert ((candidate [(\"a\", \"A\"); (\"b\", \"B\"); (\"c\", \"C\")] \"c\") = \"C\"));\n  (assert ((candidate [(\"a\", \"1\"); (\"b\", \"2\")] \"a\") = \"1\"));\n  (assert ((candidate [(\"a\", \"A\"); (\"b\", \"B\"); (\"c\", \"C\")] \"a\") = \"A\"));\n  (assert ((candidate [(\"a\", \"1\"); (\"b\", \"2\")] \"b\") = \"2\"));\n  (assert ((candidate [(\"a\", \"A\"); (\"b\", \"B\"); (\"c\", \"C\")] \"b\") = \"B\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_38089_respuesta", "language": "ml", "prompt": "(**Funcion para formatear la respuesta.\n*)\nlet respuesta (res : bool) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_38089_respuesta.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = respuesta in\n  (assert ((candidate true) = \"iguales\"));\n  (assert ((candidate false) = \"diferentes\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_381395_camelize", "language": "ml", "prompt": "(**Make a camelcase string\nArgs:\n * strings (list[string]): list of strings\nDocTests:\n * >>> camelize(['one', 'two', 'three'])\n * 'OneTwoThree'\n*)\nlet camelize (strings : string list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_381395_camelize.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = camelize in\n  (assert ((candidate [\"123\"; \"four\"]) = \"123Four\"));\n  (assert ((candidate [\"this\"; \"is\"; \"a\"; \"sentence\"]) = \"ThisIsASentence\"));\n  (assert ((candidate [\"one\"; \"two\"; \"three\"; \"four\"; \"five\"]) = \"OneTwoThreeFourFive\"));\n  (assert ((candidate [\"one\"; \"two\"; \"three\"]) = \"OneTwoThree\"));\n  (assert ((candidate [\"candidate\"; \"me\"]) = \"CamelizeMe\"));\n  (assert ((candidate [\"one\"; \"two\"; \"three\"]) = \"OneTwoThree\"));\n  (assert ((candidate list ) = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_382168__remove_by_index_list", "language": "ml", "prompt": "(**Remove all substrings inside a string, thanks to the given list of indexes\n*)\nlet _remove_by_index_list (text : string) (index_list :  int * int list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_382168__remove_by_index_list.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _remove_by_index_list in\n  (assert ((candidate \"Hello, World!\" [(100, 200)]) = \"Hello, World!\"));\n  (assert ((candidate \"Hello, World!\" [(100, 100)]) = \"Hello, World!\"));\n  (assert ((candidate \"Hello, World!\" [(1, 1); (1, 1)]) = \"Hello, World!\"));\n  (assert ((candidate \"Hello, World!\" [(100, 101); (100, 101)]) = \"Hello, World!\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_382424_weight_path", "language": "ml", "prompt": "(**Get path of weights based on path to IR\nParams:\nmodel_path: the string contains path to IR file\nReturn:\nPath to weights file\n*)\nlet weight_path (model_path : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_382424_weight_path.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = weight_path in\n  (assert ((candidate \"test.xml\") = \"test.bin\"));\n  (assert ((candidate \"/path/to/file/mobilenet-ssd.xml\") = \"/path/to/file/mobilenet-ssd.bin\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_382473_string_rotation", "language": "ml", "prompt": "(**:param x: string\n:param y: string\n:return:\n*)\nlet string_rotation (x : string) (y : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_382473_string_rotation.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = string_rotation in\n  (assert ((candidate \"waterbottle\" \"bottlewater\") = true));\n  (assert ((candidate \"waterbottle\" \"waterbottle\") = true));\n  (assert ((candidate \"123456\" \"1234567\") = false));\n  (assert ((candidate \"12345\" \"12345\") = true));\n  (assert ((candidate \"waterbottle\" \"waterbottle\") = true));\n  (assert ((candidate \"bottlewater\" \"bottlewater\") = true));\n  (assert ((candidate \"12345\" \"12345\") = true));\n  (assert ((candidate \"waterbottle\" \"bottlewater\") = true));\n  (assert ((candidate \"abcdefg\" \"efgabcd\") = true));\n  (assert ((candidate \"waterbottle\" \"erbottlewat\") = true));\n  (assert ((candidate \"waterbottle\" \"waterbottle\") = true));\n  (assert ((candidate \"waterbottle\" \"erbottlewa\") = false));\n  (assert ((candidate \"waterbottle\" \"erbottlewat\") = true));\n  (assert ((candidate \"waterbottle\" \"waterbottle\") = true));\n  (assert ((candidate \"waterbottle\" \"erbottlewat\") = true));\n  (assert ((candidate \"a\" \"b\") = false));\n  (assert ((candidate \"erbottlewax\" \"erbottlewat\") = false));\n  (assert ((candidate \"\" \"a\") = false));\n  (assert ((candidate \"waterbottle\" \"erbottleaw\") = false));\n  (assert ((candidate \"123456\" \"123789\") = false));\n  (assert ((candidate \"123456\" \"123465\") = false));\n  (assert ((candidate \"123456\" \"123456\") = true));\n  (assert ((candidate \"a\" \"a\") = true));\n  (assert ((candidate \"erbottlewat\" \"waterbottle\") = true));\n  (assert ((candidate \"123456\" \"12345\") = false));\n  (assert ((candidate \"waterbottle\" \"erbottlewat\") = true));\n  (assert ((candidate \"bottlewater\" \"waterbottle\") = true));\n  (assert ((candidate \"waterbottle\" \"waterrbottle\") = false));\n  (assert ((candidate \"waterbottle\" \"erbottlewat\") = true));\n  (assert ((candidate \"erbottlewat\" \"erbottlewax\") = false));\n  (assert ((candidate \"waterrbottle\" \"waterbottle\") = false));\n  (assert ((candidate \"123456\" \"234567\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_383084_join_namespace", "language": "ml", "prompt": "(**Joins a namespace and a bare identifier into a full identifier.\n>>> join_namespace('a', 'b')\n'a:b'\n>>> join_namespace('', 'b')\n':b'\n*)\nlet join_namespace (namespace : string) (ident : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_383084_join_namespace.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = join_namespace in\n  (assert ((candidate \"a\" \"b\") = \"a:b\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_383373_splitrip", "language": "ml", "prompt": "(**Pass.\n*)\nlet splitrip (obj : string) (split : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_383373_splitrip.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = splitrip in\n  (assert ((candidate \" a b c d \" \" \") = [\"a\"; \"b\"; \"c\"; \"d\"]));\n  (assert ((candidate \"Hello\tWorld\tHow\tAre\tYou\" \"\t\") = [\"Hello\"; \"World\"; \"How\"; \"Are\"; \"You\"]));\n  (assert ((candidate \"a\tb\t\tc\t\td\" \"\t\") = [\"a\"; \"b\"; \"c\"; \"d\"]));\n  (assert ((candidate \"\tHello\tWorld\tHow\tAre\tYou\t\" \"\t\") = [\"Hello\"; \"World\"; \"How\"; \"Are\"; \"You\"]));\n  (assert ((candidate \"Hello\tWorld\tHow\tAre\tYou\" \" \") = [\"Hello\tWorld\tHow\tAre\tYou\"]));\n  (assert ((candidate \"a b c d\" \"x\") = [\"a b c d\"]));\n  (assert ((candidate \"\t\t\" \"\t\") = []));\n  (assert ((candidate \"Hello\tWorld\tHow\tAre\tYou\t\t\" \"\t\") = [\"Hello\"; \"World\"; \"How\"; \"Are\"; \"You\"]));\n  (assert ((candidate \"\" \"\t\") = []));\n  (assert ((candidate \"a b c d\" \" \") = [\"a\"; \"b\"; \"c\"; \"d\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_383429_bool_", "language": "ml", "prompt": "(**Convert boolean or string to boolean, also 'False' and 'F' to False\n*)\nlet bool_ (input_ : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_383429_bool_.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = bool_ in\n  (assert ((candidate \"False\") = false));\n  (assert ((candidate \"Yes\") = true));\n  (assert ((candidate \"True\") = true));\n  (assert ((candidate \"Y\") = true));\n  (assert ((candidate \"T\") = true));\n  (assert ((candidate \"F\") = false));\n  (assert ((candidate \"f\") = false));\n  (assert ((candidate \"1\") = true));\n  (assert ((candidate \"\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_383665_digitsaverage", "language": "ml", "prompt": "(**Return the average of the digits until number is one digit.\ninput = integer\noutput = integer, single digit\nex. 246 = 4 i.e. avg of 2 and 4 is 3, average of 4 and 6 is 5\n * so after first iteration 246 => 35\n * avg of 3 and 5 is 4 so digitsAverage(246) returns 4\n*)\nlet digitsaverage (d : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_383665_digitsaverage.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = digitsaverage in\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 7) = 7));\n  (assert ((candidate 246) = 4));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 987) = 9));\n  (assert ((candidate 9) = 9));\n  (assert ((candidate 6) = 6));\n  (assert ((candidate 3) = 3));\n  (assert ((candidate 10) = 1));\n  (assert ((candidate 2222) = 2));\n  (assert ((candidate 5) = 5));\n  (assert ((candidate 8) = 8));\n  (assert ((candidate 4) = 4));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_384049__formatArraySplitWiden", "language": "ml", "prompt": "(**Private func that gets iterated over as part of enjambing multiple formatted arrays side-by-side.\nAdds spaces such that the mutable sequence arFmtSplit (if joined by `\n`) will print as a rectangle.\nOptionally also extends the \"height\" of the rectangle to match lineCount. If lineCount <= len(arFmtSplit), nothing happens.\n*)\nlet _formatArraySplitWiden (arFmtSplit : string list) (blank : string) (linecount : int) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_384049__formatArraySplitWiden.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _formatArraySplitWiden in\n  (assert ((candidate [\"a1\"; \"b1\"; \"c1\"; \"d1\"] \" \" 4) = [\"a1\"; \"b1\"; \"c1\"; \"d1\"]));\n  (assert ((candidate [\"a1\"; \"b1\"; \"c1\"; \"d1\"] \"\" 6) = [\"a1\"; \"b1\"; \"c1\"; \"d1\"; \"\"; \"\"]));\n  (assert ((candidate [\"a1\"; \"b1\"; \"c1\"; \"d1\"] \"\" 5) = [\"a1\"; \"b1\"; \"c1\"; \"d1\"; \"\"]));\n  (assert ((candidate [\"a1\"; \"b1\"; \"c1\"; \"d1\"] \"\" 4) = [\"a1\"; \"b1\"; \"c1\"; \"d1\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_384332_pascal_case", "language": "ml", "prompt": "(**Convert the first letter of a string to uppercase, to make the identifier\nconform to PascalCase.\nIf there are dots, remove the dots, and capitalize the letter following\nwhere the dot was. Letters that weren't following dots are left unchanged,\nexcept for the first letter of the string (which is made upper-case).\nArgs:\n * what: a string representing some identifier\nReturns:\n * String with first letter capitalized\nExample:\n * pascal_case(\"helloWorld\") == \"HelloWorld\"\n * pascal_case(\"foo\") == \"Foo\"\n * pascal_case(\"hello.world\") = \"HelloWorld\"\n * pascal_case(\"fooBar.fooBar\") = \"FooBarFooBar\"\n*)\nlet pascal_case (what : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_384332_pascal_case.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = pascal_case in\n  (assert ((candidate \"HELLO WORLD\") = \"HELLO WORLD\"));\n  (assert ((candidate \"hello.world\") = \"HelloWorld\"));\n  (assert ((candidate \"foo\") = \"Foo\"));\n  (assert ((candidate \"abc\") = \"Abc\"));\n  (assert ((candidate \"fooBar.fooBar\") = \"FooBarFooBar\"));\n  (assert ((candidate \"helloWorld\") = \"HelloWorld\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_384769_ip_to_binary", "language": "ml", "prompt": "(**Convert an IPv4 address to a string containing the binary conversion of the\nIP address.\nArgs:\n * ip - The ip address to convert\n*)\nlet ip_to_binary (ip : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_384769_ip_to_binary.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = ip_to_binary in\n  (assert ((candidate \"10.10.10.10\") = \"00001010000010100000101000001010\"));\n  (assert ((candidate \"192.168.1.1\") = \"11000000101010000000000100000001\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_384893_remove_quotes", "language": "ml", "prompt": "(**remove all (double) quotes\n*)\nlet remove_quotes (string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_384893_remove_quotes.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = remove_quotes in\n  (assert ((candidate \"abc\"\") = \"abc\"));\n  (assert ((candidate \"a\"bc\") = \"abc\"));\n  (assert ((candidate \"\"a\"bc\"\") = \"abc\"));\n  (assert ((candidate \"\"abc\") = \"abc\"));\n  (assert ((candidate \"abc\") = \"abc\"));\n  (assert ((candidate \"a\"bc\"\") = \"abc\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_385138_get_next_step_size", "language": "ml", "prompt": "(**Calculate next size of step for a TQDM progress-bar.\n:param total:\n:param block_size:\n:param current_offset:\n:return:\n*)\nlet get_next_step_size (total : int) (block_size : int) (current_offset : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_385138_get_next_step_size.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_next_step_size in\n  (assert ((candidate 2 2 0) = 0));\n  (assert ((candidate 10 2 10) = 0));\n  (assert ((candidate 10 5 10) = 0));\n  (assert ((candidate 1 0 0) = 0));\n  (assert ((candidate 2 1 1) = 1));\n  (assert ((candidate 2 2 1) = 1));\n  (assert ((candidate 10 2 1) = 1));\n  (assert ((candidate 100 10 100) = 0));\n  (assert ((candidate 3 0 1) = 1));\n  (assert ((candidate 3 0 0) = 0));\n  (assert ((candidate 100 10 5) = 5));\n  (assert ((candidate 2 0 0) = 0));\n  (assert ((candidate 0 0 0) = 0));\n  (assert ((candidate 2 0 2) = 2));\n  (assert ((candidate 0 1 0) = 0));\n  (assert ((candidate 1 0 1) = 1));\n  (assert ((candidate 10 5 5) = 5));\n  (assert ((candidate 2 0 1) = 1));\n  (assert ((candidate 100 10 10) = 10));\n  (assert ((candidate 2 1 0) = 0));\n  (assert ((candidate 1 1 0) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_385358_get_package_version_key", "language": "ml", "prompt": "(**Return unique key combining package name and version.\n*)\nlet get_package_version_key (pkg_name : string) (pkg_version : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_385358_get_package_version_key.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_package_version_key in\n  (assert ((candidate \"package_name\" \"package_version\") = \"package_name@package_version\"));\n  (assert ((candidate \"package_name\" \"package_version\") = \"package_name@package_version\"));\n  (assert ((candidate \"foo\" \"1.0\") = \"foo@1.0\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_385738_read_file", "language": "ml", "prompt": "(**Read file content\n:param filepath:\n:return:\n*)\nlet read_file (filepath : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_385738_read_file.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = read_file in\n  (assert ((candidate 0) = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_386243_sort_by_points", "language": "ml", "prompt": "(**Returns a sorted list of dictionaries from alternative_hacker_news to\nbe ordered by score (highest first).\n*)\nlet sort_by_points (hn_list : (string, int) list list) : (string, int) list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_386243_sort_by_points.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sort_by_points in\n  (assert ((candidate [[(\"id\", 1); (\"score\", 10)]; [(\"id\", 2); (\"score\", 10)]; [(\"id\", 3); (\"score\", 10)]]) = [[(\"id\", 1); (\"score\", 10)]; [(\"id\", 2); (\"score\", 10)]; [(\"id\", 3); (\"score\", 10)]]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_38627__split_chunks", "language": "ml", "prompt": "(**Generates a list of lists of neighbouring ints. `l` must not be empty.\n>>> _split_chunks([1,2,3,5,6,7,9])\n[[1,2,3],[5,6,7],[9]]\n:type l: list[int]\n:rtype list[list[int]]\n*)\nlet _split_chunks (l : int list) : int list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_38627__split_chunks.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _split_chunks in\n  (assert ((candidate list range 10) = [[0; 1; 2; 3; 4; 5; 6; 7; 8; 9]]));\n  (assert ((candidate list range 1 6) = [[1; 2; 3; 4; 5]]));\n  (assert ((candidate list range 3) = [[0; 1; 2]]));\n  (assert ((candidate [1; 2; 3; 5; 6]) = [[1; 2; 3]; [5; 6]]));\n  (assert ((candidate [1; 2; 3; 5; 6; 7; 9]) = [[1; 2; 3]; [5; 6; 7]; [9]]));\n  (assert ((candidate [1; 2; 3]) = [[1; 2; 3]]));\n  (assert ((candidate list range 6) = [[0; 1; 2; 3; 4; 5]]));\n  (assert ((candidate list range 9) = [[0; 1; 2; 3; 4; 5; 6; 7; 8]]));\n  (assert ((candidate [1; 2; 3; 5]) = [[1; 2; 3]; [5]]));\n  (assert ((candidate list range 5) = [[0; 1; 2; 3; 4]]));\n  (assert ((candidate [1; 2; 3; 4; 6; 7; 8]) = [[1; 2; 3; 4]; [6; 7; 8]]));\n  (assert ((candidate list range 1) = [[0]]));\n  (assert ((candidate list range 2) = [[0; 1]]));\n  (assert ((candidate [1]) = [[1]]));\n  (assert ((candidate [1; 2; 3; 5; 6; 7]) = [[1; 2; 3]; [5; 6; 7]]));\n  (assert ((candidate [1; 2]) = [[1; 2]]));\n  (assert ((candidate list range 7) = [[0; 1; 2; 3; 4; 5; 6]]));\n  (assert ((candidate list range 3 8) = [[3; 4; 5; 6; 7]]));\n  (assert ((candidate list range 4) = [[0; 1; 2; 3]]));\n  (assert ((candidate list range 8) = [[0; 1; 2; 3; 4; 5; 6; 7]]));\n  (assert ((candidate list range 2 7) = [[2; 3; 4; 5; 6]]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_386910_format_seconds", "language": "ml", "prompt": "(**Format a floating point representing seconds into\na nice readable string.\nArguments:\n * seconds    The seconds to format.\nReturns:\n * A formatted string as either seconds, minutes, or hours.\n*)\nlet format_seconds (seconds : float) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_386910_format_seconds.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = format_seconds in\n  (assert ((candidate 1.0) = \"1.00 seconds\"));\n  (assert ((candidate 5.9) = \"5.90 seconds\"));\n  (assert ((candidate 60.0) = \"1.00 minutes\"));\n  (assert ((candidate 3600.0) = \"1.00 hours\"));\n  (assert ((candidate 1.0) = \"1.00 seconds\"));\n  (assert ((candidate 5.1) = \"5.10 seconds\"));\n  (assert ((candidate 2.0) = \"2.00 seconds\"));\n  (assert ((candidate 7200.0) = \"2.00 hours\"));\n  (assert ((candidate 90.0) = \"1.50 minutes\"));\n  (assert ((candidate 2.5) = \"2.50 seconds\"));\n  (assert ((candidate 120.0) = \"2.00 minutes\"));\n  (assert ((candidate 1.001) = \"1.00 seconds\"));\n  (assert ((candidate 5.0) = \"5.00 seconds\"));\n  (assert ((candidate 123.0) = \"2.05 minutes\"));\n  (assert ((candidate 60.0) = \"1.00 minutes\"));\n  (assert ((candidate 2.3) = \"2.30 seconds\"));\n  (assert ((candidate 3600.0) = \"1.00 hours\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_386946_coverageIsFailing", "language": "ml", "prompt": "(**Checks if coverage or branchs coverage or both are\nbelow minimum to pass workflow run. Logs messages if it is.\nActual failing behavior should be handled by caller.\nKeyword arguments:\ncoverage - instructions coverage in interval 0.0 to 1.0.\nbranches - branches coverage in interval 0.0 to 1.0.\nminCoverage - minimum instructions coverage to pass in interval 0.0 to 1.0.\nminBranches - minimum branches coverage to pass in interval 0.0 to 1.0.\n*)\nlet coverageIsFailing (coverage : float) (branches : float) (minCoverage : float) (minBranches : float) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_386946_coverageIsFailing.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = coverageIsFailing in\n  (assert ((candidate 0.0 0.1 0.0 0.0) = false));\n  (assert ((candidate 0.1 0.1 0.0 0.0) = false));\n  (assert ((candidate 0.1 0.1 0.0 0.1) = false));\n  (assert ((candidate 0.1 0.0 0.1 0.0) = false));\n  (assert ((candidate 0.0 1.0 1.0 0.0) = true));\n  (assert ((candidate 0.75 0.8 0.9 0.95) = true));\n  (assert ((candidate 1.0 1.0 1.0 1.0) = false));\n  (assert ((candidate 0.0 1.0 1.0 1.0) = true));\n  (assert ((candidate 0.0 0.1 0.0 0.1) = false));\n  (assert ((candidate 0.0 0.0 1.0 1.0) = true));\n  (assert ((candidate 0.0 0.0 0.0 1.0) = true));\n  (assert ((candidate 1.0 0.0 1.0 1.0) = true));\n  (assert ((candidate 0.5 0.75 0.5 0.5) = false));\n  (assert ((candidate 0.4 0.75 0.5 0.5) = true));\n  (assert ((candidate 0.0 0.0 1.0 0.0) = true));\n  (assert ((candidate 1.0 0.0 0.0 1.0) = true));\n  (assert ((candidate 0.75 0.7 0.8 0.9) = true));\n  (assert ((candidate 0.8 0.8 0.9 0.8) = true));\n  (assert ((candidate 0.0 0.0 0.0 0.0) = false));\n  (assert ((candidate 0.1 0.0 0.0 0.0) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_387299_remove_length10_word", "language": "ml", "prompt": "(**remove any words have length more than 10 on str\n*)\nlet remove_length10_word (review_str : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_387299_remove_length10_word.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = remove_length10_word in\n  (assert ((candidate \"The quick brown fox jumped over the lazy dog\") = \"The quick brown fox jumped over the lazy dog\"));\n  (assert ((candidate \"this film was amazingly bad\") = \"this film was amazingly bad\"));\n  (assert ((candidate \"The quick brown fox jumped over the lazy dog.\") = \"The quick brown fox jumped over the lazy dog.\"));\n  (assert ((candidate \"The quick brown fox jumped over the lazy dog the quick brown fox jumped over the lazy dog.\") = \"The quick brown fox jumped over the lazy dog the quick brown fox jumped over the lazy dog.\"));\n  (assert ((candidate \"The quick brown fox jumped over the lazy dog. The quick brown fox jumped over the lazy dog.\") = \"The quick brown fox jumped over the lazy dog. The quick brown fox jumped over the lazy dog.\"));\n  (assert ((candidate \"A\") = \"A\"));\n  (assert ((candidate \"\") = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_388125_f", "language": "ml", "prompt": "(**function to find bifurcations for\n*)\nlet f (x : int) (r : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_388125_f.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = f in\n  (assert ((candidate 1 1) = 0));\n  (assert ((candidate 0 1) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_388515_getLine", "language": "ml", "prompt": "(**Returns a list of (x, y) tuples of every point on a line between\n(x1, y1) and (x2, y2). The x and y values inside the tuple are integers.\nLine generated with the Bresenham algorithm.\nArgs:\n * x1 (int, float): The x coordinate of the line's start point.\n * y1 (int, float): The y coordinate of the line's start point.\n * x2 (int, float): The x coordinate of the line's end point.\n * y2 (int, float): The y coordiante of the line's end point.\nReturns:\n * [(x1, y1), (x2, y2), (x3, y3), ...]\nExample:\n>>> getLine(0, 0, 6, 6)\n[(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)]\n>>> getLine(0, 0, 3, 6)\n[(0, 0), (0, 1), (1, 2), (1, 3), (2, 4), (2, 5), (3, 6)]\n>>> getLine(3, 3, -3, -3)\n[(3, 3), (2, 2), (1, 1), (0, 0), (-1, -1), (-2, -2), (-3, -3)]\n*)\nlet getLine (x1 : int) (y1 : int) (x2 : int) (y2 : int) :  int * int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_388515_getLine.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = getLine in\n  (assert ((candidate 0 1 0 0) = [(0, 1); (0, 0)]));\n  (assert ((candidate 3 3 (~3) (~3)) = [(3, 3); (2, 2); (1, 1); (0, 0); ((~1), (~1)); ((~2), (~2)); ((~3), (~3))]));\n  (assert ((candidate 0 0 3 6) = [(0, 0); (0, 1); (1, 2); (1, 3); (2, 4); (2, 5); (3, 6)]));\n  (assert ((candidate 0 0 6 6) = [(0, 0); (1, 1); (2, 2); (3, 3); (4, 4); (5, 5); (6, 6)]));\n  (assert ((candidate 2 2 1 1) = [(2, 2); (1, 1)]));\n  (assert ((candidate 0 0 0 1) = [(0, 0); (0, 1)]));\n  (assert ((candidate 3 3 0 0) = [(3, 3); (2, 2); (1, 1); (0, 0)]));\n  (assert ((candidate 0 0 0 0) = [(0, 0)]));\n  (assert ((candidate 1 0 0 0) = [(1, 0); (0, 0)]));\n  (assert ((candidate 0 0 1 1) = [(0, 0); (1, 1)]));\n  (assert ((candidate 0 0 1 0) = [(0, 0); (1, 0)]));\n  (assert ((candidate 0 0 2 2) = [(0, 0); (1, 1); (2, 2)]));\n  (assert ((candidate 0 0 2 (~2)) = [(0, 0); (1, (~1)); (2, (~2))]));\n  (assert ((candidate 1 1 1 1) = [(1, 1)]));\n  (assert ((candidate 0 0 2 0) = [(0, 0); (1, 0); (2, 0)]));\n  (assert ((candidate 1 1 1 0) = [(1, 1); (1, 0)]));\n  (assert ((candidate 1 1 2 2) = [(1, 1); (2, 2)]));\n  (assert ((candidate 0 0 0 2) = [(0, 0); (0, 1); (0, 2)]));\n  (assert ((candidate 0 0 2 1) = [(0, 0); (1, 0); (2, 1)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_388654_inverse_interleave", "language": "ml", "prompt": "(**Given a coordinate where `a` has been interleaved and `b` hasn't, return \nthe value that `a` would have at `b=0`.\n*)\nlet inverse_interleave (a : int) (b : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_388654_inverse_interleave.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = inverse_interleave in\n  (assert ((candidate 4 2) = 4));\n  (assert ((candidate 2 2) = 2));\n  (assert ((candidate 13 7) = 13));\n  (assert ((candidate candidate 0 0 0) = 0));\n  (assert ((candidate 0 0) = 0));\n  (assert ((candidate 2 1) = 3));\n  (assert ((candidate 5 5) = 5));\n  (assert ((candidate candidate 2 1 0) = 2));\n  (assert ((candidate 3 3) = 3));\n  (assert ((candidate 4 0) = 4));\n  (assert ((candidate 5 1) = 5));\n  (assert ((candidate 6 0) = 6));\n  (assert ((candidate 7 7) = 7));\n  (assert ((candidate 6 1) = 7));\n  (assert ((candidate 2 0) = 2));\n  (assert ((candidate 4 1) = 5));\n  (assert ((candidate 4 4) = 4));\n  (assert ((candidate 7 1) = 7));\n  (assert ((candidate 8 8) = 8));\n  (assert ((candidate 6 6) = 6));\n  (assert ((candidate candidate 1 0 1) = 1));\n  (assert ((candidate 0 1) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_388924_escape_accent", "language": "ml", "prompt": "(**escape the following accented character(s) (e/i) into non-accented equivalent\n*)\nlet escape_accent (mystr : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_388924_escape_accent.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = escape_accent in\n  (assert ((candidate \"\u00c3\u00a9\") = \"e\"));\n  (assert ((candidate \"L'a\u00c3\u00a9roport\") = \"L'aeroport\"));\n  (assert ((candidate \"D'a\u00c3\u00a9roport\") = \"D'aeroport\"));\n  (assert ((candidate \"L'a\u00c3\u0089roport\") = \"L'aeroport\"));\n  (assert ((candidate \"\u00c3\u00ae\") = \"i\"));\n  (assert ((candidate \"Je ne suis pas \u00e0 l'\u00e9cole. Je suis \u00e0 l'\u00e9tablissement. Je suis \u00e0 l'\u00e9cole. Je ne suis pas \u00e0 l'\u00e9tablissement.\") = candidate \"Je ne suis pas \u00e0 l'\u00e9cole. Je suis \u00e0 l'\u00e9tablissement. Je suis \u00e0 l'\u00e9cole. Je ne suis pas \u00e0 l'\u00e9tablissement.\"));\n  (assert ((candidate \"D'a\u00c3\u0089roport\") = \"D'aeroport\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_389434_findAnEven", "language": "ml", "prompt": "(**Assumes l is a list of ints\nReturns the first even num in l\nRaises ValueError if l doesn't contain an even num\n*)\nlet findAnEven (l : int list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_389434_findAnEven.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = findAnEven in\n  (assert ((candidate [2; 3; 5]) = 2));\n  (assert ((candidate [2; 4; 6; 8; 10]) = 2));\n  (assert ((candidate [2; 3; 6]) = 2));\n  (assert ((candidate [2; 3; 4]) = 2));\n  (assert ((candidate [1; 2; 3]) = 2));\n  (assert ((candidate [2; 5; 6]) = 2));\n  (assert ((candidate [3; 5; 6]) = 6));\n  (assert ((candidate [2; 4; 6; 8; 10; 12; 14; 16; 18]) = 2));\n  (assert ((candidate [2; 4; 6]) = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_390316_moffat_r", "language": "ml", "prompt": "(**Moffat profile\n:param r: radial coordinate\n:param alpha:\n:param beta:\n:return:\n*)\nlet moffat_r (r : float) (alpha : float) (beta : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_390316_moffat_r.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = moffat_r in\n  (assert ((candidate 2.0 1.0 1.0) = 0.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_391663_f_to_k", "language": "ml", "prompt": "(**Convierte temperaturas de Fahrenheit a Kelvin\nParameters:\n * tf : Temperatura en grados Fahrenheit\nReturns:\n * tk : Temperatura en grados Kelvin\n*)\nlet f_to_k (tf : int option) : float option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_391663_f_to_k.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = f_to_k in\n  (assert ((candidate Some(32)) = Some(273.5)));\n  (assert ((candidate Some(None)) = Some(None)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_391695_get_first_key", "language": "ml", "prompt": "(**Get first key in a dict for a given value.\n:param dict dictionary:\n:param string value:\n*)\nlet get_first_key (dictionary : (string, string) list) (value : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_391695_get_first_key.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_first_key in\n  (assert ((candidate [(\"foo\", \"bar\"); (\"barfoo\", \"foobar\"); (\"foobar\", \"barfoo\")] \"foobar\") = \"barfoo\"));\n  (assert ((candidate [(\"foo\", \"bar\"); (\"foobar\", \"barfoo\")] \"bar\") = \"foo\"));\n  (assert ((candidate [(\"foo\", \"bar\"); (\"foobar\", \"barfoo\"); (\"bar\", \"foo\")] \"bar\") = \"foo\"));\n  (assert ((candidate [(\"foo\", \"bar\"); (\"barfoo\", \"foobar\"); (\"foobar\", \"barfoo\")] \"bar\") = \"foo\"));\n  (assert ((candidate [(\"foo\", \"bar\"); (\"foobar\", \"barfoo\"); (\"bar\", \"foo\")] \"barfoo\") = \"foobar\"));\n  (assert ((candidate [(\"foo\", \"bar\"); (\"foobar\", \"barfoo\")] \"barfoo\") = \"foobar\"));\n  (assert ((candidate [(\"foo\", \"bar\"); (\"foobar\", \"barfoo\"); (\"bar\", \"foo\")] \"foo\") = \"bar\"));\n  (assert ((candidate [(\"foo\", \"bar\"); (\"barfoo\", \"foobar\"); (\"foobar\", \"barfoo\")] \"barfoo\") = \"foobar\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_392592_startswith_word", "language": "ml", "prompt": "(**Check if a string starts with a word\nBasic startswith method doesn't separate into words, so checking if a string\nstarts with '$foo' will return true for both '$foo' and '$fooooooo'.\nParameters\n==========\nphrase : str\n * Phrase to check startswith against.\nstartswith : str\n * Word to check whether or not phrase starts with it.\nReturns\n=======\nbool\n * True if the first word of phrase is startswith, False otherwise.\n*)\nlet startswith_word (phrase : string) (startswith : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_392592_startswith_word.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = startswith_word in\n  (assert ((candidate \"test\" \"test\") = true));\n  (assert ((candidate \"$bar $bar $foo\" \"$foo\") = false));\n  (assert ((candidate \"$foo $bar $foo\" \"$foo\") = true));\n  (assert ((candidate \"This is a $bar\" \"$foo\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_392962_is_prime", "language": "ml", "prompt": "(**Returns True if the number is prime\nelse False.\n*)\nlet is_prime (num : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_392962_is_prime.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_prime in\n  (assert ((candidate 6) = false));\n  (assert ((candidate 24) = false));\n  (assert ((candidate 33) = false));\n  (assert ((candidate 36) = false));\n  (assert ((candidate 14) = false));\n  (assert ((candidate 27) = false));\n  (assert ((candidate 29) = true));\n  (assert ((candidate 35) = false));\n  (assert ((candidate 17) = true));\n  (assert ((candidate 2) = true));\n  (assert ((candidate 0) = false));\n  (assert ((candidate 30) = false));\n  (assert ((candidate 12) = false));\n  (assert ((candidate 22) = false));\n  (assert ((candidate 16) = false));\n  (assert ((candidate 7) = true));\n  (assert ((candidate 28) = false));\n  (assert ((candidate 9) = false));\n  (assert ((candidate 19) = true));\n  (assert ((candidate 34) = false));\n  (assert ((candidate 10) = false));\n  (assert ((candidate 11) = true));\n  (assert ((candidate 5) = true));\n  (assert ((candidate 23) = true));\n  (assert ((candidate 1) = false));\n  (assert ((candidate 26) = false));\n  (assert ((candidate 32) = false));\n  (assert ((candidate 3) = true));\n  (assert ((candidate 13) = true));\n  (assert ((candidate 38) = false));\n  (assert ((candidate 20) = false));\n  (assert ((candidate 21) = false));\n  (assert ((candidate 15) = false));\n  (assert ((candidate 8) = false));\n  (assert ((candidate (~10000000001)) = true));\n  (assert ((candidate 100) = false));\n  (assert ((candidate 25) = false));\n  (assert ((candidate 18) = false));\n  (assert ((candidate 37) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_394041_escape", "language": "ml", "prompt": "(**Replace special characters '&', \"'\", '<', '>' and '\"' by XML entities.\n*)\nlet escape (s : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_394041_escape.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = escape in\n  (assert ((candidate \"a>b\") = \"a&gt;b\"));\n  (assert ((candidate \"a<b\") = \"a&lt;b\"));\n  (assert ((candidate \"1 < 2\") = \"1 &lt; 2\"));\n  (assert ((candidate \"one < two\") = \"one &lt; two\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"<\") = \"&lt;\"));\n  (assert ((candidate \"a\"b\") = \"a&quot;b\"));\n  (assert ((candidate \"\"1 < 2\"\") = \"&quot;1 &lt; 2&quot;\"));\n  (assert ((candidate \" a b c \") = \" a b c \"));\n  (assert ((candidate \"\"\") = \"&quot;\"));\n  (assert ((candidate \"'1 < 2'\") = \"&apos;1 &lt; 2&apos;\"));\n  (assert ((candidate \"<a>\") = \"&lt;a&gt;\"));\n  (assert ((candidate \">\") = \"&gt;\"));\n  (assert ((candidate \" \") = \" \"));\n  (assert ((candidate \"abc \") = \"abc \"));\n  (assert ((candidate \"foo\") = \"foo\"));\n  (assert ((candidate \"&\") = \"&amp;\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"a'b\") = \"a&apos;b\"));\n  (assert ((candidate \"a\") = \"a\"));\n  (assert ((candidate \" abc\") = \" abc\"));\n  (assert ((candidate \"'\") = \"&apos;\"));\n  (assert ((candidate \"&<>'\") = \"&amp;&lt;&gt;&apos;\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_395176_py_type_name", "language": "ml", "prompt": "(**Get the Python type name for a given model type.\n>>> py_type_name('list')\n'list'\n>>> py_type_name('structure')\n'dict'\n * :rtype: string\n*)\nlet py_type_name (type_name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_395176_py_type_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = py_type_name in\n  (assert ((candidate \"list\") = \"list\"));\n  (assert ((candidate \"structure\") = \"dict\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_396186_calculate_stations_adjoint", "language": "ml", "prompt": "(**get the files STATIONS_ADJOINT.\n*)\nlet calculate_stations_adjoint (py : string) (stations_path : string) (misfit_windows_directory : string) (output_directory : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_396186_calculate_stations_adjoint.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = calculate_stations_adjoint in\n  (assert ((candidate \"seisflow/scripts/shared/get_stations_adjoint.py\" \"asdf\" \"asdf\" \"asdf\") = \"ibrun -n 1 seisflow/scripts/shared/get_stations_adjoint.py -m seisflow.scripts.shared.get_stations_adjoint --stations_path asdf --misfit_windows_directory asdf --output_directory asdf; \n\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_396471_comment_string_with_block", "language": "ml", "prompt": "(**Return string commented using block comments\n*)\nlet comment_string_with_block (string : string option) (block_comment :  string * string option) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_396471_comment_string_with_block.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = comment_string_with_block in\n  (assert ((candidate Some(\"\") Some((\"#\", \"\"))) = Some(\"\")));\n  (assert ((candidate Some(\"\") Some((\"/*\", \"*/\"))) = Some(\"\")));\n  (assert ((candidate Some(\"a\") Some((\"#begin\", \"#end\"))) = Some(\"#begin a #end\")));\n  (assert ((candidate Some(\"\") Some(None)) = Some(\"\")));\n  (assert ((candidate Some(None) Some((\"#\", \"\"))) = Some(None)));\n  (assert ((candidate Some(\"abc\") Some((\"<!--\", \"-->\"))) = Some(\"<!-- abc -->\")));\n  (assert ((candidate Some(\"a = 1\") Some((\"/*\", \"*/\"))) = Some(\"/* a = 1 */\")));\n  (assert ((candidate Some(\"This is a string.\") Some((\"\"\"\"\", \"\"\"\"\"))) = Some(\"\"\"\" This is a string. \"\"\"\")));\n  (assert ((candidate Some(\"Hello World\") Some((\"/*\", \"*/\"))) = Some(\"/* Hello World */\")));\n  (assert ((candidate Some(\"\") Some((\"#begin\", \"#end\"))) = Some(\"\")));\n  (assert ((candidate Some(\"a = 1\nb = 2\nc = 3\") Some((\"/*\", \"*/\"))) = Some(\"/* a = 1\nb = 2\nc = 3 */\")));\n  (assert ((candidate Some(\"a\") Some((\"<!--\", \"-->\"))) = Some(\"<!-- a -->\")));\n  (assert ((candidate Some(\"This is a string.\") Some((\"/*\", \"*/\"))) = Some(\"/* This is a string. */\")));\n  (assert ((candidate Some(\"Hello World\nHow are you?\") Some((\"/*\", \"*/\"))) = Some(\"/* Hello World\nHow are you? */\")));\n  (assert ((candidate Some(None) Some((\"/*\", \"*/\"))) = Some(None)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_396730__remapLanguageCode", "language": "ml", "prompt": "(**Remap certain language codes to others, per the localization team\n*)\nlet _remapLanguageCode (code : string option) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_396730__remapLanguageCode.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _remapLanguageCode in\n  (assert ((candidate Some(\"zh-Hans\")) = Some(\"zh_CN\")));\n  (assert ((candidate Some(None)) = Some(None)));\n  (assert ((candidate Some(\"zh-Hant\")) = Some(\"zh_TW\")));\n  (assert ((candidate Some(\"en_US\")) = Some(\"en_US\")));\n  (assert ((candidate Some(\"en_GB\")) = Some(\"en_GB\")));\n  (assert ((candidate Some(\"ja_JP\")) = Some(\"ja_JP\")));\n  (assert ((candidate Some(\"en\")) = Some(\"en\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_397294_prism_item_in_list", "language": "ml", "prompt": "(**Compare a single prism specifiation to a list of PRISM files\nreturned by pyPRISMClimate.prism_iterator\n*)\nlet prism_item_in_list (qury_item : (string, string) list) (list_of_items_to_check : (string, string) list list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_397294_prism_item_in_list.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = prism_item_in_list in\n  (assert ((candidate [(\"model\", \"ACCESS1-3\"); (\"experiment\", \"rcp45\"); (\"frequency\", \"monthly\"); (\"variable\", \"ppt\")] [[(\"model\", \"ACCESS1-3\"); (\"experiment\", \"rcp45\"); (\"frequency\", \"monthly\"); (\"variable\", \"tmax\")]; [(\"model\", \"ACCESS1-3\"); (\"experiment\", \"rcp45\"); (\"frequency\", \"monthly\"); (\"variable\", \"tmax\")]; [(\"model\", \"ACCESS1-3\"); (\"experiment\", \"historical\"); (\"frequency\", \"monthly\"); (\"variable\", \"ppt\")]]) = false));\n  (assert ((candidate [(\"model\", \"ACCESS1-3\"); (\"experiment\", \"rcp45\"); (\"frequency\", \"monthly\"); (\"variable\", \"ppt\")] [[(\"model\", \"ACCESS1-3\"); (\"experiment\", \"rcp45\"); (\"frequency\", \"monthly\"); (\"variable\", \"ppt\")]; [(\"model\", \"ACCESS1-3\"); (\"experiment\", \"rcp45\"); (\"frequency\", \"monthly\"); (\"variable\", \"tmax\")]; [(\"model\", \"ACCESS1-3\"); (\"experiment\", \"historical\"); (\"frequency\", \"monthly\"); (\"variable\", \"ppt\")]]) = true));\n  (assert ((candidate [(\"model\", \"ACCESS1-3\"); (\"experiment\", \"rcp45\"); (\"frequency\", \"monthly\"); (\"variable\", \"ppt\")] [[(\"model\", \"ACCESS1-3\"); (\"experiment\", \"rcp45\"); (\"frequency\", \"monthly\"); (\"variable\", \"ppt\")]; [(\"model\", \"ACCESS1-3\"); (\"experiment\", \"rcp45\"); (\"frequency\", \"monthly\"); (\"variable\", \"tmax\")]; [(\"model\", \"ACCESS1-3\"); (\"experiment\", \"historical\"); (\"frequency\", \"monthly\"); (\"variable\", \"ppt\")]; [(\"model\", \"ACCESS1-3\"); (\"experiment\", \"historical\"); (\"frequency\", \"monthly\"); (\"variable\", \"ppt\")]]) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_3974_str_igrep", "language": "ml", "prompt": "(**Returns a list of the indices of the strings wherein the substring S\nis found.\n*)\nlet str_igrep (S : string) (strs : string list) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_3974_str_igrep.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = str_igrep in\n  (assert ((candidate \"\" [\"\"]) = [0]));\n  (assert ((candidate \"abc\" [\"aa\"; \"ab\"; \"abc\"]) = [2]));\n  (assert ((candidate \"a\" []) = []));\n  (assert ((candidate \"b\" [\"a\"; \"b\"]) = [1]));\n  (assert ((candidate \"b\" [\"b\"]) = [0]));\n  (assert ((candidate \"\" []) = []));\n  (assert ((candidate \"a\" [\"a\"; \"b\"; \"c\"; \"a\"]) = [0; 3]));\n  (assert ((candidate \"a\" [\"a\"; \"b\"]) = [0]));\n  (assert ((candidate \"ab\" []) = []));\n  (assert ((candidate \"z\" []) = []));\n  (assert ((candidate \"a\" [\"a\"; \"a\"; \"a\"]) = [0; 1; 2]));\n  (assert ((candidate \"a\" [\"a\"]) = [0]));\n  (assert ((candidate \"z\" [\"aa\"; \"ab\"; \"abc\"]) = []));\n  (assert ((candidate \"a\" [\"b\"; \"a\"]) = [1]));\n  (assert ((candidate \"b\" [\"a\"; \"b\"; \"c\"]) = [1]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_397801_make_msg", "language": "ml", "prompt": "(**Formats the error message with a file and line number that can be used by\nIDEs to quickly go to the exact line\n*)\nlet make_msg (err_or_warn : string) (file : string) (line : int) (msg : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_397801_make_msg.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = make_msg in\n  (assert ((candidate \"warning\" \"main.c\" 10 \"variable used before assignment\") = \"warning: main.c:10, variable used before assignment\"));\n  (assert ((candidate \"error\" \"test_messages.py\" 27 \"this should be an error\") = \"error: test_messages.py:27, this should be an error\"));\n  (assert ((candidate \"error\" \"main.c\" 10 \"variable used before assignment\") = \"error: main.c:10, variable used before assignment\"));\n  (assert ((candidate \"warning\" \"test_messages.py\" 27 \"this should be a warning\") = \"warning: test_messages.py:27, this should be a warning\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_397849_move_up", "language": "ml", "prompt": "(**A method that takes coordinates of bomb's\nposition and returns coordinates of neighbour\nlocated above the bomb. It returns None if\nthere isn't such a neighbour\n*)\nlet move_up (t :  int * int) :  int * int option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_397849_move_up.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = move_up in\n  (assert ((candidate (1, 2)) = Some((0, 2))));\n  (assert ((candidate (3, 3)) = Some((2, 3))));\n  (assert ((candidate (1, 1)) = Some((0, 1))));\n  (assert ((candidate (0, 1)) = Some(None)));\n  (assert ((candidate (3, 2)) = Some((2, 2))));\n  (assert ((candidate (1, 5)) = Some((0, 5))));\n  (assert ((candidate (5, 5)) = Some((4, 5))));\n  (assert ((candidate (3, 4)) = Some((2, 4))));\n  (assert ((candidate (1, 2)) = Some((0, 2))));\n  (assert ((candidate (5, 2)) = Some((4, 2))));\n  (assert ((candidate (1, 0)) = Some((0, 0))));\n  (assert ((candidate (4, 6)) = Some((3, 6))));\n  (assert ((candidate (0, 0)) = Some(None)));\n  (assert ((candidate (0, 0)) = Some(None)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_397872_fix_vidshape", "language": "ml", "prompt": "(**Compares two resolutions and get missing x and y coords\n*)\nlet fix_vidshape (res1 :  int * int) (res2 :  int * int) :  int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_397872_fix_vidshape.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = fix_vidshape in\n  (assert ((candidate (1920, 1080) (640, 360)) = (0, 0)));\n  (assert ((candidate (1920, 1080) (1280, 1080)) = (0, 0)));\n  (assert ((candidate (1920, 1080) (1280, 720)) = (0, 0)));\n  (assert ((candidate (1920, 1080) (640, 1080)) = (0, 0)));\n  (assert ((candidate (1920, 1080) (1920, 1080)) = (0, 0)));\n  (assert ((candidate (1920, 1080) (640, 540)) = (0, 0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_398023_remove_underline", "language": "ml", "prompt": "(**Remove the underline in reserved words.\nThe parameters def and type are python reserved words so it is necessary\nto add a underline to use this words, this method remove the underline\nbefore make a http request.\nArgs:\n * params (dict): Url query parameters.\nReturns:\n * (dict): Validated url query parameters.\n*)\nlet remove_underline (params : (string, string) list) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_398023_remove_underline.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = remove_underline in\n  (assert ((candidate [(\"type_\", \"type\"); (\"format_\", \"format\")]) = [(\"type\", \"type\"); (\"format\", \"format\")]));\n  (assert ((candidate [(\"def_\", \"def\"); (\"type_\", \"type\"); (\"format_\", \"format\")]) = [(\"def\", \"def\"); (\"type\", \"type\"); (\"format\", \"format\")]));\n  (assert ((candidate [(\"def_\", \"def\"); (\"type_\", \"type\"); (\"format_\", \"format\")]) = [(\"def\", \"def\"); (\"type\", \"type\"); (\"format\", \"format\")]));\n  (assert ((candidate [(\"def_\", \"def\"); (\"format_\", \"format\")]) = [(\"def\", \"def\"); (\"format\", \"format\")]));\n  (assert ((candidate [(\"def_\", \"def\"); (\"type_\", \"type\")]) = [(\"def\", \"def\"); (\"type\", \"type\")]));\n  (assert ((candidate [(\"def_\", \"def\"); (\"format_\", \"format\")]) = [(\"def\", \"def\"); (\"format\", \"format\")]));\n  (assert ((candidate [(\"def_\", \"def\")]) = [(\"def\", \"def\")]));\n  (assert ((candidate []) = []));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_398191__intersect", "language": "ml", "prompt": "(**return the intersection of two lists\n*)\nlet _intersect (lst_a : string list) (lst_b : string list) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_398191__intersect.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _intersect in\n  (assert ((candidate [\"a\"; \"b\"; \"c\"; \"d\"] [\"z\"; \"y\"; \"x\"; \"w\"]) = []));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"; \"d\"] [\"a\"; \"a\"; \"a\"; \"a\"]) = [\"a\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_3983_find_match_characters", "language": "ml", "prompt": "(**Find match match pattern string.\nArgs:\n * params: string\n * pattern\nReturns:\nRaises:\n*)\nlet find_match_characters (string : string option) (pattern : string option) :  string * int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_3983_find_match_characters.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = find_match_characters in\n  (assert ((candidate Some(\"ab\") Some(\"ab\")) = [(\"a\", 0); (\"b\", 1)]));\n  (assert ((candidate Some(\"\") Some(\"abc\")) = []));\n  (assert ((candidate Some(\"aabb\") Some(\"ab\")) = [(\"a\", 0); (\"b\", 2)]));\n  (assert ((candidate Some(\"abcz\") Some(\"abc\")) = [(\"a\", 0); (\"b\", 1); (\"c\", 2)]));\n  (assert ((candidate Some(\"a\") Some(\"ab\")) = []));\n  (assert ((candidate Some(\"\") Some(\"a\")) = []));\n  (assert ((candidate Some(\"ab\") Some(\"aba\")) = []));\n  (assert ((candidate Some(\"abc\") Some(\"xyz\")) = []));\n  (assert ((candidate Some(\"a\") Some(\"\")) = []));\n  (assert ((candidate Some(\"b\") Some(\"a\")) = []));\n  (assert ((candidate Some(\"aaab\") Some(\"ab\")) = [(\"a\", 0); (\"b\", 3)]));\n  (assert ((candidate Some(\"abab\") Some(\"babab\")) = []));\n  (assert ((candidate Some(\"\") Some(\"\")) = []));\n  (assert ((candidate Some(\"a\") Some(\"a\")) = [(\"a\", 0)]));\n  (assert ((candidate Some(None) Some(None)) = []));\n  (assert ((candidate Some(\"abc\") Some(\"\")) = []));\n  (assert ((candidate Some(\"aabb\") Some(\"aba\")) = []));\n  (assert ((candidate Some(\"babab\") Some(\"abab\")) = []));\n  (assert ((candidate Some(\"\") Some(\"\")) = []));\n  (assert ((candidate Some(\"abc\") Some(\"abc\")) = [(\"a\", 0); (\"b\", 1); (\"c\", 2)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_398704__GenerateDeviceHVInfoStr", "language": "ml", "prompt": "(**Construct the -device option string for hvinfo dict\nPV disk: virtio-blk-pci,id=disk-1234,bus=pci.0,addr=0x9\nPV NIC:  virtio-net-pci,id=nic-1234,bus=pci.0,addr=0x9\nSG disk: scsi-generic,id=disk-1234,bus=scsi.0,channel=0,scsi-id=1,lun=0\n@type hvinfo: dict\n@param hvinfo: dictionary created by _GenerateDeviceHVInfo()\n@rtype: string\n@return: The constructed string to be passed along with a -device option\n*)\nlet _GenerateDeviceHVInfoStr (hvinfo : (string, string) list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_398704__GenerateDeviceHVInfoStr.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _GenerateDeviceHVInfoStr in\n  (assert ((candidate [(\"driver\", \"virtio-blk-pci\"); (\"id\", \"disk-1234\"); (\"bus\", \"pci.0\"); (\"addr\", \"0x9\"); (\"scsi-id\", \"1\")]) = \"virtio-blk-pci,id=disk-1234,bus=pci.0,addr=0x9,scsi-id=1\"));\n  (assert ((candidate [(\"driver\", \"scsi-generic\"); (\"id\", \"disk-1234\"); (\"bus\", \"scsi.0\"); (\"channel\", \"0\"); (\"scsi-id\", \"1\"); (\"lun\", \"0\")]) = \"scsi-generic,id=disk-1234,bus=scsi.0,channel=0,scsi-id=1,lun=0\"));\n  (assert ((candidate [(\"driver\", \"virtio-net-pci\"); (\"id\", \"nic-1234\"); (\"bus\", \"pci.0\")]) = \"virtio-net-pci,id=nic-1234,bus=pci.0\"));\n  (assert ((candidate [(\"driver\", \"virtio-blk-pci\"); (\"id\", \"disk-1234\"); (\"bus\", \"pci.0\")]) = \"virtio-blk-pci,id=disk-1234,bus=pci.0\"));\n  (assert ((candidate [(\"driver\", \"scsi-generic\"); (\"id\", \"disk-1234\"); (\"bus\", \"scsi.0\"); (\"channel\", \"0\"); (\"scsi-id\", \"1\"); (\"lun\", \"0\")]) = \"scsi-generic,id=disk-1234,bus=scsi.0,channel=0,scsi-id=1,lun=0\"));\n  (assert ((candidate [(\"driver\", \"virtio-blk-pci\"); (\"id\", \"disk-1234\"); (\"bus\", \"pci.0\"); (\"addr\", \"0x9\")]) = \"virtio-blk-pci,id=disk-1234,bus=pci.0,addr=0x9\"));\n  (assert ((candidate [(\"driver\", \"virtio-net-pci\"); (\"id\", \"nic-1234\"); (\"bus\", \"pci.0\"); (\"addr\", \"0x9\")]) = \"virtio-net-pci,id=nic-1234,bus=pci.0,addr=0x9\"));\n  (assert ((candidate [(\"driver\", \"virtio-blk-pci\"); (\"id\", \"disk-1234\"); (\"bus\", \"pci.0\"); (\"addr\", \"0x9\")]) = \"virtio-blk-pci,id=disk-1234,bus=pci.0,addr=0x9\"));\n  (assert ((candidate [(\"driver\", \"virtio-net-pci\"); (\"id\", \"nic-1234\"); (\"bus\", \"pci.0\"); (\"addr\", \"0x9\")]) = \"virtio-net-pci,id=nic-1234,bus=pci.0,addr=0x9\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_398734_insert", "language": "ml", "prompt": "(**>>> insert(('a', 'b', 'c'), 0, 'x')\n('x', 'b', 'c')\n*)\nlet insert (tup :  string * string * string) (loc : int) (val : string) :  string * string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_398734_insert.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = insert in\n  (assert ((candidate (\"a\", \"b\", \"c\") 0 \"x\") = (\"x\", \"b\", \"c\")));\n  (assert ((candidate (\"a\", \"b\", \"c\") 2 \"x\") = (\"a\", \"b\", \"x\")));\n  (assert ((candidate (\"a\", \"b\", \"c\") 0 \"x\") = (\"x\", \"b\", \"c\")));\n  (assert ((candidate (\"a\", \"b\", \"c\") 2 \"z\") = (\"a\", \"b\", \"z\")));\n  (assert ((candidate (\"a\", \"b\", \"c\") 1 \"x\") = (\"a\", \"x\", \"c\")));\n  (assert ((candidate (\"a\", \"b\", \"c\") 1 \"y\") = (\"a\", \"y\", \"c\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_399266_expand_id_map", "language": "ml", "prompt": "(**Ensures all ids within all_ids are included as keys in the mapping\n*)\nlet expand_id_map (id_map : (int, int) list) (all_ids : int list) : (int, int) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_399266_expand_id_map.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = expand_id_map in\n  (assert ((candidate [] [1; 2; 3]) = [(1, 1); (2, 2); (3, 3)]));\n  (assert ((candidate [(3, 100)] [1; 2; 3; 4]) = [(1, 1); (2, 2); (3, 100); (4, 4)]));\n  (assert ((candidate [(1, 100); (2, 100); (3, 200)] [1; 2; 3]) = [(1, 100); (2, 100); (3, 200)]));\n  (assert ((candidate dict  [1; 2; 3]) = [(1, 1); (2, 2); (3, 3)]));\n  (assert ((candidate [(1, 2)] [1; 2; 3]) = [(1, 2); (2, 2); (3, 3)]));\n  (assert ((candidate [(1, 2)] [2; 3]) = [(1, 2); (2, 2); (3, 3)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_399332_volume_berbentuk_kubus", "language": "ml", "prompt": "(**kalkulasi volume kuboid\n>>> volume_berbentuk_kubus(1, 1, 1)\n1.0\n>>> volume_berbentuk_kubus(1, 2, 3)\n6.0\n*)\nlet volume_berbentuk_kubus (lebar : float) (tinggi : float) (panjang : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_399332_volume_berbentuk_kubus.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = volume_berbentuk_kubus in\n  (assert ((candidate 1.0 2.0 3.0) = 6.0));\n  (assert ((candidate 1.0 1.0 1.0) = 1.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_400319_from_time", "language": "ml", "prompt": "(**Convenience wrapper to take a series of date/time elements and return a WMI time\nof the form `yyyymmddHHMMSS.mmmmmm+UUU`. All elements may be int, string or\nomitted altogether. If omitted, they will be replaced in the output string\nby a series of stars of the appropriate length.\n:param year: The year element of the date/time\n:param month: The month element of the date/time\n:param day: The day element of the date/time\n:param hours: The hours element of the date/time\n:param minutes: The minutes element of the date/time\n:param seconds: The seconds element of the date/time\n:param microseconds: The microseconds element of the date/time\n:param timezone: The timeezone element of the date/time\n:returns: A WMI datetime string of the form: `yyyymmddHHMMSS.mmmmmm+UUU`\n*)\nlet from_time (year : int) (month : int) (day : int) (hours : int) (minutes : int) (seconds : int) (microseconds : int) (timezone : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_400319_from_time.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = from_time in\n  (assert ((candidate 2015 1 1 11 3 27 123456 (~1)) = \"20150101110327.123456-001\"));\n  (assert ((candidate 2015 1 1 11 3 27 123456) = \"20150101110327.123456+\"));\n  (assert ((candidate 1979 12 31 14 59 59 999999 0) = \"19791231145959.999999+\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_400320_find_last", "language": "ml", "prompt": "(**s and sub are non-empty strings\nReturns the index of the last occurrence of sub in s.\nReturns None if sub does not occur in s\n*)\nlet find_last (s : string) (sub : string) : int option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_400320_find_last.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = find_last in\n  (assert ((candidate \"123123123\" \"123123123\") = Some(0)));\n  (assert ((candidate \"123123123\" \"123\") = Some(6)));\n  (assert ((candidate \"123123123\" \"0\") = Some(None)));\n  (assert ((candidate \"ababc\" \"d\") = Some(None)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_400967_is_id", "language": "ml", "prompt": "(**Return True if `s` is some kind of id.\n*)\nlet is_id (s : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_400967_is_id.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_id in\n  (assert ((candidate \"a b c d e f g h i j k l m n o\") = false));\n  (assert ((candidate \"a b\") = false));\n  (assert ((candidate \"foo\") = true));\n  (assert ((candidate \"__hello_world\") = true));\n  (assert ((candidate \"a b c d e f\") = false));\n  (assert ((candidate \"a b c d e f g\") = false));\n  (assert ((candidate \" a b\") = false));\n  (assert ((candidate \"x\") = true));\n  (assert ((candidate \"a b c d\") = false));\n  (assert ((candidate \"a b c d e f g h i j k l m n\") = false));\n  (assert ((candidate \"a b c d e f g h i j k l\") = false));\n  (assert ((candidate \"123 456\") = false));\n  (assert ((candidate \"a b c d e f g h i j k\") = false));\n  (assert ((candidate \"12345\") = true));\n  (assert ((candidate \"a b c d e f g h\") = false));\n  (assert ((candidate \"a b c d e f g h i\") = false));\n  (assert ((candidate \"a b c d e\") = false));\n  (assert ((candidate \"a b c d e f g h i j\") = false));\n  (assert ((candidate \"12345 6789\") = false));\n  (assert ((candidate \"a b \") = false));\n  (assert ((candidate \"hello_world\") = true));\n  (assert ((candidate \"123\") = true));\n  (assert ((candidate \"a\") = true));\n  (assert ((candidate \"foo\") = true));\n  (assert ((candidate \"a b c\") = false));\n  (assert ((candidate \"hello world\") = false));\n  (assert ((candidate \"_hello_world\") = true));\n  (assert ((candidate \"a b c d e f g h i j k l m\") = false));\n  (assert ((candidate \"foo bar\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_401452_control_start", "language": "ml", "prompt": "(**Controls the start state\n*)\nlet control_start (cmd : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_401452_control_start.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = control_start in\n  (assert ((candidate \"no\") = \"game\"));\n  (assert ((candidate \"No\") = \"game\"));\n  (assert ((candidate \"y\") = \"instructions\"));\n  (assert ((candidate \"yeS\") = \"instructions\"));\n  (assert ((candidate \"n\") = \"game\"));\n  (assert ((candidate \"Yes\") = \"instructions\"));\n  (assert ((candidate \"Y\") = \"instructions\"));\n  (assert ((candidate \"y\") = \"instructions\"));\n  (assert ((candidate \"yes\") = \"instructions\"));\n  (assert ((candidate \"YES\") = \"instructions\"));\n  (assert ((candidate \"n\") = \"game\"));\n  (assert ((candidate \"No\") = \"game\"));\n  (assert ((candidate \"yes\") = \"instructions\"));\n  (assert ((candidate \"no\") = \"game\"));\n  (assert ((candidate \"yEs\") = \"instructions\"));\n  (assert ((candidate \"Yes\") = \"instructions\"));\n  (assert ((candidate \"NO\") = \"game\"));\n  (assert ((candidate \"YES\") = \"instructions\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_401768__quote_arg", "language": "ml", "prompt": "(**Quote the argument for safe use in a shell command line.\n*)\nlet _quote_arg (arg : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_401768__quote_arg.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _quote_arg in\n  (assert ((candidate \"-I\"C:/Program Files/...\"\") = \"-I\"C:/Program Files/...\"\"));\n  (assert ((candidate \"a\") = \"a\"));\n  (assert ((candidate \"\"foo\" bar\") = \"\"foo\" bar\"));\n  (assert ((candidate \"'foo'\") = \"'foo'\"));\n  (assert ((candidate \"a b c\") = \"\"a b c\"\"));\n  (assert ((candidate \"-I\"C:\\Program Files\\...\\include\"\") = \"-I\"C:\\Program Files\\...\\include\"\"));\n  (assert ((candidate \"a\") = \"a\"));\n  (assert ((candidate \"C:\\Program Files\\Microsoft Visual Studio 12.0\\VC\\bin\\cl.exe\") = \"\"C:\\Program Files\\Microsoft Visual Studio 12.0\\VC\\bin\\cl.exe\"\"));\n  (assert ((candidate \"a b\") = \"\"a b\"\"));\n  (assert ((candidate \"\"foo bar\"\") = \"\"foo bar\"\"));\n  (assert ((candidate \"\"\") = \"\"\"));\n  (assert ((candidate \"-I\"C:/Program Files/.../include\"\") = \"-I\"C:/Program Files/.../include\"\"));\n  (assert ((candidate \"C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC\\bin\\cl.exe\") = \"\"C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC\\bin\\cl.exe\"\"));\n  (assert ((candidate \"a\\\\b\") = \"a\\\\b\"));\n  (assert ((candidate \"\"foo\"\") = \"\"foo\"\"));\n  (assert ((candidate \"-I\"C:\\Program Files\\...\"\") = \"-I\"C:\\Program Files\\...\"\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"a b c\") = \"\"a b c\"\"));\n  (assert ((candidate \"a\\\\\\\\b\") = \"a\\\\\\\\b\"));\n  (assert ((candidate \"a\\\"b\") = \"a\\\"b\"));\n  (assert ((candidate \"a\\b\") = \"a\\b\"));\n  (assert ((candidate \"-I\"C:\\Program Files\\.../include\"\") = \"-I\"C:\\Program Files\\.../include\"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_402036_get_item_details", "language": "ml", "prompt": "(**This function finds packgen details using item\n:param item: item is a string containing packgen content type\n:return: it returns dict of details of packgen.\n*)\nlet get_item_details (item : string) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_402036_get_item_details.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_item_details in\n  (assert ((candidate \"Clothes\") = [(\"priority\", \"LP\"); (\"cost\", \"150\"); (\"Estimated Time of Delivery\", \"5\"); (\"item\", \"Clothes\")]));\n  (assert ((candidate \"Food\") = [(\"Estimated Time of Delivery\", \"3\"); (\"priority\", \"MP\"); (\"cost\", \"250\"); (\"item\", \"Food\")]));\n  (assert ((candidate \"Medicine\") = [(\"priority\", \"HP\"); (\"cost\", \"450\"); (\"Estimated Time of Delivery\", \"1\"); (\"item\", \"Medicines\")]));\n  (assert ((candidate \"Medicine\") = [(\"Estimated Time of Delivery\", \"1\"); (\"priority\", \"HP\"); (\"cost\", \"450\"); (\"item\", \"Medicines\")]));\n  (assert ((candidate \"Medicines\") = [(\"Estimated Time of Delivery\", \"1\"); (\"priority\", \"HP\"); (\"cost\", \"450\"); (\"item\", \"Medicines\")]));\n  (assert ((candidate \"Clothes\") = [(\"Estimated Time of Delivery\", \"5\"); (\"priority\", \"LP\"); (\"cost\", \"150\"); (\"item\", \"Clothes\")]));\n  (assert ((candidate \"Medicines\") = [(\"Estimated Time of Delivery\", \"1\"); (\"priority\", \"HP\"); (\"cost\", \"450\"); (\"item\", \"Medicines\")]));\n  (assert ((candidate \"Food\") = [(\"Estimated Time of Delivery\", \"3\"); (\"cost\", \"250\"); (\"item\", \"Food\"); (\"priority\", \"MP\")]));\n  (assert ((candidate \"Food\") = [(\"priority\", \"MP\"); (\"cost\", \"250\"); (\"Estimated Time of Delivery\", \"3\"); (\"item\", \"Food\")]));\n  (assert ((candidate \"Clothes\") = [(\"Estimated Time of Delivery\", \"5\"); (\"cost\", \"150\"); (\"item\", \"Clothes\"); (\"priority\", \"LP\")]));\n  (assert ((candidate \"Medicines\") = [(\"Estimated Time of Delivery\", \"1\"); (\"cost\", \"450\"); (\"item\", \"Medicines\"); (\"priority\", \"HP\")]));\n  (assert ((candidate \"Medicines\") = [(\"priority\", \"HP\"); (\"cost\", \"450\"); (\"Estimated Time of Delivery\", \"1\"); (\"item\", \"Medicines\")]));\n  (assert ((candidate \"Food\") = [(\"Estimated Time of Delivery\", \"3\"); (\"priority\", \"MP\"); (\"cost\", \"250\"); (\"item\", \"Food\")]));\n  (assert ((candidate \"Clothes\") = [(\"Estimated Time of Delivery\", \"5\"); (\"priority\", \"LP\"); (\"cost\", \"150\"); (\"item\", \"Clothes\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_402199_multi_bracket_validation", "language": "ml", "prompt": "(**This function return True if brackets are all matched up in string, and     return False if there is unmatched brackets.\n*)\nlet multi_bracket_validation (string : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_402199_multi_bracket_validation.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = multi_bracket_validation in\n  (assert ((candidate \"(hi)()\") = true));\n  (assert ((candidate \"[[[]()]]\") = true));\n  (assert ((candidate \"(hi)[(hi)]{[()]}\") = true));\n  (assert ((candidate \"(hi)[(hi)]{[()]}(hi)hi\") = true));\n  (assert ((candidate \"{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{]}}}}}}}}}}}}}}}}}}}}}}}}}}\") = false));\n  (assert ((candidate \"(hi)[(hi)]{[()]}(hi)hi(hi})\") = false));\n  (assert ((candidate \"(hi)[(hi)]\") = true));\n  (assert ((candidate \"{}\") = true));\n  (assert ((candidate \"[({})]\") = true));\n  (assert ((candidate \"[({})]([({})])\") = true));\n  (assert ((candidate \"(hi)[(hi)]{[()]}()\") = true));\n  (assert ((candidate \"[[()]]]\") = false));\n  (assert ((candidate \"{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{}}}}}}}}}}}}}}}}}}}}}}}}\") = false));\n  (assert ((candidate \"[]\") = true));\n  (assert ((candidate \"[[{}]]\") = true));\n  (assert ((candidate \"hi())\") = false));\n  (assert ((candidate \"[[[]]]\") = true));\n  (assert ((candidate \"hi(hi)\") = true));\n  (assert ((candidate \"({[]})\") = true));\n  (assert ((candidate \"[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[\") = false));\n  (assert ((candidate \"{[()]}\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_402673__reconstruct_token", "language": "ml", "prompt": "(**Reconstruct a token from a key in a graph ('SomeName_<token>')\n*)\nlet _reconstruct_token (key : string) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_402673__reconstruct_token.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _reconstruct_token in\n  (assert ((candidate \"foo_1234567\") = Some(None)));\n  (assert ((candidate \"a_11111\") = Some(None)));\n  (assert ((candidate \"<KEY>\") = Some(None)));\n  (assert ((candidate \"some_name_l\") = Some(None)));\n  (assert ((candidate \"some_name_n\") = Some(None)));\n  (assert ((candidate \"some_name_b\") = Some(None)));\n  (assert ((candidate \"foo_123456789012345678901234567890_123\") = Some(None)));\n  (assert ((candidate \"a_\") = Some(None)));\n  (assert ((candidate \"some_name_m\") = Some(None)));\n  (assert ((candidate \"a_b\") = Some(None)));\n  (assert ((candidate \"SomeName_aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\") = Some(\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\")));\n  (assert ((candidate \"\") = Some(None)));\n  (assert ((candidate \"some_name_j\") = Some(None)));\n  (assert ((candidate \"a_111111111\") = Some(None)));\n  (assert ((candidate \"some_name_\") = Some(None)));\n  (assert ((candidate \"some_name_d\") = Some(None)));\n  (assert ((candidate \"some_name_k\") = Some(None)));\n  (assert ((candidate \"someKey\") = Some(None)));\n  (assert ((candidate \"someKey_\") = Some(None)));\n  (assert ((candidate \"foo\") = Some(None)));\n  (assert ((candidate \"some_name__\") = Some(None)));\n  (assert ((candidate \"foo_123456789012345678901234567890\") = Some(None)));\n  (assert ((candidate \"a_11111111\") = Some(None)));\n  (assert ((candidate \"a\") = Some(None)));\n  (assert ((candidate \"foo_bar_baz\") = Some(None)));\n  (assert ((candidate \"some_name_i\") = Some(None)));\n  (assert ((candidate \"foo_123\") = Some(None)));\n  (assert ((candidate \"foo_123456789\") = Some(None)));\n  (assert ((candidate \"a_1111111111111111\") = Some(None)));\n  (assert ((candidate \"foo_123_456\") = Some(None)));\n  (assert ((candidate \"foo_\") = Some(None)));\n  (assert ((candidate \"SomeName_0123456789abcdef0123456789abcdef\") = Some(\"0123456789abcdef0123456789abcdef\")));\n  (assert ((candidate \"some_name_p\") = Some(None)));\n  (assert ((candidate \"some_name_a\") = Some(None)));\n  (assert ((candidate \"foo_bar\") = Some(None)));\n  (assert ((candidate \"some_name_o\") = Some(None)));\n  (assert ((candidate \"a_111111111111111111\") = Some(None)));\n  (assert ((candidate \"\") = Some(None)));\n  (assert ((candidate \"some_name_f\") = Some(None)));\n  (assert ((candidate \"someKey_0123456789abcdef0123456789abcdef0123456789abcdef\") = Some(None)));\n  (assert ((candidate \"foo_12345678\") = Some(None)));\n  (assert ((candidate \"foo\") = Some(None)));\n  (assert ((candidate \"foo_bar\") = Some(None)));\n  (assert ((candidate \"some_name\") = Some(None)));\n  (assert ((candidate \"some_name_h\") = Some(None)));\n  (assert ((candidate \"some_name_g\") = Some(None)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_402950_remove_ssml_tags", "language": "ml", "prompt": "(**Remove the SSML tags from parm text. The tags are surrounded by <chevrons>.\n*)\nlet remove_ssml_tags (parm_text : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_402950_remove_ssml_tags.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = remove_ssml_tags in\n  (assert ((candidate \"<emphasis>Hello, World!</emphasis>\") = \"Hello, World!\"));\n  (assert ((candidate \"<break time=\"5s\"/>\") = \"\"));\n  (assert ((candidate \"Hello, World!\") = \"Hello, World!\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_403090_calculate_height", "language": "ml", "prompt": "(**Calculate real person height in centimeters.\n*)\nlet calculate_height (distance : int) (y_max : int) (y_min : int) (focal_y : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_403090_calculate_height.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = calculate_height in\n  (assert ((candidate 0 0 0 2000) = 0));\n  (assert ((candidate 0 0 1000 2000) = 0));\n  (assert ((candidate 1000 0 0 2000) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_403991_node_vertex_name", "language": "ml", "prompt": "(**Returns the full name of the given node vertex\n:param mesh_node: str\n:param vertex_id: int\n:return: str\n*)\nlet node_vertex_name (mesh_node : string) (vertex_id : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_403991_node_vertex_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = node_vertex_name in\n  (assert ((candidate \"mesh\" 3) = \"mesh.vtx[3]\"));\n  (assert ((candidate \"MeshNode\" 0) = \"MeshNode.vtx[0]\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_404803_isQualified", "language": "ml", "prompt": "(**Check if a property name is qualified\n*)\nlet isQualified (name : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_404803_isQualified.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = isQualified in\n  (assert ((candidate \"\") = false));\n  (assert ((candidate \"prop\") = false));\n  (assert ((candidate \"xmlns\") = false));\n  (assert ((candidate \"xlink:type\") = true));\n  (assert ((candidate \"xlink:title\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_405193_getStatusWord", "language": "ml", "prompt": "(**Returns the status word from the status code.\n*)\nlet getStatusWord (status : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_405193_getStatusWord.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = getStatusWord in\n  (assert ((candidate 1) = \"ordered\"));\n  (assert ((candidate 0) = \"wished\"));\n  (assert ((candidate 2) = \"owned\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_405292_factorial", "language": "ml", "prompt": "(**This function calculates factorial of a number recursively.\nn! = n*(n-1)*(n-2)*...*2*1\nParameters\n----------\nnum : uint64\n * Input positive integer to calcuate factorial.\nReturns\n-------\nuint64\n * Factorial of input positive integer.\n*)\nlet factorial (num : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_405292_factorial.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = factorial in\n  (assert ((candidate 8) = 40320));\n  (assert ((candidate 5) = 120));\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 17) = 355687428096000));\n  (assert ((candidate 4) = 24));\n  (assert ((candidate 20) = 2432902008176640000));\n  (assert ((candidate 11) = 39916800));\n  (assert ((candidate 12) = 479001600));\n  (assert ((candidate 10) = 3628800));\n  (assert ((candidate 19) = 121645100408832000));\n  (assert ((candidate 15) = 1307674368000));\n  (assert ((candidate 13) = 6227020800));\n  (assert ((candidate 9) = 362880));\n  (assert ((candidate 18) = 6402373705728000));\n  (assert ((candidate 3) = 6));\n  (assert ((candidate 6) = 720));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 14) = 87178291200));\n  (assert ((candidate 7) = 5040));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_405585_dms2dd", "language": "ml", "prompt": "(**http://en.proft.me/2015/09/20/converting-latitude-and-longitude-decimal-values-p/\nArgs:\n * degrees:\n * minutes:\n * seconds:\n * direction:\nReturns:\n*)\nlet dms2dd (degrees : int) (minutes : int) (seconds : int) (direction : string) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_405585_dms2dd.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = dms2dd in\n  (assert ((candidate 40 0 0 \"N\") = 40.0));\n  (assert ((candidate 41 30 30 \"N\") = 41.50833333333333));\n  (assert ((candidate 31 30 30 \"W\") = -31.508333333333333));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_406279_realign_shifted_streams", "language": "ml", "prompt": "(**Durations are shifted by 1, F0 by 2\n>>> tokens = [\"<s>\", \"t1\",  \"t2\", \"t3\", \"</s>\", \"x\", \"x\"]\n>>> durations = [\"<0>\", \"<0>\", \"d1\", \"d2\", \"d3\", \"<0>\", \"x\"]\n>>> F0s    = [\"<0>\", \"<0>\", \"<0>\", \"f1\", \"f2\", \"f3\", \"<0>\"]\n>>> shifts = [1,2]\n>>> realign_shifted_streams(tokens, durations, F0s, shifts)\n(['<s>', 't1', 't2', 't3', '</s>'], ['<0>', 'd1', 'd2', 'd3', '<0>'], ['<0>', 'f1', 'f2', 'f3', '<0>'])\n*)\nlet realign_shifted_streams (tokens : string list) (durations : string list) (F0s : string list) (shifts : int list) :  string list * string list * string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_406279_realign_shifted_streams.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = realign_shifted_streams in\n  (assert ((candidate [\"<s>\"; \"t1\"; \"t2\"; \"t3\"; \"</s>\"; \"x\"; \"x\"] [\"<0>\"; \"<0>\"; \"d1\"; \"d2\"; \"d3\"; \"<0>\"; \"x\"] [\"<0>\"; \"<0>\"; \"<0>\"; \"f1\"; \"f2\"; \"f3\"; \"<0>\"] [1; 2]) = ([\"<s>\"; \"t1\"; \"t2\"; \"t3\"; \"</s>\"], [\"<0>\"; \"d1\"; \"d2\"; \"d3\"; \"<0>\"], [\"<0>\"; \"f1\"; \"f2\"; \"f3\"; \"<0>\"])));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_406838_wait_for_line", "language": "ml", "prompt": "(**Should the intepreter wait for another line of input or try to evaluate the\ncurrent line as is.\n*)\nlet wait_for_line (input_string : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_406838_wait_for_line.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = wait_for_line in\n  (assert ((candidate \"a = b = c = d = e = f\") = false));\n  (assert ((candidate \"(a = b = c) = (d = e = f)\") = false));\n  (assert ((candidate \"a + b * (c + d) + e\") = false));\n  (assert ((candidate \"a + b * (c + d) + e = f + g\") = false));\n  (assert ((candidate \"a = 1, b = 2;\") = false));\n  (assert ((candidate \"return 42;\") = false));\n  (assert ((candidate \"(a + b * (c + d)) + e = f + g\") = false));\n  (assert ((candidate \"(a + b) * (c + d) + e = f + g\") = false));\n  (assert ((candidate \"a = b = c\") = false));\n  (assert ((candidate \"let a = 1, b = 2;\") = false));\n  (assert ((candidate \"a + b * (c + d)\") = false));\n  (assert ((candidate \"a = b = c = d = e\") = false));\n  (assert ((candidate \"function my_func(a, b) { return a + b; }\") = false));\n  (assert ((candidate \"a = b = c = d\") = false));\n  (assert ((candidate \"a + b * (c + d) + e = f\") = false));\n  (assert ((candidate \"2 + 2;\") = false));\n  (assert ((candidate \"var a = 1, b = 2;\") = false));\n  (assert ((candidate \"a + ((b * c))\") = false));\n  (assert ((candidate \"a + (b * c)\") = false));\n  (assert ((candidate \"for (i = 0; i < 10; i++) { print(i); }\") = false));\n  (assert ((candidate \"print(1 + 1) && print(2 + 2)\") = false));\n  (assert ((candidate \"print(\"Hello, World!\");\") = false));\n  (assert ((candidate \"a + b * c\") = false));\n  (assert ((candidate \"my_func(1, 2);\") = false));\n  (assert ((candidate \"a = b = c = (d = e = f)\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_40712_generate_base_code", "language": "ml", "prompt": "(**Returns a base code, one of:\nA -- Naval Base and Scout Base/Outpost\nG -- Scout Base/Outpost and Pirate Base\nN -- Naval Base\nP -- Pirate Base\nS -- Scout Base/Outpost\n*)\nlet generate_base_code (naval_base : bool) (scout_base : bool) (pirate_base : bool) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_40712_generate_base_code.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = generate_base_code in\n  (assert ((candidate true false true) = \"N\"));\n  (assert ((candidate true true false) = \"A\"));\n  (assert ((candidate true true true) = \"A\"));\n  (assert ((candidate true false false) = \"N\"));\n  (assert ((candidate false false false) = \" \"));\n  (assert ((candidate false true false) = \"S\"));\n  (assert ((candidate false true true) = \"G\"));\n  (assert ((candidate false false true) = \"P\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_408233_parse", "language": "ml", "prompt": "(**Parse URL query into correct SQL syntax.\n:param query: SQL query pulled from URL argument.\n:return: Parsed query converted to valid SQL syntax.\n*)\nlet parse (query : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_408233_parse.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse in\n  (assert ((candidate \"SELECT * FROM film WHERE length > 60 AND title LIKE '%n'\") = \"SELECT * FROM film WHERE length > 60 AND title LIKE '%n'\"));\n  (assert ((candidate \"SELECT * FROM film WHERE length > 60 AND title LIKE '%n' AND year = 2004\") = \"SELECT * FROM film WHERE length > 60 AND title LIKE '%n' AND year = 2004\"));\n  (assert ((candidate \"SELECT * FROM table_name WHERE column_name = value\") = \"SELECT * FROM table_name WHERE column_name = value\"));\n  (assert ((candidate \"SELECT * FROM table_name WHERE column_name LIKE '%value%'\") = \"SELECT * FROM table_name WHERE column_name LIKE '%value%'\"));\n  (assert ((candidate \"SELECT * FROM table_name WHERE column_name <= value\") = \"SELECT * FROM table_name WHERE column_name <= value\"));\n  (assert ((candidate \"SELECT * FROM table_name WHERE column_name NOT LIKE '%value%'\") = \"SELECT * FROM table_name WHERE column_name NOT LIKE '%value%'\"));\n  (assert ((candidate \"SELECT * FROM table_name WHERE column_name >= value\") = \"SELECT * FROM table_name WHERE column_name >= value\"));\n  (assert ((candidate \"SELECT * FROM table_name WHERE column_name!= value\") = \"SELECT * FROM table_name WHERE column_name!= value\"));\n  (assert ((candidate \"SELECT * FROM table_name WHERE column_name IN ('value1', 'value2')\") = \"SELECT * FROM table_name WHERE column_name IN ('value1', 'value2')\"));\n  (assert ((candidate \"SELECT * FROM table_name WHERE column_name < value\") = \"SELECT * FROM table_name WHERE column_name < value\"));\n  (assert ((candidate \"SELECT * FROM table_name WHERE column_name > value\") = \"SELECT * FROM table_name WHERE column_name > value\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_409149_turnOff", "language": "ml", "prompt": "(**function to turn off lights with given coordinates from array\n*)\nlet turnOff (array : int list) (a2d : int list list) : int list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_409149_turnOff.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = turnOff in\n  (assert ((candidate [2; 1; 3; 1] [[0; 0; 0; 0]; [0; 0; 0; 0]; [0; 0; 0; 0]; [0; 0; 0; 0]]) = [[0; 0; 0; 0]; [0; 0; 0; 0]; [0; 0; 0; 0]; [0; 0; 0; 0]]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_40937_extract_name", "language": "ml", "prompt": "(**extracts the module name.\n:param module_name:\n:return: <str> the module name without the version.\n*)\nlet extract_name (module_name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_40937_extract_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = extract_name in\n  (assert ((candidate \"baz_v3\") = \"baz\"));\n  (assert ((candidate \"foo_v2\") = \"foo\"));\n  (assert ((candidate \"foo\") = \"foo\"));\n  (assert ((candidate \"bar\") = \"bar\"));\n  (assert ((candidate \"baz\") = \"baz\"));\n  (assert ((candidate \"qux\") = \"qux\"));\n  (assert ((candidate \"bar_v1\") = \"bar\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_409443_get_network_bits", "language": "ml", "prompt": "(**Returns number of network bits of given mask\n:param mask_binary: Subnet Mask in binary\n:return: Number of network bits\n*)\nlet get_network_bits (mask_binary : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_409443_get_network_bits.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_network_bits in\n  (assert ((candidate \"11111111111111111111111111111111\") = 32));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_409453_fibonacci_by_index", "language": "ml", "prompt": "(**Get the value at the index of the Fibonacci series.\nAustin W. Milne @awbmilne  <austin.milne@uwaterloo.ca>\nParameters\n----------\nindex: number\n * The index of the Fibonacci series to return.\nReturns\n-------\nThe value from the Fibonacci series at the given index.\n*)\nlet fibonacci_by_index (index : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_409453_fibonacci_by_index.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = fibonacci_by_index in\n  (assert ((candidate 2) = 1));\n  (assert ((candidate 12) = 144));\n  (assert ((candidate 9) = 34));\n  (assert ((candidate 10) = 55));\n  (assert ((candidate 13) = 233));\n  (assert ((candidate 4) = 3));\n  (assert ((candidate 11) = 89));\n  (assert ((candidate 19) = 4181));\n  (assert ((candidate 22) = 17711));\n  (assert ((candidate 14) = 377));\n  (assert ((candidate 16) = 987));\n  (assert ((candidate 15) = 610));\n  (assert ((candidate 6) = 8));\n  (assert ((candidate 24) = 46368));\n  (assert ((candidate 3) = 2));\n  (assert ((candidate 17) = 1597));\n  (assert ((candidate 23) = 28657));\n  (assert ((candidate 18) = 2584));\n  (assert ((candidate 20) = 6765));\n  (assert ((candidate 21) = 10946));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 7) = 13));\n  (assert ((candidate 8) = 21));\n  (assert ((candidate 5) = 5));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_409856_MILLISECOND", "language": "ml", "prompt": "(**Returns the millisecond portion of a date as an integer between 0 and 999.\nSee https://docs.mongodb.com/manual/reference/operator/aggregation/millisecond/\nfor more details\n:param expression: expression or variable of a Date, a Timestamp, or an ObjectID\n:return: Aggregation operator\n*)\nlet MILLISECOND (expression : int) : (string, int) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_409856_MILLISECOND.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = MILLISECOND in\n  (assert ((candidate 2017) = [(\"$millisecond\", 2017)]));\n  (assert ((candidate 1437400400000) = [(\"$millisecond\", 1437400400000)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_410378_tickDiff", "language": "ml", "prompt": "(**Returns the microsecond difference between two ticks.\nt1:= the earlier tick\nt2:= the later tick\n...\nprint(pigpio.tickDiff(4294967272, 12))\n36\n...\n*)\nlet tickDiff (t1 : int) (t2 : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_410378_tickDiff.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = tickDiff in\n  (assert ((candidate 1 2) = 1));\n  (assert ((candidate (~1) 0) = 1));\n  (assert ((candidate 1 1) = 0));\n  (assert ((candidate 0 3) = 3));\n  (assert ((candidate 123456 123456) = 0));\n  (assert ((candidate 123456 123457) = 1));\n  (assert ((candidate 0 1) = 1));\n  (assert ((candidate 4294967272 12) = 36));\n  (assert ((candidate 0 0) = 0));\n  (assert ((candidate 0 2) = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_41072_rename_candidate_hugo", "language": "ml", "prompt": "(**Renames a candidate name according to a renaming map.\n*)\nlet rename_candidate_hugo (candidate : string) (renamings : (string, string) list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_41072_rename_candidate_hugo.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = rename_candidate_hugo in\n  (assert ((candidate \"HLA-A*01:01:01:01\" [(\"HLA-A*01:01:01:01\", \"HLA-A*01:01:01:01_NewName\")]) = \"HLA-A*01:01:01:01_NewName\"));\n  (assert ((candidate \"A.a.a.a.a\" [(\"A\", \"B\")]) = \"B.a.a.a.a\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_410947_arxiv_url_sanitizer", "language": "ml", "prompt": "(**as of now, just converts \narxiv.org/pdf/ to arxiv.org/abs\n*)\nlet arxiv_url_sanitizer (url : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_410947_arxiv_url_sanitizer.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = arxiv_url_sanitizer in\n  (assert ((candidate \"http://www.arxiv.org/pdf/cond-mat/0712.1784.pdf\") = \"http://www.arxiv.org/abs/cond-mat/0712.1784\"));\n  (assert ((candidate \"https://arxiv.org/pdf/2004.09813v23.pdf\") = \"https://arxiv.org/abs/2004.09813v23\"));\n  (assert ((candidate \"https://arxiv.org/pdf/cond-mat/0712.1784.pdf\") = \"https://arxiv.org/abs/cond-mat/0712.1784\"));\n  (assert ((candidate \"https://arxiv.org/pdf/cond-mat/0712.1784v1.pdf\") = \"https://arxiv.org/abs/cond-mat/0712.1784v1\"));\n  (assert ((candidate \"https://arxiv.org/pdf/2004.09813v2.pdf\") = \"https://arxiv.org/abs/2004.09813v2\"));\n  (assert ((candidate \"https://arxiv.org/abs/2012.12345.pdf\") = \"https://arxiv.org/abs/2012.12345\"));\n  (assert ((candidate \"http://www.arxiv.org/pdf/cond-mat/0712.1784v1.pdf\") = \"http://www.arxiv.org/abs/cond-mat/0712.1784v1\"));\n  (assert ((candidate \"https://arxiv.org/abs/cond-mat/0712.1784\") = \"https://arxiv.org/abs/cond-mat/0712.1784\"));\n  (assert ((candidate \"https://arxiv.org/pdf/2004.09813.pdf\") = \"https://arxiv.org/abs/2004.09813\"));\n  (assert ((candidate \"https://arxiv.org/pdf/math.GT/0611008.pdf\") = \"https://arxiv.org/abs/math.GT/0611008\"));\n  (assert ((candidate \"http://arxiv.org/pdf/1702.06188\") = \"http://arxiv.org/abs/1702.06188\"));\n  (assert ((candidate \"http://arxiv.org/pdf/1702.06188.pdf\") = \"http://arxiv.org/abs/1702.06188\"));\n  (assert ((candidate \"https://arxiv.org/pdf/2012.12345.pdf\") = \"https://arxiv.org/abs/2012.12345\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_411394_append_default_columns", "language": "ml", "prompt": "(**appends num string to a list as col_[index]\n*)\nlet append_default_columns (start : int) (num : int) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_411394_append_default_columns.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = append_default_columns in\n  (assert ((candidate 0 1) = [\"col_1\"]));\n  (assert ((candidate 0 2) = [\"col_1\"; \"col_2\"]));\n  (assert ((candidate 10 0) = []));\n  (assert ((candidate 0 2) = [\"col_1\"; \"col_2\"]));\n  (assert ((candidate 3 0) = []));\n  (assert ((candidate 2 5) = [\"col_3\"; \"col_4\"; \"col_5\"]));\n  (assert ((candidate 0 0) = []));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_411424__re_word_boundary", "language": "ml", "prompt": "(**Adds word boundary characters to the start and end of an\nexpression to require that the match occur as a whole word,\nbut do so respecting the fact that strings starting or ending\nwith non-word characters will change word boundaries.\n*)\nlet _re_word_boundary (r : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_411424__re_word_boundary.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _re_word_boundary in\n  (assert ((candidate \"\\B\") = \"(^|\\W)\\B(\\W|$)\"));\n  (assert ((candidate \"\\W+\") = candidate \"\\W+\"));\n  (assert ((candidate \"a?\") = \"(^|\\W)a?(\\W|$)\"));\n  (assert ((candidate \"[a-zA-Z]\") = \"(^|\\W)[a-zA-Z](\\W|$)\"));\n  (assert ((candidate \"a[b-]b\") = \"(^|\\W)a[b-]b(\\W|$)\"));\n  (assert ((candidate \"a\") = \"(^|\\W)a(\\W|$)\"));\n  (assert ((candidate \"[cat]\") = \"(^|\\W)[cat](\\W|$)\"));\n  (assert ((candidate \"a[]b\") = \"(^|\\W)a[]b(\\W|$)\"));\n  (assert ((candidate \"[abc]\") = \"(^|\\W)[abc](\\W|$)\"));\n  (assert ((candidate \"[a]\") = \"(^|\\W)[a](\\W|$)\"));\n  (assert ((candidate \"[\\d\\w]\") = \"(^|\\W)[\\d\\w](\\W|$)\"));\n  (assert ((candidate \"[ab]\") = \"(^|\\W)[ab](\\W|$)\"));\n  (assert ((candidate \"foo1\") = \"(^|\\W)foo1(\\W|$)\"));\n  (assert ((candidate \"foo\\b\") = \"(^|\\W)foo\\b(\\W|$)\"));\n  (assert ((candidate \"foo-bar\") = \"(^|\\W)foo-bar(\\W|$)\"));\n  (assert ((candidate \"a[b-Xb-]b\") = \"(^|\\W)a[b-Xb-]b(\\W|$)\"));\n  (assert ((candidate \"cat\\s+\") = \"(^|\\W)cat\\s+(\\W|$)\"));\n  (assert ((candidate \"\\\\\") = \"(^|\\W)\\\\(\\W|$)\"));\n  (assert ((candidate \"x\") = \"(^|\\W)x(\\W|$)\"));\n  (assert ((candidate \"cat\") = \"(^|\\W)cat(\\W|$)\"));\n  (assert ((candidate \"foo\\bfoo\") = \"(^|\\W)foo\\bfoo(\\W|$)\"));\n  (assert ((candidate \"\\d\") = \"(^|\\W)\\d(\\W|$)\"));\n  (assert ((candidate \"[^abc]\") = \"(^|\\W)[^abc](\\W|$)\"));\n  (assert ((candidate \"\\w\") = \"(^|\\W)\\w(\\W|$)\"));\n  (assert ((candidate \"cat\\|\") = \"(^|\\W)cat\\|(\\W|$)\"));\n  (assert ((candidate \"a+b\") = \"(^|\\W)a+b(\\W|$)\"));\n  (assert ((candidate \".*\") = \"(^|\\W).*(\\W|$)\"));\n  (assert ((candidate \"\\w+\") = \"(^|\\W)\\w+(\\W|$)\"));\n  (assert ((candidate \"a\\sb\") = \"(^|\\W)a\\sb(\\W|$)\"));\n  (assert ((candidate \"abc\") = \"(^|\\W)abc(\\W|$)\"));\n  (assert ((candidate \"cat\\\\\") = \"(^|\\W)cat\\\\(\\W|$)\"));\n  (assert ((candidate \"cat\\\\\\\\\") = \"(^|\\W)cat\\\\\\\\(\\W|$)\"));\n  (assert ((candidate \"a\\b\") = \"(^|\\W)a\\b(\\W|$)\"));\n  (assert ((candidate \"\\[cat\\]\") = \"(^|\\W)\\[cat\\](\\W|$)\"));\n  (assert ((candidate \"a[\\s]b\") = \"(^|\\W)a[\\s]b(\\W|$)\"));\n  (assert ((candidate \"1foo\") = \"(^|\\W)1foo(\\W|$)\"));\n  (assert ((candidate \"(\\w+|\\\\)\") = \"(^|\\W)(\\w+|\\\\)(\\W|$)\"));\n  (assert ((candidate \"foo\") = \"(^|\\W)foo(\\W|$)\"));\n  (assert ((candidate \"[^ab]\") = \"(^|\\W)[^ab](\\W|$)\"));\n  (assert ((candidate \"123\") = \"(^|\\W)123(\\W|$)\"));\n  (assert ((candidate \"foo-bar-\") = \"(^|\\W)foo-bar-(\\W|$)\"));\n  (assert ((candidate \"\\]\") = \"(^|\\W)\\](\\W|$)\"));\n  (assert ((candidate \"\\[\") = \"(^|\\W)\\[(\\W|$)\"));\n  (assert ((candidate \"a[b-gB-G]b\") = \"(^|\\W)a[b-gB-G]b(\\W|$)\"));\n  (assert ((candidate \"foo1bar\") = \"(^|\\W)foo1bar(\\W|$)\"));\n  (assert ((candidate \"a*\") = \"(^|\\W)a*(\\W|$)\"));\n  (assert ((candidate \"foo_bar1_\") = \"(^|\\W)foo_bar1_(\\W|$)\"));\n  (assert ((candidate \"foo_bar1\") = \"(^|\\W)foo_bar1(\\W|$)\"));\n  (assert ((candidate \"\\\\cat\") = \"(^|\\W)\\\\cat(\\W|$)\"));\n  (assert ((candidate \"[^a]\") = \"(^|\\W)[^a](\\W|$)\"));\n  (assert ((candidate \"\\W\") = candidate \"\\W\"));\n  (assert ((candidate \"a_b\") = \"(^|\\W)a_b(\\W|$)\"));\n  (assert ((candidate \"\\d+\") = \"(^|\\W)\\d+(\\W|$)\"));\n  (assert ((candidate \"\\W\") = \"(^|\\W)\\W(\\W|$)\"));\n  (assert ((candidate \"foo-\") = \"(^|\\W)foo-(\\W|$)\"));\n  (assert ((candidate \"foo_bar\") = \"(^|\\W)foo_bar(\\W|$)\"));\n  (assert ((candidate \"\\b\") = \"(^|\\W)\\b(\\W|$)\"));\n  (assert ((candidate \"!\") = \"(^|\\W)!(\\W|$)\"));\n  (assert ((candidate \"\\w+\") = candidate \"\\w+\"));\n  (assert ((candidate \"foo-_bar\") = \"(^|\\W)foo-_bar(\\W|$)\"));\n  (assert ((candidate \"a\\.b\") = \"(^|\\W)a\\.b(\\W|$)\"));\n  (assert ((candidate \"a[^]b]\") = \"(^|\\W)a[^]b](\\W|$)\"));\n  (assert ((candidate \"1foo_bar1\") = \"(^|\\W)1foo_bar1(\\W|$)\"));\n  (assert ((candidate \"[a-zA-Z0-9_]\") = \"(^|\\W)[a-zA-Z0-9_](\\W|$)\"));\n  (assert ((candidate \"the\") = \"(^|\\W)the(\\W|$)\"));\n  (assert ((candidate \"1foo_bar\") = \"(^|\\W)1foo_bar(\\W|$)\"));\n  (assert ((candidate \"[a-z]\") = \"(^|\\W)[a-z](\\W|$)\"));\n  (assert ((candidate \"a.b\") = \"(^|\\W)a.b(\\W|$)\"));\n  (assert ((candidate \"foo;bar\") = \"(^|\\W)foo;bar(\\W|$)\"));\n  (assert ((candidate \"a[b-g]b\") = \"(^|\\W)a[b-g]b(\\W|$)\"));\n  (assert ((candidate \"a/b\") = \"(^|\\W)a/b(\\W|$)\"));\n  (assert ((candidate \"a[b-Za-y]b\") = \"(^|\\W)a[b-Za-y]b(\\W|$)\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_411437__prt_mode_from_unfolding", "language": "ml", "prompt": "(**Return 'fixed' or 'staggered' depending on unfolding flag\n*)\nlet _prt_mode_from_unfolding (unfolding : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_411437__prt_mode_from_unfolding.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _prt_mode_from_unfolding in\n  (assert ((candidate 0) = \"fixed\"));\n  (assert ((candidate 1) = \"staggered\"));\n  (assert ((candidate (~1)) = \"staggered\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_411619_order_of_execution", "language": "ml", "prompt": "(**This one is linear time.\n:param count:\n:param k:\n:return:\n*)\nlet order_of_execution (count : int) (k : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_411619_order_of_execution.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = order_of_execution in\n  (assert ((candidate 3 1) = [1; 2; 3]));\n  (assert ((candidate 2 3) = [1; 2]));\n  (assert ((candidate 2 1) = [1; 2]));\n  (assert ((candidate 5 1) = [1; 2; 3; 4; 5]));\n  (assert ((candidate 6 1) = [1; 2; 3; 4; 5; 6]));\n  (assert ((candidate 4 1) = [1; 2; 3; 4]));\n  (assert ((candidate 1 2) = [1]));\n  (assert ((candidate 10 1) = [1; 2; 3; 4; 5; 6; 7; 8; 9; 10]));\n  (assert ((candidate 1 3) = [1]));\n  (assert ((candidate 3 3) = [3; 1; 2]));\n  (assert ((candidate 1 1) = [1]));\n  (assert ((candidate 3 2) = [2; 1; 3]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_41197_contains_word", "language": "ml", "prompt": "(**Checks whether a string contains a certain word\n*)\nlet contains_word (s : string) (w : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_41197_contains_word.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = contains_word in\n  (assert ((candidate \"This is a string with a word in it\" \"word\") = true));\n  (assert ((candidate \"This is a string with a word in it\" \"dog\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_41279_get_attrs", "language": "ml", "prompt": "(**Get foreground and background attributes.\n*)\nlet get_attrs (foreground : int) (background : int) (style : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_41279_get_attrs.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_attrs in\n  (assert ((candidate 0 0 2) = 2));\n  (assert ((candidate 0 0 1) = 1));\n  (assert ((candidate 0 0 0) = 0));\n  (assert ((candidate 0 0 0) = 0));\n  (assert ((candidate 0 0 3) = 3));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_413062_matrix_add", "language": "ml", "prompt": "(**Accepts two lists-of-lists of numbers and returns one\nlist-of-lists with each of the corresponding numbers in the\ntwo given lists-of-lists added together.\nExample:\n>>> matrix1 = [[1, -2], [-3, 4]]\n>>> matrix2 = [[2, -1], [0, -1]]\n>>> add(matrix1, matrix2)\n[[3, -3], [-3, 3]]\n>>> matrix1 = [[1, -2, 3], [-4, 5, -6], [7, -8, 9]]\n>>> matrix2 = [[1, 1, 0], [1, -2, 3], [-2, 2, -2]]\n>>> add(matrix1, matrix2)\n[[2, -1, 3], [-3, 3, -3], [5, -6, 7]]\n*)\nlet matrix_add (list1 : int list list) (list2 : int list list) : int list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_413062_matrix_add.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = matrix_add in\n  (assert ((candidate [[1; (~2); 3]; [(~4); 5; (~6)]; [7; (~8); 9]] [[1; 1; 0]; [1; (~2); 3]; [(~2); 2; (~2)]]) = [[2; (~1); 3]; [(~3); 3; (~3)]; [5; (~6); 7]]));\n  (assert ((candidate [[1; (~2); 3]; [(~4); 5; (~6)]; [7; (~8); 9]] [[1; 1; 0]; [1; (~2); 3]; [(~2); 2; (~2)]]) = [[2; (~1); 3]; [(~3); 3; (~3)]; [5; (~6); 7]]));\n  (assert ((candidate [[1; (~2)]; [(~3); 4]] [[2; (~1)]; [0; (~1)]]) = [[3; (~3)]; [(~3); 3]]));\n  (assert ((candidate [[1; 2; (~3)]; [4; (~5); 6]] [[(~1); 1; 2]; [(~1); 2; 3]; [4; 5; 6]]) = [[0; 3; (~1)]; [3; (~3); 9]]));\n  (assert ((candidate [[1; (~2)]; [(~3); 4]] [[2; (~1)]; [0; (~1)]]) = [[3; (~3)]; [(~3); 3]]));\n  (assert ((candidate [[1; (~2)]; [(~3); 4]] [[2; (~1)]; [0; (~1)]]) = [[3; (~3)]; [(~3); 3]]));\n  (assert ((candidate [[1; 0; 1; 0]; [0; 1; 0; 1]; [1; 0; 1; 0]; [0; 1; 0; 1]] [[1; 1; 1; 1]; [1; 1; 1; 1]; [1; 1; 1; 1]; [1; 1; 1; 1]]) = [[2; 1; 2; 1]; [1; 2; 1; 2]; [2; 1; 2; 1]; [1; 2; 1; 2]]));\n  (assert ((candidate [[1; (~2); 3]; [(~4); 5; (~6)]; [7; (~8); 9]] [[1; 1; 0]; [1; (~2); 3]; [(~2); 2; (~2)]]) = [[2; (~1); 3]; [(~3); 3; (~3)]; [5; (~6); 7]]));\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]; [7; 8; 9]] [[(~1); (~2); (~3)]; [(~4); (~5); (~6)]; [(~7); (~8); (~9)]]) = [[0; 0; 0]; [0; 0; 0]; [0; 0; 0]]));\n  (assert ((candidate [[1; (~2)]; [(~3); 4]] [[2; (~1)]; [0; (~1)]]) = [[3; (~3)]; [(~3); 3]]));\n  (assert ((candidate [[1; (~2); 3]; [(~4); 5; (~6)]; [7; (~8); 9]] [[1; 1; 0]; [1; (~2); 3]; [(~2); 2; (~2)]]) = [[2; (~1); 3]; [(~3); 3; (~3)]; [5; (~6); 7]]));\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]; [7; 8; 9]] [[(~1); (~2); (~3)]; [(~4); (~5); (~6)]; [(~7); (~8); (~9)]]) = [[0; 0; 0]; [0; 0; 0]; [0; 0; 0]]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_413287_ConvertPrivateIpv6GoogleAccess", "language": "ml", "prompt": "(**Return PrivateIpv6GoogleAccess enum defined in mixer.\nArgs:\n * choice: Enum value of PrivateIpv6GoogleAccess defined in gcloud.\n*)\nlet ConvertPrivateIpv6GoogleAccess (choice : string option) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_413287_ConvertPrivateIpv6GoogleAccess.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = ConvertPrivateIpv6GoogleAccess in\n  (assert ((candidate Some(\"ENABLE_OUTBOUND_VM_ACCESS\")) = Some(\"ENABLE_OUTBOUND_VM_ACCESS_TO_GOOGLE\")));\n  (assert ((candidate Some(\"DISABLE\")) = Some(\"DISABLE_GOOGLE_ACCESS\")));\n  (assert ((candidate Some(\"ENABLE_BIDIRECTIONAL_ACCESS\")) = Some(\"ENABLE_BIDIRECTIONAL_ACCESS_TO_GOOGLE\")));\n  (assert ((candidate Some(\"ENABLE_BIDIRECTIONAL_ACCESS\")) = Some(\"ENABLE_BIDIRECTIONAL_ACCESS_TO_GOOGLE\")));\n  (assert ((candidate Some(\"ENABLE_OUTBOUND_VM_ACCESS\")) = Some(\"ENABLE_OUTBOUND_VM_ACCESS_TO_GOOGLE\")));\n  (assert ((candidate Some(\"DISABLE\")) = Some(\"DISABLE_GOOGLE_ACCESS\")));\n  (assert ((candidate Some(None)) = Some(None)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_413434_song_decoder", "language": "ml", "prompt": "(**Return decoded song string\n*)\nlet song_decoder (song : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_413434_song_decoder.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = song_decoder in\n  (assert ((candidate \"AWUB\") = \"A\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate candidate \"WUBWUBWUBWUBWUBAWUBBWUBC\") = \"A B C\"));\n  (assert ((candidate candidate \"WUBAWUBBWUBCWUB\") = \"A B C\"));\n  (assert ((candidate \"AWUBWUBWUBBWUBWUBWUBC\") = \"A B C\"));\n  (assert ((candidate candidate \"WUBAWUBBWUBC\") = \"A B C\"));\n  (assert ((candidate candidate \"WUBWUBWUBWUBWUBAWUBBWUBCWUB\") = \"A B C\"));\n  (assert ((candidate candidate \"WUBWUBWUBAWUBBWUBC\") = \"A B C\"));\n  (assert ((candidate candidate \"WUBWUBWUBWUBWUBWUBWUBWUBWUBWUB\") = \"\"));\n  (assert ((candidate \"AWUBWUBWUBBWUBWUBWUBC\") = \"A B C\"));\n  (assert ((candidate candidate \"WUBWUBAWUBBWUBC\") = \"A B C\"));\n  (assert ((candidate candidate \"WUBWUBWUBWUBWUBWUBAWUBBWUBC\") = \"A B C\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"WUBAWUBBWUBCWUB\") = \"A B C\"));\n  (assert ((candidate candidate \"WUBWUBWUBAWUBBWUBCWUBWUB\") = \"A B C\"));\n  (assert ((candidate candidate \"WUBWUBWUBWUBWUBWUBWUBWUBWUB\") = \"\"));\n  (assert ((candidate \"WUBAWUBBWUBCWUB\") = \"A B C\"));\n  (assert ((candidate \"WUBAWUB\") = \"A\"));\n  (assert ((candidate \"AWUBBWUBC\") = \"A B C\"));\n  (assert ((candidate \"WUBWUB\") = \"\"));\n  (assert ((candidate candidate \"AWUBBWUBC\") = \"A B C\"));\n  (assert ((candidate candidate \"AWUBWUBWUBBWUBWUBWUBC\") = \"A B C\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_41418_get_api_interfaces_name_by_type", "language": "ml", "prompt": "(**Extract interface names from Interfaces API response by type\n:param api_interfaces: Interfaces API response\n:param type_str: Type string to match\n:param key_name: Optional - Key name to use (default 'name')\n:return: List of Interface names matching type_str\n*)\nlet get_api_interfaces_name_by_type (api_interfaces : (string, string) list list) (type_str : string) (key_name : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_41418_get_api_interfaces_name_by_type.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_api_interfaces_name_by_type in\n  (assert ((candidate [[(\"name\", \"Ethernet0\"); (\"type\", \"iana-if-type:ethernetCsmacd\")]; [(\"name\", \"Ethernet4\"); (\"type\", \"iana-if-type:ethernetCsmacd\")]] \"iana-if-type:ethernetCsmacd\") = [\"Ethernet0\"; \"Ethernet4\"]));\n  (assert ((candidate [[(\"name\", \"Ethernet0\"); (\"type\", \"iana-if-type:ethernetCsmacd\")]; [(\"name\", \"Ethernet4\"); (\"type\", \"iana-if-type:ethernetCsmacd\")]] \"iana-if-type:ethernetCsmacd\" \"name\") = [\"Ethernet0\"; \"Ethernet4\"]));\n  (assert ((candidate [[(\"name\", \"Ethernet0\"); (\"type\", \"iana-if-type:ethernetCsmacd\")]; [(\"name\", \"Ethernet4\"); (\"type\", \"iana-if-type:ethernetCsmacd\")]] \"iana-if-type:ethernetCsmacd\" \"type\") = [\"iana-if-type:ethernetCsmacd\"; \"iana-if-type:ethernetCsmacd\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_414823_clean_whitespace", "language": "ml", "prompt": "(**Remove any extra whitespace and line breaks as needed.\n*)\nlet clean_whitespace (text : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_414823_clean_whitespace.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = clean_whitespace in\n  (assert ((candidate \"one\r\r\r\ntwo\") = \"one two\"));\n  (assert ((candidate \"one\r\n\t\t\ntwo\") = \"one two\"));\n  (assert ((candidate \"one\n\r\n\ntwo\n\") = \"one two\"));\n  (assert ((candidate \"one\ntwo\") = \"one two\"));\n  (assert ((candidate \"one\t\t\r\n\r\n\n\n\ntwo\r\n\") = \"one two\"));\n  (assert ((candidate \" \") = \"\"));\n  (assert ((candidate \"one\n\r\r\n\t\t\ntwo\n\t\t\") = \"one two\"));\n  (assert ((candidate \"one\r\n\n\ntwo\") = \"one two\"));\n  (assert ((candidate \" one \") = \"one\"));\n  (assert ((candidate \"one\n\r\r\ntwo\") = \"one two\"));\n  (assert ((candidate \"one \") = \"one\"));\n  (assert ((candidate \"  one  \") = \"one\"));\n  (assert ((candidate \" one\") = \"one\"));\n  (assert ((candidate \"one\") = \"one\"));\n  (assert ((candidate \"one\n\ntwo\n\") = \"one two\"));\n  (assert ((candidate \"one\r\n\r\r\ntwo\r\n\") = \"one two\"));\n  (assert ((candidate \"one\t\t\t\ttwo\") = \"one two\"));\n  (assert ((candidate \"one\n\ntwo\") = \"one two\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_415327_escape_bytes", "language": "ml", "prompt": "(**Escapes seven bytes to eight bytes.\nArgs:\n * value7_uint64be(int): Bytes as a 56-bit bigendian unsigned integer.\nReturns:\n * int: Escaped bytes as a 64-bit bigendian unsigned integer.\n*)\nlet escape_bytes (value7_uint64be : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_415327_escape_bytes.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = escape_bytes in\n  (assert ((candidate 72057594037927935) = 18446744073709551615));\n  (assert ((candidate 0) = 9259542123273814144));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_415365_chop_at", "language": "ml", "prompt": "(**Truncate string ``s`` at the first occurrence of ``sub``.\nIf ``inclusive`` is true, truncate just after ``sub`` rather than at it.\n>>> chop_at(\"plutocratic brats\", \"rat\")\n'plutoc'\n>>> chop_at(\"plutocratic brats\", \"rat\", True)\n'plutocrat'\n*)\nlet chop_at (s : string) (sub : string) (inclusive : bool) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_415365_chop_at.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = chop_at in\n  (assert ((candidate \"rat\" \"bar\") = \"rat\"));\n  (assert ((candidate \"foo bar\" \"bar\") = \"foo \"));\n  (assert ((candidate \"plutocratic brats\" \"bar\" true) = \"plutocratic brats\"));\n  (assert ((candidate \"\" \"rat\" true) = \"\"));\n  (assert ((candidate \"plutocratic brats\" \"rat\") = \"plutoc\"));\n  (assert ((candidate \"rat\" \"rat\") = \"\"));\n  (assert ((candidate \"a\" \"b\") = \"a\"));\n  (assert ((candidate \"abc\" \"bc\") = \"a\"));\n  (assert ((candidate \"a\" \"b\") = \"a\"));\n  (assert ((candidate \"abc\" \"c\") = \"ab\"));\n  (assert ((candidate \"a\" \"a\") = \"\"));\n  (assert ((candidate \"\" \"rat\") = \"\"));\n  (assert ((candidate \"plutocratic brats\" \"bar\") = \"plutocratic brats\"));\n  (assert ((candidate \"plutocratic brats\" \"tat\" true) = \"plutocratic brats\"));\n  (assert ((candidate \"rat\" \"bar\" true) = \"rat\"));\n  (assert ((candidate \"plutocratic brats\" \"rat\" true) = \"plutocrat\"));\n  (assert ((candidate \"plutocratic brats\" \"rat\") = \"plutoc\"));\n  (assert ((candidate \"abc\" \"ab\") = \"\"));\n  (assert ((candidate \"a\" \"b\" true) = \"a\"));\n  (assert ((candidate \"a\" \"a\") = \"\"));\n  (assert ((candidate \"plutocratic brats\" \"tat\") = \"plutocratic brats\"));\n  (assert ((candidate \"plutocratic brats\" \"rat\" true) = \"plutocrat\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_415543_add_host", "language": "ml", "prompt": "(**Make the image path absolute for those served by the server.\n*)\nlet add_host (data : (string, string) list list) (host : string) : (string, string) list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_415543_add_host.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = add_host in\n  (assert ((candidate [[(\"name\", \"name1\"); (\"image\", \"img1\")]; [(\"name\", \"name2\"); (\"image\", \"img2\")]] \"localhost:8000\") = [[(\"name\", \"name1\"); (\"image\", \"http://localhost:8000/img1\")]; [(\"name\", \"name2\"); (\"image\", \"http://localhost:8000/img2\")]]));\n  (assert ((candidate [[(\"image\", \"foo/bar.png\")]; [(\"image\", \"foo/baz.png\")]] \"example.com\") = [[(\"image\", \"http://example.com/foo/bar.png\")]; [(\"image\", \"http://example.com/foo/baz.png\")]]));\n  (assert ((candidate [[(\"name\", \"name1\"); (\"image\", \"img1\")]; [(\"name\", \"name2\"); (\"image\", \"img2\")]] \"localhost:9000/api\") = [[(\"name\", \"name1\"); (\"image\", \"http://localhost:9000/api/img1\")]; [(\"name\", \"name2\"); (\"image\", \"http://localhost:9000/api/img2\")]]));\n  (assert ((candidate [[(\"image\", \"foo/bar.png\")]; [(\"image\", \"foo/baz.png\")]; [(\"image\", \"qux/quux.png\")]] \"example.com\") = [[(\"image\", \"http://example.com/foo/bar.png\")]; [(\"image\", \"http://example.com/foo/baz.png\")]; [(\"image\", \"http://example.com/qux/quux.png\")]]));\n  (assert ((candidate [[(\"name\", \"name1\"); (\"image\", \"img1\")]; [(\"name\", \"name2\"); (\"image\", \"img2\")]] \"localhost\") = [[(\"name\", \"name1\"); (\"image\", \"http://localhost/img1\")]; [(\"name\", \"name2\"); (\"image\", \"http://localhost/img2\")]]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_415824_color2rgba", "language": "ml", "prompt": "(**convert #RRGGBB[AA] to an (R, G, B, [A]) tuple\n*)\nlet color2rgba (colorstring : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_415824_color2rgba.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = color2rgba in\n  (assert ((candidate \"#0000ffcc\") = 65484));\n  (assert ((candidate \"#0000ff00\") = 65280));\n  (assert ((candidate \"#ff0000cc\") = 4278190284));\n  (assert ((candidate \"#00ff00cc\") = 16711884));\n  (assert ((candidate \"#00000000\") = 0));\n  (assert ((candidate \"#ff0000ff\") = 4278190335));\n  (assert ((candidate \"#00ff0000\") = 16711680));\n  (assert ((candidate \"#00ff00ff\") = 16711935));\n  (assert ((candidate \"#ff000000\") = 4278190080));\n  (assert ((candidate \"#0000ffff\") = 65535));\n  (assert ((candidate \"#000000ff\") = 255));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_416641_init_method_normalizer", "language": "ml", "prompt": "(**Normalizes the name of an initialization method.\n*)\nlet init_method_normalizer (name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_416641_init_method_normalizer.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = init_method_normalizer in\n  (assert ((candidate \"kaimingnormal\") = \"kaimingnormal\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_416669_is_counting_line_passed", "language": "ml", "prompt": "(**To check if the point passed the counting line by the x coord if it left/right or y coord if it bottom/top.\n:param point: the object location.\n:param counting_line: the coordinates list of the area.\n:param line_orientation: the string of the orientation of the line.need to be top, bottom, left, right.\n:return: True if the point passed the line , False if the point didnt pass the line.\n*)\nlet is_counting_line_passed (point :  int * int) (counting_line :   int * int *  int * int) (line_orientation : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_416669_is_counting_line_passed.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_counting_line_passed in\n  (assert ((candidate (0, 0) ((1, 0), (0, 0)) \"right\") = false));\n  (assert ((candidate (0, 0) ((1, 0), (0, 0)) \"top\") = false));\n  (assert ((candidate (0, 0) ((0, 0), (0, 1)) \"left\") = false));\n  (assert ((candidate (0, 0) ((1, 0), (0, 0)) \"left\") = true));\n  (assert ((candidate (0, 0) ((0, 0), (0, 1)) \"top\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_4167_wrap", "language": "ml", "prompt": "(**:param x: a scalar\n:param m: minimum possible value in range\n:param M: maximum possible value in range\nWraps ``x`` so m <= x <= M; but unlike ``bound()`` which\ntruncates, ``wrap()`` wraps x around the coordinate system defined by m,M.\nFor example, m = -180, M = 180 (degrees), x = 360 --> returns 0.\n*)\nlet wrap (x : int) (m : int) (M : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_4167_wrap.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = wrap in\n  (assert ((candidate 180 (~180) 180) = 180));\n  (assert ((candidate (~10) 0 100) = 90));\n  (assert ((candidate 3 1 5) = 3));\n  (assert ((candidate 181 (~180) 180) = (~179)));\n  (assert ((candidate 13 10 20) = 13));\n  (assert ((candidate (~180) (~180) 180) = (~180)));\n  (assert ((candidate 0 0 100) = 0));\n  (assert ((candidate (~10) (~100) 0) = (~10)));\n  (assert ((candidate 0 (~2) 1) = 0));\n  (assert ((candidate 0 (~1) 1) = 0));\n  (assert ((candidate 1 1 1) = 1));\n  (assert ((candidate 2 1 3) = 2));\n  (assert ((candidate (~100) 0 100) = 0));\n  (assert ((candidate 5 1 5) = 5));\n  (assert ((candidate 0 (~1) 5) = 0));\n  (assert ((candidate 3 1 3) = 3));\n  (assert ((candidate 3 (~1) 0) = 0));\n  (assert ((candidate 3 (~2) (~1)) = (~1)));\n  (assert ((candidate 0 (~100) 0) = 0));\n  (assert ((candidate (~100) 1 3) = 2));\n  (assert ((candidate 10 0 100) = 10));\n  (assert ((candidate 100 1 3) = 2));\n  (assert ((candidate 360 (~180) 180) = 0));\n  (assert ((candidate 3 10 20) = 13));\n  (assert ((candidate (~181) (~180) 180) = 179));\n  (assert ((candidate 15 10 20) = 15));\n  (assert ((candidate (~3) 0 1) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_417404_even", "language": "ml", "prompt": "(**Returns 1 if x is even, 0 otherwise.\n*)\nlet even (x : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_417404_even.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = even in\n  (assert ((candidate 3) = 0));\n  (assert ((candidate 0) = 1));\n  (assert ((candidate (~1)) = 0));\n  (assert ((candidate 4) = 1));\n  (assert ((candidate 1) = 0));\n  (assert ((candidate 2) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_417916_tokenize_grapheme_langid", "language": "ml", "prompt": "(**tokenizer the langid  of word (For multilingual GBERT)\n*)\nlet tokenize_grapheme_langid (enhanced_word : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_417916_tokenize_grapheme_langid.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = tokenize_grapheme_langid in\n  (assert ((candidate \"hello}\") = [\"hello}\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_418429_normpath", "language": "ml", "prompt": "(**Normalize path, eliminating double slashes, etc.\n*)\nlet normpath (path : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_418429_normpath.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = normpath in\n  (assert ((candidate \"foo/bar/..\") = \"foo\"));\n  (assert ((candidate \"/foo/bar/..\") = \"/foo\"));\n  (assert ((candidate \"/foo/bar/../../\") = \"/\"));\n  (assert ((candidate \"/../foo/bar/../../\") = \"/\"));\n  (assert ((candidate \"/a/b/c/../..\") = \"/a\"));\n  (assert ((candidate \"/a/b/c\") = \"/a/b/c\"));\n  (assert ((candidate \"/a/b/../c\") = \"/a/c\"));\n  (assert ((candidate \"\\foo\\bar\") = \"\\foo\\bar\"));\n  (assert ((candidate \"/a/b//c\") = \"/a/b/c\"));\n  (assert ((candidate \"foo\") = \"foo\"));\n  (assert ((candidate \"/\") = \"/\"));\n  (assert ((candidate \"/../../../../a\") = \"/a\"));\n  (assert ((candidate \"/a/b/c/../../..\") = \"/\"));\n  (assert ((candidate \"/foo/bar/../..\") = \"/\"));\n  (assert ((candidate \"\") = \".\"));\n  (assert ((candidate \"/a/b/c/../../../..\") = \"/\"));\n  (assert ((candidate \"/a/b/c/../../../../..\") = \"/\"));\n  (assert ((candidate \"/foo\") = \"/foo\"));\n  (assert ((candidate \"/a/../b/c\") = \"/b/c\"));\n  (assert ((candidate \"/a/./b/c\") = \"/a/b/c\"));\n  (assert ((candidate \"/a/b/c/../../../../../..\") = \"/\"));\n  (assert ((candidate \"/a/b/c/\") = \"/a/b/c\"));\n  (assert ((candidate \"foo/bar\") = \"foo/bar\"));\n  (assert ((candidate \"a/b/c\") = \"a/b/c\"));\n  (assert ((candidate \"/../../../a\") = \"/a\"));\n  (assert ((candidate \"a/b//c\") = \"a/b/c\"));\n  (assert ((candidate \"foo\\bar\") = \"foo\\bar\"));\n  (assert ((candidate \"/foo/bar\") = \"/foo/bar\"));\n  (assert ((candidate \"/a/b/./c\") = \"/a/b/c\"));\n  (assert ((candidate \"/../../a\") = \"/a\"));\n  (assert ((candidate \"a/b/./c\") = \"a/b/c\"));\n  (assert ((candidate \"/../a\") = \"/a\"));\n  (assert ((candidate \"/a/b/c/..\") = \"/a/b\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_418893_factorial_pythonic", "language": "ml", "prompt": "(**Factorial with reduce function (pythonic approach).\nExamples:\n * >>> assert factorial_pythonic(0) == 1\n * >>> assert factorial_pythonic(1) == 1\n * >>> assert factorial_pythonic(2) == 2\n * >>> assert factorial_pythonic(3) == 6\n*)\nlet factorial_pythonic (number : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_418893_factorial_pythonic.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = factorial_pythonic in\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 3) = 6));\n  (assert ((candidate 0) = 1));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 10) = 3628800));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_419117_filter_matching_fields", "language": "ml", "prompt": "(**return fields which are same as in other_fields list, ignoring the case\n*)\nlet filter_matching_fields (fields : string list) (other_fields : string list) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_419117_filter_matching_fields.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = filter_matching_fields in\n  (assert ((candidate [] [\"FOO\"; \"BAR\"]) = []));\n  (assert ((candidate [] []) = []));\n  (assert ((candidate [\"foo\"; \"bar\"; \"baz\"] []) = []));\n  (assert ((candidate [\"aaa\"; \"bbb\"; \"ccc\"] [\"aaa\"; \"bbb\"; \"ccc\"]) = [\"aaa\"; \"bbb\"; \"ccc\"]));\n  (assert ((candidate [\"foo\"; \"bar\"; \"baz\"] [\"foo\"; \"baz\"]) = [\"foo\"; \"baz\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_420357_fixIncorrectDateEncoding", "language": "ml", "prompt": "(**Fix date string to make it conform to ISO standard.\n*)\nlet fixIncorrectDateEncoding (Date : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_420357_fixIncorrectDateEncoding.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = fixIncorrectDateEncoding in\n  (assert ((candidate \"2020-12-20\") = \"2020-12-20T00:00:00Z\"));\n  (assert ((candidate \"2020-12-20T00:00:00Z\") = \"2020-12-20T00:00:00Z\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_421139_ctz_naive", "language": "ml", "prompt": "(**counting zeros starting at the LSB until a 1-bit is encountered\n*)\nlet ctz_naive (x : int) (w : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_421139_ctz_naive.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = ctz_naive in\n  (assert ((candidate 9) = 0));\n  (assert ((candidate 3 8) = 0));\n  (assert ((candidate 8) = 3));\n  (assert ((candidate 1) = 0));\n  (assert ((candidate 3) = 0));\n  (assert ((candidate 5) = 0));\n  (assert ((candidate 11 8) = 0));\n  (assert ((candidate 10) = 1));\n  (assert ((candidate 6 8) = 1));\n  (assert ((candidate 13) = 0));\n  (assert ((candidate 12) = 2));\n  (assert ((candidate 15) = 0));\n  (assert ((candidate 262143) = 0));\n  (assert ((candidate 7 8) = 0));\n  (assert ((candidate 5 8) = 0));\n  (assert ((candidate 8) = 3));\n  (assert ((candidate 3) = 0));\n  (assert ((candidate 1 8) = 0));\n  (assert ((candidate 7) = 0));\n  (assert ((candidate 10 8) = 1));\n  (assert ((candidate 6) = 1));\n  (assert ((candidate 9 8) = 0));\n  (assert ((candidate 7) = 0));\n  (assert ((candidate 262142) = 1));\n  (assert ((candidate 18708) = 2));\n  (assert ((candidate 2 8) = 1));\n  (assert ((candidate 4 8) = 2));\n  (assert ((candidate 16) = 4));\n  (assert ((candidate 13) = 0));\n  (assert ((candidate 11) = 0));\n  (assert ((candidate 11) = 0));\n  (assert ((candidate 2) = 1));\n  (assert ((candidate 5) = 0));\n  (assert ((candidate 0) = 16));\n  (assert ((candidate 14) = 1));\n  (assert ((candidate 4) = 2));\n  (assert ((candidate 2) = 1));\n  (assert ((candidate 15) = 0));\n  (assert ((candidate 10) = 1));\n  (assert ((candidate 4) = 2));\n  (assert ((candidate 1) = 0));\n  (assert ((candidate 8 8) = 3));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_421307_get_file_type", "language": "ml", "prompt": "(**Determine file type by extracting suffix of file_name\n*)\nlet get_file_type (file_name : string option) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_421307_get_file_type.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_file_type in\n  (assert ((candidate Some(\"test.gro.nc\")) = Some(\"netcdf\")));\n  (assert ((candidate Some(\"myfile.pdb\")) = Some(\"pdb\")));\n  (assert ((candidate Some(\"test.itp\")) = Some(\"itp\")));\n  (assert ((candidate Some(\"a/b/c.cms\")) = Some(\"mae\")));\n  (assert ((candidate Some(\"a/b/c.gro\")) = Some(\"gro\")));\n  (assert ((candidate Some(\"x/y/z/a/b/c.d\")) = Some(\"d\")));\n  (assert ((candidate Some(\"something.txt\")) = Some(\"txt\")));\n  (assert ((candidate Some(\"test.gro\")) = Some(\"gro\")));\n  (assert ((candidate Some(\"a/b/c.nc\")) = Some(\"netcdf\")));\n  (assert ((candidate Some(\"myfile.mae\")) = Some(\"mae\")));\n  (assert ((candidate Some(\"test.nc\")) = Some(\"netcdf\")));\n  (assert ((candidate Some(\"a/b/c.prmtop\")) = Some(\"parm7\")));\n  (assert ((candidate Some(\"test.pdb\")) = Some(\"pdb\")));\n  (assert ((candidate Some(\"test.cms\")) = Some(\"mae\")));\n  (assert ((candidate Some(\"a/b/c.d\")) = Some(\"d\")));\n  (assert ((candidate Some(\"something.netcdf\")) = Some(\"netcdf\")));\n  (assert ((candidate Some(None)) = Some(None)));\n  (assert ((candidate Some(\"myfile.cms\")) = Some(\"mae\")));\n  (assert ((candidate Some(\"a/b/c.pdbx\")) = Some(\"pdbx\")));\n  (assert ((candidate Some(\"a/b/c.pdb\")) = Some(\"pdb\")));\n  (assert ((candidate Some(\"something.pdb\")) = Some(\"pdb\")));\n  (assert ((candidate Some(\"something.nc\")) = Some(\"netcdf\")));\n  (assert ((candidate Some(\"something.pdbx\")) = Some(\"pdbx\")));\n  (assert ((candidate Some(\"something.mae\")) = Some(\"mae\")));\n  (assert ((candidate Some(\"test.prmtop\")) = Some(\"parm7\")));\n  (assert ((candidate Some(\"something.prmtop\")) = Some(\"parm7\")));\n  (assert ((candidate Some(\"something.sdf\")) = Some(\"sdf\")));\n  (assert ((candidate Some(\"test.top\")) = Some(\"top\")));\n  (assert ((candidate Some(\"something.cms\")) = Some(\"mae\")));\n  (assert ((candidate Some(\"test.cif\")) = Some(\"pdbx\")));\n  (assert ((candidate Some(\"a/b/c.cif\")) = Some(\"pdbx\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_421350_extract", "language": "ml", "prompt": "(**Return a tuple (uin, nick) from 'O11111111\tnickname'\n*)\nlet extract (line : string) :  string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_421350_extract.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = extract in\n  (assert ((candidate \"O22222222\tNickname:with:colons\") = (\"22222222\", \"Nickname_with_colons\")));\n  (assert ((candidate \"O11111111\tn/ickn:ame\") = (\"11111111\", \"n_ickn_ame\")));\n  (assert ((candidate \"O11111111\tNickname\") = (\"11111111\", \"Nickname\")));\n  (assert ((candidate \"O11111111\tnickname\") = (\"11111111\", \"nickname\")));\n  (assert ((candidate \"O44444444\tNickname/with:mixed/slashes:and:colons\") = (\"44444444\", \"Nickname_with_mixed_slashes_and_colons\")));\n  (assert ((candidate \"O12345678\tmy_cool_nickname\") = (\"12345678\", \"my_cool_nickname\")));\n  (assert ((candidate \"O12345678\tmy/cool/nickname\") = (\"12345678\", \"my_cool_nickname\")));\n  (assert ((candidate \"O12345678\tmy:cool:nickname\") = (\"12345678\", \"my_cool_nickname\")));\n  (assert ((candidate \"O33333333\tNickname/with/slashes\") = (\"33333333\", \"Nickname_with_slashes\")));\n  (assert ((candidate \"O12345678\tnick:name\") = (\"12345678\", \"nick_name\")));\n  (assert ((candidate \"O11111111\tnickname\") = (\"11111111\", \"nickname\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_42140_get_train_valid_test_split_", "language": "ml", "prompt": "(**Get dataset splits from comma or '/' separated string list.\n*)\nlet get_train_valid_test_split_ (splits_string : string) (size : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_42140_get_train_valid_test_split_.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_train_valid_test_split_ in\n  (assert ((candidate \"0.6,0.2,0.2\" 10) = [0; 6; 8; 10]));\n  (assert ((candidate \"0.6/0.2/0.2\" 10) = [0; 6; 8; 10]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_421692_convert_target_counters", "language": "ml", "prompt": "(**This function converts the FxxxGxxx xml format to the final format. E.g: F29G034 -> 29034,\nF08G069 -> 8069.\n*)\nlet convert_target_counters (x : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_421692_convert_target_counters.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = convert_target_counters in\n  (assert ((candidate \"F08G069\") = \"8069\"));\n  (assert ((candidate \"F08G069\") = \"8069\"));\n  (assert ((candidate \"F29G034\") = \"29034\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_421969_sum_scores", "language": "ml", "prompt": "(**Sums all the scores\n*)\nlet sum_scores (scores : (string, int) list) (query : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_421969_sum_scores.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sum_scores in\n  (assert ((candidate [(\"a\", 1); (\"b\", 2)] \"a b\") = 3));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3)] \"a b c\") = 6));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2)] \"a b\") = 3));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3)] \"c a b\") = 6));\n  (assert ((candidate [] \"a\") = 0));\n  (assert ((candidate [(\"a\", 1)] \"a\") = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_422550_solution", "language": "ml", "prompt": "(**Returns the first ten digits of the sum of the array elements.\n>>> import os\n>>> sum = 0\n>>> array = []\n>>> with open(os.path.dirname(__file__) + \"/num.txt\",\"r\") as f:\n...     for line in f:\n...         array.append(int(line))\n...\n>>> solution(array)\n'5537376230'\n*)\nlet solution (array : int list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_422550_solution.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = solution in\n  (assert ((candidate list range 1 101) = \"5050\"));\n  (assert ((candidate list range 1 1001) = \"500500\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_422804_charencode", "language": "ml", "prompt": "(**String.CharCode\n*)\nlet charencode (string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_422804_charencode.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = charencode in\n  (assert ((candidate \"z\") = \"122\"));\n  (assert ((candidate \"abcde\") = \"97,98,99,100,101\"));\n  (assert ((candidate \"ABC\") = \"65,66,67\"));\n  (assert ((candidate \"aA1\") = \"97,65,49\"));\n  (assert ((candidate \"AaA1\") = \"65,97,65,49\"));\n  (assert ((candidate \"AB\") = \"65,66\"));\n  (assert ((candidate \"A1a\") = \"65,49,97\"));\n  (assert ((candidate \"Aa1\") = \"65,97,49\"));\n  (assert ((candidate \"Aa1A\") = \"65,97,49,65\"));\n  (assert ((candidate \"abcdefghi\") = \"97,98,99,100,101,102,103,104,105\"));\n  (assert ((candidate \"123\") = \"49,50,51\"));\n  (assert ((candidate \"Hello\") = \"72,101,108,108,111\"));\n  (assert ((candidate \"1a\") = \"49,97\"));\n  (assert ((candidate \"Hello, World!\") = \"72,101,108,108,111,44,32,87,111,114,108,100,33\"));\n  (assert ((candidate \"Aa\") = \"65,97\"));\n  (assert ((candidate \"abc\") = \"97,98,99\"));\n  (assert ((candidate \"1aA\") = \"49,97,65\"));\n  (assert ((candidate \"abcdef\") = \"97,98,99,100,101,102\"));\n  (assert ((candidate \"abc123\") = \"97,98,99,49,50,51\"));\n  (assert ((candidate \"a\") = \"97\"));\n  (assert ((candidate \"Z\") = \"90\"));\n  (assert ((candidate \"ab\") = \"97,98\"));\n  (assert ((candidate \"a\") = \"97\"));\n  (assert ((candidate \"A1Aa\") = \"65,49,65,97\"));\n  (assert ((candidate \"1A1a\") = \"49,65,49,97\"));\n  (assert ((candidate \"a1\") = \"97,49\"));\n  (assert ((candidate \"A\") = \"65\"));\n  (assert ((candidate \" \") = \"32\"));\n  (assert ((candidate \"abc,def,ghi\") = \"97,98,99,44,100,101,102,44,103,104,105\"));\n  (assert ((candidate \"a,b,c\") = \"97,44,98,44,99\"));\n  (assert ((candidate \"aA\") = \"97,65\"));\n  (assert ((candidate \"A1aA\") = \"65,49,97,65\"));\n  (assert ((candidate \"1AaA\") = \"49,65,97,65\"));\n  (assert ((candidate \"1Aa\") = \"49,65,97\"));\n  (assert ((candidate \"abcd\") = \"97,98,99,100\"));\n  (assert ((candidate \"A\") = \"65\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_422870_calc_bits", "language": "ml", "prompt": "(**Generates the string of where the bits of that property in a register live \nParameters\n----------\noffset : int,  \nsize : int, \nReturns \n----------\nret_str : str, the string\n*)\nlet calc_bits (offset : int) (size : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_422870_calc_bits.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = calc_bits in\n  (assert ((candidate 16 2) = \"[17:16]\"));\n  (assert ((candidate 15 1) = \"[15]\"));\n  (assert ((candidate 0 16) = \"[15:0]\"));\n  (assert ((candidate 0 32) = \"[31:0]\"));\n  (assert ((candidate 16 1) = \"[16]\"));\n  (assert ((candidate 4 4) = \"[7:4]\"));\n  (assert ((candidate 1 1) = \"[1]\"));\n  (assert ((candidate 0 2) = \"[1:0]\"));\n  (assert ((candidate 0 1) = \"[0]\"));\n  (assert ((candidate 0 4) = \"[3:0]\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_423409_pretty_print", "language": "ml", "prompt": "(**We just print so it looks decent in a terminal\n*)\nlet pretty_print (parsed_file : (string, string) list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_423409_pretty_print.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = pretty_print in\n  (assert ((candidate [(\"origpath\", \"foo/bar\"); (\"artifact\", \"foo/bar.baz\"); (\"uncommented_content\", \"foobarbaz\nfoobarbaz\n\")]) = \"foo/bar (foo/bar.baz):\n    foobarbaz\n    foobarbaz\"));\n  (assert ((candidate [(\"origpath\", \"foo/bar\"); (\"artifact\", \"foo/bar.baz\"); (\"uncommented_content\", \"foobarbaz\n\")]) = \"foo/bar (foo/bar.baz):\n    foobarbaz\"));\n  (assert ((candidate [(\"origpath\", \"foo/bar\"); (\"artifact\", \"foo/bar.baz\"); (\"uncommented_content\", \"foobarbaz\")]) = \"foo/bar (foo/bar.baz):\n    foobarbaz\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_423580__jinja2_filter_datetime", "language": "ml", "prompt": "(**Extract an excert of a post\n*)\nlet _jinja2_filter_datetime (data : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_423580__jinja2_filter_datetime.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _jinja2_filter_datetime in\n  (assert ((candidate \"Hello World! I'm a Pythonista!\") = \"Hello World! I'm a Pythonista!\"));\n  (assert ((candidate \"2019-01-01 10:00:00\") = \"2019-01-01 10:00:00\"));\n  (assert ((candidate \"A long time ago in a galaxy far, far away...\") = \"A long time ago in a galaxy far, far away...\"));\n  (assert ((candidate \"2019-06-13 10:00:00.1234567890123456789\") = \"2019-06-13 10:00:00.1234567890123456789\"));\n  (assert ((candidate \"2019-06-13 10:00:00.123456\") = \"2019-06-13 10:00:00.123456\"));\n  (assert ((candidate \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\") = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\"));\n  (assert ((candidate \"Hello World!\") = \"Hello World!\"));\n  (assert ((candidate \"2019-06-13 10:00:00\") = \"2019-06-13 10:00:00\"));\n  (assert ((candidate \"Hello World! I'm a Pythonista! I'm a Pythonista! I'm a Pythonista! I'm a Pythonista! I'm a Pythonista!\") = \"Hello World! I'm a Pythonista! I'm a Pythonista! I'm a Pythonista! I'm a Pythonista! I'm a Pythonista!\"));\n  (assert ((candidate \"There was a time...\") = \"There was a time...\"));\n  (assert ((candidate \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\") = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\"));\n  (assert ((candidate \"2019-06-13 10:00\") = \"2019-06-13 10:00\"));\n  (assert ((candidate \"Hello World! I'm a Pythonista! I'm a Pythonista!\") = \"Hello World! I'm a Pythonista! I'm a Pythonista!\"));\n  (assert ((candidate \"2012-09-22T16:00:00+02:00\") = \"2012-09-22T16:00:00+02:00\"));\n  (assert ((candidate \"Once upon a time...\") = \"Once upon a time...\"));\n  (assert ((candidate \"2019-06-13 10:00:00.123456789\") = \"2019-06-13 10:00:00.123456789\"));\n  (assert ((candidate \"\") = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_423776_yearmonthplusoffset", "language": "ml", "prompt": "(**calculate new year/month from year/month and offset\n*)\nlet yearmonthplusoffset (year : int) (month : int) (offset : int) :  int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_423776_yearmonthplusoffset.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = yearmonthplusoffset in\n  (assert ((candidate 2019 12 0) = (2019, 12)));\n  (assert ((candidate 2018 1 3) = (2018, 4)));\n  (assert ((candidate 2017 1 1) = (2017, 2)));\n  (assert ((candidate 2000 12 1) = (2001, 1)));\n  (assert ((candidate 2000 1 13) = (2001, 2)));\n  (assert ((candidate 2018 1 13) = (2019, 2)));\n  (assert ((candidate 2018 1 4) = (2018, 5)));\n  (assert ((candidate 2017 1 (~1)) = (2016, 12)));\n  (assert ((candidate 2000 1 (~13)) = (1998, 12)));\n  (assert ((candidate 2018 1 9) = (2018, 10)));\n  (assert ((candidate 2018 1 11) = (2018, 12)));\n  (assert ((candidate 2019 12 13) = (2021, 1)));\n  (assert ((candidate 2000 12 0) = (2000, 12)));\n  (assert ((candidate 2000 12 12) = (2001, 12)));\n  (assert ((candidate 2000 1 10) = (2000, 11)));\n  (assert ((candidate 2018 1 5) = (2018, 6)));\n  (assert ((candidate 2017 1 11) = (2017, 12)));\n  (assert ((candidate 2017 1 12) = (2018, 1)));\n  (assert ((candidate 2017 1 0) = (2017, 1)));\n  (assert ((candidate 2017 1 13) = (2018, 2)));\n  (assert ((candidate 2018 1 1) = (2018, 2)));\n  (assert ((candidate 2018 1 2) = (2018, 3)));\n  (assert ((candidate 2018 1 6) = (2018, 7)));\n  (assert ((candidate 2018 1 0) = (2018, 1)));\n  (assert ((candidate 2019 12 (~11)) = (2019, 1)));\n  (assert ((candidate 2000 1 (~12)) = (1999, 1)));\n  (assert ((candidate 2017 1 (~11)) = (2016, 2)));\n  (assert ((candidate 2018 1 10) = (2018, 11)));\n  (assert ((candidate 2000 1 1) = (2000, 2)));\n  (assert ((candidate 2000 1 12) = (2001, 1)));\n  (assert ((candidate 2018 1 12) = (2019, 1)));\n  (assert ((candidate 2019 12 (~1)) = (2019, 11)));\n  (assert ((candidate 2018 1 8) = (2018, 9)));\n  (assert ((candidate 2000 1 0) = (2000, 1)));\n  (assert ((candidate 2019 12 1) = (2020, 1)));\n  (assert ((candidate 2000 12 13) = (2002, 1)));\n  (assert ((candidate 2018 1 7) = (2018, 8)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_424985_sanitize", "language": "ml", "prompt": "(**Removes backticks (code tag) and linebreaks from a message.\n*)\nlet sanitize (message : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_424985_sanitize.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sanitize in\n  (assert ((candidate \"`hello`\") = \"hello\"));\n  (assert ((candidate \"No backticks\") = \"No backticks\"));\n  (assert ((candidate \"hello\") = \"hello\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"`\") = \"\"));\n  (assert ((candidate \"\n\") = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_425289_compreso", "language": "ml", "prompt": "(**checks whether or not a number is between low and high\n*)\nlet compreso (num : int) (low : int) (high : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_425289_compreso.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = compreso in\n  (assert ((candidate 10 1 5) = false));\n  (assert ((candidate 10 3 10) = true));\n  (assert ((candidate 3 3 6) = true));\n  (assert ((candidate (~5) (~3) 1) = false));\n  (assert ((candidate 10 10 5) = false));\n  (assert ((candidate 3 3 5) = true));\n  (assert ((candidate 5 3 10) = true));\n  (assert ((candidate 1 1 3) = true));\n  (assert ((candidate 3 (~3) 6) = true));\n  (assert ((candidate 3 1 5) = true));\n  (assert ((candidate 10 10 10) = true));\n  (assert ((candidate 10 3 6) = false));\n  (assert ((candidate (~5) (~3) 6) = false));\n  (assert ((candidate 5 10 10) = false));\n  (assert ((candidate 1 3 6) = false));\n  (assert ((candidate 1 1 5) = true));\n  (assert ((candidate 1 2 3) = false));\n  (assert ((candidate 10 3 5) = false));\n  (assert ((candidate 10 (~3) 6) = false));\n  (assert ((candidate 2 1 3) = true));\n  (assert ((candidate 3 1 3) = true));\n  (assert ((candidate 10 (~3) 1) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_425575_milli_2_readadble", "language": "ml", "prompt": "(**Function:  milli_2_readadble\nDescription:  Converts milliseconds into days, hours, minutes and seconds.\n * Returns values with appropriate tags.\nArguments:\n * (input) msecs -> Milliseconds.\n*)\nlet milli_2_readadble (msecs : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_425575_milli_2_readadble.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = milli_2_readadble in\n  (assert ((candidate 86400000) = \"1 days 0 hours 0 minutes 0 seconds\"));\n  (assert ((candidate 0) = \"0 days 0 hours 0 minutes 0 seconds\"));\n  (assert ((candidate 86400001) = \"1 days 0 hours 0 minutes 0 seconds\"));\n  (assert ((candidate 172800000) = \"2 days 0 hours 0 minutes 0 seconds\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_425947_exactly", "language": "ml", "prompt": "(**Match the previous pattern exactly `length` times.\n>>> import superexpressive as se\n>>> se.exactly(4)\n'{4}'\n>>> import superexpressive as se\n>>> se.DIGIT + se.exactly(6)\n'\\\\d{6}'\n*)\nlet exactly (length : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_425947_exactly.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = exactly in\n  (assert ((candidate 8) = \"{8}\"));\n  (assert ((candidate 7) = \"{7}\"));\n  (assert ((candidate 3) = \"{3}\"));\n  (assert ((candidate 110) = \"{110}\"));\n  (assert ((candidate 6) = \"{6}\"));\n  (assert ((candidate 1) = \"{1}\"));\n  (assert ((candidate 42) = \"{42}\"));\n  (assert ((candidate 10) = \"{10}\"));\n  (assert ((candidate 4) = \"{4}\"));\n  (assert ((candidate 1000000) = \"{1000000}\"));\n  (assert ((candidate 6) = \"{6}\"));\n  (assert ((candidate 1000) = \"{1000}\"));\n  (assert ((candidate 10) = \"{10}\"));\n  (assert ((candidate 4) = \"{4}\"));\n  (assert ((candidate 100) = \"{100}\"));\n  (assert ((candidate 100000) = \"{100000}\"));\n  (assert ((candidate 5) = \"{5}\"));\n  (assert ((candidate 9) = \"{9}\"));\n  (assert ((candidate 2) = \"{2}\"));\n  (assert ((candidate 3) = \"{3}\"));\n  (assert ((candidate 51) = \"{51}\"));\n  (assert ((candidate 30) = \"{30}\"));\n  (assert ((candidate 10000) = \"{10000}\"));\n  (assert ((candidate 222) = \"{222}\"));\n  (assert ((candidate 333) = \"{333}\"));\n  (assert ((candidate 1) = \"{1}\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_426317_HSVtoRGB", "language": "ml", "prompt": "(**Convert HSV values to RGB\nAlgorithm is taken from https://www.cs.rit.edu/~ncs/color/t_convert.html\n*)\nlet HSVtoRGB (h : int) (s : int) (v : int) :  int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_426317_HSVtoRGB.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = HSVtoRGB in\n  (assert ((candidate 0 0 0) = (0, 0, 0)));\n  (assert ((candidate 120 0 0) = (0, 0, 0)));\n  (assert ((candidate 0 0 1) = (255, 255, 255)));\n  (assert ((candidate 0 0 0) = (0, 0, 0)));\n  (assert ((candidate 300 1 1) = (255, 0, 255)));\n  (assert ((candidate 60 1 1) = (255, 255, 0)));\n  (assert ((candidate 0 1 1) = (255, 0, 0)));\n  (assert ((candidate 0 0 1) = (255, 255, 255)));\n  (assert ((candidate 240 0 0) = (0, 0, 0)));\n  (assert ((candidate 0 1 1) = (255, 0, 0)));\n  (assert ((candidate 300 1 1) = (255, 0, 255)));\n  (assert ((candidate 120 1 1) = (0, 255, 0)));\n  (assert ((candidate 60 1 1) = (255, 255, 0)));\n  (assert ((candidate 120 1 1) = (0, 255, 0)));\n  (assert ((candidate 240 1 1) = (0, 0, 255)));\n  (assert ((candidate 180 1 1) = (0, 255, 255)));\n  (assert ((candidate 240 1 1) = (0, 0, 255)));\n  (assert ((candidate 180 1 1) = (0, 255, 255)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_426643_remove_keys", "language": "ml", "prompt": "(**Gracefully remove keys from dict.\n*)\nlet remove_keys (dict_ : (string, int) list) (seq : string list) : (string, int) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_426643_remove_keys.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = remove_keys in\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3); (\"d\", 4)] [\"a\"; \"b\"]) = [(\"c\", 3); (\"d\", 4)]));\n  (assert ((candidate dict  []) = dict ));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3); (\"d\", 4)] [\"a\"; \"b\"; \"c\"; \"d\"]) = []));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3); (\"d\", 4); (\"e\", 5); (\"f\", 6)] [\"d\"; \"c\"; \"b\"; \"a\"; \"e\"; \"f\"]) = []));\n  (assert ((candidate dict  [\"a\"; \"b\"]) = dict ));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3); (\"d\", 4)] [\"a\"; \"e\"]) = [(\"b\", 2); (\"c\", 3); (\"d\", 4)]));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3); (\"d\", 4)] [\"d\"; \"c\"]) = [(\"a\", 1); (\"b\", 2)]));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3); (\"d\", 4)] []) = [(\"a\", 1); (\"b\", 2); (\"c\", 3); (\"d\", 4)]));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3); (\"d\", 4)] [\"a\"; \"b\"]) = [(\"c\", 3); (\"d\", 4)]));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3); (\"d\", 4); (\"e\", 5); (\"f\", 6)] [\"a\"; \"b\"; \"c\"; \"d\"; \"e\"; \"f\"]) = []));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3); (\"d\", 4)] [\"a\"; \"b\"; \"c\"]) = [(\"d\", 4)]));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3); (\"d\", 4)] []) = [(\"a\", 1); (\"b\", 2); (\"c\", 3); (\"d\", 4)]));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3); (\"d\", 4)] [\"a\"; \"b\"; \"c\"]) = [(\"d\", 4)]));\n  (assert ((candidate dict  [\"a\"]) = dict ));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_426793_natMult3and5", "language": "ml", "prompt": "(**Find the sum of all the multiples of 3 or 5 below 'limit'\n*)\nlet natMult3and5 (limit : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_426793_natMult3and5.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = natMult3and5 in\n  (assert ((candidate 100) = 2318));\n  (assert ((candidate 10) = 23));\n  (assert ((candidate 10) = 23));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 1000) = 233168));\n  (assert ((candidate 20) = 78));\n  (assert ((candidate 1000) = 233168));\n  (assert ((candidate 1) = 0));\n  (assert ((candidate 20) = 78));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_426978_validate_slice_int", "language": "ml", "prompt": "(**Ensure that the given integer makes sense as a slice entry, and move to\na normalized form.\nParameters\n----------\nthe_int : int\nbound : int\ninclude : bool\nReturns\n-------\nint\n*)\nlet validate_slice_int (the_int : int) (bound : int) (include : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_426978_validate_slice_int.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = validate_slice_int in\n  (assert ((candidate (~5) 10) = 5));\n  (assert ((candidate (~5) 10 true) = 5));\n  (assert ((candidate 9 10) = 9));\n  (assert ((candidate 0 10) = 0));\n  (assert ((candidate 0 100) = 0));\n  (assert ((candidate 1 10 true) = 1));\n  (assert ((candidate 99 100) = 99));\n  (assert ((candidate 1 10) = 1));\n  (assert ((candidate (~50) 100) = 50));\n  (assert ((candidate (~1) 10 true) = 9));\n  (assert ((candidate (~1) 10) = 9));\n  (assert ((candidate (~10) 10) = 0));\n  (assert ((candidate (~1) 100) = 99));\n  (assert ((candidate 5 10 true) = 5));\n  (assert ((candidate 0 10 true) = 0));\n  (assert ((candidate (~10) 10 true) = 0));\n  (assert ((candidate 9 10 true) = 9));\n  (assert ((candidate 50 100) = 50));\n  (assert ((candidate 10 10 false) = 10));\n  (assert ((candidate 2 10) = 2));\n  (assert ((candidate (~100) 100) = 0));\n  (assert ((candidate 5 10) = 5));\n  (assert ((candidate (~3) 10) = 7));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_427698__num_starting_hashes", "language": "ml", "prompt": "(**Return the number of hashes (#) at the beginning of the line.\n*)\nlet _num_starting_hashes (line : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_427698__num_starting_hashes.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _num_starting_hashes in\n  (assert ((candidate \"hello, world! #\") = 0));\n  (assert ((candidate \"# hello, world!\") = 1));\n  (assert ((candidate \"# hello, world! #\") = 1));\n  (assert ((candidate \"\") = 0));\n  (assert ((candidate \"\") = 0));\n  (assert ((candidate \"##### hello, world! ###\") = 5));\n  (assert ((candidate \"hello, world!\") = 0));\n  (assert ((candidate \"one\") = 0));\n  (assert ((candidate \"##### hello, world! #\") = 5));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_428261_file_names", "language": "ml", "prompt": "(**Return the linkname and filename for dotfile based on user input.\n*)\nlet file_names (inp_fname : string) :  string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_428261_file_names.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = file_names in\n  (assert ((candidate \".inp_fname\") = (\".inp_fname\", \"dot.inp_fname.symlink\")));\n  (assert ((candidate ) = (\".a\", \"dot.a.symlink\")));\n  (assert ((candidate ) = (\".a\", \"dot.a.symlink\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_428422_greeting", "language": "ml", "prompt": "(**Build the greeting message\n*)\nlet greeting (name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_428422_greeting.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = greeting in\n  (assert ((candidate \"William\") = \"Hello, William!\"));\n  (assert ((candidate \"Alexander\") = \"Hello, Alexander!\"));\n  (assert ((candidate \"Eric\") = \"Hello, Eric!\"));\n  (assert ((candidate \"Anne\") = \"Hello, Anne!\"));\n  (assert ((candidate \"John\") = \"Hello, John!\"));\n  (assert ((candidate \"Robert\") = \"Hello, Robert!\"));\n  (assert ((candidate \"World\") = \"Hello, World!\"));\n  (assert ((candidate \"Sarah\") = \"Hello, Sarah!\"));\n  (assert ((candidate \"Ryan\") = \"Hello, Ryan!\"));\n  (assert ((candidate \"Michael\") = \"Hello, Michael!\"));\n  (assert ((candidate \"Christopher\") = \"Hello, Christopher!\"));\n  (assert ((candidate \"Bryan\") = \"Hello, Bryan!\"));\n  (assert ((candidate \"Luis\") = \"Hello, Luis!\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_429755_select_supporting_facts", "language": "ml", "prompt": "(**select supporting facts according to the provided thresholds\n:param scored_sfs: a list of (sentence_id, score)\n:param min_thresholds: a list of minimum scores for top ranked supporting facts:\n * [min_score_for_top_ranked, min_score_for_second_ranked, min_score_for_others]\n:return: a list of sentence ids predicted as supporting facts\n*)\nlet select_supporting_facts (scored_sfs :  int * float list) (min_thresholds : float list) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_429755_select_supporting_facts.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = select_supporting_facts in\n  (assert ((candidate [(0, 0.4); (1, 0.5); (2, 0.6)] [0.6; 0.6]) = [2]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_431077_check_for_take", "language": "ml", "prompt": "(**Helper Function that checks to see if clapperboard elements\nfollows set of rules to be identified as a \"take\" element\nParameters\n----------\nstring: String\n * (The string thay will be checked\nReturns\n-------\nBoolean\n * True if object follows set of rules\n * False if not.\n*)\nlet check_for_take (string : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_431077_check_for_take.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = check_for_take in\n  (assert ((candidate \"23\") = true));\n  (assert ((candidate \"25\") = true));\n  (assert ((candidate \"1234567\") = false));\n  (assert ((candidate \"1234\") = false));\n  (assert ((candidate \"18\") = true));\n  (assert ((candidate \"123\") = false));\n  (assert ((candidate \"foo\") = false));\n  (assert ((candidate \"27\") = true));\n  (assert ((candidate \"12345678\") = false));\n  (assert ((candidate \"12345\") = false));\n  (assert ((candidate \"\") = false));\n  (assert ((candidate \"21\") = true));\n  (assert ((candidate \"28\") = true));\n  (assert ((candidate \"172\") = false));\n  (assert ((candidate \"123456\") = false));\n  (assert ((candidate \"1234567890\") = false));\n  (assert ((candidate \"a\") = false));\n  (assert ((candidate \"24\") = true));\n  (assert ((candidate \"22\") = true));\n  (assert ((candidate \"29\") = true));\n  (assert ((candidate \"123456789\") = false));\n  (assert ((candidate \"15\") = true));\n  (assert ((candidate \"16\") = true));\n  (assert ((candidate \"20\") = true));\n  (assert ((candidate \"19\") = true));\n  (assert ((candidate \"17\") = true));\n  (assert ((candidate \"11\") = true));\n  (assert ((candidate \"30\") = false));\n  (assert ((candidate \"26\") = true));\n  (assert ((candidate \"100\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_431116_replace", "language": "ml", "prompt": "(**If pattern in the template replaces it with subst.\nReturns str object template with replaced patterns.\n*)\nlet replace (template : string) (pattern : string) (subst : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_431116_replace.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = replace in\n  (assert ((candidate \"The quick brown fox jumps over the lazy dog\" \"The\" \"The\") = \"The quick brown fox jumps over the lazy dog\"));\n  (assert ((candidate \"a test\" \"test\" \"result\") = \"a result\"));\n  (assert ((candidate \"The quick brown fox jumps over the lazy dog\" \"fox\" \"fox\") = \"The quick brown fox jumps over the lazy dog\"));\n  (assert ((candidate \"The quick brown fox jumps over the lazy dog\" \"lazy\" \"fox\") = \"The quick brown fox jumps over the fox dog\"));\n  (assert ((candidate candidate \"X\" \"Y\" \"Z\" \"Y\" \"X\") = \"X\"));\n  (assert ((candidate \"The quick brown fox jumps over the lazy dog\" \"dog\" \"cat\") = \"The quick brown fox jumps over the lazy cat\"));\n  (assert ((candidate \"The quick brown fox jumps over the lazy dog\" \"dog\" \"fox\") = \"The quick brown fox jumps over the lazy fox\"));\n  (assert ((candidate \"The quick brown fox jumps over the lazy dog\" \"fox\" \"cat\") = \"The quick brown cat jumps over the lazy dog\"));\n  (assert ((candidate candidate \"X\" \"Y\" \"Z\" \"Y\" \"Z\") = \"X\"));\n  (assert ((candidate \"The quick brown fox jumps over the lazy dog\" \"The\" \"a\") = \"a quick brown fox jumps over the lazy dog\"));\n  (assert ((candidate \"The quick brown fox jumps over the lazy dog\" \"The\" \"lazy\") = \"lazy quick brown fox jumps over the lazy dog\"));\n  (assert ((candidate candidate \"X\" \"X\" \"X\" \"X\" \"Z\") = \"Z\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_432490_splitStringIntoChunks", "language": "ml", "prompt": "(**Split string into chunks of defined size\n*)\nlet splitStringIntoChunks (string : string) (length : int) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_432490_splitStringIntoChunks.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = splitStringIntoChunks in\n  (assert ((candidate \"abcdefghijklmn\" 3) = [\"abc\"; \"def\"; \"ghi\"; \"jkl\"; \"mn\"]));\n  (assert ((candidate \"abcdef\") = [\"abcdef\"]));\n  (assert ((candidate \"abcdefghij\") = [\"abcdefghij\"]));\n  (assert ((candidate \"abcdefg\" 3) = [\"abc\"; \"def\"; \"g\"]));\n  (assert ((candidate \"This is a test\" 14) = [\"This is a test\"]));\n  (assert ((candidate \"abcdefghij\" 5) = [\"abcde\"; \"fghij\"]));\n  (assert ((candidate \"ab\" 1) = [\"a\"; \"b\"]));\n  (assert ((candidate \"hello world!\") = [\"hello world!\"]));\n  (assert ((candidate \"a\" 1) = [\"a\"]));\n  (assert ((candidate \"This is a test\") = [\"This is a test\"]));\n  (assert ((candidate \"\" 1) = [\"\"]));\n  (assert ((candidate \"abcdef\" 2) = [\"ab\"; \"cd\"; \"ef\"]));\n  (assert ((candidate \"abcdef\" 3) = [\"abc\"; \"def\"]));\n  (assert ((candidate \"a\" 2) = [\"a\"]));\n  (assert ((candidate \"abc\") = [\"abc\"]));\n  (assert ((candidate \"ab\" 2) = [\"ab\"]));\n  (assert ((candidate \"abcdef\" 2) = [\"ab\"; \"cd\"; \"ef\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_432816_get_base_out_of_iri", "language": "ml", "prompt": "(**Give an iri, returns an the ontology base name\nArgs:\n * iri\nReturns:\n * str\n*)\nlet get_base_out_of_iri (iri : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_432816_get_base_out_of_iri.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_base_out_of_iri in\n  (assert ((candidate \"http://example.com#\") = \"http://example.com\"));\n  (assert ((candidate \"http://example.com/ontology#\") = \"http://example.com/ontology\"));\n  (assert ((candidate \"http://webprotege.stanford.edu/RDwpQ8vbi7HaApq8VoqJUXH#\") = \"http://webprotege.stanford.edu/RDwpQ8vbi7HaApq8VoqJUXH\"));\n  (assert ((candidate \"http://webprotege.stanford.edu/RDwpQ8vbi7HaApq8VoqJUXH#Human\") = \"http://webprotege.stanford.edu/RDwpQ8vbi7HaApq8VoqJUXH\"));\n  (assert ((candidate \"http://example.com/ontology/term\") = \"http://example.com/ontology\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_433197_binaryalert_yara_match", "language": "ml", "prompt": "(**author:       Austin Byers (Airbnb CSIRT)\ndescription:  BinaryAlert found a binary matching a YARA rule\nreference:    https://binaryalert.io\n*)\nlet binaryalert_yara_match (rec : (string, int) list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_433197_binaryalert_yara_match.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = binaryalert_yara_match in\n  (assert ((candidate [(\"NumMatchedRules\", 1)]) = true));\n  (assert ((candidate [(\"NumMatchedRules\", 0)]) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_433253__fk", "language": "ml", "prompt": "(**Construct a dict key for a feature instance\n*)\nlet _fk (feature_name : string) (channel : string) (target : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_433253__fk.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _fk in\n  (assert ((candidate \"A\" \"c1\" \"t1\") = \"A::c1::t1\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_433350_addslashes", "language": "ml", "prompt": "(**Adds slashes before quotes. Useful for escaping strings in CSV, for\nexample. Less useful for escaping JavaScript; use the ``escapejs``\nfilter instead.\n*)\nlet addslashes (value : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_433350_addslashes.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = addslashes in\n  (assert ((candidate \"and \" quotes\") = \"and \\\" quotes\"));\n  (assert ((candidate \"\"123\") = \"\\\"123\"));\n  (assert ((candidate \"foo 'bar'\") = \"foo \\'bar\\'\"));\n  (assert ((candidate \"a\"b\") = \"a\\\"b\"));\n  (assert ((candidate \"\\\\\") = \"\\\\\\\\\"));\n  (assert ((candidate \"\\r\\n\") = \"\\\\r\\\\n\"));\n  (assert ((candidate \"slash /\") = \"slash /\"));\n  (assert ((candidate \"1\\2\\3\") = \"1\\\\2\\\\3\"));\n  (assert ((candidate \"\\\") = \"\\\\\"));\n  (assert ((candidate \"'\") = \"\\'\"));\n  (assert ((candidate \"\"foo\"\") = \"\\\"foo\\\"\"));\n  (assert ((candidate \"This is a \"test\"\") = \"This is a \\\"test\\\"\"));\n  (assert ((candidate \"\\\\\") = \"\\\\\\\\\"));\n  (assert ((candidate \"\"\") = \"\\\"\"));\n  (assert ((candidate \"foo\\tbar\\n\\baz\\n\") = \"foo\\\\tbar\\\\n\\\\baz\\\\n\"));\n  (assert ((candidate \"123\"\") = \"123\\\"\"));\n  (assert ((candidate \"foo \"bar\"\") = \"foo \\\"bar\\\"\"));\n  (assert ((candidate \"this is a \\ test\") = \"this is a \\\\ test\"));\n  (assert ((candidate \"test\\ntest\") = \"test\\\\ntest\"));\n  (assert ((candidate \"abc\"def\") = \"abc\\\"def\"));\n  (assert ((candidate \"This is a \"\"test\"\"\") = \"This is a \\\"\\\"test\\\"\\\"\"));\n  (assert ((candidate \"this is a \"test\"\") = \"this is a \\\"test\\\"\"));\n  (assert ((candidate \"\\\"\") = \"\\\\\\\"\"));\n  (assert ((candidate \"123\") = \"123\"));\n  (assert ((candidate \"this is a test\") = \"this is a test\"));\n  (assert ((candidate \"I'm a fan of yours, Johnny.\") = \"I\\'m a fan of yours, Johnny.\"));\n  (assert ((candidate \"this is \"a test\"\") = \"this is \\\"a test\\\"\"));\n  (assert ((candidate \"\\'\"\") = \"\\\\\\'\\\"\"));\n  (assert ((candidate \"this is 'a test'\") = \"this is \\'a test\\'\"));\n  (assert ((candidate \"\\t\") = \"\\\\t\"));\n  (assert ((candidate \"'foo'\") = \"\\'foo\\'\"));\n  (assert ((candidate \"\\'\") = \"\\\\\\'\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_433455_this_exist_not_null", "language": "ml", "prompt": "(**Check if parameter exists or not\n*)\nlet this_exist_not_null (param : string option) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_433455_this_exist_not_null.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = this_exist_not_null in\n  (assert ((candidate Some(\"not empty\")) = true));\n  (assert ((candidate Some(None)) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_433810_megagcd", "language": "ml", "prompt": "(**needs in diophantic function\n*)\nlet megagcd (a : int) (b : int) :  int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_433810_megagcd.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = megagcd in\n  (assert ((candidate 1 1) = (1, 0, 1)));\n  (assert ((candidate 1234567890123456789 1234567890123456789) = (1234567890123456789, 0, 1)));\n  (assert ((candidate 2 1) = (1, 0, 1)));\n  (assert ((candidate 2 4) = (2, 1, 0)));\n  (assert ((candidate 40 120) = (40, 1, 0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_433930_build_select", "language": "ml", "prompt": "(**Build a select request.\nParameters\n----------\ntable : str\n * Table where query will be directed.\nto_set: iterable\n * The list of columns to select.\nwhere: iterable\n * The list of conditions to constrain the query.\nReturns\n-------\nstr\n * Built query string.\n*)\nlet build_select (table : string) (to_select : string list) (where : string list option) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_433930_build_select.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = build_select in\n  (assert ((candidate \"person\" [\"first_name\"; \"last_name\"]) = \"SELECT first_name, last_name FROM \"person\"\"));\n  (assert ((candidate \"User\" [\"User.id\"; \"User.name\"]) = \"SELECT User.id, User.name FROM \"User\"\"));\n  (assert ((candidate \"artists\" [\"name\"] Some([\"genre\"; \"name\"])) = \"SELECT name FROM \"artists\" WHERE genre = :genre AND name = :name\"));\n  (assert ((candidate \"person\" [\"first_name\"; \"last_name\"] Some([\"first_name\"; \"last_name\"])) = \"SELECT first_name, last_name FROM \"person\" WHERE first_name = :first_name AND last_name = :last_name\"));\n  (assert ((candidate \"artists\" [\"name\"] Some(None)) = \"SELECT name FROM \"artists\"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_434357_sample_width_to_string", "language": "ml", "prompt": "(**Convert sample width (bytes) to ALSA format string.\n*)\nlet sample_width_to_string (sample_width : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_434357_sample_width_to_string.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sample_width_to_string in\n  (assert ((candidate 2) = \"s16\"));\n  (assert ((candidate 1) = \"s8\"));\n  (assert ((candidate 4) = \"s32\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_434952_register_dictionary", "language": "ml", "prompt": "(**creates the dictionary that can be used for registration\n*)\nlet register_dictionary (nickname : string) (email : string) (password : string) (repeat_password : string) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_434952_register_dictionary.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = register_dictionary in\n  (assert ((candidate \"a\" \"b\" \"c\" \"d\") = [(\"nickname\", \"a\"); (\"email\", \"b\"); (\"password\", \"c\"); (\"repeat_password\", \"d\")]));\n  (assert ((candidate \"A\" \"<EMAIL>\" \"password\" \"password\") = [(\"nickname\", \"A\"); (\"email\", \"<EMAIL>\"); (\"password\", \"password\"); (\"repeat_password\", \"password\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_435735_get_wsgi_header", "language": "ml", "prompt": "(**Returns a WSGI compliant HTTP header.\nSee https://www.python.org/dev/peps/pep-3333/#environ-variables for\ninformation from the spec.\n*)\nlet get_wsgi_header (header : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_435735_get_wsgi_header.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_wsgi_header in\n  (assert ((candidate \"accept-charset\") = \"HTTP_ACCEPT_CHARSET\"));\n  (assert ((candidate \"dnt\") = \"HTTP_DNT\"));\n  (assert ((candidate \"content-type\") = \"HTTP_CONTENT_TYPE\"));\n  (assert ((candidate \"CoNtEnT-tyPe\") = \"HTTP_CONTENT_TYPE\"));\n  (assert ((candidate \"content-type\") = \"HTTP_CONTENT_TYPE\"));\n  (assert ((candidate \"content-md5\") = \"HTTP_CONTENT_MD5\"));\n  (assert ((candidate \"expect\") = \"HTTP_EXPECT\"));\n  (assert ((candidate \"user-agent\") = \"HTTP_USER_AGENT\"));\n  (assert ((candidate \"authorization\") = \"HTTP_AUTHORIZATION\"));\n  (assert ((candidate \"Host\") = \"HTTP_HOST\"));\n  (assert ((candidate \"if-none-match\") = \"HTTP_IF_NONE_MATCH\"));\n  (assert ((candidate \"content-TYPE\") = \"HTTP_CONTENT_TYPE\"));\n  (assert ((candidate \"content-length\") = \"HTTP_CONTENT_LENGTH\"));\n  (assert ((candidate \"CONTENT-type\") = \"HTTP_CONTENT_TYPE\"));\n  (assert ((candidate \"X-Some-Header-Here\") = \"HTTP_X_SOME_HEADER_HERE\"));\n  (assert ((candidate \"content-type\") = candidate \"CONTENT-TYPE\"));\n  (assert ((candidate \"X-Some-Header\") = \"HTTP_X_SOME_HEADER\"));\n  (assert ((candidate \"cookie\") = \"HTTP_COOKIE\"));\n  (assert ((candidate \"Content-TYPE\") = \"HTTP_CONTENT_TYPE\"));\n  (assert ((candidate \"x-forwarded-proto\") = \"HTTP_X_FORWARDED_PROTO\"));\n  (assert ((candidate \"upgrade-insecure-requests\") = \"HTTP_UPGRADE_INSECURE_REQUESTS\"));\n  (assert ((candidate \"accept-encoding\") = \"HTTP_ACCEPT_ENCODING\"));\n  (assert ((candidate \"accept-language\") = \"HTTP_ACCEPT_LANGUAGE\"));\n  (assert ((candidate \"host\") = \"HTTP_HOST\"));\n  (assert ((candidate \"connection\") = \"HTTP_CONNECTION\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_436371__tbl_str_width", "language": "ml", "prompt": "(**Returns the width-argument for an html table cell using the width from\nthe list of widths.\nReturns width=\"[some number]\" or the empty-string if no width is\nspecified for this num\n*)\nlet _tbl_str_width (num : int) (widths : int list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_436371__tbl_str_width.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _tbl_str_width in\n  (assert ((candidate 3 [20; 30]) = \"\"));\n  (assert ((candidate 0 [10; 20]) = \" width=\"10\"\"));\n  (assert ((candidate 0 []) = \"\"));\n  (assert ((candidate 2 []) = \"\"));\n  (assert ((candidate 3 [20; 30; 40]) = \"\"));\n  (assert ((candidate 0 []) = \"\"));\n  (assert ((candidate 1000 []) = \"\"));\n  (assert ((candidate 4 [1; 2; 3]) = \"\"));\n  (assert ((candidate 2 [10; 20]) = \"\"));\n  (assert ((candidate 3 [20]) = \"\"));\n  (assert ((candidate 2 [10]) = \"\"));\n  (assert ((candidate 0 [10]) = \" width=\"10\"\"));\n  (assert ((candidate 1 [10; 20]) = \" width=\"20\"\"));\n  (assert ((candidate 1 []) = \"\"));\n  (assert ((candidate 1 [10]) = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_436426_parse_slots", "language": "ml", "prompt": "(**Parse the list of slots.\nCleans up spaces between items.\nParameters\n----------\ncontent: :class:`str`\n * A string containing comma separated values.\nReturns\n-------\n:class:`str`:\n * The slots string.\n*)\nlet parse_slots (content : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_436426_parse_slots.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_slots in\n  (assert ((candidate \"Slot1,Slot2,Slot3,Slot4,Slot5,Slot6,Slot7,Slot8\") = \"Slot1,Slot2,Slot3,Slot4,Slot5,Slot6,Slot7,Slot8\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"Slot1,Slot2\") = \"Slot1,Slot2\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_436791___equivalent_lists", "language": "ml", "prompt": "(**Return True if list1 and list2 contain the same items.\n*)\nlet __equivalent_lists (list1 : int list) (list2 : int list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_436791___equivalent_lists.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = __equivalent_lists in\n  (assert ((candidate list [1; 2; 3; 4] list [2; 4; 3; 1]) = true));\n  (assert ((candidate list [1; 2; 3; 4] list [4; 3; 2; 1]) = true));\n  (assert ((candidate list [1] list ) = false));\n  (assert ((candidate list [1; 2; 3] list [1; 3; 4]) = false));\n  (assert ((candidate list [1; 2] list [2; 1]) = true));\n  (assert ((candidate list [1; 2; 3; 4] list [2; 4; 1; 3]) = true));\n  (assert ((candidate list [1; 2; 3; 4] list [4; 3; 1; 2]) = true));\n  (assert ((candidate list [1; 2; 3] list [2; 1; 3]) = true));\n  (assert ((candidate list [1] list [1]) = true));\n  (assert ((candidate list [1; 2] list [1; 3]) = false));\n  (assert ((candidate list [1; 2; 3] list [3; 1; 2]) = true));\n  (assert ((candidate list  list ) = true));\n  (assert ((candidate list [1; 2; 3; 4] list [3; 4; 1; 2]) = true));\n  (assert ((candidate list [1; 2; 3] list [1; 3; 2]) = true));\n  (assert ((candidate list [1; 2; 3; 4] list [3; 4; 2; 1]) = true));\n  (assert ((candidate list [1] list [2]) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_43689_detect_graphql", "language": "ml", "prompt": "(**\n*)\nlet detect_graphql (payload : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_43689_detect_graphql.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = detect_graphql in\n  (assert ((candidate \"this is some text\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_437285_valid", "language": "ml", "prompt": "(**Check if the coordinates are in bounds.\n:param x:\n:param y:\n:param n:\n:param m:\n:return:\n*)\nlet valid (x : int) (y : int) (n : int) (m : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_437285_valid.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = valid in\n  (assert ((candidate 0 0 3 2) = true));\n  (assert ((candidate 1 3 3 3) = false));\n  (assert ((candidate 2 3 3 3) = false));\n  (assert ((candidate 2 2 3 3) = true));\n  (assert ((candidate 0 3 3 3) = false));\n  (assert ((candidate (~1) 1 3 3) = false));\n  (assert ((candidate 0 (~1) 3 3) = false));\n  (assert ((candidate (~1) (~1) 3 2) = false));\n  (assert ((candidate 3 0 3 2) = false));\n  (assert ((candidate 4 4 3 3) = false));\n  (assert ((candidate 2 0 3 2) = true));\n  (assert ((candidate 2 1 3 3) = true));\n  (assert ((candidate 2 1 3 2) = true));\n  (assert ((candidate (~1) 0 3 3) = false));\n  (assert ((candidate 3 1 3 3) = false));\n  (assert ((candidate 3 0 3 3) = false));\n  (assert ((candidate 1 1 3 3) = true));\n  (assert ((candidate 3 1 3 2) = false));\n  (assert ((candidate 4 3 3 2) = false));\n  (assert ((candidate 1 1 3 2) = true));\n  (assert ((candidate 1 (~1) 3 3) = false));\n  (assert ((candidate 0 0 3 3) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_437295_get_max_key", "language": "ml", "prompt": "(**Return the key from the dict with the max value.\n*)\nlet get_max_key (d : (string, int) list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_437295_get_max_key.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_max_key in\n  (assert ((candidate [(\"b\", 2)]) = \"b\"));\n  (assert ((candidate [(\"a\", 1)]) = \"a\"));\n  (assert ((candidate [(\"c\", 3)]) = \"c\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_43748__is_summary", "language": "ml", "prompt": "(**Checks if the line is the summary line 'Found X errors in Y files (checked Z source files)'\n*)\nlet _is_summary (l : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_43748__is_summary.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _is_summary in\n  (assert ((candidate \"Found 3 errors in 2 files (checked 11 source files)\nother line\") = false));\n  (assert ((candidate \"Found 3 errors in 2 files (checked 11 source files)\n\n\") = false));\n  (assert ((candidate \"Found 0 errors in 0 files (checked 24 source files)\n\") = true));\n  (assert ((candidate \"Found 0 errors in 1 files (checked 5 source files)\n\") = true));\n  (assert ((candidate \"Found 3 errors in 2 files (checked 11 source files)\n\") = true));\n  (assert ((candidate \"Found 1 errors in 1 files (checked 1 source files)\n\") = true));\n  (assert ((candidate \"Found 10 errors in 100 files (checked 1000 source files)\n\") = true));\n  (assert ((candidate \"Found 1 error in 1 files (checked 10 source files)\n\") = true));\n  (assert ((candidate \"Found 3 errors in 2 files (checked 11 source files\n\") = false));\n  (assert ((candidate \"Found 1 errors in 1 files (checked 1 source files) \n\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_437626_progessbar", "language": "ml", "prompt": "(**Builds progressbar\nArgs:\n * new: current progress\n * tot: total length of the download\nReturns:\n * progressbar as a string of length 20\n*)\nlet progessbar (new : int) (tot : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_437626_progessbar.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = progessbar in\n  (assert ((candidate 100 100) = \"[====================] 100.0 %\r\"));\n  (assert ((candidate 0 100) = \"[--------------------] 0.0 %\r\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_437635_get_str_bytes_length", "language": "ml", "prompt": "(**- source: https://stackoverflow.com/a/30686735/8445442\n*)\nlet get_str_bytes_length (value : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_437635_get_str_bytes_length.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_str_bytes_length in\n  (assert ((candidate \"test\") = 4));\n  (assert ((candidate \"\") = 0));\n  (assert ((candidate \"1234567890\") = 10));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_437844_is_identity_matrix", "language": "ml", "prompt": "(**Returns True if the input matrix is an identity matrix, False otherwise.\n*)\nlet is_identity_matrix (L : int list list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_437844_is_identity_matrix.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_identity_matrix in\n  (assert ((candidate [[1; 0; 0; 0]; [0; 1; 0; 0]; [0; 0; 1; 0]; [0; 0; 0; 1]]) = true));\n  (assert ((candidate [[1; 1; 1]; [0; 1; 0]; [0; 0; 1]]) = false));\n  (assert ((candidate [[0; 1; 2; 3]; [4; 5; 6; 7]; [8; 9; 10; 11]; [12; 13; 14; 15]]) = false));\n  (assert ((candidate [[1; 0; 0; 0]; [0; 1; 1; 0]; [0; 0; 1; 0]; [0; 0; 0; 1]]) = false));\n  (assert ((candidate [[1; 0; 0; 0]; [0; 1; 0; 0]; [0; 0; 1; 0]; [0; 0; 0; 1]]) = true));\n  (assert ((candidate [[1; 0; 0; 0]; [0; 1; 0; 0]; [0; 0; 0; 0]; [0; 0; 0; 1]]) = false));\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]; [7; 8; 9]]) = false));\n  (assert ((candidate [[1; 0; 0; 0]; [0; 1; 0; 0]; [0; 0; 0; 1]; [0; 0; 1; 0]]) = false));\n  (assert ((candidate [[1; 0; 0]; [0; 1; 0]; [0; 0; 1]]) = true));\n  (assert ((candidate [[1; 0; 0; 0]; [0; 0; 0; 0]; [0; 0; 1; 0]; [0; 0; 0; 1]]) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_438500_pax_to_human_time", "language": "ml", "prompt": "(**Converts a pax time to a human-readable representation\n*)\nlet pax_to_human_time (num : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_438500_pax_to_human_time.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = pax_to_human_time in\n  (assert ((candidate 1000000000000000000000) = \"1.000 T\"));\n  (assert ((candidate 1100000000) = \"1.100 s\"));\n  (assert ((candidate 1000000000000) = \"1.000 ks\"));\n  (assert ((candidate 999) = \"999.000 ns\"));\n  (assert ((candidate 1000) = \"1.000 us\"));\n  (assert ((candidate 999999) = \"999.999 us\"));\n  (assert ((candidate 10000) = \"10.000 us\"));\n  (assert ((candidate 123) = \"123.000 ns\"));\n  (assert ((candidate 1000000000) = \"1.000 s\"));\n  (assert ((candidate 100) = \"100.000 ns\"));\n  (assert ((candidate 12345) = \"12.345 us\"));\n  (assert ((candidate 1) = \"1.000 ns\"));\n  (assert ((candidate 12345) = \"12.345 us\"));\n  (assert ((candidate 10) = \"10.000 ns\"));\n  (assert ((candidate 1000000) = \"1.000 ms\"));\n  (assert ((candidate 1000000000000000000) = \"1.000 G\"));\n  (assert ((candidate 1000000000000000) = \"1.000 Ms\"));\n  (assert ((candidate 0) = \"0.000 ns\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_43932_area", "language": "ml", "prompt": "(**Area of a polygone\n:param p: list of the points taken in any orientation,\n * p[0] can differ from p[-1]\n:returns: area\n:complexity: linear\n*)\nlet area (p : int list list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_43932_area.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = area in\n  (assert ((candidate [[0; 0]; [2; 0]; [0; 2]; [0; 0]]) = 2));\n  (assert ((candidate [[0; 0]; [2; 0]; [2; 2]; [0; 2]]) = 4));\n  (assert ((candidate [[0; 0]; [2; 0]; [2; 1]; [0; 1]]) = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_439474_dms_to_dmm", "language": "ml", "prompt": "(**Converts degrees, minutes and decimal seconds to degrees and decimal minutes.\nExample: (41, 24, 12.2) -> (41, 24.2033)\n:param int d: degrees\n:param int m: minutes\n:param float s: decimal seconds\n:rtype: str\n*)\nlet dms_to_dmm (d : int) (m : int) (s : int) :  int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_439474_dms_to_dmm.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = dms_to_dmm in\n  (assert ((candidate (~10) 0 0) = ((~10), 0)));\n  (assert ((candidate 41 24 0) = (41, 24)));\n  (assert ((candidate 10 0 0) = (10, 0)));\n  (assert ((candidate 0 0 0) = (0, 0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_439518_fnSeconds_To_Hours", "language": "ml", "prompt": "(**Convert from seconds to hours, minutes and seconds.\nDate: 16 October 2016\noriginally in AstroFunctions.py\n*)\nlet fnSeconds_To_Hours (time_period : int) :  int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_439518_fnSeconds_To_Hours.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = fnSeconds_To_Hours in\n  (assert ((candidate 3600) = (1, 0, 0)));\n  (assert ((candidate 60) = (0, 1, 0)));\n  (assert ((candidate 0) = (0, 0, 0)));\n  (assert ((candidate 30) = (0, 0, 30)));\n  (assert ((candidate 90) = (0, 1, 30)));\n  (assert ((candidate 1) = (0, 0, 1)));\n  (assert ((candidate 0) = (0, 0, 0)));\n  (assert ((candidate 3600) = (1, 0, 0)));\n  (assert ((candidate 3723) = (1, 2, 3)));\n  (assert ((candidate 86400) = (24, 0, 0)));\n  (assert ((candidate 120) = (0, 2, 0)));\n  (assert ((candidate 1) = (0, 0, 1)));\n  (assert ((candidate 60) = (0, 1, 0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_439784_containsDuplicate", "language": "ml", "prompt": "(**:type nums: List[int]\n:rtype: bool\n*)\nlet containsDuplicate (nums : int list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_439784_containsDuplicate.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = containsDuplicate in\n  (assert ((candidate list [1; 2; 3]) = false));\n  (assert ((candidate [1; 2]) = false));\n  (assert ((candidate []) = false));\n  (assert ((candidate list [1; 2]) = false));\n  (assert ((candidate list ) = false));\n  (assert ((candidate list [1; 2; 3; 4]) = false));\n  (assert ((candidate [1]) = false));\n  (assert ((candidate [1; 2; 3]) = false));\n  (assert ((candidate list [1; 1; 1; 3; 3; 4; 3; 2; 4; 2]) = true));\n  (assert ((candidate list [1]) = false));\n  (assert ((candidate [1; 2; 2]) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_440003_map_range", "language": "ml", "prompt": "(**Map a value in one range to another.\n*)\nlet map_range (value : int) (from_lower : int) (from_upper : int) (to_lower : int) (to_upper : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_440003_map_range.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = map_range in\n  (assert ((candidate 5 1 10 10 10) = 10));\n  (assert ((candidate 5 1 10 1 1) = 1));\n  (assert ((candidate 7 1 10 1 10) = 7));\n  (assert ((candidate 10 1 10 0 1) = 1));\n  (assert ((candidate 6 0 10 100 200) = 160));\n  (assert ((candidate 5 1 10 5 5) = 5));\n  (assert ((candidate 50 0 100 0 200) = 100));\n  (assert ((candidate 0 0 10 0 100) = 0));\n  (assert ((candidate 15 0 10 100 200) = 200));\n  (assert ((candidate 7 0 10 100 200) = 170));\n  (assert ((candidate 10 0 10 100 0) = 0));\n  (assert ((candidate 5 0 10 0 100) = 50));\n  (assert ((candidate 1 1 10 1 10) = 1));\n  (assert ((candidate 13 0 10 100 200) = 200));\n  (assert ((candidate 16 0 10 100 200) = 200));\n  (assert ((candidate 10 0 10 100 200) = 200));\n  (assert ((candidate 0 0 100 0 100) = 0));\n  (assert ((candidate 11 0 10 100 200) = 200));\n  (assert ((candidate 50 0 100 0 100) = 50));\n  (assert ((candidate 10 1 10 1 10) = 10));\n  (assert ((candidate 0 1 10 1 10) = 1));\n  (assert ((candidate 10 1 10 10 20) = 20));\n  (assert ((candidate 5 0 10 100 200) = 150));\n  (assert ((candidate 6 1 10 1 10) = 6));\n  (assert ((candidate 2 10 1 100 10) = 10));\n  (assert ((candidate 12 0 10 100 200) = 200));\n  (assert ((candidate 9 1 10 1 10) = 9));\n  (assert ((candidate (~5) 0 10 0 100) = 0));\n  (assert ((candidate 100 0 100 0 100) = 100));\n  (assert ((candidate 14 0 10 100 200) = 200));\n  (assert ((candidate 0 0 100 (~100) 100) = (~100)));\n  (assert ((candidate 5 1 10 1 10) = 5));\n  (assert ((candidate 10 0 10 0 100) = 100));\n  (assert ((candidate 4 1 10 1 10) = 4));\n  (assert ((candidate 10 10 1 1 100) = 1));\n  (assert ((candidate 100 0 100 0 200) = 200));\n  (assert ((candidate 10 1 10 0 100) = 100));\n  (assert ((candidate 2 1 10 1 10) = 2));\n  (assert ((candidate 0 0 100 0 200) = 0));\n  (assert ((candidate 100 0 100 (~200) (~100)) = (~100)));\n  (assert ((candidate 4 0 10 100 200) = 140));\n  (assert ((candidate 3 1 10 1 10) = 3));\n  (assert ((candidate 9 0 10 100 200) = 190));\n  (assert ((candidate 8 1 10 1 10) = 8));\n  (assert ((candidate 50 0 100 100 200) = 150));\n  (assert ((candidate 8 0 10 100 200) = 180));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_44003_vmul", "language": "ml", "prompt": "(**Return element wise multiplication\n*)\nlet vmul (vec1 : int list) (vec2 : int list) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_44003_vmul.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = vmul in\n  (assert ((candidate [1; (~2); 3] [1; 2; 3]) = [1; (~4); 9]));\n  (assert ((candidate [1; 2; 3] [1; 2; 3]) = [1; 4; 9]));\n  (assert ((candidate [1; 2; (~3)] [1; 2; 3]) = [1; 4; (~9)]));\n  (assert ((candidate [1000; 2000; 3000] [1; 2; 3]) = [1000; 4000; 9000]));\n  (assert ((candidate [(~1); 2; 3] [1; (~2); 3]) = [(~1); (~4); 9]));\n  (assert ((candidate [1; 2; 3] [10; 20; 30]) = [10; 40; 90]));\n  (assert ((candidate [2] [2]) = [4]));\n  (assert ((candidate [3; 1; 5] [1; 2; 0]) = [3; 2; 0]));\n  (assert ((candidate [(~3); 0; 1] [1; (~1); 3]) = [(~3); 0; 3]));\n  (assert ((candidate [1; 2; 3] [1; 2; 3]) = [1; 4; 9]));\n  (assert ((candidate [1; 2; 3] [(~1); 2; (~3)]) = [(~1); 4; (~9)]));\n  (assert ((candidate [1; 2; 3] [100; 200; 300]) = [100; 400; 900]));\n  (assert ((candidate [1; 2; 3] [1; 0; 3]) = [1; 0; 9]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_440770_filter_python_file", "language": "ml", "prompt": "(**filter python files from simulation folder\n*)\nlet filter_python_file (files : string list) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_440770_filter_python_file.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = filter_python_file in\n  (assert ((candidate [\"simulations/example.py\"; \"simulations/example_1.py\"; \"simulations/example_2.py\"]) = [\"simulations/example.py\"; \"simulations/example_1.py\"; \"simulations/example_2.py\"]));\n  (assert ((candidate [\"simulations/test_a.py\"; \"simulations/test_b.py\"; \"simulations/test_c.txt\"]) = [\"simulations/test_a.py\"; \"simulations/test_b.py\"]));\n  (assert ((candidate [\"simulations/file1.py\"; \"simulations/subdir/file2.py\"; \"file3.py\"; \"simulations/subdir/file4.pyc\"]) = [\"simulations/file1.py\"; \"simulations/subdir/file2.py\"]));\n  (assert ((candidate [\"simulations/file1.py\"; \"simulations/subdir/file2.py\"; \"file3.py\"]) = [\"simulations/file1.py\"; \"simulations/subdir/file2.py\"]));\n  (assert ((candidate [\"simulations/test_a.py\"; \"simulations/test_b.py\"]) = [\"simulations/test_a.py\"; \"simulations/test_b.py\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_441120_get_method_color", "language": "ml", "prompt": "(**Return color given the method name.\n*)\nlet get_method_color (method : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_441120_get_method_color.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_method_color in\n  (assert ((candidate \"Random\") = \"blue\"));\n  (assert ((candidate \"SubSample\") = \"rebeccapurple\"));\n  (assert ((candidate \"BoostIn\") = \"orange\"));\n  (assert ((candidate \"Loss\") = \"yellow\"));\n  (assert ((candidate \"LOO\") = \"red\"));\n  (assert ((candidate \"TreeSim\") = \"mediumseagreen\"));\n  (assert ((candidate \"Target\") = \"cyan\"));\n  (assert ((candidate \"InputSim\") = \"gray\"));\n  (assert ((candidate \"LeafInfSP\") = \"brown\"));\n  (assert ((candidate \"TREX\") = \"green\"));\n  (assert ((candidate \"Minority\") = \"cyan\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_441315_filter_func", "language": "ml", "prompt": "(**Given a list of bigrams from a review's text, returns true if the review is\nincentivized by using a lookup list\n:param bigrams: Bigrams from the review's text, lemmatized for better matching\n:return: True if the review is incentivized, False otherwise\n*)\nlet filter_func (bigrams :  string * string list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_441315_filter_func.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = filter_func in\n  (assert ((candidate [(\"free\", \"discount\"); (\"free\", \"exchange\")]) = true));\n  (assert ((candidate [(\"unbiased\", \"view\")]) = true));\n  (assert ((candidate [(\"return\", \"unbiased\"); (\"review\", \"sample\")]) = true));\n  (assert ((candidate [(\"opinion\", \"state\"); (\"opinion\", \"own\")]) = true));\n  (assert ((candidate [(\"complimentary\", \"copy\"); (\"discount\", \"exchange\")]) = true));\n  (assert ((candidate [(\"sample\", \"product\"); (\"sample\", \"unbiased\")]) = true));\n  (assert ((candidate [(\"provide\", \"exchange\"); (\"provided\", \"sample\")]) = true));\n  (assert ((candidate [(\"free\", \"sample\"); (\"free\", \"unbiased\")]) = true));\n  (assert ((candidate [(\"honest\", \"feedback\"); (\"honest\", \"unbiased\")]) = true));\n  (assert ((candidate [(\"receive\", \"free\"); (\"received\", \"sample\")]) = true));\n  (assert ((candidate [(\"unbiased\", \"review\"); (\"unbiased\", \"opinion\")]) = true));\n  (assert ((candidate [(\"sample\", \"free\"); (\"send\", \"sample\")]) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_441869_is_candidate_word", "language": "ml", "prompt": "(**check a word is correct candidate word for identifying pronoun\n*)\nlet is_candidate_word (word : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_441869_is_candidate_word.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_candidate_word in\n  (assert ((candidate \"The Dog\") = true));\n  (assert ((candidate \"the cat\") = true));\n  (assert ((candidate \"\") = false));\n  (assert ((candidate \"the Cat\") = true));\n  (assert ((candidate \"the\") = false));\n  (assert ((candidate \"a\") = false));\n  (assert ((candidate \"cat\") = true));\n  (assert ((candidate \"apple\") = true));\n  (assert ((candidate \"The Cat\") = true));\n  (assert ((candidate \"The dog\") = true));\n  (assert ((candidate \"an\") = false));\n  (assert ((candidate \"The\") = false));\n  (assert ((candidate \"the Dog\") = true));\n  (assert ((candidate \"dog\") = true));\n  (assert ((candidate \" \") = false));\n  (assert ((candidate \"banana\") = true));\n  (assert ((candidate \"the dog\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_441928_mtoft", "language": "ml", "prompt": "(**Convertie les meters en feets\nnote: 12 [in] = 1 [ft] and 1 [in] = 25.4 [mm] and 1000 [mm] = 1 [m]\n:param m: length [m]\n:return ft: length [ft]\n*)\nlet mtoft (m : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_441928_mtoft.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = mtoft in\n  (assert ((candidate 0) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_442368_remove_leading_zeros", "language": "ml", "prompt": "(**>>> remove_leading_zeros(\"0033\")\n'33'\n*)\nlet remove_leading_zeros (numeric_string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_442368_remove_leading_zeros.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = remove_leading_zeros in\n  (assert ((candidate \"000\") = \"\"));\n  (assert ((candidate \"00\") = \"\"));\n  (assert ((candidate \"1234\") = \"1234\"));\n  (assert ((candidate \"0123\") = \"123\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_442462_count_leading_spaces", "language": "ml", "prompt": "(**Count the number of spaces in a string before any other character.\n:param string: input string\n:return: number of spaces\n*)\nlet count_leading_spaces (string : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_442462_count_leading_spaces.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = count_leading_spaces in\n  (assert ((candidate \"  hello  \tworld\") = 2));\n  (assert ((candidate \"  hello\") = 2));\n  (assert ((candidate \"  hello\") = 2));\n  (assert ((candidate \"hello\tworld\") = 0));\n  (assert ((candidate \"hello\") = 0));\n  (assert ((candidate \"  hello  \") = 2));\n  (assert ((candidate \"     hello     \") = 5));\n  (assert ((candidate \"  hello   world\") = 2));\n  (assert ((candidate \"  hello  \") = 2));\n  (assert ((candidate \"\") = 0));\n  (assert ((candidate \"  hello world\") = 2));\n  (assert ((candidate \"hello   \") = 0));\n  (assert ((candidate \"This is a string without leading spaces.\") = 0));\n  (assert ((candidate \"    hello\") = 4));\n  (assert ((candidate \"    hello\") = 4));\n  (assert ((candidate \"hello\") = 0));\n  (assert ((candidate \"   hello\") = 3));\n  (assert ((candidate \"hello    \") = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_442522_editDistance", "language": "ml", "prompt": "(**Calculate edit distance between 2 strings\nArgs:\n * s1: string 1\n * s2: string 2\nReturns:\n * Edit distance between s1 and s2\n*)\nlet editDistance (s1 : string) (s2 : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_442522_editDistance.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = editDistance in\n  (assert ((candidate \"aaab\" \"aaa\") = 1));\n  (assert ((candidate \"aaac\" \"aaa\") = 1));\n  (assert ((candidate \"aab\" \"aaa\") = 1));\n  (assert ((candidate \"a\" \"bb\") = 2));\n  (assert ((candidate \"aaa\" \"aaa\") = 0));\n  (assert ((candidate \"a\" \"a\") = 0));\n  (assert ((candidate \"\" \"\") = 0));\n  (assert ((candidate \"foo\" \"fO0baR\") = 4));\n  (assert ((candidate \"aaa\" \"aaab\") = 1));\n  (assert ((candidate \"a\" \"ccc\") = 3));\n  (assert ((candidate \"ABC\" \"ABC\") = 0));\n  (assert ((candidate \"bb\" \"a\") = 2));\n  (assert ((candidate \"a\" \"b\") = 1));\n  (assert ((candidate \"\" \"a\") = 1));\n  (assert ((candidate \"foo\" \"bar\") = 3));\n  (assert ((candidate \"b\" \"a\") = 1));\n  (assert ((candidate \"aaa\" \"aab\") = 1));\n  (assert ((candidate \"sunday\" \"saturday\") = 3));\n  (assert ((candidate \"kitten\" \"sitting\") = 3));\n  (assert ((candidate \"ccc\" \"a\") = 3));\n  (assert ((candidate \"a\" \"\") = 1));\n  (assert ((candidate \"aaa\" \"aaac\") = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_442974_label_to_int", "language": "ml", "prompt": "(**Label to tensor\n:param label:\n:return:\n*)\nlet label_to_int (label : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_442974_label_to_int.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = label_to_int in\n  (assert ((candidate \"male\") = 1));\n  (assert ((candidate \"female\") = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_443062_partition", "language": "ml", "prompt": "(**Returns: a list splitting s in two parts\nThe 1st element of the list consists of all characters in even\npositions (starting at 0), while the 2nd element is the odd\npositions.\nExamples:\n * partition('abcde') is ['ace','bd']\n * partition('aabb') is ['ab', 'ab']\nParameter s: the string to partition\nPrecondition: s is a string\n*)\nlet partition (s : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_443062_partition.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = partition in\n  (assert ((candidate \"abcde\") = [\"ace\"; \"bd\"]));\n  (assert ((candidate \"12345\") = [\"135\"; \"24\"]));\n  (assert ((candidate \"a\") = [\"a\"; \"\"]));\n  (assert ((candidate \"\") = [\"\"; \"\"]));\n  (assert ((candidate \"abcde\") = [\"ace\"; \"bd\"]));\n  (assert ((candidate \"\") = [\"\"; \"\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_443442_column", "language": "ml", "prompt": "(**Gets column of matrix. \nINPUTS:     \n * Matrix, Int of column to look at\nRETURNS:    \n * Array of the column\n*)\nlet column (matrix : int list list) (i : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_443442_column.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = column in\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]] 1) = [2; 5]));\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]] 0) = [1; 4]));\n  (assert ((candidate [[1; 2; 3]; [4; 5; 6]] 2) = [3; 6]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_444222__get_num_to_fold", "language": "ml", "prompt": "(**Returns the number of gates to fold to achieve the desired (approximate)\nstretch factor.\nArgs:\n * stretch: Floating point value to stretch the circuit by.\n * ngates: Number of gates in the circuit to stretch.\n*)\nlet _get_num_to_fold (stretch : float) (ngates : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_444222__get_num_to_fold.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _get_num_to_fold in\n  (assert ((candidate 1.0 1) = 0));\n  (assert ((candidate 3.5 5) = 6));\n  (assert ((candidate 3.0 5) = 5));\n  (assert ((candidate 1.5 2) = 0));\n  (assert ((candidate 2.0 3) = 2));\n  (assert ((candidate 1.0 5) = 0));\n  (assert ((candidate 2.0 1000) = 500));\n  (assert ((candidate 2.0 100) = 50));\n  (assert ((candidate 1.1 10) = 1));\n  (assert ((candidate 1.4 12) = 2));\n  (assert ((candidate 1.6 12) = 4));\n  (assert ((candidate 1.0 100) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_444241_bin2int", "language": "ml", "prompt": "(**convert the binary (as string) to integer\n*)\nlet bin2int (bin : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_444241_bin2int.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = bin2int in\n  (assert ((candidate \"10111110011\") = 1523));\n  (assert ((candidate \"10101110\") = 174));\n  (assert ((candidate \"100101100101110111\") = 153975));\n  (assert ((candidate \"10101110010111\") = 11159));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_444506_rename_dupe_cols", "language": "ml", "prompt": "(**Renames duplicate columns in order of occurrence.\ncolumns [0, 0, 0, 0]\nturn into [0, 1, 2, 3]\ncolumns [name10, name10, name10, name10]\nturn into [name10, name11, name12, name13]\n:param cols: iterable of columns\n:return: unique columns with digits incremented.\n*)\nlet rename_dupe_cols (cols : string list) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_444506_rename_dupe_cols.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = rename_dupe_cols in\n  (assert ((candidate [\"name10\"; \"name10\"; \"name10\"; \"name10\"; \"name10\"; \"name10\"]) = [\"name10\"; \"name11\"; \"name12\"; \"name13\"; \"name14\"; \"name15\"]));\n  (assert ((candidate [\"name1\"; \"name2\"; \"name3\"; \"name4\"; \"name5\"; \"name6\"; \"name7\"; \"name8\"]) = [\"name1\"; \"name2\"; \"name3\"; \"name4\"; \"name5\"; \"name6\"; \"name7\"; \"name8\"]));\n  (assert ((candidate [\"name1\"; \"name2\"; \"name3\"; \"name4\"; \"name5\"; \"name6\"; \"name7\"; \"name8\"; \"name9\"]) = [\"name1\"; \"name2\"; \"name3\"; \"name4\"; \"name5\"; \"name6\"; \"name7\"; \"name8\"; \"name9\"]));\n  (assert ((candidate [\"name10\"; \"name10\"; \"name10\"; \"name10\"]) = [\"name10\"; \"name11\"; \"name12\"; \"name13\"]));\n  (assert ((candidate [\"name10\"; \"name11\"; \"name12\"; \"name13\"; \"name14\"; \"name15\"]) = [\"name10\"; \"name11\"; \"name12\"; \"name13\"; \"name14\"; \"name15\"]));\n  (assert ((candidate list \"abc\") = list \"abc\"));\n  (assert ((candidate [\"name1\"; \"name1\"; \"name1\"; \"name1\"; \"name1\"; \"name1\"; \"name1\"; \"name1\"]) = [\"name1\"; \"name2\"; \"name3\"; \"name4\"; \"name5\"; \"name6\"; \"name7\"; \"name8\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_445003_add_trailing_slash", "language": "ml", "prompt": "(**Add trailing slash.\n*)\nlet add_trailing_slash (s : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_445003_add_trailing_slash.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = add_trailing_slash in\n  (assert ((candidate \"fiddle/\") = \"fiddle/\"));\n  (assert ((candidate \"eggplant/\") = \"eggplant/\"));\n  (assert ((candidate \"durian\") = \"durian/\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_445676__format_time", "language": "ml", "prompt": "(**Defines how to format time in FunctionEvent\n*)\nlet _format_time (time_us : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_445676__format_time.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _format_time in\n  (assert ((candidate 100) = \"100.000us\"));\n  (assert ((candidate 1000) = \"1.000ms\"));\n  (assert ((candidate 10000) = \"10.000ms\"));\n  (assert ((candidate 100000) = \"100.000ms\"));\n  (assert ((candidate 1000000) = \"1.000s\"));\n  (assert ((candidate 100000000) = \"100.000s\"));\n  (assert ((candidate 10000000) = \"10.000s\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_445722_org_add_payload", "language": "ml", "prompt": "(**Provide an organization payload for adding a member.\n*)\nlet org_add_payload (org_default_payload : (string, string) list) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_445722_org_add_payload.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = org_add_payload in\n  (assert ((candidate [(\"action\", \"member_added\")]) = [(\"action\", \"member_added\")]));\n  (assert ((candidate [(\"action\", \"member_removed\")]) = [(\"action\", \"member_added\")]));\n  (assert ((candidate [(\"action\", \"member_removed\")]) = [(\"action\", \"member_added\")]));\n  (assert ((candidate [(\"action\", \"member_added\")]) = [(\"action\", \"member_added\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_445953_dopant_site", "language": "ml", "prompt": "(**With the given VASP POSCAR file, determine the impurity location\ngiven the folder structure\nInputs\n------\nposcar:  File path for the relevant POSCAR file\nOutputs\n-------\nimpurity type of the defect as defined by collaborators\n*)\nlet dopant_site (poscar : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_445953_dopant_site.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = dopant_site in\n  (assert ((candidate \"M_i_S_site/POSCAR\") = \"M_i_S_site\"));\n  (assert ((candidate \"M_i_Se_site/POSCAR\") = \"M_i_Se_site\"));\n  (assert ((candidate \"M_i_Cd_site/POSCAR\") = \"M_i_Cd_site\"));\n  (assert ((candidate \"M_Se/POSCAR\") = \"M_Se\"));\n  (assert ((candidate \"M_Cd/POSCAR\") = \"M_Cd\"));\n  (assert ((candidate \"M_i_other/POSCAR\") = \"M_i_old\"));\n  (assert ((candidate \"M_i_neutral_site/POSCAR\") = \"M_i_old\"));\n  (assert ((candidate \"M_Cd/POSCAR\") = \"M_Cd\"));\n  (assert ((candidate \"M_i_Te_site/POSCAR\") = \"M_i_Te_site\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_446431_decolonize", "language": "ml", "prompt": "(**Remove the colon at the end of the word\nThis will be used by the unique word of\ntemplate class to sanitize attr accesses\n*)\nlet decolonize (val : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_446431_decolonize.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = decolonize in\n  (assert ((candidate str 400) = \"400\"));\n  (assert ((candidate str 1600) = \"1600\"));\n  (assert ((candidate str 2100) = \"2100\"));\n  (assert ((candidate str 1900) = \"1900\"));\n  (assert ((candidate str 1100) = \"1100\"));\n  (assert ((candidate str 200) = \"200\"));\n  (assert ((candidate str 600) = \"600\"));\n  (assert ((candidate str 800) = \"800\"));\n  (assert ((candidate \"Hello\") = \"Hello\"));\n  (assert ((candidate str 300) = \"300\"));\n  (assert ((candidate \"Hello \") = \"Hello \"));\n  (assert ((candidate str 100) = \"100\"));\n  (assert ((candidate str 1000) = \"1000\"));\n  (assert ((candidate str 1400) = \"1400\"));\n  (assert ((candidate str 1500) = \"1500\"));\n  (assert ((candidate str 500) = \"500\"));\n  (assert ((candidate str 700) = \"700\"));\n  (assert ((candidate \":foo\") = \"foo\"));\n  (assert ((candidate \"Hello :  \") = \"Hello :  \"));\n  (assert ((candidate \"  \") = \"  \"));\n  (assert ((candidate \":FOO\") = \"FOO\"));\n  (assert ((candidate \"Foo:\") = \"Foo\"));\n  (assert ((candidate str 2000) = \"2000\"));\n  (assert ((candidate \"FOO\") = \"FOO\"));\n  (assert ((candidate str 1800) = \"1800\"));\n  (assert ((candidate str 900) = \"900\"));\n  (assert ((candidate \"FOO:\") = \"FOO\"));\n  (assert ((candidate str 1200) = \"1200\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"foo:\") = \"foo\"));\n  (assert ((candidate \" \") = \" \"));\n  (assert ((candidate \"foo\") = \"foo\"));\n  (assert ((candidate str 1700) = \"1700\"));\n  (assert ((candidate \":Foo\") = \"Foo\"));\n  (assert ((candidate \"Foo\") = \"Foo\"));\n  (assert ((candidate str 1300) = \"1300\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_446564__nipype_logging_config", "language": "ml", "prompt": "(**This Function takes in...\n:param wfrun: cachedir\n:return:\n*)\nlet _nipype_logging_config (cachedir : string) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_446564__nipype_logging_config.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _nipype_logging_config in\n  (assert ((candidate \"testdir\") = [(\"workflow_level\", \"INFO\"); (\"filemanip_level\", \"INFO\"); (\"interface_level\", \"INFO\"); (\"log_directory\", \"testdir\")]));\n  (assert ((candidate \"foo\") = [(\"workflow_level\", \"INFO\"); (\"filemanip_level\", \"INFO\"); (\"interface_level\", \"INFO\"); (\"log_directory\", \"foo\")]));\n  (assert ((candidate \"cachedir\") = [(\"workflow_level\", \"INFO\"); (\"filemanip_level\", \"INFO\"); (\"interface_level\", \"INFO\"); (\"log_directory\", \"cachedir\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_446882_sort_012", "language": "ml", "prompt": "(**Sort a list containing the integers 0, 1, and 2, in a single traversal\n:param input_list: list\n:return: list\n*)\nlet sort_012 (input_list : int list) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_446882_sort_012.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sort_012 in\n  (assert ((candidate [1; 0; 2]) = [0; 1; 2]));\n  (assert ((candidate [2; 0; 1]) = [0; 1; 2]));\n  (assert ((candidate [1; 2; 0]) = [0; 1; 2]));\n  (assert ((candidate [0; 2; 1]) = [0; 1; 2]));\n  (assert ((candidate [0; 0; 2]) = [0; 0; 2]));\n  (assert ((candidate [2; 2; 2]) = [2; 2; 2]));\n  (assert ((candidate [2; 1; 0]) = [0; 1; 2]));\n  (assert ((candidate [0; 0; 0]) = [0; 0; 0]));\n  (assert ((candidate [0; 1; 2]) = [0; 1; 2]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_446968_format_markdown", "language": "ml", "prompt": "(**Format content with config parameters.\nArguments:\n * content {str} -- Unformatted content\nReturns:\n * {str} -- Formatted content\n*)\nlet format_markdown (content : string) (params : (string, string) list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_446968_format_markdown.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = format_markdown in\n  (assert ((candidate \"The following is a **{document}** document.\" [(\"document\", \"document\")]) = \"The following is a **document** document.\"));\n  (assert ((candidate \"The following is a **markdown** document.\" [(\"document\", \"document\")]) = \"The following is a **markdown** document.\"));\n  (assert ((candidate \"The following is a **{markdown}** document.\" []) = \"The following is a **{markdown}** document.\"));\n  (assert ((candidate \"The following is a **markdown** document.\" [(\"document\", \"document\"); (\"markdown\", \"**markdown**\")]) = \"The following is a **markdown** document.\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_447141_distance_between_points", "language": "ml", "prompt": "(**Calculates the Distance between 2 points. (x^2 + y^2) ^ 0.5\n:param first_point: tuple of x and y value of point 1\n:param second_point: tuple of x and y value of point 2\n:return: Float value of the distance between the 2 points\n:rtype: float\n*)\nlet distance_between_points (first_point :  int * int) (second_point :  int * int) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_447141_distance_between_points.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = distance_between_points in\n  (assert ((candidate (0, 1) (1, 0)) = 1.4142135623730951));\n  (assert ((candidate ((~1), 0) (3, 0)) = 4.0));\n  (assert ((candidate (0, 0) (3, 4)) = 5.0));\n  (assert ((candidate (0, 0) (1, 1)) = 1.4142135623730951));\n  (assert ((candidate ((~1), (~1)) (1, 1)) = 2.8284271247461903));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_448228_ind_dict2list", "language": "ml", "prompt": "(**:param dic: dictionary form object ot index, starting from zero\n:return:\n*)\nlet ind_dict2list (dic : (string, int) list) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_448228_ind_dict2list.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = ind_dict2list in\n  (assert ((candidate [(\"x\", 0); (\"y\", 1); (\"z\", 2)]) = [\"x\"; \"y\"; \"z\"]));\n  (assert ((candidate dict zip list \"abcde\" range 5) = list \"abcde\"));\n  (assert ((candidate dict ) = []));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_448750_simple_decompression", "language": "ml", "prompt": "(**Decompression for `simple_compression(string)`\n*)\nlet simple_decompression (compressed_string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_448750_simple_decompression.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = simple_decompression in\n  (assert ((candidate \"c3\") = \"ccc\"));\n  (assert ((candidate \"a4\") = \"aaaa\"));\n  (assert ((candidate \"b1\") = \"b\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_448838_pad_diff", "language": "ml", "prompt": "(**Pads img_arr width or height < samples_size with zeros\n*)\nlet pad_diff (actual_height : int) (actual_width : int) (desired_height : int) (desired_width : int) :  int * int * int * int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_448838_pad_diff.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = pad_diff in\n  (assert ((candidate 10 10 15 15) = (0, 0, 5, 5)));\n  (assert ((candidate 2 2 4 4) = (0, 0, 2, 2)));\n  (assert ((candidate 2 2 3 3) = (0, 0, 1, 1)));\n  (assert ((candidate 100 100 100 200) = (0, 0, 100, 0)));\n  (assert ((candidate 200 300 200 300) = (0, 0, 0, 0)));\n  (assert ((candidate 100 100 200 100) = (0, 0, 0, 100)));\n  (assert ((candidate 4 6 4 6) = (0, 0, 0, 0)));\n  (assert ((candidate 1 1 3 2) = (0, 0, 1, 2)));\n  (assert ((candidate 1 1 2 2) = (0, 0, 1, 1)));\n  (assert ((candidate 100 100 100 100) = (0, 0, 0, 0)));\n  (assert ((candidate 10 10 10 10) = (0, 0, 0, 0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_44905_calc_intersection", "language": "ml", "prompt": "(**Calculates the intersection of 2 rects\nMaths from https://es.wikipedia.org/wiki/Intersecci%C3%B3n_de_dos_rectas\n:param r1:\n:param r2:\n:return:\n*)\nlet calc_intersection (r1 :   int * int *  int * int) (r2 :   int * int *  int * int) :  int * int option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_44905_calc_intersection.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = calc_intersection in\n  (assert ((candidate ((0, 0), (0, 1)) ((0, 0), (1, 0))) = Some((0, 0))));\n  (assert ((candidate ((0, 0), (0, 1)) (((~1), 0), (1, 0))) = Some((0, 0))));\n  (assert ((candidate ((1, 1), (2, 2)) (((~1), 1), (1, 3))) = Some(None)));\n  (assert ((candidate ((1, 1), (3, 3)) ((1, 2), (3, 2))) = Some((2, 2))));\n  (assert ((candidate ((0, 0), (0, 1)) ((0, 0), (1, 1))) = Some((0, 0))));\n  (assert ((candidate ((0, 0), (0, 1)) (((~1), 1), (1, 1))) = Some((0, 1))));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_449923_get_as_clause_multicol", "language": "ml", "prompt": "(**get_as_clause will return tuple of column names of intermediate table c of postgresql query.\n:param columns_to_query_lst: columns for where clause.E.g [col1]\n:param update_param_list: new column names for columns to be updated.E.g [updatecol2,updatecol3]\n:return as_clause: string. E.g \"as c(col1,updatecol2,updatecol3)\"\n*)\nlet get_as_clause_multicol (columns_to_query_lst : string list) (update_param_list : string list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_449923_get_as_clause_multicol.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_as_clause_multicol in\n  (assert ((candidate [\"col1\"] [\"updatecol2\"; \"updatecol3\"]) = \"as c(col1,updatecol2,updatecol3)\"));\n  (assert ((candidate [\"col1\"; \"col2\"] [\"updatecol2\"; \"updatecol3\"]) = \"as c(col1,col2,updatecol2,updatecol3)\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_450025_word_count", "language": "ml", "prompt": "(**The word-count of the given text. Goes through the string exactly\nonce and has constant memory usage. Not super sophisticated though.\n*)\nlet word_count (text : string option) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_450025_word_count.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = word_count in\n  (assert ((candidate Some(\"a b c d e \")) = 5));\n  (assert ((candidate Some(\"a\")) = 1));\n  (assert ((candidate Some(\"\nfoo\")) = 1));\n  (assert ((candidate Some(\"foo\tbar\")) = 2));\n  (assert ((candidate Some(\"a b c d e f g h i j k l m n o p q r s t u v w x y z\")) = 26));\n  (assert ((candidate Some(\"a b\")) = 2));\n  (assert ((candidate Some(\"\")) = 0));\n  (assert ((candidate Some(\"a b c d e f g\")) = 7));\n  (assert ((candidate Some(\"foo\n  \n  bar\")) = 2));\n  (assert ((candidate Some(\"foo  bar  baz\")) = 3));\n  (assert ((candidate Some(\"foo bar baz quux\")) = 4));\n  (assert ((candidate Some(\"foo\rbar\")) = 2));\n  (assert ((candidate Some(\"\")) = 0));\n  (assert ((candidate Some(\"foo \")) = 1));\n  (assert ((candidate Some(\"\n\n\n\n\n\")) = 0));\n  (assert ((candidate Some(\"foo\n\")) = 1));\n  (assert ((candidate Some(None)) = 0));\n  (assert ((candidate Some(\"a b c d e\")) = 5));\n  (assert ((candidate Some(\"a\")) = 1));\n  (assert ((candidate Some(\"\n\")) = 0));\n  (assert ((candidate Some(\"a b c d e f \")) = 6));\n  (assert ((candidate Some(\"\")) = 0));\n  (assert ((candidate Some(\"Hello  World!\")) = 2));\n  (assert ((candidate Some(\"a b c d e f g h \")) = 8));\n  (assert ((candidate Some(\"foo \n bar \n baz\")) = 3));\n  (assert ((candidate Some(\"\t\n\n\n\t\t\")) = 0));\n  (assert ((candidate Some(\"a b c\")) = 3));\n  (assert ((candidate Some(\"a b c d e f g \")) = 7));\n  (assert ((candidate Some(\"foo\n  bar\")) = 2));\n  (assert ((candidate Some(\"\")) = 0));\n  (assert ((candidate Some(\"foo\n\nbar\")) = 2));\n  (assert ((candidate Some(\"foo\tbar\tbaz?\")) = 3));\n  (assert ((candidate Some(\" foo\")) = 1));\n  (assert ((candidate Some(\"a b c d e f g h\")) = 8));\n  (assert ((candidate Some(\"foo\nbar\nbaz\")) = 3));\n  (assert ((candidate Some(\"a b c d e f g h i \")) = 9));\n  (assert ((candidate Some(\"foo\")) = 1));\n  (assert ((candidate Some(\"\")) = 0));\n  (assert ((candidate Some(\"foo bar baz\")) = 3));\n  (assert ((candidate Some(\"a b c d\")) = 4));\n  (assert ((candidate Some(\"a b c d e f g h i\")) = 9));\n  (assert ((candidate Some(\"foo  \t\tbar\")) = 2));\n  (assert ((candidate Some(\"foo\nbar\")) = 2));\n  (assert ((candidate Some(\" a b  c \")) = 3));\n  (assert ((candidate Some(\"a b c d e f\")) = 6));\n  (assert ((candidate Some(\"foo bar\")) = 2));\n  (assert ((candidate Some(\"foo\tbar\tbaz\")) = 3));\n  (assert ((candidate Some(\"a b c d \")) = 4));\n  (assert ((candidate Some(\"foo\")) = 1));\n  (assert ((candidate Some(\"Hello\n\nWorld!\")) = 2));\n  (assert ((candidate Some(\"Hello World!\")) = 2));\n  (assert ((candidate Some(\"  \")) = 0));\n  (assert ((candidate Some(\"  foo\")) = 1));\n  (assert ((candidate Some(\"foo\t\tbar\")) = 2));\n  (assert ((candidate Some(\"foo   bar  \t\n  baz\")) = 3));\n  (assert ((candidate Some(\"Hello\tWorld!\")) = 2));\n  (assert ((candidate Some(\"foo bar baz\")) = 3));\n  (assert ((candidate Some(\" a b \")) = 2));\n  (assert ((candidate Some(\"a b\")) = 2));\n  (assert ((candidate Some(\"foo\r\nbar\")) = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_45007_process_value", "language": "ml", "prompt": "(**Returns a processed value for an environment variable.\n*)\nlet process_value (value : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_45007_process_value.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = process_value in\n  (assert ((candidate \"\"a\"\") = \"a\"));\n  (assert ((candidate \"\"a\") = \"\"a\"));\n  (assert ((candidate \"\"a\"b\") = \"\"a\"b\"));\n  (assert ((candidate \"a\") = \"a\"));\n  (assert ((candidate \"\"a b\"\") = \"a b\"));\n  (assert ((candidate \"\"a\"\") = \"a\"));\n  (assert ((candidate \"a\"b\"\") = \"a\"b\"\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"a\"\") = \"a\"\"));\n  (assert ((candidate \"a\"b\") = \"a\"b\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_450178_startWithArabic", "language": "ml", "prompt": "(**this function return true if the given string starts with am Arabic numeral\n*)\nlet startWithArabic (Instr : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_450178_startWithArabic.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = startWithArabic in\n  (assert ((candidate \"1999\") = true));\n  (assert ((candidate \"12345\") = true));\n  (assert ((candidate \"7\") = true));\n  (assert ((candidate \"1\") = true));\n  (assert ((candidate \"123\") = true));\n  (assert ((candidate \"8\") = true));\n  (assert ((candidate \"10000000\") = true));\n  (assert ((candidate \"999\") = true));\n  (assert ((candidate \"7000\") = true));\n  (assert ((candidate \"x\") = false));\n  (assert ((candidate \"\") = false));\n  (assert ((candidate \"0\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_450346_search_escape", "language": "ml", "prompt": "(**Escape URLs such that preexisting { and } are handled properly.\nWill obviously trash a properly-formatted qutebrowser URL.\n*)\nlet search_escape (url : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_450346_search_escape.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = search_escape in\n  (assert ((candidate \"http://example.com/?q=a}b\") = \"http://example.com/?q=a}}b\"));\n  (assert ((candidate \"some/url/with/{special characters}\") = \"some/url/with/{{special characters}}\"));\n  (assert ((candidate \"some/url/with/no/{characters}\") = \"some/url/with/no/{{characters}}\"));\n  (assert ((candidate \"some/url/with/no/special/characters\") = \"some/url/with/no/special/characters\"));\n  (assert ((candidate \"https://duckduckgo.com/?q=foo+bar&t=h_\") = \"https://duckduckgo.com/?q=foo+bar&t=h_\"));\n  (assert ((candidate \"http://example.com/?q=a{\") = \"http://example.com/?q=a{{\"));\n  (assert ((candidate \"http://example.com/?q=}\") = \"http://example.com/?q=}}\"));\n  (assert ((candidate \"http://example.com/?q=a}\") = \"http://example.com/?q=a}}\"));\n  (assert ((candidate \"https://duckduckgo.com/?q=foo+bar&t=h_\") = \"https://duckduckgo.com/?q=foo+bar&t=h_\"));\n  (assert ((candidate \"http://example.com/?q=a}b}\") = \"http://example.com/?q=a}}b}}\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_450375_get_y_indicator_variable_index", "language": "ml", "prompt": "(**Map the i,j indices to the sequential indicator variable index\nfor the y_{ij} variable.\nThis is basically the (2-dimensional) 'array equation' (as per\nrow-major arrays in C for example).\nNote that for MiniSat+, the variables are juist indexed sequentially\nand we are mapping the y_{ij} to y_r for 0 <= r < m*n variables.\nThis function gets the sequential index for a y_{ij} variable.\nParameters:\n * i, j   - indices for y indicator variable\n * m - order of tableau a (0 <= i,k < m)\n * n - order of tableau b (0 <= j,l < n)\nReturn value:\n * index r of indicator variable y_{r} corresponding to y_{ij}\n*)\nlet get_y_indicator_variable_index (i : int) (j : int) (m : int) (n : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_450375_get_y_indicator_variable_index.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_y_indicator_variable_index in\n  (assert ((candidate 0 0 0 0) = 0));\n  (assert ((candidate 1 1 2 2) = 3));\n  (assert ((candidate 0 3 5 6) = 3));\n  (assert ((candidate 0 0 5 6) = 0));\n  (assert ((candidate 0 1 1 2) = 1));\n  (assert ((candidate 0 0 1 1) = 0));\n  (assert ((candidate 0 2 5 6) = 2));\n  (assert ((candidate 1 0 1 1) = 1));\n  (assert ((candidate 0 0 3 4) = 0));\n  (assert ((candidate 1 0 2 1) = 1));\n  (assert ((candidate 0 0 1 2) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_450502_default", "language": "ml", "prompt": "(**Return default if no input_str, otherwise stripped input_str.\n*)\nlet default (input_str : string option) (name : string option) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_450502_default.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = default in\n  (assert ((candidate Some(\"\") Some(\"name\")) = Some(\"name\")));\n  (assert ((candidate Some(\"abc\") Some(None)) = Some(\"abc\")));\n  (assert ((candidate Some(\"  hi  \") Some(\"candidate\")) = Some(\"hi\")));\n  (assert ((candidate Some(None) Some(\"name\")) = Some(\"name\")));\n  (assert ((candidate Some(\"  \") Some(None)) = Some(\"\")));\n  (assert ((candidate Some(\"  abc  \") Some(None)) = Some(\"abc\")));\n  (assert ((candidate Some(None) Some(None)) = Some(None)));\n  (assert ((candidate Some(None) Some(\"bob\")) = Some(\"bob\")));\n  (assert ((candidate Some(\"1\") Some(None)) = Some(\"1\")));\n  (assert ((candidate Some(\"  bob  \") Some(\"bob\")) = Some(\"bob\")));\n  (assert ((candidate Some(\"name\") Some(\"name\")) = Some(\"name\")));\n  (assert ((candidate Some(\"\t   \t\") Some(\"candidate\")) = Some(\"\")));\n  (assert ((candidate Some(\"   str   \") Some(\"candidate\")) = Some(\"str\")));\n  (assert ((candidate Some(\"bob\") Some(\"bob\")) = Some(\"bob\")));\n  (assert ((candidate Some(\"  \") Some(\"bob\")) = Some(\"\")));\n  (assert ((candidate Some(None) Some(\"candidate\")) = Some(\"candidate\")));\n  (assert ((candidate Some(\"\n\n\") Some(\"candidate\")) = Some(\"\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_451058_est_palindrome3", "language": "ml", "prompt": "(**... cf. ci-dessus ...\n*)\nlet est_palindrome3 (s : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_451058_est_palindrome3.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = est_palindrome3 in\n  (assert ((candidate \"abb\") = false));\n  (assert ((candidate \"aabaa\") = true));\n  (assert ((candidate \"abbbbbbbbbbba\") = true));\n  (assert ((candidate \"abbaabb\") = false));\n  (assert ((candidate \"abbbbba\") = true));\n  (assert ((candidate \"0\") = true));\n  (assert ((candidate \"toto0\") = false));\n  (assert ((candidate \"abbbbbbbaa\") = false));\n  (assert ((candidate \"abbbaabb\") = false));\n  (assert ((candidate \"abbaabba\") = true));\n  (assert ((candidate \"\") = true));\n  (assert ((candidate \"aba\") = true));\n  (assert ((candidate \"00\") = true));\n  (assert ((candidate \"abbba\") = true));\n  (assert ((candidate \"ab\") = false));\n  (assert ((candidate \"abbbbbbba\") = true));\n  (assert ((candidate \"bab\") = true));\n  (assert ((candidate \"abba\") = true));\n  (assert ((candidate \"a\") = true));\n  (assert ((candidate \"abbab\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_451156_dhash_hamming_distance", "language": "ml", "prompt": "(**Calculate the hamming distance between two dhash values\n:param dhash1: str, the dhash of an image returned by `calculate_dhash`\n:param dhash2: str, the dhash of an image returned by `calculate_dhash`\n:return: int, the hamming distance between two dhash values\n*)\nlet dhash_hamming_distance (dhash1 : string) (dhash2 : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_451156_dhash_hamming_distance.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = dhash_hamming_distance in\n  (assert ((candidate \"1234567890abcdef1234567890abcdef\" \"1234567890abcdef1234567890abcdef\") = 0));\n  (assert ((candidate \"1234567890abcdef1234567890abcdee\" \"1234567890abcdef1234567890abcdee\") = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_451382_findimagenumber", "language": "ml", "prompt": "(**find the number for each image file\n*)\nlet findimagenumber (filename : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_451382_findimagenumber.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = findimagenumber in\n  (assert ((candidate \"Data/OBSDATE0001.jpg\") = 1));\n  (assert ((candidate \"Data/OBSDATE0010.jpg\") = 10));\n  (assert ((candidate \"OBSDATE0001.fits\") = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_451777__rescale_score_by_abs", "language": "ml", "prompt": "(**Normalizes an attribution score to the range [0., 1.], where a score\nscore of 0. is mapped to 0.5.\n:param score: An attribution score\n:param max_score: The maximum possible attribution score\n:param min_score: The minimum possible attribution score\n:return: The normalized score\n*)\nlet _rescale_score_by_abs (score : float) (max_score : float) (min_score : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_451777__rescale_score_by_abs.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _rescale_score_by_abs in\n  (assert ((candidate 0.0 1.0 0.0) = 0.5));\n  (assert ((candidate (~1).0 0.0 0.0) = 0.5));\n  (assert ((candidate 1.0 1.0 -1.0) = 1.0));\n  (assert ((candidate 0.0 0.0 0.0) = 0.5));\n  (assert ((candidate 1.0 1.0 0.0) = 1.0));\n  (assert ((candidate 1.0 1.0 0.0) = 1.0));\n  (assert ((candidate 0.0 1.0 -1.0) = 0.5));\n  (assert ((candidate 0.0 0.0 0.0) = 0.5));\n  (assert ((candidate 0.0 1e-05.0 0.0) = 0.5));\n  (assert ((candidate 0.0 0.0 (~1).0) = 0.5));\n  (assert ((candidate -1.0 1.0 0.0) = 0.0));\n  (assert ((candidate -1.0 1.0 -1.0) = 0.0));\n  (assert ((candidate 0.0 1.0 0.0) = 0.5));\n  (assert ((candidate 0.0 0.0 1.0) = 0.5));\n  (assert ((candidate 0.0 0.0 0.0) = 0.5));\n  (assert ((candidate 1.0 0.0 0.0) = 0.5));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_451986_update_dependencies", "language": "ml", "prompt": "(**Update the source package's existing dependencies.\nWhen a user passes additional dependencies from the command line,\nthese dependencies will be added to the source package's existing dependencies.\nIf the dependencies passed from the command line are existing dependencies,\nthese existing dependencies are overwritten.\nPositional arguments:\nnew_dependencies (List[str]) -- the dependencies passed from the command line\nexisting_dependencies (List[str]) -- the dependencies found in the source\n * package's index.json file\n*)\nlet update_dependencies (new_dependencies : string list) (existing_dependencies : string list) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_451986_update_dependencies.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = update_dependencies in\n  (assert ((candidate [\"test\"; \"tests\"; \"testing\"] []) = [\"test\"; \"tests\"; \"testing\"]));\n  (assert ((candidate [\"foo\"; \"bar\"; \"baz\"] []) = [\"foo\"; \"bar\"; \"baz\"]));\n  (assert ((candidate [] [\"foo\"; \"bar\"; \"baz\"]) = [\"foo\"; \"bar\"; \"baz\"]));\n  (assert ((candidate [\"test\"; \"tests\"; \"testing\"] [\"test\"]) = [\"test\"; \"tests\"; \"testing\"]));\n  (assert ((candidate [\"foo 4.5.6\"] [\"hello 1.2.3\"; \"goodbye 3.2.1\"; \"foo 4.5.6\"]) = [\"hello 1.2.3\"; \"goodbye 3.2.1\"; \"foo 4.5.6\"]));\n  (assert ((candidate [] []) = []));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_452069_convertBoolean", "language": "ml", "prompt": "(**Convert Python bool to JS boolean.\nArgs:\n * value (bool): True/False\n*)\nlet convertBoolean (value : bool) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_452069_convertBoolean.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = convertBoolean in\n  (assert ((candidate false) = \"false\"));\n  (assert ((candidate true) = \"true\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_452718_hash_generator", "language": "ml", "prompt": "(**Generate hash for tokens in 'tokens' using 'token_to_id'.\nArgs:\n * token_to_id: dict. A dictionary which maps each token to a unique ID.\n * tokens: list(str). A list of tokens.\nReturns:\n * int. Hash value generated for tokens in 'tokens' using 'token_to_id'.\n*)\nlet hash_generator (token_to_id : (string, int) list) (tokens : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_452718_hash_generator.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = hash_generator in\n  (assert ((candidate dict zip \"abcdefghijklmnopqrstuvwxyz\" range 26 \"a\") = 0));\n  (assert ((candidate dict zip \"abc\" range 5 \"a\") = 0));\n  (assert ((candidate dict zip \"abc\" range 3 \"a\") = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_45275_RPL_ADMINEMAIL", "language": "ml", "prompt": "(**Reply Code 259\n*)\nlet RPL_ADMINEMAIL (sender : string) (receipient : string) (message : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_45275_RPL_ADMINEMAIL.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = RPL_ADMINEMAIL in\n  (assert ((candidate \"foo\" \"bar\" \"baz\") = \"<foo>: baz\"));\n  (assert ((candidate \"foo\" \"bar\" \"baz\") = \"<foo>: baz\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_453163_piece_placed", "language": "ml", "prompt": "(**This function determines the piece played.\nIt takes the coordinates of the piece, the player number, and the board.\nThe pieces are zeros or ones and the function returns the piece on the board based on the number.\n*)\nlet piece_placed (x : int) (y : int) (player : int) (board : int list list) : int list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_453163_piece_placed.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = piece_placed in\n  (assert ((candidate 1 1 1 [[0; 0; 0]; [0; 0; 0]; [0; 0; 0]]) = [[0; 0; 0]; [0; 2; 0]; [0; 0; 0]]));\n  (assert ((candidate 0 0 0 [[0; 0; 0]; [0; 0; 0]; [0; 0; 0]]) = [[1; 0; 0]; [0; 0; 0]; [0; 0; 0]]));\n  (assert ((candidate 1 1 1 [[1; 0; 0]; [0; 0; 1]; [0; 0; 0]]) = [[1; 0; 0]; [0; 2; 1]; [0; 0; 0]]));\n  (assert ((candidate 0 0 0 [[0; 0; 0; 0]; [0; 0; 0; 0]; [0; 0; 0; 0]; [0; 0; 0; 0]]) = [[1; 0; 0; 0]; [0; 0; 0; 0]; [0; 0; 0; 0]; [0; 0; 0; 0]]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_453517_do_math", "language": "ml", "prompt": "(**Helper function that performs computation between two numbers.\n*)\nlet do_math (a : int) (b : int) (operator : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_453517_do_math.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = do_math in\n  (assert ((candidate 1 3 \"*\") = 3));\n  (assert ((candidate 2 4 \"*\") = 8));\n  (assert ((candidate 1 2 \"*\") = 2));\n  (assert ((candidate 1 1 \"/\") = 1));\n  (assert ((candidate 1 1 \"+\") = 2));\n  (assert ((candidate 1 3 \"-\") = 2));\n  (assert ((candidate 1 1 \"*\") = 1));\n  (assert ((candidate 2 4 \"-\") = 2));\n  (assert ((candidate 1 2 \"+\") = 3));\n  (assert ((candidate 1 1 \"-\") = 0));\n  (assert ((candidate 2 3 \"+\") = 5));\n  (assert ((candidate 2 4 \"/\") = 2));\n  (assert ((candidate 2 4 \"+\") = 6));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_453870_get_version", "language": "ml", "prompt": "(**Generate a PEP386  compliant version\nStolen from django.utils.version.get_version\n:param v tuple: A five part tuple indicating the version\n:returns str: Compliant version\n*)\nlet get_version (v :  int * int * int * string * int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_453870_get_version.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_version in\n  (assert ((candidate (1, 2, 3, \"beta\", 1)) = \"1.2.3b1\"));\n  (assert ((candidate (1, 0, 1, \"alpha\", 0)) = \"1.0.1a0\"));\n  (assert ((candidate (0, 1, 0, \"rc\", 100)) = \"0.1c100\"));\n  (assert ((candidate (1, 2, 0, \"beta\", 11)) = \"1.2b11\"));\n  (assert ((candidate (1, 2, 0, \"final\", 0)) = \"1.2\"));\n  (assert ((candidate (0, 1, 0, \"rc\", 0)) = \"0.1c0\"));\n  (assert ((candidate (0, 1, 0, \"rc\", 10)) = \"0.1c10\"));\n  (assert ((candidate (1, 1, 0, \"final\", 0)) = \"1.1\"));\n  (assert ((candidate (1, 2, 0, \"rc\", 1)) = \"1.2c1\"));\n  (assert ((candidate (1, 2, 0, \"alpha\", 2)) = \"1.2a2\"));\n  (assert ((candidate (0, 1, 1, \"final\", 0)) = \"0.1.1\"));\n  (assert ((candidate (1, 0, 1, \"beta\", 0)) = \"1.0.1b0\"));\n  (assert ((candidate (1, 1, 0, \"alpha\", 1)) = \"1.1a1\"));\n  (assert ((candidate (1, 2, 0, \"beta\", 2)) = \"1.2b2\"));\n  (assert ((candidate (0, 1, 0, \"rc\", 1)) = \"0.1c1\"));\n  (assert ((candidate (1, 0, 1, \"rc\", 0)) = \"1.0.1c0\"));\n  (assert ((candidate (1, 0, 0, \"final\", 0)) = \"1.0\"));\n  (assert ((candidate (0, 1, 0, \"final\", 1)) = \"0.1\"));\n  (assert ((candidate (1, 2, 1, \"final\", 11)) = \"1.2.1\"));\n  (assert ((candidate (1, 2, 0, \"alpha\", 0)) = \"1.2a0\"));\n  (assert ((candidate (0, 1, 0, \"beta\", 0)) = \"0.1b0\"));\n  (assert ((candidate (1, 1, 0, \"beta\", 3)) = \"1.1b3\"));\n  (assert ((candidate (0, 1, 0, \"final\", 100)) = \"0.1\"));\n  (assert ((candidate (1, 1, 0, \"rc\", 3)) = \"1.1c3\"));\n  (assert ((candidate (0, 1, 1, \"beta\", 2)) = \"0.1.1b2\"));\n  (assert ((candidate (1, 2, 0, \"alpha\", 11)) = \"1.2a11\"));\n  (assert ((candidate (2, 1, 0, \"final\", 0)) = \"2.1\"));\n  (assert ((candidate (0, 1, 0, \"final\", 10)) = \"0.1\"));\n  (assert ((candidate (0, 1, 0, \"alpha\", 0)) = \"0.1a0\"));\n  (assert ((candidate (0, 1, 0, \"rc\", 1000)) = \"0.1c1000\"));\n  (assert ((candidate (1, 0, 1, \"final\", 0)) = \"1.0.1\"));\n  (assert ((candidate (2, 1, 1, \"final\", 0)) = \"2.1.1\"));\n  (assert ((candidate (1, 2, 1, \"final\", 0)) = \"1.2.1\"));\n  (assert ((candidate (1, 2, 0, \"rc\", 11)) = \"1.2c11\"));\n  (assert ((candidate (0, 1, 0, \"final\", 0)) = \"0.1\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_454038_norm_mac", "language": "ml", "prompt": "(**Normalize a MAC Address from the pypowervm format to the neutron format.\nThat means that the format will be converted to lower case and will have\ncolons added.\n:param mac: A pypowervm mac address.  E.g. 1234567890AB\n:returns: A mac that matches the standard neutron format.\n * E.g. 12:34:56:78:90:ab\n*)\nlet norm_mac (mac : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_454038_norm_mac.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = norm_mac in\n  (assert ((candidate \"1234567890AB\") = \"12:34:56:78:90:ab\"));\n  (assert ((candidate \"1234567890AB\") = \"12:34:56:78:90:ab\"));\n  (assert ((candidate \"1234:5678:90AB\") = \"12:34:56:78:90:ab\"));\n  (assert ((candidate \"1234567890ab\") = \"12:34:56:78:90:ab\"));\n  (assert ((candidate \"1234567890AB\") = \"12:34:56:78:90:ab\"));\n  (assert ((candidate \"1234567890AB\") = \"12:34:56:78:90:ab\"));\n  (assert ((candidate \"1234567890ab\") = \"12:34:56:78:90:ab\"));\n  (assert ((candidate \"000000000000\") = \"00:00:00:00:00:00\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_454515_contains_common_item_2", "language": "ml", "prompt": "(**loop through first array and create dictionary object where the keys are the items in the array\nloop through the second array and check if item in second array exists in the created dictionary\n*)\nlet contains_common_item_2 (arr1 : string list) (arr2 : string list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_454515_contains_common_item_2.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = contains_common_item_2 in\n  (assert ((candidate [\"apples\"; \"carrots\"; \"pears\"] [\"oranges\"; \"bananas\"; \"apples\"]) = true));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"; \"d\"] [\"a\"; \"y\"; \"x\"]) = true));\n  (assert ((candidate [] [\"z\"; \"y\"; \"x\"]) = false));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"; \"d\"] [\"x\"; \"y\"; \"z\"]) = false));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"; \"d\"] []) = false));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"; \"d\"] [\"b\"; \"c\"; \"d\"]) = true));\n  (assert ((candidate [\"b\"; \"a\"; \"c\"; \"d\"] [\"z\"; \"y\"; \"x\"]) = false));\n  (assert ((candidate [] []) = false));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"; \"d\"] [\"z\"; \"y\"; \"x\"]) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_454709_port_to_ip_mapping", "language": "ml", "prompt": "(**A user defined mapping port_id (kni) to ipv4.\n*)\nlet port_to_ip_mapping (index : int) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_454709_port_to_ip_mapping.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = port_to_ip_mapping in\n  (assert ((candidate 0) = [(\"vEth0_0\", \"192.167.10.1\")]));\n  (assert ((candidate 2) = [(\"vEth0_2\", \"192.167.10.3\")]));\n  (assert ((candidate 3) = [(\"vEth0_3\", \"192.167.10.4\")]));\n  (assert ((candidate 3) = [(\"vEth0_3\", \"192.167.10.4\")]));\n  (assert ((candidate 7) = [(\"vEth0_7\", \"192.167.10.8\")]));\n  (assert ((candidate 5) = [(\"vEth0_5\", \"192.167.10.6\")]));\n  (assert ((candidate 5) = [(\"vEth0_5\", \"192.167.10.6\")]));\n  (assert ((candidate 1) = [(\"vEth0_1\", \"192.167.10.2\")]));\n  (assert ((candidate 4) = [(\"vEth0_4\", \"192.167.10.5\")]));\n  (assert ((candidate 6) = [(\"vEth0_6\", \"192.167.10.7\")]));\n  (assert ((candidate 1) = [(\"vEth0_1\", \"192.167.10.2\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_455809__handle_sort_key", "language": "ml", "prompt": "(**Generate sort keys according to the passed in sort key from user.\n:param model_name: Database model name be query.(alarm, meter, etc.)\n:param sort_key: sort key passed from user.\nreturn: sort keys list\n*)\nlet _handle_sort_key (model_name : string) (sort_key : string option) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_455809__handle_sort_key.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _handle_sort_key in\n  (assert ((candidate \"alarm\" Some(\"name\")) = [\"name\"; \"user_id\"; \"project_id\"]));\n  (assert ((candidate \"meter\" Some(\"user_id\")) = [\"user_id\"; \"project_id\"]));\n  (assert ((candidate \"meter\" Some(\"user_id\")) = [\"user_id\"; \"project_id\"]));\n  (assert ((candidate \"resource\" Some(None)) = [\"user_id\"; \"project_id\"; \"timestamp\"]));\n  (assert ((candidate \"meter\" Some(\"user_id\")) = [\"user_id\"; \"project_id\"]));\n  (assert ((candidate \"resource\" Some(\"user_id\")) = [\"user_id\"; \"project_id\"; \"timestamp\"]));\n  (assert ((candidate \"meter\" Some(None)) = [\"user_id\"; \"project_id\"]));\n  (assert ((candidate \"alarm\" Some(\"name\")) = [\"name\"; \"user_id\"; \"project_id\"]));\n  (assert ((candidate \"resource\" Some(\"user_id\")) = [\"user_id\"; \"project_id\"; \"timestamp\"]));\n  (assert ((candidate \"alarm\" Some(None)) = [\"name\"; \"user_id\"; \"project_id\"]));\n  (assert ((candidate \"resource\" Some(None)) = [\"user_id\"; \"project_id\"; \"timestamp\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_45618_nearest_square", "language": "ml", "prompt": "(**Function to calculate nearest square of any number.\nArgs: \n * num (int): Any integer\nReturns: \n * Int: Nearest Square of num\n*)\nlet nearest_square (num : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_45618_nearest_square.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = nearest_square in\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 2) = 1));\n  (assert ((candidate 5) = 4));\n  (assert ((candidate 3) = 1));\n  (assert ((candidate 17) = 16));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_456370_path_inside_dir", "language": "ml", "prompt": "(**Returns True if the specified @path is inside @directory,\nperforming component-wide comparison. Otherwise returns False.\n*)\nlet path_inside_dir (path : string) (directory : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_456370_path_inside_dir.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = path_inside_dir in\n  (assert ((candidate \"foo/bar/baz\" \"foo\") = true));\n  (assert ((candidate \"some/path\" \"\") = true));\n  (assert ((candidate \"foo/bar\" \"foo\\bar\\baz\\quux\") = false));\n  (assert ((candidate \"some/path/\" \"other/path\") = false));\n  (assert ((candidate \"some/path\" \"other/path\") = false));\n  (assert ((candidate \"/a/b/c/d/e\" \"/a/b/c\") = true));\n  (assert ((candidate \"foo\\bar\" \"foo\\bar\\baz\") = false));\n  (assert ((candidate \"foo/bar\" \"foo/bar/baz\") = false));\n  (assert ((candidate \"foo\\bar\" \"foo\\bar\") = false));\n  (assert ((candidate \"some/path/\" \"other/directory\") = false));\n  (assert ((candidate \"foo\\bar\" \"foo\\bar\\baz\\quux\") = false));\n  (assert ((candidate \"foo\\bar\" \"foo/bar/baz/quux\") = false));\n  (assert ((candidate \"some/path\" \"some/path/path\") = false));\n  (assert ((candidate \"some/path\" \"some/path/\") = false));\n  (assert ((candidate \"foo/bar\" \"foo/bar\") = false));\n  (assert ((candidate \"some/path/\" \"\") = true));\n  (assert ((candidate \"foo/bar\" \"foo\") = true));\n  (assert ((candidate \"\" \"some/path\") = false));\n  (assert ((candidate \"foo/bar\" \"foo\\bar\\baz\") = false));\n  (assert ((candidate \"some/path\" \"some/directory/path\") = false));\n  (assert ((candidate \"foo/bar\" \"foo/bar/baz/quux\") = false));\n  (assert ((candidate \"foo\\bar\" \"foo/bar/baz\") = false));\n  (assert ((candidate \"some/path\" \"other/directory\") = false));\n  (assert ((candidate \"\" \"\") = false));\n  (assert ((candidate \"/a/b/c/d/e\" \"/a/b/c/\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_45640_num_digits", "language": "ml", "prompt": "(**Returns number of digits in an integer.\n:param number: Integer\n:return: Number of digits\n*)\nlet num_digits (number : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_45640_num_digits.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = num_digits in\n  (assert ((candidate 3) = 1));\n  (assert ((candidate 223100) = 6));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 1000) = 4));\n  (assert ((candidate 0) = 1));\n  (assert ((candidate 23) = 2));\n  (assert ((candidate 123) = 3));\n  (assert ((candidate 12345) = 5));\n  (assert ((candidate 99999999) = 8));\n  (assert ((candidate 1234567890) = 10));\n  (assert ((candidate 223) = 3));\n  (assert ((candidate 123456) = 6));\n  (assert ((candidate 999999) = 6));\n  (assert ((candidate 10) = 2));\n  (assert ((candidate 9999) = 4));\n  (assert ((candidate 22310) = 5));\n  (assert ((candidate 2231) = 4));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_457283_unf_gas_density_kgm3", "language": "ml", "prompt": "(**Equation for gas density\n:param t_K: temperature\n:param p_MPaa: pressure\n:param gamma_gas: specific gas density by air\n:param z: z-factor\n:return: gas density\n*)\nlet unf_gas_density_kgm3 (t_K : float) (p_MPaa : int) (gamma_gas : int) (z : float) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_457283_unf_gas_density_kgm3.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = unf_gas_density_kgm3 in\n  (assert ((candidate 293.15 101325 0 0.5) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_457405_count_tilings", "language": "ml", "prompt": "(**Returns the number of unique ways to tile a row of length n >= 1.\n*)\nlet count_tilings (n : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_457405_count_tilings.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = count_tilings in\n  (assert ((candidate 4) = 8));\n  (assert ((candidate 5) = 15));\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 1) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_458323_parse_boolean", "language": "ml", "prompt": "(**Returns boolean representation of argument.\n*)\nlet parse_boolean (arg : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_458323_parse_boolean.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_boolean in\n  (assert ((candidate 0) = false));\n  (assert ((candidate \"TRUE\") = true));\n  (assert ((candidate \"true\") = true));\n  (assert ((candidate \"True\") = true));\n  (assert ((candidate false) = false));\n  (assert ((candidate \"true\") = true));\n  (assert ((candidate \"FALSE\") = false));\n  (assert ((candidate \"false\") = false));\n  (assert ((candidate \"TRUE\") = true));\n  (assert ((candidate \"True\") = true));\n  (assert ((candidate \"False\") = false));\n  (assert ((candidate \"FALSE\") = false));\n  (assert ((candidate \"false\") = false));\n  (assert ((candidate \"0\") = false));\n  (assert ((candidate true) = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_45854_check_fields_to_join", "language": "ml", "prompt": "(**Check which fields have been passed to be joined\n*)\nlet check_fields_to_join (fields_to_join : string list) :  bool * bool * bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_45854_check_fields_to_join.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = check_fields_to_join in\n  (assert ((candidate [\"oa\"; \"lad\"; \"gor\"]) = (true, true, true)));\n  (assert ((candidate [\"oa\"; \"lad\"]) = (true, true, false)));\n  (assert ((candidate [\"oa\"; \"gor\"]) = (true, false, true)));\n  (assert ((candidate [\"lad\"; \"gor\"]) = (false, true, true)));\n  (assert ((candidate []) = (false, false, false)));\n  (assert ((candidate [\"lad\"]) = (false, true, false)));\n  (assert ((candidate [\"oa\"]) = (true, false, false)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_458724_pageHeader", "language": "ml", "prompt": "(***Generate a pageHeader - TBS style*\n**Key Arguments:**\n * - ``headline`` -- the headline text\n * - ``tagline`` -- the tagline text for below the headline\n**Return:**\n * - ``pageHeader`` -- the pageHeader\n*)\nlet pageHeader (headline : string) (tagline : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_458724_pageHeader.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = pageHeader in\n  (assert ((candidate \"headline\" \"tagline\") = \"\n        <div class=\"page-header\" id=\"  \">\n            <h1>headline<br><small>tagline</small></h1>\n        </div>\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_46021_gauss_sum", "language": "ml", "prompt": "(**Computes the gaussian sum for an input number.\n*)\nlet gauss_sum (number : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_46021_gauss_sum.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = gauss_sum in\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 10) = 55));\n  (assert ((candidate 6) = 21));\n  (assert ((candidate 20) = 210));\n  (assert ((candidate 2) = 3));\n  (assert ((candidate 7) = 28));\n  (assert ((candidate 5) = 15));\n  (assert ((candidate 2) = 3));\n  (assert ((candidate 4) = 10));\n  (assert ((candidate 3) = 6));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_46688_get_variable_sites", "language": "ml", "prompt": "(**Get a list of sites where data[index] are stored\n*)\nlet get_variable_sites (index : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_46688_get_variable_sites.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_variable_sites in\n  (assert ((candidate 21) = [2]));\n  (assert ((candidate 25) = [6]));\n  (assert ((candidate 19) = [10]));\n  (assert ((candidate 1) = [2]));\n  (assert ((candidate 23) = [4]));\n  (assert ((candidate 7) = [8]));\n  (assert ((candidate 15) = [6]));\n  (assert ((candidate 3) = [4]));\n  (assert ((candidate 17) = [8]));\n  (assert ((candidate 11) = [2]));\n  (assert ((candidate 5) = [6]));\n  (assert ((candidate 9) = [10]));\n  (assert ((candidate 13) = [4]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_4747_create_url", "language": "ml", "prompt": "(**Method which creates new url from base url\n:param url: base url\n:param data: data to append to base url\n:return: new url\n*)\nlet create_url (url : string) (data : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_4747_create_url.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = create_url in\n  (assert ((candidate \"http://example.com\" \"test\") = \"http://example.com/test\"));\n  (assert ((candidate \"http://www.codewars.com\" \"users/mattC\") = \"http://www.codewars.com/users/mattC\"));\n  (assert ((candidate \"https://www.reddit.com/r/dailyprogrammer/comments/2ofb7m/20140926_challenge_177_easy_morse_code\" \"upvote\") = \"https://www.reddit.com/r/dailyprogrammer/comments/2ofb7m/20140926_challenge_177_easy_morse_code/upvote\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_49061_format32BitHexStr", "language": "ml", "prompt": "(**format the given string which represents a valid 32-bit hexadecimal number.\nprefix \"0x\" will be added and will replace any valid prefix.\nalphabetic letter will be formatted into upper case.\n\"0\" will be used to fill the hexadecimal number if this number is represented as less than 8-letter.\nExmaple usage:\ninput: 0Xff  -> output:0x000000FF\ninput: Ab -> output: 0x000000AB\ninput 0xAf -> output: 0x000000AF\n:param hexStr:  a valid string representing a 32-bit hexadecimal number\n:return: a formatted string representing 32-bit hexadecimal number as described\n*)\nlet format32BitHexStr (hexStr : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_49061_format32BitHexStr.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = format32BitHexStr in\n  (assert ((candidate \"0xAF\") = \"0x000000AF\"));\n  (assert ((candidate \"0xAB\") = \"0x000000AB\"));\n  (assert ((candidate \"0XAB\") = \"0x000000AB\"));\n  (assert ((candidate \"aB\") = \"0x000000AB\"));\n  (assert ((candidate \"AB\") = \"0x000000AB\"));\n  (assert ((candidate \"0XFF\") = \"0x000000FF\"));\n  (assert ((candidate \"FF\") = \"0x000000FF\"));\n  (assert ((candidate \"AF\") = \"0x000000AF\"));\n  (assert ((candidate \"0xFF\") = \"0x000000FF\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_5015_SEARCH", "language": "ml", "prompt": "(**Returns the position at which a string is first found within text, ignoring case.\nFind is case-sensitive. The returned position is 1 if within_text starts with find_text.\nStart_num specifies the character at which to start the search, defaulting to 1 (the first\ncharacter of within_text).\nIf find_text is not found, or start_num is invalid, raises ValueError.\n>>> SEARCH(\"e\", \"Statements\", 6)\n7\n>>> SEARCH(\"margin\", \"Profit Margin\")\n8\n>>> SEARCH(\" \", \"Profit Margin\")\n7\n>>> SEARCH('\"', 'The \"boss\" is here.')\n5\n>>> SEARCH(\"gle\", \"Google\")\n4\n>>> SEARCH(\"GLE\", \"Google\")\n4\n*)\nlet SEARCH (find_text : string) (within_text : string) (start_num : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_5015_SEARCH.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = SEARCH in\n  (assert ((candidate \" \" \"Profit Margin\") = 7));\n  (assert ((candidate \"GLE\" \"Google\") = 4));\n  (assert ((candidate \"e\" \"Statements\" 6) = 7));\n  (assert ((candidate \"\"\" \"The \"boss\" is here.\") = 5));\n  (assert ((candidate \"e\" \"Statements\" 6) = 7));\n  (assert ((candidate \"\"\" \"The \"boss\" is here.\") = 5));\n  (assert ((candidate \"gle\" \"Google\") = 4));\n  (assert ((candidate \"margin\" \"Profit Margin\") = 8));\n  (assert ((candidate \" \" \"Profit Margin\") = 7));\n  (assert ((candidate \"gle\" \"Google\") = 4));\n  (assert ((candidate \"e\" \"Statements\" 6) = 7));\n  (assert ((candidate \"margin\" \"Profit Margin\") = 8));\n  (assert ((candidate \"GLE\" \"Google\") = 4));\n  (assert ((candidate \"g\" \"Google\" 4) = 4));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_50398_task2", "language": "ml", "prompt": "(**Second task that depends on the output of the first task.\n*)\nlet task2 (arg1 : int) :  bool *  string * string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_50398_task2.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = task2 in\n  (assert ((candidate 102) = (true, (\"arg1\", \"arg2\", \"arg3\"))));\n  (assert ((candidate 104) = (true, (\"arg1\", \"arg2\", \"arg3\"))));\n  (assert ((candidate 105) = (true, (\"arg1\", \"arg2\", \"arg3\"))));\n  (assert ((candidate 101) = (true, (\"arg1\", \"arg2\", \"arg3\"))));\n  (assert ((candidate 1) = (true, (\"arg1\", \"arg2\", \"arg3\"))));\n  (assert ((candidate 3) = (true, (\"arg1\", \"arg2\", \"arg3\"))));\n  (assert ((candidate 103) = (true, (\"arg1\", \"arg2\", \"arg3\"))));\n  (assert ((candidate 2) = (true, (\"arg1\", \"arg2\", \"arg3\"))));\n  (assert ((candidate 4) = (true, (\"arg1\", \"arg2\", \"arg3\"))));\n  (assert ((candidate 5) = (true, (\"arg1\", \"arg2\", \"arg3\"))));\n  (assert ((candidate 109) = (true, (\"arg1\", \"arg2\", \"arg3\"))));\n  (assert ((candidate 108) = (true, (\"arg1\", \"arg2\", \"arg3\"))));\n  (assert ((candidate 100) = (true, (\"arg1\", \"arg2\", \"arg3\"))));\n  (assert ((candidate 107) = (true, (\"arg1\", \"arg2\", \"arg3\"))));\n  (assert ((candidate 106) = (true, (\"arg1\", \"arg2\", \"arg3\"))));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_50616_suffixed_file_name", "language": "ml", "prompt": "(**Returns file path with appended string (preserving file type)\n:param file_path: (string) either relative or absolute path of file\n:param suffix_string: (string) string to append to the original file name\n:return: (string) suffixed file path\nexample:\n * append_path(\"foo.html.bar.html\", \"_BAZ\")\n * >>> \"foo.html.bar.html_BAZ.html\"\n*)\nlet suffixed_file_name (file_path : string) (suffix_string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_50616_suffixed_file_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = suffixed_file_name in\n  (assert ((candidate \"foo.html\" \"\") = \"foo.html\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_50913__normalize_block_name", "language": "ml", "prompt": "(**Implements Unicode name normalization for block names.\nRemoves white space, '-', '_' and forces lower case.\n*)\nlet _normalize_block_name (block_name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_50913__normalize_block_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _normalize_block_name in\n  (assert ((candidate \"A B C\") = \"abc\"));\n  (assert ((candidate \"Block_Name_ \") = \"blockname\"));\n  (assert ((candidate \"block-name\") = \"blockname\"));\n  (assert ((candidate \"foo bar\") = \"foobar\"));\n  (assert ((candidate \"foo\nbar\") = \"foobar\"));\n  (assert ((candidate \"ABC_DEF\") = \"abcdef\"));\n  (assert ((candidate \"foo\") = \"foo\"));\n  (assert ((candidate \"foo-bar\") = \"foobar\"));\n  (assert ((candidate \"block name\n\r\t\") = \"blockname\"));\n  (assert ((candidate \"\t\n\rfoo-bar\") = \"foobar\"));\n  (assert ((candidate \"ABC-DEF\") = \"abcdef\"));\n  (assert ((candidate \"foo\tbar\") = \"foobar\"));\n  (assert ((candidate \"Block-Name\n\r\t\") = \"blockname\"));\n  (assert ((candidate \"Block_Name-\") = \"blockname\"));\n  (assert ((candidate \"A  B  C\") = \"abc\"));\n  (assert ((candidate \"A-B-C\") = \"abc\"));\n  (assert ((candidate \"Block_Name_\") = \"blockname\"));\n  (assert ((candidate \"block_name\") = \"blockname\"));\n  (assert ((candidate \"foo_bar\") = \"foobar\"));\n  (assert ((candidate \"A_B_C\") = \"abc\"));\n  (assert ((candidate \"Block-Name \n\r\t\") = \"blockname\"));\n  (assert ((candidate \"ABC  DEF\") = \"abcdef\"));\n  (assert ((candidate \"  block-name \n\n\t\") = \"blockname\"));\n  (assert ((candidate \"block name\t\") = \"blockname\"));\n  (assert ((candidate \"blockname\") = \"blockname\"));\n  (assert ((candidate \"ABC\") = \"abc\"));\n  (assert ((candidate \"foo-bar_1\") = \"foobar1\"));\n  (assert ((candidate \"Block_Name\") = \"blockname\"));\n  (assert ((candidate \"foo-1_bar\") = \"foo1bar\"));\n  (assert ((candidate \"foo-bar-1\") = \"foobar1\"));\n  (assert ((candidate \"o-ya\") = \"oya\"));\n  (assert ((candidate \"block-name\r\n\t\") = \"blockname\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_51126_get_tag_line", "language": "ml", "prompt": "(**Get the revision hash for the tag matching the given project revision in\nthe given lines containing revision hashes. Uses the given array of tag\nprefix strings if provided. For example, given an array of tag prefixes\n[\"checker-framework-\", \"checkers-\"] and project revision \"2.0.0\", the\ntags named \"checker-framework-2.0.0\" and \"checkers-2.0.0\" are sought.\n*)\nlet get_tag_line (lines : string list) (revision : string) (tag_prefixes : string list) : string option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_51126_get_tag_line.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_tag_line in\n  (assert ((candidate [\"checkers-2.1.5\"; \"checkers-2.1.6\"] \"2.1.5\" [\"checker-framework-\"; \"checkers-\"]) = Some(\"checkers-2.1.5\")));\n  (assert ((candidate [\"checker-framework-1.0.0\"; \"checker-framework-1.0.1\"] \"1.0.1\" [\"checker-framework-\"]) = Some(\"checker-framework-1.0.1\")));\n  (assert ((candidate [\"checkers-2.1.6\"; \"checkers-2.1.5\"] \"2.1.6\" [\"checker-framework-\"; \"checkers-\"]) = Some(\"checkers-2.1.6\")));\n  (assert ((candidate [\"checker-framework-2.0.0\"; \"checker-framework-2.0.1\"] \"2.0.1\" [\"checker-framework-\"]) = Some(\"checker-framework-2.0.1\")));\n  (assert ((candidate [\"a\"; \"b\"; \"c\"] \"d\" [\"e\"; \"f\"]) = Some(None)));\n  (assert ((candidate [\"checker-framework-2.0.0\"; \"checker-framework-2.0.1\"; \"checker-framework-2.0.2\"] \"2.0.2\" [\"checker-framework-\"; \"checkers-\"]) = Some(\"checker-framework-2.0.2\")));\n  (assert ((candidate [\"checker-framework-2.1.10\"; \"checker-framework-2.1.11\"; \"checker-framework-2.2.0\"] \"2.2.0\" [\"checker-framework-\"; \"checkers-\"]) = Some(\"checker-framework-2.2.0\")));\n  (assert ((candidate [\"checker-framework-2.0.0\"; \"checker-framework-2.0.1\"; \"checker-framework-2.0.2\"] \"2.0.2\" []) = Some(None)));\n  (assert ((candidate [\"checker-framework-2.1.10\"; \"checker-framework-2.1.11\"; \"checker-framework-2.2.0\"] \"2.2.0\" [\"checker-framework-\"]) = Some(\"checker-framework-2.2.0\")));\n  (assert ((candidate [\"checkers-2.1.5\"; \"checkers-2.1.6\"] \"2.1.6\" [\"checker-framework-\"; \"checkers-\"]) = Some(\"checkers-2.1.6\")));\n  (assert ((candidate [\"checker-framework-2.1.6\"; \"checker-framework-2.1.5\"] \"2.1.6\" [\"checker-framework-\"; \"checkers-\"]) = Some(\"checker-framework-2.1.6\")));\n  (assert ((candidate [\"checker-framework-2.0.0\"; \"checker-framework-2.0.1\"] \"2.0.1\" [\"checkers-\"]) = Some(None)));\n  (assert ((candidate [\"checkers-2.1.6\"; \"checkers-2.1.5\"] \"2.1.5\" [\"checker-framework-\"; \"checkers-\"]) = Some(\"checkers-2.1.5\")));\n  (assert ((candidate [\"checker-framework-2.0.0\"; \"checker-framework-2.0.1\"; \"checker-framework-2.0.2\"] \"2.0.2\" [\"checker-framework-\"]) = Some(\"checker-framework-2.0.2\")));\n  (assert ((candidate [\"checker-framework-2.1.6\"; \"checker-framework-2.1.5\"] \"2.1.5\" [\"checker-framework-\"; \"checkers-\"]) = Some(\"checker-framework-2.1.5\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_51134_extract_class_label", "language": "ml", "prompt": "(**arg:\nfilename: string, e.g.\n'images/001.Black_footed_Albatross/Black_footed_Albatross_0001_2950163169.jpg'\n * return:\nA class label as integer, e.g. 1\n*)\nlet extract_class_label (filename : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_51134_extract_class_label.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = extract_class_label in\n  (assert ((candidate \"images/002.Laysan_Albatross/Laysan_Albatross_0004_2950165039.jpg\") = 2));\n  (assert ((candidate \"images/007.Parakeet_Auklet/Parakeet_Auklet_0002_2950163991.jpg\") = 7));\n  (assert ((candidate \"images/001.Black_footed_Albatross/Black_footed_Albatross_0001_2950163169.jpg\") = 1));\n  (assert ((candidate \"images/003.Sooty_Albatross/Sooty_Albatross_0005_2950164871.jpg\") = 3));\n  (assert ((candidate \"images/006.Least_Auklet/Least_Auklet_0001_2950163844.jpg\") = 6));\n  (assert ((candidate \"images/004.Groove_billed_Ani/Groove_billed_Ani_0001_2950166344.jpg\") = 4));\n  (assert ((candidate \"images/005.Crested_Auklet/Crested_Auklet_0005_2950164507.jpg\") = 5));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_51820_getcardinals", "language": "ml", "prompt": "(**Get lats and longs to mark on map\n:param minv:\n:type minv: float\n:param maxv:\n:type maxv: float\n:param stepv:\n:type stepv: int\n:return:\n:rtype: list\n*)\nlet getcardinals (minv : int) (maxv : int) (stepv : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_51820_getcardinals.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = getcardinals in\n  (assert ((candidate (~5) 5 1) = [(~5); (~4); (~3); (~2); (~1); 0; 1; 2; 3; 4]));\n  (assert ((candidate 0 360 360) = [0]));\n  (assert ((candidate 1 5 1) = [1; 2; 3; 4]));\n  (assert ((candidate 0 100 20) = [0; 20; 40; 60; 80]));\n  (assert ((candidate 2 9 2) = [2; 4; 6; 8]));\n  (assert ((candidate 0 360 90) = [0; 90; 180; 270]));\n  (assert ((candidate 0 10 6) = [0; 6]));\n  (assert ((candidate 1 10 1) = [1; 2; 3; 4; 5; 6; 7; 8; 9]));\n  (assert ((candidate 10 100 10) = [10; 20; 30; 40; 50; 60; 70; 80; 90]));\n  (assert ((candidate 0 10 1) = [0; 1; 2; 3; 4; 5; 6; 7; 8; 9]));\n  (assert ((candidate 0 5 2) = [0; 2; 4]));\n  (assert ((candidate 0 5 3) = [0; 3]));\n  (assert ((candidate 0 10 2) = [0; 2; 4; 6; 8]));\n  (assert ((candidate 0 5 1) = [0; 1; 2; 3; 4]));\n  (assert ((candidate 10 100 200) = []));\n  (assert ((candidate 20 100 10) = [20; 30; 40; 50; 60; 70; 80; 90]));\n  (assert ((candidate 360 0 360) = []));\n  (assert ((candidate 0 10 5) = [0; 5]));\n  (assert ((candidate 0 10 4) = [0; 4; 8]));\n  (assert ((candidate 10 100 100) = []));\n  (assert ((candidate 0 5 4) = [0; 4]));\n  (assert ((candidate 0 10 3) = [0; 3; 6; 9]));\n  (assert ((candidate 1 11 1) = [1; 2; 3; 4; 5; 6; 7; 8; 9; 10]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_51944_validate_stdout", "language": "ml", "prompt": "(**:param stdout:\n:return: true if stdout does not indicate test failure\n*)\nlet validate_stdout (stdout : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_51944_validate_stdout.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = validate_stdout in\n  (assert ((candidate \"Hello World\") = true));\n  (assert ((candidate \"Hello!!!PANIC!!! World\") = false));\n  (assert ((candidate \"Hello!!!PANIC!!!\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_52012_sqlite3_column_affinity", "language": "ml", "prompt": "(**Return the sqlite3 column affinity corresponding to a type string.\n*)\nlet sqlite3_column_affinity (column_type : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_52012_sqlite3_column_affinity.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sqlite3_column_affinity in\n  (assert ((candidate \"BLOB(12)\") = \"NONE\"));\n  (assert ((candidate \"VARCHAR(12)\") = \"TEXT\"));\n  (assert ((candidate \"CHARACTER VARYING\") = \"TEXT\"));\n  (assert ((candidate \"CHARACTER VARYING(12)\") = \"TEXT\"));\n  (assert ((candidate \"not a number\") = \"NUMERIC\"));\n  (assert ((candidate \"blob(12)\") = \"NONE\"));\n  (assert ((candidate \"DOUBLE\") = \"REAL\"));\n  (assert ((candidate \"DOUBLE(12)\") = \"REAL\"));\n  (assert ((candidate \"CHARACTER\") = \"TEXT\"));\n  (assert ((candidate \"CHARACTER(12)\") = \"TEXT\"));\n  (assert ((candidate \"text\") = \"TEXT\"));\n  (assert ((candidate \"TEXT\") = \"TEXT\"));\n  (assert ((candidate \"DOUBLE PRECISION(12)\") = \"REAL\"));\n  (assert ((candidate str \"1234567890123456789012345678901234567890\") = \"NUMERIC\"));\n  (assert ((candidate \"REAL\") = \"REAL\"));\n  (assert ((candidate \"CLOB\") = \"TEXT\"));\n  (assert ((candidate str (~1234567890123456789012345678901234567890)) = \"NUMERIC\"));\n  (assert ((candidate \"Int\") = \"INTEGER\"));\n  (assert ((candidate str \"-1234567890123456789012345678901234567890\") = \"NUMERIC\"));\n  (assert ((candidate \"BLOB\") = \"NONE\"));\n  (assert ((candidate \"FLOAT\") = \"REAL\"));\n  (assert ((candidate \"CHAR(12)\") = \"TEXT\"));\n  (assert ((candidate \"CLOB(12)\") = \"TEXT\"));\n  (assert ((candidate \"FLOAT(12)\") = \"REAL\"));\n  (assert ((candidate str 1234567890123456789012345678901234567890) = \"NUMERIC\"));\n  (assert ((candidate \"VARCHAR\") = \"TEXT\"));\n  (assert ((candidate \"DOUBLE PRECISION\") = \"REAL\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_5259_without_end_slash", "language": "ml", "prompt": "(**Makes sure there is no end slash at the end of a url.\n*)\nlet without_end_slash (url : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_5259_without_end_slash.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = without_end_slash in\n  (assert ((candidate \"www.python.org/books\") = \"www.python.org/books\"));\n  (assert ((candidate \"http://python.org/\") = \"http://python.org\"));\n  (assert ((candidate \"http://www.hackerrank.com/challenges/nested-list/\") = \"http://www.hackerrank.com/challenges/nested-list\"));\n  (assert ((candidate \"http://python.org/books\") = \"http://python.org/books\"));\n  (assert ((candidate \"http://www.python.org/\") = \"http://www.python.org\"));\n  (assert ((candidate \"python.org/books\") = \"python.org/books\"));\n  (assert ((candidate \"www.python.org/\") = \"www.python.org\"));\n  (assert ((candidate \"python.org/books/\") = \"python.org/books\"));\n  (assert ((candidate \"http://python.org\") = \"http://python.org\"));\n  (assert ((candidate \"http://www.python.org/books\") = \"http://www.python.org/books\"));\n  (assert ((candidate \"www.python.org\") = \"www.python.org\"));\n  (assert ((candidate \"http://www.python.org/books/\") = \"http://www.python.org/books\"));\n  (assert ((candidate \"python.org/\") = \"python.org\"));\n  (assert ((candidate \"http://www.python.org\") = \"http://www.python.org\"));\n  (assert ((candidate \"www.python.org/books/\") = \"www.python.org/books\"));\n  (assert ((candidate \"http://python.org/books/\") = \"http://python.org/books\"));\n  (assert ((candidate \"http://www.hackerrank.com/challenges/nested-list\") = \"http://www.hackerrank.com/challenges/nested-list\"));\n  (assert ((candidate \"python.org\") = \"python.org\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_52634__clear_data", "language": "ml", "prompt": "(**Check and clear data\n*)\nlet _clear_data (data : (string, int) list) (need_fields_tuple :  string * string) : (string, int) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_52634__clear_data.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _clear_data in\n  (assert ((candidate [(\"A\", 1); (\"B\", 2); (\"C\", 3)] (\"A\", \"C\")) = [(\"A\", 1); (\"C\", 3)]));\n  (assert ((candidate [(\"A\", 1); (\"B\", 2); (\"C\", 3)] (\"A\", \"B\")) = [(\"A\", 1); (\"B\", 2)]));\n  (assert ((candidate [(\"A\", 1); (\"B\", 2); (\"C\", 3)] ()) = []));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3)] (\"a\", \"b\")) = [(\"a\", 1); (\"b\", 2)]));\n  (assert ((candidate [(\"A\", 1); (\"B\", 2); (\"C\", 3)] (\"C\", \"B\")) = [(\"C\", 3); (\"B\", 2)]));\n  (assert ((candidate [(\"a\", 1); (\"b\", 2); (\"c\", 3)] ()) = []));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_52943_Hubble", "language": "ml", "prompt": "(**LCDM AP parameter auxiliary function\n*)\nlet Hubble (Om : int) (z : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_52943_Hubble.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = Hubble in\n  (assert ((candidate 1 0) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_5314_int_to_float", "language": "ml", "prompt": "(**Converts a uniformly random [[64-bit computing|64-bit]]\ninteger to uniformly random floating point number on interval <math>[0, 1)</math>.\n*)\nlet int_to_float (value : int) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_5314_int_to_float.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = int_to_float in\n  (assert ((candidate 0) = 0.0));\n  (assert ((candidate 18446744073709551615) = 0.9999999999999999));\n  (assert ((candidate (~1)) = 0.9999999999999999));\n  (assert ((candidate 0) = 0.0));\n  (assert ((candidate 0) = 0.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_54360_has_seven", "language": "ml", "prompt": "(**Returns True if at least one of the digits of k is a 7, False otherwise.\n>>> has_seven(3)\nFalse\n>>> has_seven(7)\nTrue\n>>> has_seven(2734)\nTrue\n>>> has_seven(2634)\nFalse\n>>> has_seven(734)\nTrue\n>>> has_seven(7777)\nTrue\n>>> from construct_check import check\n>>> check(HW_SOURCE_FILE, 'has_seven',\n...       ['Assign', 'AugAssign'])\nTrue\n*)\nlet has_seven (k : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_54360_has_seven.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = has_seven in\n  (assert ((candidate 7) = true));\n  (assert ((candidate 734) = true));\n  (assert ((candidate 11235813) = false));\n  (assert ((candidate 2734) = true));\n  (assert ((candidate 3) = false));\n  (assert ((candidate 7777) = true));\n  (assert ((candidate 1234) = false));\n  (assert ((candidate 300000000) = false));\n  (assert ((candidate 2634) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_5448_POS", "language": "ml", "prompt": "(**Returns 'F' if position indicator is present. The AllSportCG sends a * in a specific position to indicate which\nteam has posession, and this changes that character to an 'F'. Using font Mattbats, F is a football.\n*)\nlet POS (POSInt : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_5448_POS.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = POS in\n  (assert ((candidate 24) = \"\"));\n  (assert ((candidate 29) = \"\"));\n  (assert ((candidate 14) = \"\"));\n  (assert ((candidate 21) = \"\"));\n  (assert ((candidate 20) = \"\"));\n  (assert ((candidate 42) = \"F\"));\n  (assert ((candidate 0) = \"\"));\n  (assert ((candidate 13) = \"\"));\n  (assert ((candidate 19) = \"\"));\n  (assert ((candidate 7) = \"\"));\n  (assert ((candidate 25) = \"\"));\n  (assert ((candidate 27) = \"\"));\n  (assert ((candidate 34) = \"\"));\n  (assert ((candidate ) = \"F\"));\n  (assert ((candidate 39) = \"\"));\n  (assert ((candidate 28) = \"\"));\n  (assert ((candidate 5) = \"\"));\n  (assert ((candidate 37) = \"\"));\n  (assert ((candidate 2) = \"\"));\n  (assert ((candidate 11) = \"\"));\n  (assert ((candidate 12) = \"\"));\n  (assert ((candidate 18) = \"\"));\n  (assert ((candidate 41) = \"\"));\n  (assert ((candidate 23) = \"\"));\n  (assert ((candidate 40) = \"\"));\n  (assert ((candidate 4) = \"\"));\n  (assert ((candidate 3) = \"\"));\n  (assert ((candidate 36) = \"\"));\n  (assert ((candidate 43) = \"\"));\n  (assert ((candidate 17) = \"\"));\n  (assert ((candidate 30) = \"\"));\n  (assert ((candidate 9) = \"\"));\n  (assert ((candidate ) = \"\"));\n  (assert ((candidate 32) = \"\"));\n  (assert ((candidate 42) = \"F\"));\n  (assert ((candidate 10) = \"\"));\n  (assert ((candidate 35) = \"\"));\n  (assert ((candidate 38) = \"\"));\n  (assert ((candidate 16) = \"\"));\n  (assert ((candidate 22) = \"\"));\n  (assert ((candidate 1) = \"\"));\n  (assert ((candidate 6) = \"\"));\n  (assert ((candidate 26) = \"\"));\n  (assert ((candidate 8) = \"\"));\n  (assert ((candidate 31) = \"\"));\n  (assert ((candidate 15) = \"\"));\n  (assert ((candidate 33) = \"\"));\n  (assert ((candidate 3) = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_55281_get_name_from_selector", "language": "ml", "prompt": "(**A basic method to get the name from a name selector.\n*)\nlet get_name_from_selector (selector : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_55281_get_name_from_selector.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_name_from_selector in\n  (assert ((candidate \"name=x\") = \"x\"));\n  (assert ((candidate \"&\") = \"\"));\n  (assert ((candidate \"x\") = \"x\"));\n  (assert ((candidate \"&x\") = \"x\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_55787_get_custom_kickstart_name", "language": "ml", "prompt": "(**This function is to generate a name for the custom kickstart file based on the type of OS and server serial number\nArguments:\n * os_type {string}              -- Type of the opertaing system - RHEL\n * server_serial_number {string} -- Server serial number\nReturns:\n * string -- custom kickstart filename\n*)\nlet get_custom_kickstart_name (os_type : string) (server_serial_number : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_55787_get_custom_kickstart_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_custom_kickstart_name in\n  (assert ((candidate \"RHEL\" \"8888888888\") = \"RHEL8888888888_ks.cfg\"));\n  (assert ((candidate \"RHEL\" \"123456\") = \"RHEL123456_ks.cfg\"));\n  (assert ((candidate \"RHEL\" \"C2251756072\") = \"RHELC2251756072_ks.cfg\"));\n  (assert ((candidate \"RHEL\" \"7777777777\") = \"RHEL7777777777_ks.cfg\"));\n  (assert ((candidate \"RHEL\" \"C2251756072\") = \"RHELC2251756072_ks.cfg\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_56082_drop_role", "language": "ml", "prompt": "(**Helper method to construct SQL: drop role.\n*)\nlet drop_role (role : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_56082_drop_role.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = drop_role in\n  (assert ((candidate ) = \"DROP ROLE IF EXISTS my_role;\"));\n  (assert ((candidate \"a\") = \"DROP ROLE IF EXISTS a;\"));\n  (assert ((candidate \"my_role\") = \"DROP ROLE IF EXISTS my_role;\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_56324_dice_roll", "language": "ml", "prompt": "(**Dice roll as number of rolls (eg 6) or as num and sides (2x6)\n*)\nlet dice_roll (arg : string) :  int * int option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_56324_dice_roll.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = dice_roll in\n  (assert ((candidate \"1x-2\") = Some(None)));\n  (assert ((candidate \"x5y6\") = Some(None)));\n  (assert ((candidate \"5x10\") = Some((5, 10))));\n  (assert ((candidate \"5x6 3\") = Some(None)));\n  (assert ((candidate \"5 6\") = Some(None)));\n  (assert ((candidate \"6\") = Some((6, 6))));\n  (assert ((candidate \"5x6x3x9x8\") = Some(None)));\n  (assert ((candidate \"x5x6\") = Some(None)));\n  (assert ((candidate \"2x0\") = Some(None)));\n  (assert ((candidate \" \") = Some(None)));\n  (assert ((candidate \"5y6x\") = Some(None)));\n  (assert ((candidate \"4x6\") = Some((4, 6))));\n  (assert ((candidate \"18x20\") = Some((18, 20))));\n  (assert ((candidate \"x4\") = Some(None)));\n  (assert ((candidate \"5x6x3\") = Some(None)));\n  (assert ((candidate \"5x12\") = Some((5, 12))));\n  (assert ((candidate \"0x1\") = Some(None)));\n  (assert ((candidate \"5x6y3\") = Some(None)));\n  (assert ((candidate \"-1x2\") = Some(None)));\n  (assert ((candidate \"1x1\") = Some((1, 1))));\n  (assert ((candidate \"2x4\") = Some((2, 4))));\n  (assert ((candidate \"\n\") = Some(None)));\n  (assert ((candidate \"1x0\") = Some(None)));\n  (assert ((candidate \"5y6\") = Some(None)));\n  (assert ((candidate \"2\") = Some((2, 6))));\n  (assert ((candidate \"2x\") = Some(None)));\n  (assert ((candidate \"\") = Some(None)));\n  (assert ((candidate \"\t\") = Some(None)));\n  (assert ((candidate \"0x0\") = Some(None)));\n  (assert ((candidate \"2x6\") = Some((2, 6))));\n  (assert ((candidate \"3x6\") = Some((3, 6))));\n  (assert ((candidate \"5x6x3x9\") = Some(None)));\n  (assert ((candidate \"1x2\") = Some((1, 2))));\n  (assert ((candidate \"5x6x\") = Some(None)));\n  (assert ((candidate \"-1x-2\") = Some(None)));\n  (assert ((candidate \"1x10\") = Some((1, 10))));\n  (assert ((candidate \"5y6x3\") = Some(None)));\n  (assert ((candidate \"5x6\") = Some((5, 6))));\n  (assert ((candidate \"5x6y\") = Some(None)));\n  (assert ((candidate \"1x100\") = Some((1, 100))));\n  (assert ((candidate \"x5x6y\") = Some(None)));\n  (assert ((candidate \"10x4\") = Some((10, 4))));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_56391_charCodeAt", "language": "ml", "prompt": "(**Returns the Unicode value of the character at the specified location.\n@param - index The zero-based index of the desired character.\nIf there is no character at the specified index, NaN is returned.\nThis was added for compatibility with python\n*)\nlet charCodeAt (src : string) (pos : int) : int option =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_56391_charCodeAt.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = charCodeAt in\n  (assert ((candidate \"\" 0) = Some(None)));\n  (assert ((candidate \"abc\" (~2)) = Some(98)));\n  (assert ((candidate \"abc\" (~3)) = Some(97)));\n  (assert ((candidate \"\" (~1)) = Some(None)));\n  (assert ((candidate \"hello world\" 21) = Some(None)));\n  (assert ((candidate \"abc\" 3) = Some(None)));\n  (assert ((candidate \"abc\" 3) = Some(None)));\n  (assert ((candidate \"abc\" 1) = Some(98)));\n  (assert ((candidate \"hello world\" 1) = Some(101)));\n  (assert ((candidate \"abc\" 0) = Some(97)));\n  (assert ((candidate \"abc\" (~4)) = Some(None)));\n  (assert ((candidate \"abc\" 2) = Some(99)));\n  (assert ((candidate \"hello world\" 2) = Some(108)));\n  (assert ((candidate \"\ud83d\ude0a\ud83d\udc0d\" 3) = Some(None)));\n  (assert ((candidate \"abc\" 2) = Some(99)));\n  (assert ((candidate \"\ud83d\ude0a\ud83d\udc0d\" (~4)) = Some(None)));\n  (assert ((candidate \"abc\" 0) = Some(97)));\n  (assert ((candidate \"abc\" 1) = Some(98)));\n  (assert ((candidate \"\" 2) = Some(None)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_56448_filter", "language": "ml", "prompt": "(**Filters a plain text and makes it acceptable for docbook\n*)\nlet filter (s : string option) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_56448_filter.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = filter in\n  (assert ((candidate Some(\"abc\")) = \"abc\"));\n  (assert ((candidate Some(\"<><>\")) = \"&lt;&gt;&lt;&gt;\"));\n  (assert ((candidate Some(\">\")) = \"&gt;\"));\n  (assert ((candidate Some(\"<>\")) = \"&lt;&gt;\"));\n  (assert ((candidate Some(\"foo\")) = \"foo\"));\n  (assert ((candidate Some(\"<Hello world>\")) = \"&lt;Hello world&gt;\"));\n  (assert ((candidate Some(\"<\")) = \"&lt;\"));\n  (assert ((candidate Some(\"a < b\")) = \"a &lt; b\"));\n  (assert ((candidate Some(None)) = \"\"));\n  (assert ((candidate Some(\"this is plain text\")) = \"this is plain text\"));\n  (assert ((candidate Some(\"Hello world!\")) = \"Hello world!\"));\n  (assert ((candidate Some(\"><\")) = \"&gt;&lt;\"));\n  (assert ((candidate Some(\"a\")) = \"a\"));\n  (assert ((candidate Some(\"\")) = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_56655_bool_to_string", "language": "ml", "prompt": "(**Convert a boolean type to string.\nArgs:\n * b (bool): A Boolean.\nRaises:\n * TypeError\nReturns:\n * str: String representation of a bool type.\n*)\nlet bool_to_string (b : bool) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_56655_bool_to_string.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = bool_to_string in\n  (assert ((candidate bool false) = candidate false));\n  (assert ((candidate bool true) = candidate true));\n  (assert ((candidate true) = \"true\"));\n  (assert ((candidate false) = \"false\"));\n  (assert ((candidate true) = candidate bool true));\n  (assert ((candidate bool false) = \"false\"));\n  (assert ((candidate false) = candidate bool false));\n  (assert ((candidate bool true) = \"true\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_56738_sum_of_powers", "language": "ml", "prompt": "(**Sums each number raised to power\nEx: sum_of_powers([2, 3, 4], 2) = 2^2 + 3^2 + 4^2 = 29\n*)\nlet sum_of_powers (numbers : int list) (power : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_56738_sum_of_powers.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sum_of_powers in\n  (assert ((candidate [1; 2; 3] 3) = 36));\n  (assert ((candidate [2; 3; 4] 2) = 29));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_56766_factorial", "language": "ml", "prompt": "(**Returns the factorial of the number, the product of all positive integers smaller or equal to the number.\nBy convention an empty product is considered 1, meaning factorial(0) will return 1.\n:param k: A positive integer\n:return: The factorial of that integer\n*)\nlet factorial (k : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_56766_factorial.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = factorial in\n  (assert ((candidate 17) = 355687428096000));\n  (assert ((candidate 9) = 362880));\n  (assert ((candidate 20) = 2432902008176640000));\n  (assert ((candidate 5) = 120));\n  (assert ((candidate 11) = 39916800));\n  (assert ((candidate 14) = 87178291200));\n  (assert ((candidate 10) = 3628800));\n  (assert ((candidate 0) = 1));\n  (assert ((candidate 12) = 479001600));\n  (assert ((candidate 8) = 40320));\n  (assert ((candidate 13) = 6227020800));\n  (assert ((candidate 15) = 1307674368000));\n  (assert ((candidate 6) = 720));\n  (assert ((candidate 18) = 6402373705728000));\n  (assert ((candidate 4) = 24));\n  (assert ((candidate 3) = 6));\n  (assert ((candidate 16) = 20922789888000));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 7) = 5040));\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 19) = 121645100408832000));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_57139_build_type_flag", "language": "ml", "prompt": "(**returns flags specific to the build type (Debug, Release, etc.)\n(-s, -g, /Zi, etc.)\n*)\nlet build_type_flag (compiler : string option) (build_type : string option) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_57139_build_type_flag.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = build_type_flag in\n  (assert ((candidate Some(\"Visual Studio\") Some(\"Release\")) = \"\"));\n  (assert ((candidate Some(\"Visual Studio\") Some(\"Debug\")) = \"-Zi\"));\n  (assert ((candidate Some(\"foo\") Some(\"RelWithDebInfo\")) = \"\"));\n  (assert ((candidate Some(None) Some(\"Release\")) = \"\"));\n  (assert ((candidate Some(None) Some(\"Release\")) = \"\"));\n  (assert ((candidate Some(\"Visual Studio\") Some(\"RelWithDebInfo\")) = \"\"));\n  (assert ((candidate Some(\"Visual Studio\") Some(None)) = \"\"));\n  (assert ((candidate Some(\"foo\") Some(None)) = \"\"));\n  (assert ((candidate Some(\"foo\") Some(\"Release\")) = \"\"));\n  (assert ((candidate Some(None) Some(\"RelWithDebInfo\")) = \"\"));\n  (assert ((candidate Some(None) Some(\"Debug\")) = \"\"));\n  (assert ((candidate Some(None) Some(None)) = \"\"));\n  (assert ((candidate Some(\"Visual Studio\") Some(\"Debug\")) = \"-Zi\"));\n  (assert ((candidate Some(\"Visual Studio\") Some(None)) = \"\"));\n  (assert ((candidate Some(\"gcc\") Some(\"Debug\")) = \"-g\"));\n  (assert ((candidate Some(\"gcc\") Some(None)) = \"\"));\n  (assert ((candidate Some(\"gcc\") Some(\"Release\")) = \"-s\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_57161_remove_cdata_tags_from_every_node", "language": "ml", "prompt": "(**[removes a CDATA tag from every node in the document]\n*)\nlet remove_cdata_tags_from_every_node (content : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_57161_remove_cdata_tags_from_every_node.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = remove_cdata_tags_from_every_node in\n  (assert ((candidate \"<![CDATA[this is a cdata]]>\") = \"<this is a cdata>\"));\n  (assert ((candidate \"this is not a cdata\") = \"this is not a cdata\"));\n  (assert ((candidate \"<div>Hi there</div>\") = \"<div>Hi there</div>\"));\n  (assert ((candidate \"I am not a CDATA tag!\") = \"I am not a CDATA tag!\"));\n  (assert ((candidate \"<a><b><![CDATA[this is a cdata]]></b></a>\") = \"<a><b><this is a cdata></b></a>\"));\n  (assert ((candidate \"<a><b><![CDATA[this is not a cdata]]></b><![CDATA[so this one too]]></a>\") = \"<a><b><this is not a cdata></b><so this one too></a>\"));\n  (assert ((candidate \"<![CDATA[this is not a cdata]]><![CDATA[so this one too]]>\") = \"<this is not a cdata><so this one too>\"));\n  (assert ((candidate \"\") = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_57396_convert_case", "language": "ml", "prompt": "(**Given a string in snake case, conver to CamelCase\n*)\nlet convert_case (s : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_57396_convert_case.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = convert_case in\n  (assert ((candidate \"this_is_snake_case\") = \"ThisIsSnakeCase\"));\n  (assert ((candidate \"James\") = \"James\"));\n  (assert ((candidate \"sally_brown\") = \"SallyBrown\"));\n  (assert ((candidate \"this_is_snake_case_too\") = \"ThisIsSnakeCaseToo\"));\n  (assert ((candidate \"Sally_Brown\") = \"SallyBrown\"));\n  (assert ((candidate \"sAlly_bRoWn\") = \"SallyBrown\"));\n  (assert ((candidate \"this__is__snake__case_too\") = \"ThisIsSnakeCaseToo\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_57398_correct_sentence", "language": "ml", "prompt": "(**returns a corrected sentence which starts with a capital letter\nand ends with a dot.\n*)\nlet correct_sentence (text : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_57398_correct_sentence.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = correct_sentence in\n  (assert ((candidate \"hello world.\") = \"Hello world.\"));\n  (assert ((candidate \"hello world\") = \"Hello world.\"));\n  (assert ((candidate \"hello world.\") = \"Hello world.\"));\n  (assert ((candidate \"hello world\") = \"Hello world.\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_58289_api_repo_url", "language": "ml", "prompt": "(**With the supplied organization name, constructs a GitHub API URL\n:param org_name: GitHub organization name\n:return: URL to GitHub API to query org's repos\n*)\nlet api_repo_url (org_name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_58289_api_repo_url.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = api_repo_url in\n  (assert ((candidate \"github\") = \"https://api.github.com/orgs/github/repos\"));\n  (assert ((candidate \"org2\") = \"https://api.github.com/orgs/org2/repos\"));\n  (assert ((candidate \"google\") = \"https://api.github.com/orgs/google/repos\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_5841__root_sort_key", "language": "ml", "prompt": "(**Allow root comparison when sorting.\nArgs:\n * root (str or re.Pattern): Root.\nReturns:\n * str: Comparable root string.\n*)\nlet _root_sort_key (root : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_5841__root_sort_key.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _root_sort_key in\n  (assert ((candidate \"^/a/b/?$\") = \"^/a/b/?$\"));\n  (assert ((candidate \"^/foo/bar/baz/quux/a[b]c.*$\") = \"^/foo/bar/baz/quux/a[b]c.*$\"));\n  (assert ((candidate \"^/foo/bar/baz/quux/a[b]c.*\") = \"^/foo/bar/baz/quux/a[b]c.*\"));\n  (assert ((candidate \".*\") = \".*\"));\n  (assert ((candidate \"foo\") = \"foo\"));\n  (assert ((candidate \"/?$\") = \"/?$\"));\n  (assert ((candidate \"^/$\") = \"^/$\"));\n  (assert ((candidate \"^/foo/bar/baz/quux/.*\") = \"^/foo/bar/baz/quux/.*\"));\n  (assert ((candidate \"root_2\") = \"root_2\"));\n  (assert ((candidate \"^/foo/bar/baz/quux$\") = \"^/foo/bar/baz/quux$\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_59500_lr_schedule_adam", "language": "ml", "prompt": "(**Learning Rate Schedule\n# Arguments\n * epoch (int): The number of epochs\n# Returns\n * lr (float32): learning rate\n*)\nlet lr_schedule_adam (epoch : int) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_59500_lr_schedule_adam.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = lr_schedule_adam in\n  (assert ((candidate 100) = 0.001));\n  (assert ((candidate 400) = 1e-05.0));\n  (assert ((candidate 200) = 0.0005));\n  (assert ((candidate 10) = 0.001));\n  (assert ((candidate 0) = 0.001));\n  (assert ((candidate 50) = 0.001));\n  (assert ((candidate 50) = 0.001));\n  (assert ((candidate 200) = 0.0005));\n  (assert ((candidate 149) = 0.0005));\n  (assert ((candidate 0) = 0.001));\n  (assert ((candidate 151) = 0.0005));\n  (assert ((candidate 99) = 0.001));\n  (assert ((candidate 49) = 0.001));\n  (assert ((candidate 150) = 0.0005));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_60112_set_to_dm_limits", "language": "ml", "prompt": "(**Check that the values for piston, tip, and tilt are not exceeding the hardware\nlimit and reset to limit if limit is exceeded. These limits are the same as what\nthe IrisAO GUI has set.\n:param ppt_list: list, of tuples existing of piston, tip, tilt, values for each\n * segment in a pupil, in DM units\n:param limit: float, in DM units. Default = 5.\n:return: list of tuples of the piston, tip, tilt values in DM units for each segment listed\n * such that none of the values exceed the limit\n*)\nlet set_to_dm_limits (ptt_list :  float * float * float * float list) (limit : float) :  float * float * float * float list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_60112_set_to_dm_limits.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = set_to_dm_limits in\n  (assert ((candidate [(0.2, 0.5, 0.3, 1000.0); (0.5, 0.5, 0.3, 0.1); (0.4, 0.5, 0.3, 0.1)]) = [(0.2, 0.5, 0.3, 5.0); (0.5, 0.5, 0.3, 0.1); (0.4, 0.5, 0.3, 0.1)]));\n  (assert ((candidate [(0.2, 0.5, 0.3, 0.2); (0.5, 0.5, 0.3, 0.1); (0.4, 0.5, 0.3, 0.1)]) = [(0.2, 0.5, 0.3, 0.2); (0.5, 0.5, 0.3, 0.1); (0.4, 0.5, 0.3, 0.1)]));\n  (assert ((candidate [(0.2, 0.5, 0.3, 0.2); (0.5, 0.5, 0.3, 0.1); (0.4, 0.5, 0.3, 0.1)] 1.0) = [(0.2, 0.5, 0.3, 0.2); (0.5, 0.5, 0.3, 0.1); (0.4, 0.5, 0.3, 0.1)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_60491_prime_factors", "language": "ml", "prompt": "(**Compute the prime factors of the given number\n:param n: Number you want to compute the prime factors (intger)\n:return: Prime factors of the given number (list of integer)\n*)\nlet prime_factors (n : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_60491_prime_factors.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = prime_factors in\n  (assert ((candidate 15) = [3; 5]));\n  (assert ((candidate 21) = [3; 7]));\n  (assert ((candidate 4) = [2; 2]));\n  (assert ((candidate 6) = [2; 3]));\n  (assert ((candidate 19) = [19]));\n  (assert ((candidate 13) = [13]));\n  (assert ((candidate 12) = [2; 2; 3]));\n  (assert ((candidate 26) = [2; 13]));\n  (assert ((candidate 3) = [3]));\n  (assert ((candidate 8) = [2; 2; 2]));\n  (assert ((candidate 10) = [2; 5]));\n  (assert ((candidate 0) = []));\n  (assert ((candidate 2) = [2]));\n  (assert ((candidate 24) = [2; 2; 2; 3]));\n  (assert ((candidate 18) = [2; 3; 3]));\n  (assert ((candidate 1) = []));\n  (assert ((candidate 16) = [2; 2; 2; 2]));\n  (assert ((candidate 20) = [2; 2; 5]));\n  (assert ((candidate 23) = [23]));\n  (assert ((candidate 14) = [2; 7]));\n  (assert ((candidate 22) = [2; 11]));\n  (assert ((candidate 11) = [11]));\n  (assert ((candidate 9) = [3; 3]));\n  (assert ((candidate 25) = [5; 5]));\n  (assert ((candidate 5) = [5]));\n  (assert ((candidate 17) = [17]));\n  (assert ((candidate 7) = [7]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_6077_get_index_str", "language": "ml", "prompt": "(**To convert an int 'i' to a string.\nParameters\n----------\nn : int\n * Order to put 0 if necessary.\ni : int\n * The number to convert.\nReturns\n-------\nres : str\n * The number as a string.\nExamples\n--------\n```python\n * getIndexStr(100,15)\n```\nOut:\n```\n * '015'\n```\n*)\nlet get_index_str (n : int) (i : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_6077_get_index_str.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_index_str in\n  (assert ((candidate 10 1) = \"01\"));\n  (assert ((candidate 100 100) = \"100\"));\n  (assert ((candidate 10 10) = \"10\"));\n  (assert ((candidate 10 0) = \"00\"));\n  (assert ((candidate 100 0) = \"000\"));\n  (assert ((candidate 10 9) = \"09\"));\n  (assert ((candidate 10 10) = \"10\"));\n  (assert ((candidate 1 1) = str 1));\n  (assert ((candidate 20 10) = \"10\"));\n  (assert ((candidate 100 15) = \"015\"));\n  (assert ((candidate 100 99) = \"099\"));\n  (assert ((candidate 0 0) = \"0\"));\n  (assert ((candidate 10 2) = \"02\"));\n  (assert ((candidate 10 10) = \"10\"));\n  (assert ((candidate 1 0) = \"0\"));\n  (assert ((candidate 100 15) = \"015\"));\n  (assert ((candidate 1 1) = \"1\"));\n  (assert ((candidate 100 15) = \"015\"));\n  (assert ((candidate 1 1) = \"1\"));\n  (assert ((candidate 100 10) = \"010\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_61119__topo_to_sphere", "language": "ml", "prompt": "(**Convert 2D topo coordinates to spherical.\n*)\nlet _topo_to_sphere (theta : float) (radius : float) :  float * float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_61119__topo_to_sphere.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _topo_to_sphere in\n  (assert ((candidate 0.0 0.5) = (0.0, 0.0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_6150__dof", "language": "ml", "prompt": "(**Returns the degrees of freedom for the chi-2 distribution from the mean and\nvariance of the uncertainty model, as reported in equation 5.5 of Al Atik\n(2015)\n*)\nlet _dof (mean_tau : float) (sd_tau2 : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_6150__dof.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _dof in\n  (assert ((candidate ) = candidate 0.1 0.001));\n  (assert ((candidate 1.0 1.0) = 2.0));\n  (assert ((candidate 1.0 1.0) = 2.0));\n  (assert ((candidate 0.1) = candidate 0.1 0.001));\n  (assert ((candidate 2.0 8.0) = 0.5));\n  (assert ((candidate 1.0 2.0) = 0.5));\n  (assert ((candidate 2.0 2.0) = 8.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_61922_http_verifier", "language": "ml", "prompt": "(**verifies if the url starts with\nhttp:// or https://. If not, http://\nis put in the start of url\n:param url: url to be verified\n:return: url with http://\n*)\nlet http_verifier (url : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_61922_http_verifier.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = http_verifier in\n  (assert ((candidate \"http://www.codewars.com\") = \"http://www.codewars.com\"));\n  (assert ((candidate \"http://www.codewars.com/users/GiacomoSorbi?ref=codewars\") = \"http://www.codewars.com/users/GiacomoSorbi?ref=codewars\"));\n  (assert ((candidate \"http://foo.bar\") = \"http://foo.bar\"));\n  (assert ((candidate \"http://www.codewars.com/users/GiacomoSorbi?ref=codewars&foo=bar\") = \"http://www.codewars.com/users/GiacomoSorbi?ref=codewars&foo=bar\"));\n  (assert ((candidate \"http://google.com\") = \"http://google.com\"));\n  (assert ((candidate \"http://www.codewars.com/users/GiacomoSorbi?ref=other\") = \"http://www.codewars.com/users/GiacomoSorbi?ref=other\"));\n  (assert ((candidate \"https://www.foo.bar\") = \"https://www.foo.bar\"));\n  (assert ((candidate \"https://youtube.com\") = \"https://youtube.com\"));\n  (assert ((candidate \"http://www.python.org/\") = \"http://www.python.org/\"));\n  (assert ((candidate \"codewars.com\") = \"http://codewars.com\"));\n  (assert ((candidate \"www.foo.bar\") = \"http://www.foo.bar\"));\n  (assert ((candidate \"https://foo.bar\") = \"https://foo.bar\"));\n  (assert ((candidate \"www.codewars.com\") = \"http://www.codewars.com\"));\n  (assert ((candidate \"http://www.codewars.com/users/GiacomoSorbi?ref=mycodewars\") = \"http://www.codewars.com/users/GiacomoSorbi?ref=mycodewars\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_61942_write_var_length", "language": "ml", "prompt": "(**Take a numerical value, and convert it to a 7-bit packed string\nwith high bit of each byte set as a flag to indicate to the reader that\nthe value that follows in the following byte is to be consumed as well.\n*)\nlet write_var_length (var : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_61942_write_var_length.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = write_var_length in\n  (assert ((candidate 23) = \"\u0017\"));\n  (assert ((candidate 1) = \"\u0001\"));\n  (assert ((candidate 127) = \"\u007f\"));\n  (assert ((candidate 268435455) = \"\u00ff\u00ff\u00ff\u007f\"));\n  (assert ((candidate 16384) = \"\u0081\u0080\u0000\"));\n  (assert ((candidate 16383) = \"\u00ff\u007f\"));\n  (assert ((candidate 268435456) = \"\u0081\u0080\u0080\u0080\u0000\"));\n  (assert ((candidate 0) = \"\u0000\"));\n  (assert ((candidate 128) = \"\u0081\u0000\"));\n  (assert ((candidate 0) = \"\u0000\"));\n  (assert ((candidate 127) = chr 127));\n  (assert ((candidate 2097151) = \"\u00ff\u00ff\u007f\"));\n  (assert ((candidate 1) = \"\u0001\"));\n  (assert ((candidate 127) = \"\u007f\"));\n  (assert ((candidate 2097152) = \"\u0081\u0080\u0080\u0000\"));\n  (assert ((candidate 1) = chr 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_62278_fibonacci", "language": "ml", "prompt": "(**Returns the n-th number in the Fibonacci sequence.\nParameters\n----------\nn: int\n * The n-th number in the Fibonacci sequence.\n*)\nlet fibonacci (n : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_62278_fibonacci.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = fibonacci in\n  (assert ((candidate 12) = 144));\n  (assert ((candidate 18) = 2584));\n  (assert ((candidate 2) = 1));\n  (assert ((candidate 19) = 4181));\n  (assert ((candidate 8) = 21));\n  (assert ((candidate 7) = 13));\n  (assert ((candidate 22) = 17711));\n  (assert ((candidate 25) = 75025));\n  (assert ((candidate 14) = 377));\n  (assert ((candidate 15) = 610));\n  (assert ((candidate 21) = 10946));\n  (assert ((candidate 13) = 233));\n  (assert ((candidate 11) = 89));\n  (assert ((candidate 26) = 121393));\n  (assert ((candidate 24) = 46368));\n  (assert ((candidate 6) = 8));\n  (assert ((candidate 9) = 34));\n  (assert ((candidate 1) = 1));\n  (assert ((candidate 20) = 6765));\n  (assert ((candidate 3) = 2));\n  (assert ((candidate 27) = 196418));\n  (assert ((candidate 30) = 832040));\n  (assert ((candidate 17) = 1597));\n  (assert ((candidate 29) = 514229));\n  (assert ((candidate 28) = 317811));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 5) = 5));\n  (assert ((candidate 4) = 3));\n  (assert ((candidate 23) = 28657));\n  (assert ((candidate 16) = 987));\n  (assert ((candidate 10) = 55));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_62303_genSubparts", "language": "ml", "prompt": "(**Partition a string into all possible two parts, e.g.\ngiven \"abcd\", generate [(\"a\", \"bcd\"), (\"ab\", \"cd\"), (\"abc\", \"d\")]\nFor string of length 1, return empty list\n*)\nlet genSubparts (string : string) :  string * string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_62303_genSubparts.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = genSubparts in\n  (assert ((candidate \"\") = []));\n  (assert ((candidate \"\") = []));\n  (assert ((candidate \"abcd\") = [(\"a\", \"bcd\"); (\"ab\", \"cd\"); (\"abc\", \"d\")]));\n  (assert ((candidate \"abcd\") = [(\"a\", \"bcd\"); (\"ab\", \"cd\"); (\"abc\", \"d\")]));\n  (assert ((candidate \"abcd\") = [(\"a\", \"bcd\"); (\"ab\", \"cd\"); (\"abc\", \"d\")]));\n  (assert ((candidate \"abc\") = [(\"a\", \"bc\"); (\"ab\", \"c\")]));\n  (assert ((candidate \"abcd\") = [(\"a\", \"bcd\"); (\"ab\", \"cd\"); (\"abc\", \"d\")]));\n  (assert ((candidate \"a\") = []));\n  (assert ((candidate \"\") = []));\n  (assert ((candidate \"abcd\") = [(\"a\", \"bcd\"); (\"ab\", \"cd\"); (\"abc\", \"d\")]));\n  (assert ((candidate \"ab\") = [(\"a\", \"b\")]));\n  (assert ((candidate \"abcd\") = [(\"a\", \"bcd\"); (\"ab\", \"cd\"); (\"abc\", \"d\")]));\n  (assert ((candidate \"\") = []));\n  (assert ((candidate \"abc\") = [(\"a\", \"bc\"); (\"ab\", \"c\")]));\n  (assert ((candidate \"a\") = []));\n  (assert ((candidate \"ab\") = [(\"a\", \"b\")]));\n  (assert ((candidate \"abc\") = [(\"a\", \"bc\"); (\"ab\", \"c\")]));\n  (assert ((candidate \"abc\") = [(\"a\", \"bc\"); (\"ab\", \"c\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_63573_check_bounds", "language": "ml", "prompt": "(**Limit voltage.\nVoltage limits are 45 (1.1%) and 4055 (99.0%) of a 4095 max.\nValve calibrated so that at 45 (1.1%) it's fully shutoff.\n*)\nlet check_bounds (volts : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_63573_check_bounds.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = check_bounds in\n  (assert ((candidate 500) = 500));\n  (assert ((candidate 4046) = 4046));\n  (assert ((candidate 4037) = 4037));\n  (assert ((candidate 4033) = 4033));\n  (assert ((candidate 4055) = 4055));\n  (assert ((candidate 4044) = 4044));\n  (assert ((candidate 4048) = 4048));\n  (assert ((candidate 4034) = 4034));\n  (assert ((candidate 4056) = 4055));\n  (assert ((candidate 45) = 45));\n  (assert ((candidate 4050) = 4050));\n  (assert ((candidate 0) = 45));\n  (assert ((candidate 4041) = 4041));\n  (assert ((candidate 4054) = 4054));\n  (assert ((candidate 4045) = 4045));\n  (assert ((candidate 1) = 45));\n  (assert ((candidate 4047) = 4047));\n  (assert ((candidate 4049) = 4049));\n  (assert ((candidate 4042) = 4042));\n  (assert ((candidate 4040) = 4040));\n  (assert ((candidate 3000) = 3000));\n  (assert ((candidate 4035) = 4035));\n  (assert ((candidate 4095) = 4055));\n  (assert ((candidate 4039) = 4039));\n  (assert ((candidate 4036) = 4036));\n  (assert ((candidate 4096) = 4055));\n  (assert ((candidate 4038) = 4038));\n  (assert ((candidate 4043) = 4043));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_63833_multiline_test", "language": "ml", "prompt": "(**test if the current line is a multiline with \"=\" at the end\n:param line: 'O1 3 -0.01453 1.66590 0.10966 11.00 0.05 ='\n:type line: string\n>>> line = 'C1    1    0.278062    0.552051    0.832431    11.00000    0.02895    0.02285 ='\n>>> multiline_test(line)\nTrue\n>>> line = 'C1    1    0.278062    0.552051    0.832431    11.00000    0.05 '\n>>> multiline_test(line)\nFalse\n*)\nlet multiline_test (line : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_63833_multiline_test.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = multiline_test in\n  (assert ((candidate \"O1 3 -0.01453 1.66590 0.10966 11.00 0.05 =\") = true));\n  (assert ((candidate \"O1 3 -0.01453 1.66590 0.10966 11.00 0.05 \") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_64387_cleanForIRI", "language": "ml", "prompt": "(**Cleans a string to be suitable for use as an IRI (punctation we dont want is removed)\n*)\nlet cleanForIRI (string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_64387_cleanForIRI.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = cleanForIRI in\n  (assert ((candidate \"123 456\") = \"123456\"));\n  (assert ((candidate \"123\") = \"123\"));\n  (assert ((candidate \"hello world!\") = \"helloworld\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_65087_trim_lost_U", "language": "ml", "prompt": "(**test for lost U at the 3' end of the PCR primer sequence\n*)\nlet trim_lost_U (seq_F : string) (qual_F : string) (LOSTUSEQS : string list) :  string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_65087_trim_lost_U.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = trim_lost_U in\n  (assert ((candidate \"AACC\" \"DEB\" [\"AACC\"]) = (\"\", \"\")));\n  (assert ((candidate \"AACC\" \"DEB\" [\"AACC\"; \"ACTA\"]) = (\"\", \"\")));\n  (assert ((candidate \"CGT\" \"DEB\" [\"AACT\"]) = (\"CGT\", \"DEB\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_65211_findDuplicate", "language": "ml", "prompt": "(**:type nums: List[int]\n:rtype: int\n*)\nlet findDuplicate (nums : int list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_65211_findDuplicate.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = findDuplicate in\n  (assert ((candidate [1; 1; 2]) = 1));\n  (assert ((candidate [1; 3; 4; 2; 2]) = 2));\n  (assert ((candidate [1; 1]) = 1));\n  (assert ((candidate [1; 1; 2; 2; 3; 3; 4; 4]) = 1));\n  (assert ((candidate [3; 1; 3; 4; 2]) = 3));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_65436_remove_min_line", "language": "ml", "prompt": "(**Soustraction des min par ligne\n*)\nlet remove_min_line (matrix : int list list) (list_min_line : int list) : int list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_65436_remove_min_line.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = remove_min_line in\n  (assert ((candidate [[4; 1; 4; 4]; [4; 4; 1; 4]; [4; 4; 4; 1]] [1; 1; 1]) = [[3; 0; 3; 3]; [3; 3; 0; 3]; [3; 3; 3; 0]]));\n  (assert ((candidate [[1; 2; 3; 4]] [1]) = [[0; 1; 2; 3]]));\n  (assert ((candidate [[2; 2; 2]; [5; 5; 5]] [2; 2; 2]) = [[0; 0; 0]; [3; 3; 3]]));\n  (assert ((candidate [[3; 4; 5; 6; 7; 8; 9; 0]] [1; 2; 3; 4]) = [[2; 3; 4; 5; 6; 7; 8; (~1)]]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_65809_misencode", "language": "ml", "prompt": "(**Take a properly represented text, encode into win1250 and decode\nback into latin2 (iso-8859-2) so it could be encoded back as such over the wire.\nHas to be used when querying database for data stored by original application,\nrepresented by MisencodedChar/TextField.\n*)\nlet misencode (text : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_65809_misencode.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = misencode in\n  (assert ((candidate \"abc\") = \"abc\"));\n  (assert ((candidate \"\u017b\") = \"\u017b\"));\n  (assert ((candidate \"x\") = \"x\"));\n  (assert ((candidate \"\u0119\u0142\") = \"\u0119\u0142\"));\n  (assert ((candidate \"\u0119\") = \"\u0119\"));\n  (assert ((candidate \"a\") = \"a\"));\n  (assert ((candidate \"x\n\r\t a\") = \"x\n\r\t a\"));\n  (assert ((candidate \"x\n\r\t\") = \"x\n\r\t\"));\n  (assert ((candidate \"x \") = \"x \"));\n  (assert ((candidate \"abcd\") = \"abcd\"));\n  (assert ((candidate \"\u00f3\") = \"\u00f3\"));\n  (assert ((candidate \"\u0142\u0119\") = \"\u0142\u0119\"));\n  (assert ((candidate \"\u017c\") = \"\u017c\"));\n  (assert ((candidate \" \") = \" \"));\n  (assert ((candidate \"x\ta\") = \"x\ta\"));\n  (assert ((candidate \"\u0118\") = \"\u0118\"));\n  (assert ((candidate \"\u0142\") = \"\u0142\"));\n  (assert ((candidate \"ab\") = \"ab\"));\n  (assert ((candidate \"\u0142\") = \"\u0142\"));\n  (assert ((candidate \"\u0119\") = \"\u0119\"));\n  (assert ((candidate \"x\na\") = \"x\na\"));\n  (assert ((candidate \"\u0141\") = \"\u0141\"));\n  (assert ((candidate \"x\n\r a\n\") = \"x\n\r a\n\"));\n  (assert ((candidate \"x a\") = \"x a\"));\n  (assert ((candidate \"x\r\na\") = \"x\r\na\"));\n  (assert ((candidate \"x\n\r\") = \"x\n\r\"));\n  (assert ((candidate \"x\n\r\t\na\") = \"x\n\r\t\na\"));\n  (assert ((candidate \"\u00d3\") = \"\u00d3\"));\n  (assert ((candidate \"\u0119\") = \"\u0119\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"ab\u010d\") = \"ab\u010d\"));\n  (assert ((candidate \"x\n\ra\n\") = \"x\n\ra\n\"));\n  (assert ((candidate \"\u0143\") = \"\u0143\"));\n  (assert ((candidate \"\u0144\") = \"\u0144\"));\n  (assert ((candidate \"x\n\ra\") = \"x\n\ra\"));\n  (assert ((candidate \"x\n\r a\") = \"x\n\r a\"));\n  (assert ((candidate \"\u0118\") = \"\u0118\"));\n  (assert ((candidate \"ab\u010d\") = \"ab\u010d\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_66931___validate_float_fields", "language": "ml", "prompt": "(**Validate float values from a dictionary.\nParameters\n----------\nvalue : float\n * Value to be validated.\nerror_msg : str\n * Error message for an invalid value.\nReturns\n-------\nfloat\n * Validated value.\nRaises\n------\nTypeError\n * Raised when the value is not valid (namely, when it is data that cannot be cast to float).\n*)\nlet __validate_float_fields (value : float) (error_msg : string) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_66931___validate_float_fields.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = __validate_float_fields in\n  (assert ((candidate -273.15 \"\") = -273.15));\n  (assert ((candidate 0.0 \"\") = 0.0));\n  (assert ((candidate \"1\".0 \"Should be valid.\") = 1.0));\n  (assert ((candidate 1.0 \"Error: Invalid value\") = 1.0));\n  (assert ((candidate 1.0 \"Input value cannot be cast to float.\") = 1.0));\n  (assert ((candidate float \"inf\".0 \"\") = float \"inf\".0));\n  (assert ((candidate 10.0 \"Input value is not a float.\") = 10.0));\n  (assert ((candidate \"1\".0 \"Error: Invalid value\") = 1.0));\n  (assert ((candidate 1.0 \"Input value cannot be cast to float.\") = 1.0));\n  (assert ((candidate 1.0 \"Error: Invalid value\") = 1.0));\n  (assert ((candidate (~10).0 \"\") = (~10).0));\n  (assert ((candidate 10.0 \"Input value is not a float.\") = 10.0));\n  (assert ((candidate 1.0 \"\") = 1.0));\n  (assert ((candidate (~1).0 \"Input value cannot be cast to float.\") = -1.0));\n  (assert ((candidate -1.0 \"Input value cannot be cast to float.\") = -1.0));\n  (assert ((candidate 3.14159 \"\") = 3.14159));\n  (assert ((candidate 1.0 \"Should be valid.\") = 1.0));\n  (assert ((candidate \"1.0\" \"Should be valid.\") = 1.0));\n  (assert ((candidate 0.0 \"Input value cannot be cast to float.\") = 0.0));\n  (assert ((candidate 0.0 \"Input value cannot be cast to float.\") = 0.0));\n  (assert ((candidate 1.0 \"Should be valid.\") = 1.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_67171_remove_unencodable", "language": "ml", "prompt": "(**:type str_: str\n:param str_: string to remove unencodable character\n:return: string removed unencodable character\n*)\nlet remove_unencodable (str_ : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_67171_remove_unencodable.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = remove_unencodable in\n  (assert ((candidate \"\u201cHe said, \u201cLet us go to the movies tonight\u201d\u201d\") = \"\u201cHe said, \u201cLet us go to the movies tonight\u201d\u201d\"));\n  (assert ((candidate \"The British Beatles were an English rock band formed in London in 1960 by <NAME>, <NAME> and <NAME>\") = \"The British Beatles were an English rock band formed in London in 1960 by <NAME>, <NAME> and <NAME>\"));\n  (assert ((candidate \"The American actress and author, <NAME>, is perhaps best known for her role as <NAME> in the 1994 film, Selma.\") = \"The American actress and author, <NAME>, is perhaps best known for her role as <NAME> in the 1994 film, Selma.\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_6730_char_to_bool", "language": "ml", "prompt": "(**Transform character (J/N) to Bool.\n*)\nlet char_to_bool (letter : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_6730_char_to_bool.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = char_to_bool in\n  (assert ((candidate \"j\") = true));\n  (assert ((candidate \"N\") = false));\n  (assert ((candidate \"J\") = true));\n  (assert ((candidate \"n\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_67323_is_belong_train_set", "language": "ml", "prompt": "(**Args:\nfname: string, file name without dir path\n * Returns:\nboolean\n*)\nlet is_belong_train_set (fname : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_67323_is_belong_train_set.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_belong_train_set in\n  (assert ((candidate \"2_2_1.txt\") = true));\n  (assert ((candidate \"3_1_1.txt\") = false));\n  (assert ((candidate \"2_1_1.txt\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_67419_get_index_of_char", "language": "ml", "prompt": "(**Returns all indices of all appearances of char in str\n:param file_name:\n:param char:\n:return:\n*)\nlet get_index_of_char (my_string : string) (char : string) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_67419_get_index_of_char.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_index_of_char in\n  (assert ((candidate \"123123123\" \"2\") = [1; 4; 7]));\n  (assert ((candidate \"abcdefg\" \"z\") = []));\n  (assert ((candidate \"123123123\" \"1\") = [0; 3; 6]));\n  (assert ((candidate \"abc\nabc\" \"\n\") = [3]));\n  (assert ((candidate \"\" \"\") = []));\n  (assert ((candidate \"abcdef\" \"z\") = []));\n  (assert ((candidate \"123123123\" \"x\") = []));\n  (assert ((candidate \"a1b2c3\" \"x\") = []));\n  (assert ((candidate \"abcdefg\" \"d\") = [3]));\n  (assert ((candidate \"abc\" \"d\") = []));\n  (assert ((candidate \"1abc2\" \"d\") = []));\n  (assert ((candidate \"abcabc\" \"z\") = []));\n  (assert ((candidate \"abc\" \"c\") = [2]));\n  (assert ((candidate \"abc\" \"c\") = [2]));\n  (assert ((candidate \"abcdefg\" \"a\") = [0]));\n  (assert ((candidate \"a1b2c3\" \"1\") = [1]));\n  (assert ((candidate \"aaaaaaaaaa\" \"a\") = [0; 1; 2; 3; 4; 5; 6; 7; 8; 9]));\n  (assert ((candidate \"abc\" \"b\") = [1]));\n  (assert ((candidate \"1abc2\" \"b\") = [2]));\n  (assert ((candidate \"123123123\" \"3\") = [2; 5; 8]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_67437_check_dead", "language": "ml", "prompt": "(**Method to check if either player is dead\n:param left_hp: Hit points of priority player\n:param right_hp: Hit points of right player\n:return: True if somebody is dead, else False\n*)\nlet check_dead (left_hp : int) (right_hp : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_67437_check_dead.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = check_dead in\n  (assert ((candidate (~1) 1) = true));\n  (assert ((candidate 0 5) = true));\n  (assert ((candidate 1 1) = false));\n  (assert ((candidate 0 0) = true));\n  (assert ((candidate 1 0) = true));\n  (assert ((candidate 5 0) = true));\n  (assert ((candidate 1 (~1)) = true));\n  (assert ((candidate 0 1) = true));\n  (assert ((candidate 5 5) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_67598_strip_str", "language": "ml", "prompt": "(**Strip string.\n*)\nlet strip_str (string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_67598_strip_str.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = strip_str in\n  (assert ((candidate candidate candidate \"  a  \") = candidate \"  a  \"));\n  (assert ((candidate \"  \") = \"\"));\n  (assert ((candidate \"Hello'World\") = \"Hello'World\"));\n  (assert ((candidate \"Hello World!    \") = \"Hello World!\"));\n  (assert ((candidate \"    Hello World!\") = \"Hello World!\"));\n  (assert ((candidate \"Hello \" World\") = \"Hello \" World\"));\n  (assert ((candidate \"  hello  world  \") = \"hello  world\"));\n  (assert ((candidate \"'hello  world'\") = \"hello  world\"));\n  (assert ((candidate \" Hello World\") = \"Hello World\"));\n  (assert ((candidate candidate candidate \"' a '\") = candidate \"' a '\"));\n  (assert ((candidate \"\"hello  world\"\") = \"hello  world\"));\n  (assert ((candidate \"'hello'\") = \"hello\"));\n  (assert ((candidate \"  'hello'  'world'  \") = \"'hello'  'world'\"));\n  (assert ((candidate \"hi\") = \"hi\"));\n  (assert ((candidate \"Hello World\") = \"Hello World\"));\n  (assert ((candidate \"Hello 'World\") = \"Hello 'World\"));\n  (assert ((candidate \"Hello World!\") = \"Hello World!\"));\n  (assert ((candidate \"Hello \" World!\") = \"Hello \" World!\"));\n  (assert ((candidate \"Hello'World! \") = \"Hello'World!\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"  hi  \") = \"hi\"));\n  (assert ((candidate \"    Hello World!    \") = \"Hello World!\"));\n  (assert ((candidate \"hi\") = \"hi\"));\n  (assert ((candidate \"Hello World \") = \"Hello World\"));\n  (assert ((candidate \"Hello\" World\") = \"Hello\" World\"));\n  (assert ((candidate \"  \"hello\"  \"world\"  \") = \"\"hello\"  \"world\"\"));\n  (assert ((candidate \"Hello'World\") = \"Hello'World\"));\n  (assert ((candidate \"\"hello\"\") = \"hello\"));\n  (assert ((candidate \" Hello World \") = \"Hello World\"));\n  (assert ((candidate \"''\") = \"\"));\n  (assert ((candidate \"\"\"\") = \"\"));\n  (assert ((candidate \"Hello' World\") = \"Hello' World\"));\n  (assert ((candidate \"  hello  \") = \"hello\"));\n  (assert ((candidate \"  \"hello\"  'world'  \") = \"\"hello\"  'world'\"));\n  (assert ((candidate \"hello\") = \"hello\"));\n  (assert ((candidate \"Hello World!\") = \"Hello World!\"));\n  (assert ((candidate \"Hello\"World\") = \"Hello\"World\"));\n  (assert ((candidate candidate candidate \"\" a \"\") = candidate \"\" a \"\"));\n  (assert ((candidate \"Hello \"World\") = \"Hello \"World\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_68506_fib", "language": "ml", "prompt": "(**Calculate the nth digit of Fibonacci\n0 1 1 2 3 5 8 13 21 34 ...\n*)\nlet fib (n : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_68506_fib.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = fib in\n  (assert ((candidate 2) = 1));\n  (assert ((candidate 0) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_68615_is_even", "language": "ml", "prompt": "(**Check if a number is even.\n*)\nlet is_even (number : int) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_68615_is_even.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_even in\n  (assert ((candidate 5) = false));\n  (assert ((candidate 0) = true));\n  (assert ((candidate 4) = true));\n  (assert ((candidate 1) = false));\n  (assert ((candidate 2) = true));\n  (assert ((candidate 10) = true));\n  (assert ((candidate 3) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_68774_extract", "language": "ml", "prompt": "(**Extract label from transition.\n*)\nlet extract (token : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_68774_extract.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = extract in\n  (assert ((candidate \"'bc'\") = \"bc\"));\n  (assert ((candidate \"''\") = \"\"));\n  (assert ((candidate \"[a]\") = \"a\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"'a'\") = \"a\"));\n  (assert ((candidate \"a\") = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_68849_removeElement", "language": "ml", "prompt": "(**:type nums: List[int]\n:type val: int\n:rtype: int\n*)\nlet removeElement (nums : int list) (val : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_68849_removeElement.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = removeElement in\n  (assert ((candidate [0; 1; 2; 2; 3; 0; 4; 2] 2) = 5));\n  (assert ((candidate [1; 2; 3; 3] 3) = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_69513_comma_counter", "language": "ml", "prompt": "(**:param field:\n:return:\n*)\nlet comma_counter (field : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_69513_comma_counter.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = comma_counter in\n  (assert ((candidate \"a,b,c,d,e\") = 4));\n  (assert ((candidate \"hello,,world\") = 2));\n  (assert ((candidate \"\") = 0));\n  (assert ((candidate \"hello\") = 0));\n  (assert ((candidate \"hello,world\") = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_69832_strip_all", "language": "ml", "prompt": "(**Strips leading and trailing whitespace from all strings in a list.\nArgs:\n * lst (list of str): The list of strings to strip.\nReturns:\n * list of str: The list of stripped strings.\n*)\nlet strip_all (lst : string list) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_69832_strip_all.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = strip_all in\n  (assert ((candidate [\" \r\n one \r\n\"; \" two \r\n\"; \" three \r\n\"]) = [\"one\"; \"two\"; \"three\"]));\n  (assert ((candidate [\"  \"; \"\"; \"  hello  \"; \"  world\"; \"  \"; \"\"; \"  \"]) = [\"\"; \"\"; \"hello\"; \"world\"; \"\"; \"\"; \"\"]));\n  (assert ((candidate [\"    one   \"; \"   two  \"; \"  three\"]) = [\"one\"; \"two\"; \"three\"]));\n  (assert ((candidate [\"\"; \"\"; \"\"]) = [\"\"; \"\"; \"\"]));\n  (assert ((candidate [\"one\"; \" two\"; \" three\"]) = [\"one\"; \"two\"; \"three\"]));\n  (assert ((candidate []) = []));\n  (assert ((candidate []) = []));\n  (assert ((candidate [\"     Hello,     World!     \"; \"Hello, World!\"]) = [\"Hello,     World!\"; \"Hello, World!\"]));\n  (assert ((candidate [\"hello\"; \"world\"]) = [\"hello\"; \"world\"]));\n  (assert ((candidate [\"\"; \"hello  \"; \"  world\"]) = [\"\"; \"hello\"; \"world\"]));\n  (assert ((candidate [\" \n one\n\"; \" two \n\"; \" three \n\"]) = [\"one\"; \"two\"; \"three\"]));\n  (assert ((candidate [\" one \"; \" two \"; \" three\"]) = [\"one\"; \"two\"; \"three\"]));\n  (assert ((candidate [\"  \"; \"  \"; \"  \"]) = [\"\"; \"\"; \"\"]));\n  (assert ((candidate [\"  hello  \"; \"world\"; \"\"]) = [\"hello\"; \"world\"; \"\"]));\n  (assert ((candidate [\"one\"; \"\"; \"two\"; \"three\"]) = [\"one\"; \"\"; \"two\"; \"three\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_70041_format_timedelta", "language": "ml", "prompt": "(**Returns a formatted message that is displayed whenever a command wants to display a duration\n*)\nlet format_timedelta (seconds : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_70041_format_timedelta.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = format_timedelta in\n  (assert ((candidate 3661) = \"1h 1m\"));\n  (assert ((candidate 0) = \"0h 0m\"));\n  (assert ((candidate 7200) = \"2h 0m\"));\n  (assert ((candidate 86399) = \"23h 59m\"));\n  (assert ((candidate 3600) = \"1h 0m\"));\n  (assert ((candidate 60) = \"0h 1m\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_71150_max_divisible", "language": "ml", "prompt": "(**Keep dividing(a/b) till it's divisible(a % b == 0)\ne.g.\nInput: a = 300; b = 2\nOutput: 75\n:param a:\n:param b:\n:return:\n*)\nlet max_divisible (a : int) (b : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_71150_max_divisible.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = max_divisible in\n  (assert ((candidate 100 4) = 25));\n  (assert ((candidate 24 4) = 6));\n  (assert ((candidate 300 100) = 3));\n  (assert ((candidate 15 3) = 5));\n  (assert ((candidate 100 25) = 4));\n  (assert ((candidate 300 2) = 75));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_72364_get_xi_from_ARPS_simulation", "language": "ml", "prompt": "(**Extract xi from full name of ARPS files\n*)\nlet get_xi_from_ARPS_simulation (simulation : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_72364_get_xi_from_ARPS_simulation.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_xi_from_ARPS_simulation in\n  (assert ((candidate \"wind_N2000_dx0.05_xi00001_sigma0.001_small\") = \"00001\"));\n  (assert ((candidate \"wind_N1000_dx0.05_xi00100_sigma0.001_small\") = \"00100\"));\n  (assert ((candidate \"topo_N100_dx0.02_xi00100_sigma0.001_small\") = \"00100\"));\n  (assert ((candidate \"topo_N100_dx0.02_xi00200_sigma0.001_small\") = \"00200\"));\n  (assert ((candidate \"topo_N100_dx0.02_xi00300_sigma0.001_small\") = \"00300\"));\n  (assert ((candidate \"wind_N2000_dx0.05_xi00300_sigma0.001_small\") = \"00300\"));\n  (assert ((candidate \"wind_N2000_dx0.05_xi00200_sigma0.001_small\") = \"00200\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_72597_plurality", "language": "ml", "prompt": "(**Return, for input dict d mapping vids to (real) counts, vid with largest count.\n(Tie-breaking done arbitrarily here.)\n*)\nlet plurality (d : (int, int) list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_72597_plurality.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = plurality in\n  (assert ((candidate [(1, 10)]) = 1));\n  (assert ((candidate dict [(0, 1); (1, 2); (2, 1); (3, 1); (4, 1); (5, 1)]) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_72678_f", "language": "ml", "prompt": "(**Defining Function\n*)\nlet f (x : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_72678_f.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = f in\n  (assert ((candidate 0) = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_73015_init_loop_state", "language": "ml", "prompt": "(**Initialize the file row counter, the file counter,\nand the list representing file data.\nJanky, I know, but this needed to be done in 2 spots.\n*)\nlet init_loop_state (file_counter : int) :  int * int * string list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_73015_init_loop_state.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = init_loop_state in\n  (assert ((candidate 0) = (0, 1, [[\"Date\"; \"Weight (lb)\"; \"Fat mass (lb)\"]])));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_73332__make_even", "language": "ml", "prompt": "(**Return largest even integer less than or equal to `n`.\n*)\nlet _make_even (n : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_73332__make_even.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _make_even in\n  (assert ((candidate 29) = 28));\n  (assert ((candidate 0) = 0));\n  (assert ((candidate 10) = 10));\n  (assert ((candidate 8) = 8));\n  (assert ((candidate 11) = 10));\n  (assert ((candidate 13) = 12));\n  (assert ((candidate 5) = 4));\n  (assert ((candidate 24) = 24));\n  (assert ((candidate 21) = 20));\n  (assert ((candidate 15) = 14));\n  (assert ((candidate 22) = 22));\n  (assert ((candidate 30) = 30));\n  (assert ((candidate 32) = 32));\n  (assert ((candidate 6) = 6));\n  (assert ((candidate 23) = 22));\n  (assert ((candidate 17) = 16));\n  (assert ((candidate 20) = 20));\n  (assert ((candidate 19) = 18));\n  (assert ((candidate 16) = 16));\n  (assert ((candidate 1) = 0));\n  (assert ((candidate 2) = 2));\n  (assert ((candidate 3) = 2));\n  (assert ((candidate 25) = 24));\n  (assert ((candidate 14) = 14));\n  (assert ((candidate 7) = 6));\n  (assert ((candidate 4) = 4));\n  (assert ((candidate 18) = 18));\n  (assert ((candidate 12) = 12));\n  (assert ((candidate 28) = 28));\n  (assert ((candidate 4) = candidate candidate 4));\n  (assert ((candidate 31) = 30));\n  (assert ((candidate 9) = 8));\n  (assert ((candidate 27) = 26));\n  (assert ((candidate 26) = 26));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_73550__desktop_escape", "language": "ml", "prompt": "(**Escape a filepath for use in a .desktop file\n*)\nlet _desktop_escape (s : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_73550__desktop_escape.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _desktop_escape in\n  (assert ((candidate \"\\v\") = \"\\\\v\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"\\\\s\") = \"\\\\\\\\s\"));\n  (assert ((candidate \"C:\\Users\\foo\\Desktop\\bar\") = \"C:\\\\Users\\\\foo\\\\Desktop\\\\bar\"));\n  (assert ((candidate \"abc\") = \"abc\"));\n  (assert ((candidate \"\\\\\\a\") = \"\\\\\\\\\\\\a\"));\n  (assert ((candidate \"\\\\\\s\") = \"\\\\\\\\\\\\s\"));\n  (assert ((candidate \"\\\\\\0\") = \"\\\\\\\\\\\\0\"));\n  (assert ((candidate \"\\\\a\") = \"\\\\\\\\a\"));\n  (assert ((candidate \"C:\\Users\\foo\\Desktop\\tab\\t\") = \"C:\\\\Users\\\\foo\\\\Desktop\\\\tab\\\\t\"));\n  (assert ((candidate \"abcde\") = \"abcde\"));\n  (assert ((candidate \"\\s\") = \"\\\\s\"));\n  (assert ((candidate \"C:\\Users\\foo\\Desktop\\newline\\n\") = \"C:\\\\Users\\\\foo\\\\Desktop\\\\newline\\\\n\"));\n  (assert ((candidate \"C:\\Users\\foo\\Desktop\\backslash\\backslash\") = \"C:\\\\Users\\\\foo\\\\Desktop\\\\backslash\\\\backslash\"));\n  (assert ((candidate \"\\\\f\") = \"\\\\\\\\f\"));\n  (assert ((candidate \"\\\\\\f\") = \"\\\\\\\\\\\\f\"));\n  (assert ((candidate \"\\\\\\v\") = \"\\\\\\\\\\\\v\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"\\\\v\") = \"\\\\\\\\v\"));\n  (assert ((candidate \"a\") = \"a\"));\n  (assert ((candidate \"\\0\") = \"\\\\0\"));\n  (assert ((candidate \"\\\\0\") = \"\\\\\\\\0\"));\n  (assert ((candidate \"ab\") = \"ab\"));\n  (assert ((candidate \"\\f\") = \"\\\\f\"));\n  (assert ((candidate \"\\a\") = \"\\\\a\"));\n  (assert ((candidate \"abcd\") = \"abcd\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_73986_manhattan_distance", "language": "ml", "prompt": "(**It is the sum of absolute values of differences in the point 1's x and y coordinates and the\npoint 2's x and y coordinates respectively\n*)\nlet manhattan_distance (point1_x : int) (point1_y : int) (point2_x : int) (point2_y : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_73986_manhattan_distance.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = manhattan_distance in\n  (assert ((candidate 1 1 0 0) = 2));\n  (assert ((candidate 0 0 (~3) (~4)) = 7));\n  (assert ((candidate (~2) (~2) (~4) (~4)) = 4));\n  (assert ((candidate 10 10 0 0) = 20));\n  (assert ((candidate 0 0 (~10) 10) = 20));\n  (assert ((candidate 1 1 3 4) = 5));\n  (assert ((candidate 1 1 1 1) = 0));\n  (assert ((candidate 0 0 10 (~10)) = 20));\n  (assert ((candidate 0 0 10 10) = 20));\n  (assert ((candidate 3 (~4) 0 0) = 7));\n  (assert ((candidate 0 0 0 0) = 0));\n  (assert ((candidate 0 0 3 4) = 7));\n  (assert ((candidate 1 2 3 4) = 4));\n  (assert ((candidate (~3) 4 0 0) = 7));\n  (assert ((candidate (~1) (~1) (~1) (~1)) = 0));\n  (assert ((candidate 0 0 (~10) (~10)) = 20));\n  (assert ((candidate (~10) 10 0 0) = 20));\n  (assert ((candidate 2 2 2 2) = 0));\n  (assert ((candidate (~10) (~10) 0 0) = 20));\n  (assert ((candidate 1 1 2 2) = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_74366_to_unicode_repr", "language": "ml", "prompt": "(**helpful in situations where browser/app may recognize Unicode encoding\nin the \u0b8e type syntax but not actual unicode glyph/code-point\n*)\nlet to_unicode_repr (_letter : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_74366_to_unicode_repr.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = to_unicode_repr in\n  (assert ((candidate \"\u0b8e\u0b8e\") = \"u'\\u0b8e\\u0b8e'\"));\n  (assert ((candidate \"\u0905\u0906\u0907\u0908\u0909\u090a\") = \"u'\\u0905\\u0906\\u0907\\u0908\\u0909\\u090a'\"));\n  (assert ((candidate \"\") = \"u''\"));\n  (assert ((candidate \"\u0b8e\u0b8e\u0b8e\") = \"u'\\u0b8e\\u0b8e\\u0b8e'\"));\n  (assert ((candidate \"\u0b8e\") = \"u'\\u0b8e'\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_76381_str_list", "language": "ml", "prompt": "(**convert string to list\n*)\nlet str_list (input_Str : string) : float list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_76381_str_list.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = str_list in\n  (assert ((candidate \"0 0 1 1 2 3 5 8\") = [0.0; 0.0; 1.0; 1.0; 2.0; 3.0; 5.0; 8.0]));\n  (assert ((candidate \"1.0 2.0 3.0\") = [1.0; 2.0; 3.0]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_77434_get_str_ip", "language": "ml", "prompt": "(**turns a list of 4 integers into IP address format.\n*)\nlet get_str_ip (list_ip : int list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_77434_get_str_ip.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_str_ip in\n  (assert ((candidate [192; 168; 1; 0]) = \"192.168.1.0\"));\n  (assert ((candidate [10; 0; 1; 0]) = \"10.0.1.0\"));\n  (assert ((candidate [10; 0; 0; 1]) = \"10.0.0.1\"));\n  (assert ((candidate [192; 168; 0; 1]) = \"192.168.0.1\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_77523_get_prefix", "language": "ml", "prompt": "(**@Description:\nget the prefix of a url\nto form the sub-level url\n---------\n@Param:\nurl:str\n-------\n@Returns:\na substr end where '/' last time appears\n-------\n*)\nlet get_prefix (url : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_77523_get_prefix.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_prefix in\n  (assert ((candidate \"http://github.com/\") = \"http://github.com/\"));\n  (assert ((candidate \"http://github.com/this_is_a_test.py/this_is_another_test.py/\") = \"http://github.com/this_is_a_test.py/this_is_another_test.py/\"));\n  (assert ((candidate \"http://www.example.com/some/path/\") = \"http://www.example.com/some/path/\"));\n  (assert ((candidate \"https://www.coursera.org/api/onDemandProgrammingScripting\") = \"https://www.coursera.org/api/\"));\n  (assert ((candidate \"http://data.pr4e.org/data/animals.txt\") = \"http://data.pr4e.org/data/\"));\n  (assert ((candidate \"http://github.com/this_is_a_test.py\") = \"http://github.com/\"));\n  (assert ((candidate \"http://172.16.31.10/data.php\") = \"http://172.16.31.10/\"));\n  (assert ((candidate \"http://github.com/this_is_a_test.py/this_is_another_test.py/?some_variable=some_value\") = \"http://github.com/this_is_a_test.py/this_is_another_test.py/\"));\n  (assert ((candidate \"https://www.coursera.org/api/onDemandProgrammingScripting?a=1&b=2\") = \"https://www.coursera.org/api/\"));\n  (assert ((candidate \"http://www.example.com/\") = \"http://www.example.com/\"));\n  (assert ((candidate \"https://www.coursera.org/api/onDemandProgrammingScripting?a=1\") = \"https://www.coursera.org/api/\"));\n  (assert ((candidate \"http://www.example.com/some/path\") = \"http://www.example.com/some/\"));\n  (assert ((candidate \"http://github.com/this_is_a_test.py/this_is_another_test.py/?some_variable=some_value&other_variable=other_value\") = \"http://github.com/this_is_a_test.py/this_is_another_test.py/\"));\n  (assert ((candidate \"http://data.pr4e.org/data/intro-short.txt\") = \"http://data.pr4e.org/data/\"));\n  (assert ((candidate \"http://data.pr4e.org/intro-short.txt\") = \"http://data.pr4e.org/\"));\n  (assert ((candidate \"github.com\") = \"\"));\n  (assert ((candidate \"http://172.16.31.10/data.php\") = \"http://172.16.31.10/\"));\n  (assert ((candidate \"http://stackoverflow.com/questions/tagged/python\") = \"http://stackoverflow.com/questions/tagged/\"));\n  (assert ((candidate \"http://github.com/this_is_a_test.py/this_is_another_test.py\") = \"http://github.com/this_is_a_test.py/\"));\n  (assert ((candidate \"http://coursera.org/api/onDemandProgrammingScripting\") = \"http://coursera.org/api/\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_77581_has_no_trailing_zeroes", "language": "ml", "prompt": "(**True if string has no trailing zeroes, False otherwise.\nPARAMETERS:\n * string : str\nRETURNS: bool\n*)\nlet has_no_trailing_zeroes (string : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_77581_has_no_trailing_zeroes.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = has_no_trailing_zeroes in\n  (assert ((candidate \"040\") = false));\n  (assert ((candidate \"4\") = true));\n  (assert ((candidate \"40\") = true));\n  (assert ((candidate \"0\") = true));\n  (assert ((candidate \"0400\") = false));\n  (assert ((candidate \"400\") = true));\n  (assert ((candidate \"000\") = false));\n  (assert ((candidate \"04\") = false));\n  (assert ((candidate \"00\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_77664_sumDigits", "language": "ml", "prompt": "(**Assumes s is a string\nReturns the sum of the decimal digits in s\nFor example, if s is 'a2b3c' it returns 5\n*)\nlet sumDigits (s : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_77664_sumDigits.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sumDigits in\n  (assert ((candidate \"a2b3c\") = 5));\n  (assert ((candidate \"a2b3c0\") = 5));\n  (assert ((candidate \"1 2 3 4\") = 10));\n  (assert ((candidate \"a2b3c\") = 5));\n  (assert ((candidate \"a2b3c1\") = 6));\n  (assert ((candidate \"12 34\") = 10));\n  (assert ((candidate \"a2b3c\") = 5));\n  (assert ((candidate \"\") = 0));\n  (assert ((candidate \"987654321\") = 45));\n  (assert ((candidate \"1\") = 1));\n  (assert ((candidate \"a\") = 0));\n  (assert ((candidate \"1234\") = 10));\n  (assert ((candidate \"xyz\") = 0));\n  (assert ((candidate \"0123456789\") = 45));\n  (assert ((candidate \"\") = 0));\n  (assert ((candidate \"123\") = 6));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_7831_mixed_radix_to_base_10", "language": "ml", "prompt": "(**Convert the `mixed radix`_ integer with digits `x` and bases `b` to base 10.\nArgs:\n * x (list): a list of digits ordered by increasing place values\n * b (list): a list of bases corresponding to the digits\nExamples:\n * Generally, the base 10 representation of the mixed radix number :math:`x_n\\ldots x_1` where :math:`x_i` is a digit in place value :math:`i` with base :math:`b_i` is\n * .. math::\n * \\sum_{i=1}^nx_i\\prod_{j=i+1}^nb_j = x_n + b_nx_{n-1} + b_nb_{n-1}x_{n-2} + \\cdots + b_n\\cdots b_2x_1\n * Convert 111 with bases :math:`(b_1,b_2,b_3)=(2,3,4)` to base 10:\n * >>> from fem.discrete.combinatorics import mixed_radix_to_base_10\n * >>> mixed_radix_to_base_10([1,1,1], [2,3,4])\n * 17\n.. _mixed radix:\n * https://en.wikipedia.org/wiki/Mixed_radix\n*)\nlet mixed_radix_to_base_10 (x : int list) (b : int list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_7831_mixed_radix_to_base_10.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = mixed_radix_to_base_10 in\n  (assert ((candidate [1; 1; 1] [2; 3; 4]) = 17));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_79249_removeDuplicateChars", "language": "ml", "prompt": "(**assumes a-string is a string\nreturns a string, a_string with any duplicate characters removed\n*)\nlet removeDuplicateChars (a_string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_79249_removeDuplicateChars.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = removeDuplicateChars in\n  (assert ((candidate \"aaabbbccc\") = \"abc\"));\n  (assert ((candidate \"aabbcde\") = \"abcde\"));\n  (assert ((candidate \"abcde\") = \"abcde\"));\n  (assert ((candidate \"aaaaaa\") = \"a\"));\n  (assert ((candidate \"aabbcdef\") = \"abcdef\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_79326_fix_forts", "language": "ml", "prompt": "(**Changes Ft. -> Fort.\n*)\nlet fix_forts (report_city : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_79326_fix_forts.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = fix_forts in\n  (assert ((candidate \"Ft. Myers, Missouri  \") = \"Fort Myers, Missouri  \"));\n  (assert ((candidate \"Ft. Myers\") = \"Fort Myers\"));\n  (assert ((candidate \"Ft. Myers  \") = \"Fort Myers  \"));\n  (assert ((candidate \"Ft.  Myers \") = \"Fort  Myers \"));\n  (assert ((candidate \"Ft. Myers, Missouri\") = \"Fort Myers, Missouri\"));\n  (assert ((candidate \"Ft.  Myers, Missouri \") = \"Fort  Myers, Missouri \"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_79846_failed", "language": "ml", "prompt": "(**Simply attaches a failed marker to a message\n:param message: The message\n:return: String\n*)\nlet failed (message : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_79846_failed.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = failed in\n  (assert ((candidate \"test\") = \"Failed: test\"));\n  (assert ((candidate \"2\") = \"Failed: 2\"));\n  (assert ((candidate \"Message\") = \"Failed: Message\"));\n  (assert ((candidate \"This test passed!\") = \"Failed: This test passed!\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_80983_get_color", "language": "ml", "prompt": "(**Valid matplotlib colors. Could be used to automatically pick colors.\n:param n:   an integer\n:return:    a valid matploglib color string\n*)\nlet get_color (n : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_80983_get_color.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_color in\n  (assert ((candidate 23) = \"w\"));\n  (assert ((candidate 5) = candidate 13));\n  (assert ((candidate 17) = \"g\"));\n  (assert ((candidate 3) = \"c\"));\n  (assert ((candidate 31) = \"w\"));\n  (assert ((candidate 1) = candidate 17));\n  (assert ((candidate 3) = candidate 11));\n  (assert ((candidate 2) = candidate 10));\n  (assert ((candidate (~1)) = \"w\"));\n  (assert ((candidate 7) = \"w\"));\n  (assert ((candidate 4) = candidate 20));\n  (assert ((candidate 13) = \"y\"));\n  (assert ((candidate 9) = \"g\"));\n  (assert ((candidate 20) = \"m\"));\n  (assert ((candidate 25) = \"g\"));\n  (assert ((candidate 4) = \"m\"));\n  (assert ((candidate 4) = candidate 12));\n  (assert ((candidate 7) = candidate 15));\n  (assert ((candidate 0) = candidate 16));\n  (assert ((candidate 16) = \"b\"));\n  (assert ((candidate 24) = \"b\"));\n  (assert ((candidate 6) = \"k\"));\n  (assert ((candidate 6) = candidate 14));\n  (assert ((candidate 1) = candidate 9));\n  (assert ((candidate 5) = candidate 21));\n  (assert ((candidate 5) = \"y\"));\n  (assert ((candidate 12) = \"m\"));\n  (assert ((candidate 21) = \"y\"));\n  (assert ((candidate 14) = \"k\"));\n  (assert ((candidate 30) = \"k\"));\n  (assert ((candidate 2) = candidate 18));\n  (assert ((candidate 22) = \"k\"));\n  (assert ((candidate 7) = candidate 23));\n  (assert ((candidate 10) = \"r\"));\n  (assert ((candidate 1) = \"g\"));\n  (assert ((candidate 8) = \"b\"));\n  (assert ((candidate 3) = candidate 19));\n  (assert ((candidate 27) = \"c\"));\n  (assert ((candidate 0) = \"b\"));\n  (assert ((candidate 29) = \"y\"));\n  (assert ((candidate 15) = \"w\"));\n  (assert ((candidate 19) = \"c\"));\n  (assert ((candidate 26) = \"r\"));\n  (assert ((candidate 2) = \"r\"));\n  (assert ((candidate 28) = \"m\"));\n  (assert ((candidate 0) = candidate 8));\n  (assert ((candidate 18) = \"r\"));\n  (assert ((candidate 11) = \"c\"));\n  (assert ((candidate 6) = candidate 22));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_82442_get_params", "language": "ml", "prompt": "(**Turn arguments leftovers into service params.\n*)\nlet get_params (leftovers : string list) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_82442_get_params.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_params in\n  (assert ((candidate []) = []));\n  (assert ((candidate [\"--param1\"; \"--param2\"; \"b\"]) = []));\n  (assert ((candidate [\"--param1\"; \"a\"; \"--param2\"; \"b\"; \"c\"]) = []));\n  (assert ((candidate [\"--foo=1\"; \"--bar=2\"; \"--baz\"; \"baz=3\"]) = [(\"foo\", \"1\"); (\"bar\", \"2\"); (\"baz\", true); (\"baz\", \"3\")]));\n  (assert ((candidate [\"--foo=1\"; \"--bar=2\"; \"baz=3\"]) = [(\"foo\", \"1\"); (\"bar\", \"2\"); (\"baz\", \"3\")]));\n  (assert ((candidate [\"--foo=1\"; \"--bar=2\"]) = [(\"foo\", \"1\"); (\"bar\", \"2\")]));\n  (assert ((candidate [\"--foo=1\"; \"--bar=2\"; \"--baz\"; \"--baz=3\"]) = [(\"foo\", \"1\"); (\"bar\", \"2\"); (\"baz\", true); (\"baz\", \"3\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_82529_filter_file_paths_by_extension", "language": "ml", "prompt": "(**Filters out file paths that do not have an appropriate extension.\n:param file_paths: list of file path strings\n:param ext: valid extension\n*)\nlet filter_file_paths_by_extension (file_paths : string list) (ext : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_82529_filter_file_paths_by_extension.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = filter_file_paths_by_extension in\n  (assert ((candidate [\"a.csv\"; \"b.csv\"; \"c.csv\"; \"d.txt\"; \"e.txt\"; \"f.json\"; \"g.csv\"] \"  \") = []));\n  (assert ((candidate []) = []));\n  (assert ((candidate [\"my_file_0.csv\"]) = [\"my_file_0.csv\"]));\n  (assert ((candidate [\"a.csv\"; \"b.csv\"; \"c.csv\"; \"d.txt\"; \"e.txt\"; \"f.json\"; \"g.csv\"] \"csvx\") = []));\n  (assert ((candidate [\"my_file_0.csv\"; \"my_file_1.csv\"; \"my_file_2.csv\"; \"my_file_3.txt\"; \"my_file_4.png\"]) = [\"my_file_0.csv\"; \"my_file_1.csv\"; \"my_file_2.csv\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_82780_is_bidirectional_conversion", "language": "ml", "prompt": "(**Check that two unicode value are also a mapping value of each other.\n:param letter_id: An integer, representing the unicode code point of the character.\n:param other_case_mapping: Comparable case mapping table which possible contains\n * the return direction of the conversion.\n:return: True, if it's a reverible conversion, false otherwise.\n*)\nlet is_bidirectional_conversion (letter_id : int) (letter_case : (int, string) list) (reverse_letter_case : (int, string) list) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_82780_is_bidirectional_conversion.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_bidirectional_conversion in\n  (assert ((candidate 65 [(65, \"A\")] [(66, \"B\")]) = false));\n  (assert ((candidate 65 [(65, \"a\"); (66, \"B\")] [(66, \"b\")]) = false));\n  (assert ((candidate 65 [(65, \"a\")] [(66, \"B\")]) = false));\n  (assert ((candidate 65 [(65, \"A\")] [(97, \"B\")]) = false));\n  (assert ((candidate 223 [(223, \"ss\")] [(83, \"S\")]) = false));\n  (assert ((candidate 65 [(65, \"A\")] [(66, \"a\")]) = false));\n  (assert ((candidate 65 [(65, \"A\")] [(65, \"a\")]) = false));\n  (assert ((candidate 65 [(65, \"a\")] [(65, \"a\")]) = false));\n  (assert ((candidate 65 [(65, \"A\")] [(97, \"A\")]) = false));\n  (assert ((candidate 65 [(65, \"A\")] [(98, \"a\")]) = false));\n  (assert ((candidate 65 [(65, \"A\")] [(98, \"B\")]) = false));\n  (assert ((candidate 97 [(65, \"A\")] [(65, \"A\")]) = false));\n  (assert ((candidate 65 [(65, \"A\"); (66, \"B\")] [(66, \"b\")]) = false));\n  (assert ((candidate 98 [(66, \"B\")] [(66, \"B\")]) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_8290_dot", "language": "ml", "prompt": "(**v and u are vectors. v and u -> list\n*)\nlet dot (v : int list) (u : int list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_8290_dot.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = dot in\n  (assert ((candidate [1; 2] [3; 4]) = 11));\n  (assert ((candidate ) = 11));\n  (assert ((candidate ) = 5));\n  (assert ((candidate [(~1); 2] [3; 4]) = 5));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_8323__get_text_alignment", "language": "ml", "prompt": "(**Get the horizontal and vertical text alignment keywords for text placed at the end of a line segment from point1 to point2\nargs:\n * point1 - x,y pair\n * point2 - x,y pair\nreturns:\n * ha - horizontal alignment string\n * va - vertical alignment string\n*)\nlet _get_text_alignment (point1 :  int * int) (point2 :  int * int) :  string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_8323__get_text_alignment.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _get_text_alignment in\n  (assert ((candidate (0, 0) (1, 1)) = (\"left\", \"bottom\")));\n  (assert ((candidate ((~1), (~1)) (1, 1)) = (\"left\", \"bottom\")));\n  (assert ((candidate (0, 0) ((~1), (~1))) = (\"right\", \"top\")));\n  (assert ((candidate (1, 1) ((~1), (~1))) = (\"right\", \"top\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_83484_getRefId", "language": "ml", "prompt": "(**Get the reference ID for a reference name\n*)\nlet getRefId (refs : string list) (refname : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_83484_getRefId.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = getRefId in\n  (assert ((candidate [\"A\"; \"B\"; \"C\"] \"A\") = 0));\n  (assert ((candidate [\"A\"; \"B\"; \"C\"] \"I\") = (~1)));\n  (assert ((candidate list \"GATTACA\" \"GG\") = (~1)));\n  (assert ((candidate list \"GATTACA\" \"A\") = 1));\n  (assert ((candidate [\"A\"; \"B\"; \"C\"] \"E\") = (~1)));\n  (assert ((candidate list \"GATTACA\" \"GATAA\") = (~1)));\n  (assert ((candidate [\"A\"; \"B\"; \"C\"] \"D\") = (~1)));\n  (assert ((candidate [\"A\"; \"B\"; \"C\"] \"F\") = (~1)));\n  (assert ((candidate [\"A\"; \"B\"; \"C\"] \"L\") = (~1)));\n  (assert ((candidate [\"A\"; \"B\"; \"C\"] \"K\") = (~1)));\n  (assert ((candidate [\"A\"; \"B\"; \"C\"] \"J\") = (~1)));\n  (assert ((candidate [\"A\"; \"B\"; \"C\"] \"G\") = (~1)));\n  (assert ((candidate [\"A\"; \"B\"; \"C\"] \"A\") = 0));\n  (assert ((candidate [\"A\"; \"B\"; \"C\"] \"D\") = (~1)));\n  (assert ((candidate [\"A\"; \"B\"; \"C\"] \"H\") = (~1)));\n  (assert ((candidate [\"A\"; \"B\"; \"C\"] \"C\") = 2));\n  (assert ((candidate [\"A\"; \"B\"; \"C\"] \"C\") = 2));\n  (assert ((candidate [\"A\"; \"B\"; \"C\"] \"B\") = 1));\n  (assert ((candidate list \"GATTACA\" \"G\") = 0));\n  (assert ((candidate [\"A\"; \"B\"; \"C\"] \"B\") = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_83818_solution2", "language": "ml", "prompt": "(**given an index i, sort  the array such that elements less then i appear before i\nthen element at i, then all items that are larger\n*)\nlet solution2 (n : int list) (i : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_83818_solution2.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = solution2 in\n  (assert ((candidate [1; 4; 3; 2; 6] 0) = [1; 4; 3; 2; 6]));\n  (assert ((candidate [1; 4; 3; 2; 6] 1) = [1; 3; 2; 4; 6]));\n  (assert ((candidate [1; 2; 5; 3; 4] 2) = [1; 2; 3; 4; 5]));\n  (assert ((candidate list range 10 5) = list range 10));\n  (assert ((candidate [1; 4; 3; 2; 6] 2) = [1; 2; 3; 4; 6]));\n  (assert ((candidate [1; 2; 3; 4; 5] 4) = [1; 2; 3; 4; 5]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_84115_solution1", "language": "ml", "prompt": "(**Solves the first part of the challenge\n*)\nlet solution1 (inp : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_84115_solution1.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = solution1 in\n  (assert ((candidate \"1721\n979\n366\n299\n675\n1456\") = 514579));\n  (assert ((candidate \"\n1721\n979\n366\n299\n675\n1456\n\") = 514579));\n  (assert ((candidate \"1721\n    979\n    366\n    299\n    675\n    1456\") = 514579));\n  (assert ((candidate \"\n1721\n979\n366\n299\n675\n1456\n\") = 514579));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_84207_isize", "language": "ml", "prompt": "(**Get a readable size from a number of bytes.\n*)\nlet isize (n : int) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_84207_isize.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = isize in\n  (assert ((candidate 1023) = \"1023 B\"));\n  (assert ((candidate 1024) = \"1.00 KB\"));\n  (assert ((candidate 1025) = \"1.00 KB\"));\n  (assert ((candidate 1) = \"1 B\"));\n  (assert ((candidate 0) = \"0 B\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_84583_min_abs_mod", "language": "ml", "prompt": "(**This function returns absolute minimum modulo of a over b.\n*)\nlet min_abs_mod (a : int) (b : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_84583_min_abs_mod.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = min_abs_mod in\n  (assert ((candidate 10 10) = 0));\n  (assert ((candidate (~1) 1) = 0));\n  (assert ((candidate 3 10) = 3));\n  (assert ((candidate 3 (~5)) = (~2)));\n  (assert ((candidate 1 1) = 0));\n  (assert ((candidate (~15) 5) = 0));\n  (assert ((candidate (~3) 5) = 2));\n  (assert ((candidate 10 5) = 0));\n  (assert ((candidate 8 6) = 2));\n  (assert ((candidate 3 3) = 0));\n  (assert ((candidate (~2) 2) = 0));\n  (assert ((candidate 10 3) = 1));\n  (assert ((candidate 2 (~2)) = 0));\n  (assert ((candidate 2 2) = 0));\n  (assert ((candidate 2 (~1)) = 0));\n  (assert ((candidate 7 6) = 1));\n  (assert ((candidate 8 8) = 0));\n  (assert ((candidate 5 5) = 0));\n  (assert ((candidate (~2) (~1)) = 0));\n  (assert ((candidate 4 4) = 0));\n  (assert ((candidate (~10) 5) = 0));\n  (assert ((candidate 1 5) = 1));\n  (assert ((candidate 2 1) = 0));\n  (assert ((candidate (~1) (~2)) = (~1)));\n  (assert ((candidate (~2) 1) = 0));\n  (assert ((candidate 6 6) = 0));\n  (assert ((candidate 0 1) = 0));\n  (assert ((candidate 1 (~1)) = 0));\n  (assert ((candidate 7 5) = 2));\n  (assert ((candidate (~2) (~2)) = 0));\n  (assert ((candidate 0 5) = 0));\n  (assert ((candidate 10 7) = 3));\n  (assert ((candidate 4 3) = 1));\n  (assert ((candidate 8 4) = 0));\n  (assert ((candidate (~1) (~1)) = 0));\n  (assert ((candidate (~1) 2) = 1));\n  (assert ((candidate 1 3) = 1));\n  (assert ((candidate 2 5) = 2));\n  (assert ((candidate 4 2) = 0));\n  (assert ((candidate (~5) 5) = 0));\n  (assert ((candidate 7 7) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_84972_parse_hex", "language": "ml", "prompt": "(**Helper function for RA and Dec parsing, takes hex string, returns list of floats.\nNot normally called directly by user. TESTS OK 2020-10-24.\n * :param hex_string: string in either full hex (\"12:34:56.7777\" or \"12 34 56.7777\"),\n * or degrees (\"234.55\")\n * :return: list of strings representing floats (hours:min:sec or deg:arcmin:arcsec).\n*)\nlet parse_hex (hex_string : string) : string list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_84972_parse_hex.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_hex in\n  (assert ((candidate \"234.55\") = [\"234.55\"]));\n  (assert ((candidate \"123456.777\") = [\"123456.777\"]));\n  (assert ((candidate \"12:34:56.7777\") = candidate \"12 34 56.7777\"));\n  (assert ((candidate \"23:45:12.456\") = [\"23\"; \"45\"; \"12.456\"]));\n  (assert ((candidate \"-23:45:12.456\") = [\"-23\"; \"45\"; \"12.456\"]));\n  (assert ((candidate \"12 34 56.7777\") = [\"12\"; \"34\"; \"56.7777\"]));\n  (assert ((candidate \"12 34 56.777 78 90 11.111\") = [\"12\"; \"34\"; \"56.777\"; \"78\"; \"90\"; \"11.111\"]));\n  (assert ((candidate \"-234.5555\") = [\"-234.5555\"]));\n  (assert ((candidate \"12:34:56\") = [\"12\"; \"34\"; \"56\"]));\n  (assert ((candidate \"12 34 56.7777\") = [\"12\"; \"34\"; \"56.7777\"]));\n  (assert ((candidate \"12 34 56.777\") = [\"12\"; \"34\"; \"56.777\"]));\n  (assert ((candidate \"12:34:56.7777\") = [\"12\"; \"34\"; \"56.7777\"]));\n  (assert ((candidate \"12:34:56.777\") = [\"12\"; \"34\"; \"56.777\"]));\n  (assert ((candidate \"234.5555\") = [\"234.5555\"]));\n  (assert ((candidate \"12 34 56\") = [\"12\"; \"34\"; \"56\"]));\n  (assert ((candidate \"12:34:56\") = [\"12\"; \"34\"; \"56\"]));\n  (assert ((candidate \"12:34:56.7777\") = [\"12\"; \"34\"; \"56.7777\"]));\n  (assert ((candidate \"12 34 56\") = [\"12\"; \"34\"; \"56\"]));\n  (assert ((candidate \"234.55\") = [\"234.55\"]));\n  (assert ((candidate \"234.55 24.12\") = [\"234.55\"; \"24.12\"]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_854_arg_return_greetings", "language": "ml", "prompt": "(**This is greeting function with arguments and return greeting message\n:param name:\n:return:\n*)\nlet arg_return_greetings (name : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_854_arg_return_greetings.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = arg_return_greetings in\n  (assert ((candidate \"Bob\") = \"hello Bob\"));\n  (assert ((candidate \"Milton\") = \"hello Milton\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_85909_validate_training_proportion_input", "language": "ml", "prompt": "(**Validates the training proportion input\n:param input: The training proportion before parsing\n:return: The training proportion after parsing\n*)\nlet validate_training_proportion_input (input : string) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_85909_validate_training_proportion_input.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = validate_training_proportion_input in\n  (assert ((candidate 0.1) = 0.1));\n  (assert ((candidate ) = 0.3));\n  (assert ((candidate 0.2) = 0.2));\n  (assert ((candidate 0.3) = 0.3));\n  (assert ((candidate \"1\") = 1.0));\n  (assert ((candidate 1) = 1.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_86450_matrix_n_by_n_determinant", "language": "ml", "prompt": "(**find the determinant of a n by n matrix\n*)\nlet matrix_n_by_n_determinant (nb_rows : int) (nb_cols : int) (matrix : int list list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_86450_matrix_n_by_n_determinant.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = matrix_n_by_n_determinant in\n  (assert ((candidate 1 2 [[1; 2]]) = 1));\n  (assert ((candidate 1 1 [[5]]) = 5));\n  (assert ((candidate 4 4 [[1; 2; 3; 4]; [5; 6; 7; 8]; [9; 10; 11; 12]; [13; 14; 15; 16]]) = 0));\n  (assert ((candidate 1 1 [[1]]) = 1));\n  (assert ((candidate 1 1 [[2]]) = 2));\n  (assert ((candidate 2 2 [[2; 3]; [4; 5]]) = (~2)));\n  (assert ((candidate 1 3 [[1; 2; 3]]) = 1));\n  (assert ((candidate 2 2 [[1; 2]; [3; 4]]) = (~2)));\n  (assert ((candidate 3 3 [[1; 2; 3]; [4; 5; 6]; [7; 8; 9]]) = 0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_86590_horizontal_index", "language": "ml", "prompt": "(**Compute the array index using horizontal-display logic\n*)\nlet horizontal_index (ncols : int) (row : int) (col : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_86590_horizontal_index.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = horizontal_index in\n  (assert ((candidate 2 1 1) = 1));\n  (assert ((candidate 2 1 2) = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_86759_parse_codesys", "language": "ml", "prompt": "(**Operating System: Nucleus PLUS\nOperating System Details: Nucleus PLUS version unknown\nProduct: 3S-Smart Software Solutions\n*)\nlet parse_codesys (info : string) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_86759_parse_codesys.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_codesys in\n  (assert ((candidate \"Operating System: Nucleus PLUS\nOperating System Details: Nucleus PLUS version unknown\nProduct: 3S-Smart Software Solutions\n\") = [(\"Operating System\", \"Nucleus PLUS\"); (\"Operating System Details\", \"Nucleus PLUS version unknown\"); (\"Product\", \"3S-Smart Software Solutions\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_86814_polynomial_decay_learning_rate", "language": "ml", "prompt": "(**Manual implementation of polynomial decay for learning rate\n:param step: which step we're on\n:param learning_rate_start: learning rate for epoch 0\n:param learning_rate_final: learning rate for epoch decay_steps\n:param decay_steps: epoch at which learning rate stops changing\n:param power: exponent\n:return:\n*)\nlet polynomial_decay_learning_rate (step : int) (learning_rate_start : float) (learning_rate_final : float) (decay_steps : int) (power : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_86814_polynomial_decay_learning_rate.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = polynomial_decay_learning_rate in\n  (assert ((candidate 25 1.0 0.0 25 1.0) = 0.0));\n  (assert ((candidate 50 1.0 0.0 25 1.0) = 0.0));\n  (assert ((candidate 0 1.0 0.0 25 1.0) = 1.0));\n  (assert ((candidate 10 0.1 0.5 1 2.0) = 0.5));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_87160_steps_cancel_out", "language": "ml", "prompt": "(**>>> steps_cancel_out(None, \"U\")\nFalse\n>>> steps_cancel_out(\"U\", \"U'\")\nTrue\n>>> steps_cancel_out(\"U'\", \"U\")\nTrue\n>>> steps_cancel_out(\"U2\", \"U2\")\nTrue\n>>> steps_cancel_out(\"U\", \"U\")\nFalse\n*)\nlet steps_cancel_out (prev_step : string option) (step : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_87160_steps_cancel_out.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = steps_cancel_out in\n  (assert ((candidate Some(\"U2\") \"U2\") = true));\n  (assert ((candidate Some(\"U\") \"U2\") = false));\n  (assert ((candidate Some(\"U2\") \"U\") = false));\n  (assert ((candidate Some(\"U'\") \"U\") = true));\n  (assert ((candidate Some(\"U\") \"U'\") = true));\n  (assert ((candidate Some(\"U\") \"U\") = false));\n  (assert ((candidate Some(None) \"U\") = false));\n  (assert ((candidate Some(\"U2\") \"D2\") = false));\n  (assert ((candidate Some(\"U'\") \"U2\") = false));\n  (assert ((candidate Some(\"U2\") \"U'\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_87271_longestPalindrome", "language": "ml", "prompt": "(**Finds the longest instance of a palindrome in a string\n*)\nlet longestPalindrome (text : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_87271_longestPalindrome.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = longestPalindrome in\n  (assert ((candidate \"a\") = \"a\"));\n  (assert ((candidate \"abcba\") = \"abcba\"));\n  (assert ((candidate \"aa\") = \"aa\"));\n  (assert ((candidate \"abba\") = \"abba\"));\n  (assert ((candidate \"abababa\") = \"abababa\"));\n  (assert ((candidate \"racecar\") = \"racecar\"));\n  (assert ((candidate \"bananas\") = \"anana\"));\n  (assert ((candidate \"aba\") = \"aba\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_87596_delimiter_check", "language": "ml", "prompt": "(**Determines what delimiter is used in given text file.\nParameters:\n * -line: str\n * line from text file\nReturns:\n * -delim: str\n * delimiter used in text file\nNotes:\nRecognizes only \",\", \"\t\", and \":\" delimiters.\n*)\nlet delimiter_check (line : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_87596_delimiter_check.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = delimiter_check in\n  (assert ((candidate \"a,b,c\") = \",\"));\n  (assert ((candidate \"a\tb\tc\") = \"\t\"));\n  (assert ((candidate \"a:b:c\") = \":\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_87843_create_fixed_income_regex", "language": "ml", "prompt": "(**Creates a regular expression pattern to match the fixed income symbology.\nTo create the regular expression patter, the function uses the fact that within the\nICE consolidated feed, all the fixed income instruments are identified by the root\nsymbol ( a unique mnemonic based on the exchange ticker or the ISIN, where no exchange\nticker is available), prefixed with the type and the optional session indicator. In\naddition to this minimal symbology setup, fixed income symbols can present optional\nelements such as the \"dirty bond\" marker and the sub-market indicator.\nThe function only requires the root symbol, prefixed with the type and the optional\nsession indicator, to generate a regular expression pattern, and takes care to\nautonomously extend the pattern to match as well all the optional components of the\nsymbol.\nParameters\n----------\ninput_symbol: str\n * A fixed income symbol consisting of the root symbol prefixed with the type\n * identifier (B) and optional session indicator.\nReturns\n-------\nstr\n * The regular expression pattern that matches the input symbol as well as all the\n * optional components.\n*)\nlet create_fixed_income_regex (input_symbol : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_87843_create_fixed_income_regex.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = create_fixed_income_regex in\n  (assert ((candidate \"B\\d{1,10}\") = \"\\bB\\d{1,10}\\b\\\\{0,1}D{0,1}@{0,1}[a-zA-Z0-9]{1,10}\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_87844_min_value", "language": "ml", "prompt": "(**Compute min of a pair of two ints.\n*)\nlet min_value (a : int) (b : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_87844_min_value.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = min_value in\n  (assert ((candidate 3 5) = 3));\n  (assert ((candidate 2 1) = 1));\n  (assert ((candidate 0 (~2)) = (~2)));\n  (assert ((candidate (~1) (~2)) = (~2)));\n  (assert ((candidate 2 3) = 2));\n  (assert ((candidate 3 4) = 3));\n  (assert ((candidate 3 1) = 1));\n  (assert ((candidate 100 1) = 1));\n  (assert ((candidate 2 2) = 2));\n  (assert ((candidate 1 100) = 1));\n  (assert ((candidate 0 0) = 0));\n  (assert ((candidate 1 1) = 1));\n  (assert ((candidate 1 3) = 1));\n  (assert ((candidate 3 3) = 3));\n  (assert ((candidate 5 3) = 3));\n  (assert ((candidate 1 2) = 1));\n  (assert ((candidate 3 2) = 2));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_88209_location", "language": "ml", "prompt": "(**Function to format location\n*)\nlet location (loc : string) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_88209_location.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = location in\n  (assert ((candidate \"40.780831,-73.965339, 150 ft\") = [(\"parsed\", \"40.780831,-73.965339, 150 ft\"); (\"string\", \"40.780831,-73.965339, 150 ft\")]));\n  (assert ((candidate \"E\") = [(\"parsed\", \"E\"); (\"string\", \"E\")]));\n  (assert ((candidate \"F\") = [(\"parsed\", \"F\"); (\"string\", \"F\")]));\n  (assert ((candidate \"H\") = [(\"parsed\", \"H\"); (\"string\", \"H\")]));\n  (assert ((candidate \"D\") = [(\"parsed\", \"D\"); (\"string\", \"D\")]));\n  (assert ((candidate \"New York, NY\") = [(\"parsed\", \"New York, NY\"); (\"string\", \"New York, NY\")]));\n  (assert ((candidate \"somewhere\") = [(\"parsed\", \"somewhere\"); (\"string\", \"somewhere\")]));\n  (assert ((candidate \"G\") = [(\"parsed\", \"G\"); (\"string\", \"G\")]));\n  (assert ((candidate \"742 Evergreen Terrace\") = [(\"parsed\", \"742 Evergreen Terrace\"); (\"string\", \"742 Evergreen Terrace\")]));\n  (assert ((candidate \"New York City\") = [(\"parsed\", \"New York City\"); (\"string\", \"New York City\")]));\n  (assert ((candidate \"Q\") = [(\"parsed\", \"Q\"); (\"string\", \"Q\")]));\n  (assert ((candidate \"New York\") = [(\"parsed\", \"New York\"); (\"string\", \"New York\")]));\n  (assert ((candidate \"L\") = [(\"parsed\", \"L\"); (\"string\", \"L\")]));\n  (assert ((candidate \"CaliforniA, Irvine\") = [(\"parsed\", \"CaliforniA, Irvine\"); (\"string\", \"CaliforniA, Irvine\")]));\n  (assert ((candidate \"P\") = [(\"parsed\", \"P\"); (\"string\", \"P\")]));\n  (assert ((candidate \"M\") = [(\"parsed\", \"M\"); (\"string\", \"M\")]));\n  (assert ((candidate \"A\") = [(\"parsed\", \"A\"); (\"string\", \"A\")]));\n  (assert ((candidate \"UCLA\") = [(\"parsed\", \"UCLA\"); (\"string\", \"UCLA\")]));\n  (assert ((candidate \"University of California, Irvine\") = [(\"parsed\", \"University of California, Irvine\"); (\"string\", \"University of California, Irvine\")]));\n  (assert ((candidate \"R\") = [(\"parsed\", \"R\"); (\"string\", \"R\")]));\n  (assert ((candidate \"40.780831, -73.965339\") = [(\"parsed\", \"40.780831, -73.965339\"); (\"string\", \"40.780831, -73.965339\")]));\n  (assert ((candidate \"NYC\") = [(\"parsed\", \"NYC\"); (\"string\", \"NYC\")]));\n  (assert ((candidate \"C\") = [(\"parsed\", \"C\"); (\"string\", \"C\")]));\n  (assert ((candidate \"40.780831,-73.965339\") = [(\"parsed\", \"40.780831,-73.965339\"); (\"string\", \"40.780831,-73.965339\")]));\n  (assert ((candidate \"San Diego State University\") = [(\"parsed\", \"San Diego State University\"); (\"string\", \"San Diego State University\")]));\n  (assert ((candidate \"O\") = [(\"parsed\", \"O\"); (\"string\", \"O\")]));\n  (assert ((candidate \"\") = [(\"parsed\", \"\"); (\"string\", \"\")]));\n  (assert ((candidate \"J\") = [(\"parsed\", \"J\"); (\"string\", \"J\")]));\n  (assert ((candidate \"K\") = [(\"parsed\", \"K\"); (\"string\", \"K\")]));\n  (assert ((candidate \"University of California, San Diego\") = [(\"parsed\", \"University of California, San Diego\"); (\"string\", \"University of California, San Diego\")]));\n  (assert ((candidate \"N\") = [(\"parsed\", \"N\"); (\"string\", \"N\")]));\n  (assert ((candidate \"None\") = [(\"parsed\", \"None\"); (\"string\", \"N/A\")]));\n  (assert ((candidate \"New York State University\") = [(\"parsed\", \"New York State University\"); (\"string\", \"New York State University\")]));\n  (assert ((candidate \"I\") = [(\"parsed\", \"I\"); (\"string\", \"I\")]));\n  (assert ((candidate \"B\") = [(\"parsed\", \"B\"); (\"string\", \"B\")]));\n  (assert ((candidate \"New York State\") = [(\"parsed\", \"New York State\"); (\"string\", \"New York State\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_8834_count_digit", "language": "ml", "prompt": "(**Return how many times digit appears in n.\n>>> count_digit(55055, 5)\n4\n>>> count_digit(1231421, 1)\n3\n>>> count_digit(12, 3)\n0\n*)\nlet count_digit (n : int) (digit : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_8834_count_digit.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = count_digit in\n  (assert ((candidate 55055 5) = 4));\n  (assert ((candidate 12345 6) = 0));\n  (assert ((candidate 1234 2) = 1));\n  (assert ((candidate 1234 3) = 1));\n  (assert ((candidate 1231421 1) = 3));\n  (assert ((candidate 12 3) = 0));\n  (assert ((candidate 1231421 0) = 0));\n  (assert ((candidate 1234 5) = 0));\n  (assert ((candidate 1231421 5) = 0));\n  (assert ((candidate 1234 4) = 1));\n  (assert ((candidate 1234 1) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_89299_get_pkg_vendor_name", "language": "ml", "prompt": "(**Method to extract vendor and name information from package. If vendor information is not available\npackage url is used to extract the package registry provider such as pypi, maven\n*)\nlet get_pkg_vendor_name (pkg : (string, string) list) :  string * string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_89299_get_pkg_vendor_name.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = get_pkg_vendor_name in\n  (assert ((candidate [(\"purl\", \"pkg:pypi/pip\"); (\"type\", \"pypi\"); (\"name\", \"pip\"); (\"version\", \"20.3.4\"); (\"scope\", \"dependencies\")]) = (\"pypi\", \"pip\")));\n  (assert ((candidate [(\"purl\", \"pkg:pypi/pip@20.3.4\"); (\"type\", \"pypi\"); (\"name\", \"pip\"); (\"version\", \"20.3.4\"); (\"scope\", \"dependencies\")]) = (\"pypi\", \"pip\")));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_8962_is_catalog_record_owner", "language": "ml", "prompt": "(**Does user_id own catalog_record.\n:param catalog_record:\n:param user_id:\n:return:\n*)\nlet is_catalog_record_owner (catalog_record : (string, string) list) (user_id : string option) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_8962_is_catalog_record_owner.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_catalog_record_owner in\n  (assert ((candidate [(\"metadata_provider_user\", \"a\"); (\"owner\", \"b\")] Some(\"a\")) = true));\n  (assert ((candidate [(\"metadata_provider_user\", \"a\"); (\"owner\", \"a\")] Some(\"b\")) = false));\n  (assert ((candidate [(\"metadata_provider_user\", \"a\"); (\"owner\", \"b\")] Some(None)) = false));\n  (assert ((candidate [(\"metadata_provider_user\", \"a\"); (\"owner\", \"a\")] Some(None)) = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_89762_maxSatisfied", "language": "ml", "prompt": "(**:type customers: List[int]\n:type grumpy: List[int]\n:type X: int\n:rtype: int\n*)\nlet maxSatisfied (customers : int list) (grumpy : int list) (X : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_89762_maxSatisfied.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = maxSatisfied in\n  (assert ((candidate [0; 0] [0; 0] 1) = 0));\n  (assert ((candidate [1; 0; 1; 2; 1; 1; 7; 5] [0; 1; 0; 1; 0; 1; 0; 1] 3) = 16));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_90472_conv_ls", "language": "ml", "prompt": "(**convert a number in a list of integers\n*)\nlet conv_ls (N : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_90472_conv_ls.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = conv_ls in\n  (assert ((candidate 5) = [5]));\n  (assert ((candidate 7) = [7]));\n  (assert ((candidate 256) = [2; 5; 6]));\n  (assert ((candidate 123456789) = [1; 2; 3; 4; 5; 6; 7; 8; 9]));\n  (assert ((candidate 12345) = [1; 2; 3; 4; 5]));\n  (assert ((candidate 2) = [2]));\n  (assert ((candidate 9) = [9]));\n  (assert ((candidate 1) = [1]));\n  (assert ((candidate 19) = [1; 9]));\n  (assert ((candidate 123) = [1; 2; 3]));\n  (assert ((candidate 21) = [2; 1]));\n  (assert ((candidate 100) = [1; 0; 0]));\n  (assert ((candidate 12345) = [1; 2; 3; 4; 5]));\n  (assert ((candidate 23) = [2; 3]));\n  (assert ((candidate 253) = [2; 5; 3]));\n  (assert ((candidate 20) = [2; 0]));\n  (assert ((candidate 0) = [0]));\n  (assert ((candidate 32) = [3; 2]));\n  (assert ((candidate 13) = [1; 3]));\n  (assert ((candidate 11) = [1; 1]));\n  (assert ((candidate 18) = [1; 8]));\n  (assert ((candidate 1000) = [1; 0; 0; 0]));\n  (assert ((candidate 1234567) = [1; 2; 3; 4; 5; 6; 7]));\n  (assert ((candidate 12) = [1; 2]));\n  (assert ((candidate 123456) = [1; 2; 3; 4; 5; 6]));\n  (assert ((candidate 17) = [1; 7]));\n  (assert ((candidate 24) = [2; 4]));\n  (assert ((candidate 111) = [1; 1; 1]));\n  (assert ((candidate 8) = [8]));\n  (assert ((candidate 1234) = [1; 2; 3; 4]));\n  (assert ((candidate 22) = [2; 2]));\n  (assert ((candidate 26) = [2; 6]));\n  (assert ((candidate 4) = [4]));\n  (assert ((candidate 15) = [1; 5]));\n  (assert ((candidate 25) = [2; 5]));\n  (assert ((candidate 6) = [6]));\n  (assert ((candidate 257) = [2; 5; 7]));\n  (assert ((candidate 3) = [3]));\n  (assert ((candidate 10) = [1; 0]));\n  (assert ((candidate 16) = [1; 6]));\n  (assert ((candidate 14) = [1; 4]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_9048_upto", "language": "ml", "prompt": "(**return all the text up to the limit string\n*)\nlet upto (limit : string) (text : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_9048_upto.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = upto in\n  (assert ((candidate \" \" \"Python is the best choice to start learning\") = \"Python\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_90538_rev", "language": "ml", "prompt": "(**>>> rev([20, 13, 8, 19, 19, 4, 18, 19, 8, 18, 1, 4, 19, 19, 4, 17])\n'unittestisbetter'\n*)\nlet rev (l : int list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_90538_rev.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = rev in\n  (assert ((candidate list \"\") = \"\"));\n  (assert ((candidate [20; 13; 8; 19; 19; 4; 18; 19; 8; 18; 1; 4; 19; 19; 4; 17]) = \"unittestisbetter\"));\n  (assert ((candidate []) = \"\"));\n  (assert ((candidate [20; 13; 8; 19; 19; 4; 18; 19; 8; 18; 1; 4; 19; 19; 4; 17]) = \"unittestisbetter\"));\n  (assert ((candidate [20; 13; 8; 19; 19; 4; 18; 19; 8; 18; 1; 4; 19; 19; 4; 17]) = \"unittestisbetter\"));\n  (assert ((candidate [20; 13; 8; 19; 19; 4; 18; 19; 8; 18; 1; 4; 19; 19; 4; 17]) = \"unittestisbetter\"));\n  (assert ((candidate [20; 13; 8; 19; 19; 4; 18; 19; 8; 18; 1; 4; 19; 19; 4; 17]) = \"unittestisbetter\"));\n  (assert ((candidate list range 20) = \"abcdefghijklmnopqrst\"));\n  (assert ((candidate list map ord \"\") = \"\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_90563_smallest_difference", "language": "ml", "prompt": "(**Finds smallest angle between two bearings\n:param value1:\n:param value2:\n:return:\n*)\nlet smallest_difference (value1 : int) (value2 : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_90563_smallest_difference.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = smallest_difference in\n  (assert ((candidate 10 10) = 0));\n  (assert ((candidate (~5) 5) = 10));\n  (assert ((candidate 30 35) = 5));\n  (assert ((candidate 290 270) = 20));\n  (assert ((candidate 270 270) = 0));\n  (assert ((candidate 30 50) = 20));\n  (assert ((candidate 0 360) = 0));\n  (assert ((candidate 20 35) = 15));\n  (assert ((candidate 30 30) = 0));\n  (assert ((candidate 35 20) = 15));\n  (assert ((candidate (~10) 10) = 20));\n  (assert ((candidate 35 30) = 5));\n  (assert ((candidate 20 50) = 30));\n  (assert ((candidate 15 45) = 30));\n  (assert ((candidate (~5) 25) = 30));\n  (assert ((candidate 270 360) = 90));\n  (assert ((candidate 270 290) = 20));\n  (assert ((candidate 10 20) = 10));\n  (assert ((candidate 25 (~5)) = 30));\n  (assert ((candidate 350 360) = 10));\n  (assert ((candidate 350 355) = 5));\n  (assert ((candidate 350 350) = 0));\n  (assert ((candidate 10 30) = 20));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_90785_dist_point", "language": "ml", "prompt": "(**Computes the distance square between a point and a line\ninputs:\n * - point : (x,y)\n * - line  : (slope, intercept)\n*)\nlet dist_point (point :  int * int) (line :  int * int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_90785_dist_point.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = dist_point in\n  (assert ((candidate (1, 2) (1, 3)) = 4));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_91158_count_leading_empty_lines", "language": "ml", "prompt": "(**Count the number of leading empty cells.\n*)\nlet count_leading_empty_lines (cell : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_91158_count_leading_empty_lines.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = count_leading_empty_lines in\n  (assert ((candidate \"Hello world!\") = 0));\n  (assert ((candidate \"\n# This is a comment\n# This is another comment\nhello\nworld\n\") = 1));\n  (assert ((candidate \"hello world\") = 0));\n  (assert ((candidate \"\n\nhello\nworld\n\") = 2));\n  (assert ((candidate \"The first line is not empty\") = 0));\n  (assert ((candidate \"    \n    \") = 2));\n  (assert ((candidate \"    Hello, world!\n    \") = 0));\n  (assert ((candidate \"\nA long cell with leading empty lines\n\n\") = 1));\n  (assert ((candidate \"\n# This is a comment\nhello\nworld\n\") = 1));\n  (assert ((candidate \"\n\n\") = 2));\n  (assert ((candidate \"This cell contains one line of text.\") = 0));\n  (assert ((candidate \"    \n    \n    \") = 3));\n  (assert ((candidate \"def func():\n    print('Hi')\n\") = 0));\n  (assert ((candidate \"\n\n\nhello\nworld\n\") = 3));\n  (assert ((candidate \"text\") = 0));\n  (assert ((candidate \"\") = 0));\n  (assert ((candidate \"\n\nhello\nworld\n\") = 2));\n  (assert ((candidate \"\n\n\ntext\") = 3));\n  (assert ((candidate \"\n\n# This is a comment\nhello\nworld\n\") = 2));\n  (assert ((candidate \"hello\nworld\n\") = 0));\n  (assert ((candidate \"\n\n\n\") = 3));\n  (assert ((candidate \"\n\n\n   \ntext\") = 4));\n  (assert ((candidate \"\nhello\nworld\n\") = 1));\n  (assert ((candidate \"   \") = 1));\n  (assert ((candidate \"\n\n    \") = 3));\n  (assert ((candidate \"\") = 0));\n  (assert ((candidate \"\n\") = 1));\n  (assert ((candidate \"\") = 0));\n  (assert ((candidate \"hello world\") = 0));\n  (assert ((candidate \"\n\n\nhello\nworld\n\") = 3));\n  (assert ((candidate \"\nA long cell with leading empty lines\n\n \n\n\n\n \n\n\n\") = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_91177_calc_mi", "language": "ml", "prompt": "(**Calculate migration index (MI).\nFor the right hip, MI = (lat acetabulum - lat head) / (med head - lat head)\nFor the left hip first need to multiple each point by -1.\nArgs:\n * med_head_x: x coordinate of medial head\n * lat_head_x: x coordinate of lateral head\n * lat_acetabulum_x: x coordinate of lateral acetabulum\n * side: side of hip from which points come (i.e., 'right' or 'left')\nRaise:\n * ValueError if side not in ['right', 'left']\nReturns:\n * Migration index in interval [0,1]\n*)\nlet calc_mi (med_head_x : int) (lat_head_x : int) (lat_acetabulum_x : int) (side : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_91177_calc_mi.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = calc_mi in\n  (assert ((candidate 2 1 2 \"right\") = 1));\n  (assert ((candidate 2 1 1 \"right\") = 0));\n  (assert ((candidate 2 1 2 \"left\") = 1));\n  (assert ((candidate 1 0 0 \"right\") = 0));\n  (assert ((candidate 100 0 0 \"left\") = 0));\n  (assert ((candidate 0 1 0 \"left\") = 1));\n  (assert ((candidate 1 0 0 \"left\") = 0));\n  (assert ((candidate 2 1 1 \"left\") = 0));\n  (assert ((candidate 100 0 0 \"right\") = 0));\n  (assert ((candidate 0 1 0 \"right\") = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_91262_password_rule_2", "language": "ml", "prompt": "(**Check if going from left to right, the digits never decrease; they only ever increase or\nstay the same (like 111123 or 135679).\n:param password: str\n:return: bool\n*)\nlet password_rule_2 (password : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_91262_password_rule_2.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = password_rule_2 in\n  (assert ((candidate \"111122\") = true));\n  (assert ((candidate \"1\") = true));\n  (assert ((candidate \"333\") = true));\n  (assert ((candidate \"223450\") = false));\n  (assert ((candidate \"123456\") = true));\n  (assert ((candidate \"4444\") = true));\n  (assert ((candidate \"111123\") = true));\n  (assert ((candidate \"\") = false));\n  (assert ((candidate \"22\") = true));\n  (assert ((candidate \"666666\") = true));\n  (assert ((candidate \"111111\") = true));\n  (assert ((candidate \"999999999\") = true));\n  (assert ((candidate \"55555\") = true));\n  (assert ((candidate \"88888888\") = true));\n  (assert ((candidate \"135679\") = true));\n  (assert ((candidate \"7777777\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_91318_decapitalize", "language": "ml", "prompt": "(**This method will be used to lower case the first character of SQS\nmessage attributes being received by Lambda to resolve inconsistencies.\nIssue outlined here: https://github.com/boto/boto3/issues/2582\n*)\nlet decapitalize (key : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_91318_decapitalize.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = decapitalize in\n  (assert ((candidate \"Foo\") = \"foo\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"foo\") = \"foo\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_91803_is_valid_square_input", "language": "ml", "prompt": "(**Checks if an entry square value is a valid input to the sudoku\n:param text: Str\n:return: True if valid, False if not\n*)\nlet is_valid_square_input (text : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_91803_is_valid_square_input.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = is_valid_square_input in\n  (assert ((candidate \"a\") = false));\n  (assert ((candidate \"abc\") = false));\n  (assert ((candidate \"1\") = true));\n  (assert ((candidate \"-1\") = false));\n  (assert ((candidate \"1.0\") = false));\n  (assert ((candidate \"11\") = false));\n  (assert ((candidate \"10\") = false));\n  (assert ((candidate \" \") = false));\n  (assert ((candidate \"2\") = true));\n  (assert ((candidate \"9\") = true));\n  (assert ((candidate \"00000\") = false));\n  (assert ((candidate \"3\") = true));\n  (assert ((candidate \"\") = true));\n  (assert ((candidate \"100\") = false));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_92093_format_makehelp", "language": "ml", "prompt": "(**return \"{target}:\t{detail}\"\n*)\nlet format_makehelp (target : string) (detail : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_92093_format_makehelp.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = format_makehelp in\n  (assert ((candidate \"all\" \"This target builds the following targets: clean, debug, release, and test.\") = \"all:\tThis target builds the following targets: clean, debug, release, and test.\"));\n  (assert ((candidate \"debug\" \"Build with debug symbols\") = \"debug:\tBuild with debug symbols\"));\n  (assert ((candidate \"clean\" \"Removes the build directory\") = \"clean:\tRemoves the build directory\"));\n  (assert ((candidate \"release-test\" \"Build release binary, run unit tests\") = \"release-test:\tBuild release binary, run unit tests\"));\n  (assert ((candidate \"target\" \"detail\") = \"target:\tdetail\"));\n  (assert ((candidate \"run\" \"Runs the program\") = \"run:\tRuns the program\"));\n  (assert ((candidate \"test\" \"this is a test\") = \"test:\tthis is a test\"));\n  (assert ((candidate \"clean\" \"Remove all build artifacts\") = \"clean:\tRemove all build artifacts\"));\n  (assert ((candidate \"debug-test\" \"Build debug binary, run unit tests\") = \"debug-test:\tBuild debug binary, run unit tests\"));\n  (assert ((candidate \"test\" \"Run all tests\") = \"test:\tRun all tests\"));\n  (assert ((candidate \"release\" \"Build without debug symbols\") = \"release:\tBuild without debug symbols\"));\n  (assert ((candidate \"clean-debug\" \"Remove all debug build artifacts\") = \"clean-debug:\tRemove all debug build artifacts\"));\n  (assert ((candidate \"target\" \"detail\") = \"target:\tdetail\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_92403__list_product", "language": "ml", "prompt": "(**Computes product of all elements in a list.\n*)\nlet _list_product (num_list : int list) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_92403__list_product.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _list_product in\n  (assert ((candidate []) = 1));\n  (assert ((candidate list range 1 10) = 362880));\n  (assert ((candidate list range 1 11) = 3628800));\n  (assert ((candidate list range 1 21) = 2432902008176640000));\n  (assert ((candidate list range 1 6) = 120));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_92626_gcd", "language": "ml", "prompt": "(**(int, int) -> int\nUses Euclid's method to compute the greatest common factor\n(greatest common divisor) of two integers, <m> and <n>\nReturns greatest common factor (gcd) of the two integers\n*)\nlet gcd (m : int) (n : int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_92626_gcd.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = gcd in\n  (assert ((candidate 12 6) = 6));\n  (assert ((candidate 12 24) = 12));\n  (assert ((candidate 2 12) = 2));\n  (assert ((candidate 9 6) = 3));\n  (assert ((candidate 10 100) = 10));\n  (assert ((candidate 5 15) = 5));\n  (assert ((candidate 4 2) = 2));\n  (assert ((candidate 8 2) = 2));\n  (assert ((candidate 56 110) = 2));\n  (assert ((candidate 18 12) = 6));\n  (assert ((candidate 15 5) = 5));\n  (assert ((candidate 1024 1024) = 1024));\n  (assert ((candidate 36 6) = 6));\n  (assert ((candidate 12 3) = 3));\n  (assert ((candidate 36 24) = 12));\n  (assert ((candidate 5 0) = 5));\n  (assert ((candidate 12 18) = 6));\n  (assert ((candidate 19 3) = 1));\n  (assert ((candidate 3 12) = 3));\n  (assert ((candidate 6 36) = 6));\n  (assert ((candidate 0 5) = 5));\n  (assert ((candidate 20 15) = 5));\n  (assert ((candidate 6 9) = 3));\n  (assert ((candidate ) = 10));\n  (assert ((candidate 6 12) = 6));\n  (assert ((candidate 30 10) = 10));\n  (assert ((candidate 12 12) = 12));\n  (assert ((candidate 2 4) = 2));\n  (assert ((candidate 0 2) = 2));\n  (assert ((candidate 0 0) = 0));\n  (assert ((candidate 6 18) = 6));\n  (assert ((candidate 24 36) = 12));\n  (assert ((candidate 12 2) = 2));\n  (assert ((candidate 2 0) = 2));\n  (assert ((candidate 2 8) = 2));\n  (assert ((candidate 12 0) = 12));\n  (assert ((candidate 2 10) = 2));\n  (assert ((candidate 18 6) = 6));\n  (assert ((candidate 1 1) = 1));\n  (assert ((candidate 1000 10) = 10));\n  (assert ((candidate 3 4) = 1));\n  (assert ((candidate 10 2) = 2));\n  (assert ((candidate 1000 10000) = 1000));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_9273_clean_text_simple", "language": "ml", "prompt": "(**Remove all \u0019 from the string formatted with simple colors:\n\u00198\n*)\nlet clean_text_simple (string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_9273_clean_text_simple.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = clean_text_simple in\n  (assert ((candidate \"This \u00191is\u00193 \u00199just\u00193 some\u00193 \u00199text.\u00193\") = \"This is just some text.\"));\n  (assert ((candidate \"This is just some text.\") = \"This is just some text.\"));\n  (assert ((candidate \"\u00190Red\u00198 \u00190Green\u00198 \u00190Blue\u00198 \u00190Yellow\u00198\") = \"Red Green Blue Yellow\"));\n  (assert ((candidate \"\\x198\\x1913\") = \"\\x198\\x1913\"));\n  (assert ((candidate \"\\x198\\x198\\x19888\") = \"\\x198\\x198\\x19888\"));\n  (assert ((candidate \"This \u00199is\u00193 \u00199just\u00193 some\u00193 \u00191text.\u00193\") = \"This is just some text.\"));\n  (assert ((candidate \"\u00194Red\u00198 \u00194Green\u00198 \u00194Blue\u00198 \u00194Yellow\u00198\") = \"Red Green Blue Yellow\"));\n  (assert ((candidate \"\\x198888\") = \"\\x198888\"));\n  (assert ((candidate \"\\x1913\\x198888\") = \"\\x1913\\x198888\"));\n  (assert ((candidate \"\\x198\") = \"\\x198\"));\n  (assert ((candidate \"\u00194Red\u00198 \u00190Green\u00198 \u00192Blue\u00198 \u00191Yellow\u00198\") = \"Red Green Blue Yellow\"));\n  (assert ((candidate \"\\x1988\\x1988\\x1988\") = \"\\x1988\\x1988\\x1988\"));\n  (assert ((candidate \"\u00194Red\u00198 \u00191Green\u00198 \u00192Blue\u00198 \u00193Yellow\u00198\") = \"Red Green Blue Yellow\"));\n  (assert ((candidate \"This \u00191is\u00193 \u00199just\u00193 some\u00193 \u00191text.\u00193\") = \"This is just some text.\"));\n  (assert ((candidate \"\\x198\\x198\\x198\") = \"\\x198\\x198\\x198\"));\n  (assert ((candidate \"This \u00199is\u00193 \u00199just\u00193 some\u00193 text.\u00193\") = \"This is just some text.\"));\n  (assert ((candidate \"\u00191Red\u00198 \u00191Green\u00198 \u00191Blue\u00198 \u00191Yellow\u00198\") = \"Red Green Blue Yellow\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_92801_parse_hl_lines", "language": "ml", "prompt": "(**Support our syntax for emphasizing certain lines of code.\nexpr should be like '1 2' to emphasize lines 1 and 2 of a code block.\nReturns a list of ints, the line numbers to emphasize.\n*)\nlet parse_hl_lines (expr : string option) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_92801_parse_hl_lines.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_hl_lines in\n  (assert ((candidate Some(\"10 \")) = [10]));\n  (assert ((candidate Some(\" 10\")) = [10]));\n  (assert ((candidate Some(\" 1\")) = [1]));\n  (assert ((candidate Some(\"1\")) = [1]));\n  (assert ((candidate Some(\" 10 11 \")) = [10; 11]));\n  (assert ((candidate Some(\"10 11 12 13 \")) = [10; 11; 12; 13]));\n  (assert ((candidate Some(\" \")) = []));\n  (assert ((candidate Some(\"10 11\")) = [10; 11]));\n  (assert ((candidate Some(\"1 2\")) = [1; 2]));\n  (assert ((candidate Some(\"1\")) = [1]));\n  (assert ((candidate Some(\"\")) = []));\n  (assert ((candidate Some(\"10 11 a\")) = []));\n  (assert ((candidate Some(\"\")) = []));\n  (assert ((candidate Some(\"10\")) = [10]));\n  (assert ((candidate Some(\"   \")) = []));\n  (assert ((candidate Some(\"10 11 \")) = [10; 11]));\n  (assert ((candidate Some(None)) = []));\n  (assert ((candidate Some(\"10 11 12 13\")) = [10; 11; 12; 13]));\n  (assert ((candidate Some(\" 10 11 12 13 \")) = [10; 11; 12; 13]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_92907_distance", "language": "ml", "prompt": "(**Manthatten distance\n*)\nlet distance (a :  int * int) (b :  int * int) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_92907_distance.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = distance in\n  (assert ((candidate (0, 0) (0, 0)) = 0));\n  (assert ((candidate ((~1), 1) (1, 1)) = 2));\n  (assert ((candidate (1, 1) ((~1), 1)) = 2));\n  (assert ((candidate (1, 1) (1, 1)) = 0));\n  (assert ((candidate (0, 0) (0, 1)) = 1));\n  (assert ((candidate (0, 0) (0, 0)) = 0));\n  (assert ((candidate (1, 1) (1, (~1))) = 2));\n  (assert ((candidate (1, 1) (2, 2)) = 2));\n  (assert ((candidate (1, 1) (1, 2)) = 1));\n  (assert ((candidate (1, 1) (2, 1)) = 1));\n  (assert ((candidate (1, 1) (1, 1)) = 0));\n  (assert ((candidate (0, 0) (1, 1)) = 2));\n  (assert ((candidate (1, 1) (0, 0)) = 2));\n  (assert ((candidate (3, 4) (3, 4)) = 0));\n  (assert ((candidate (0, 0) (1, 0)) = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_92983_areStringsEqual", "language": "ml", "prompt": "(**Returns if two strings are the same, disregarding cases.\n*)\nlet areStringsEqual (a : string) (b : string) : bool =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_92983_areStringsEqual.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = areStringsEqual in\n  (assert ((candidate \"t\" \"test\") = false));\n  (assert ((candidate \"TEST\" \"test\") = true));\n  (assert ((candidate \"test\" \"test\") = true));\n  (assert ((candidate \"TeSt\" \"test\") = true));\n  (assert ((candidate \"Hello\" \"hello\") = true));\n  (assert ((candidate \"Hello\" \"world\") = false));\n  (assert ((candidate \"\" \"\") = true));\n  (assert ((candidate \"TESt\" \"test\") = true));\n  (assert ((candidate \"Hello\" \"Hello\") = true));\n  (assert ((candidate \"tESt\" \"test\") = true));\n  (assert ((candidate \"test\" \"other\") = false));\n  (assert ((candidate \"te\" \"test\") = false));\n  (assert ((candidate \"test\" \"TEST\") = true));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_93087_binary_search", "language": "ml", "prompt": "(**Apply binary search to find either a \"start\" or \"end\" of a particular number\n>>> binary_search([2, 3, 3, 3, 4], 3, 'start')\n1\n>>> binary_search([2, 3, 3, 3, 4], 3, 'end')\n3\n>>> binary_search([2, 3, 3, 3, 4], 5, 'start')\n-1\n>>> binary_search([2, 3, 3, 3, 4], 5, 'end')\n-1\n>>> binary_search([2, 3, 3, 3, 5], 4, 'start')\n-1\n*)\nlet binary_search (array : int list) (k : int) (pos : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_93087_binary_search.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = binary_search in\n  (assert ((candidate [2; 3; 3; 3; 5] 4 \"start\") = (~1)));\n  (assert ((candidate [2; 3; 3; 3; 4] 5 \"start\") = (~1)));\n  (assert ((candidate [2; 3; 3; 3; 4] 3 \"start\") = 1));\n  (assert ((candidate [2; 3; 3; 3; 4] 3 \"end\") = 3));\n  (assert ((candidate [2; 3; 3; 3; 4] 5 \"end\") = (~1)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_93501_parse_line_contents", "language": "ml", "prompt": "(**Extract the sigma, gamma, lambda and m from the line:\njust read until we get something looking like a float and then store the first three of them\n*)\nlet parse_line_contents (line : string) :  float * float * float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_93501_parse_line_contents.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_line_contents in\n  (assert ((candidate \"sigma: 1.0 gamma: 1.0 lambda: 1 m: 1\") = (1.0, 1.0, 1.0)));\n  (assert ((candidate \"0.00000000 0.0 0.0\") = (0.0, 0.0, 0.0)));\n  (assert ((candidate \"lambda: 1 m: 1 sigma: 1 gamma: 1\") = (1.0, 1.0, 1.0)));\n  (assert ((candidate \"sigma: 1.0 gamma: 1.0 lambda: 1.0 m: 1\") = (1.0, 1.0, 1.0)));\n  (assert ((candidate \"0.307228 0.010438 12.869096 0.0000000\") = (0.307228, 0.010438, 12.869096)));\n  (assert ((candidate \"0.307228 0.010438 12.869096\") = (0.307228, 0.010438, 12.869096)));\n  (assert ((candidate \"1.234567890 2345.678901 3.456789012\") = (1.23456789, 2345.678901, 3.456789012)));\n  (assert ((candidate \"123.4567890 2.345678901 3.456789012\") = (123.456789, 2.345678901, 3.456789012)));\n  (assert ((candidate \"0.0 0.1 0.0\") = (0.0, 0.1, 0.0)));\n  (assert ((candidate \"1.234567890 2.345678901 3.456789012\") = (1.23456789, 2.345678901, 3.456789012)));\n  (assert ((candidate \"0.0 0.0 0.0\") = (0.0, 0.0, 0.0)));\n  (assert ((candidate \"123456.7890 2.345678901 3.456789012\") = (123456.789, 2.345678901, 3.456789012)));\n  (assert ((candidate \"0.307228 0.010438 12.869096 0.0000000\") = (0.307228, 0.010438, 12.869096)));\n  (assert ((candidate \"0.05 0.0 0.0\") = (0.05, 0.0, 0.0)));\n  (assert ((candidate \"0.5 0.0 0.0\") = (0.5, 0.0, 0.0)));\n  (assert ((candidate \"0.00 0.0 0.0\") = (0.0, 0.0, 0.0)));\n  (assert ((candidate \"0.0 0.0 0.2\") = (0.0, 0.0, 0.2)));\n  (assert ((candidate \"sigma: 1.0 gamma: 1.0 m: 1 lambda: 1\") = (1.0, 1.0, 1.0)));\n  (assert ((candidate \"sigma: 1.0 lambda: 1 m: 1 gamma: 1\") = (1.0, 1.0, 1.0)));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_93912_selection_to_string", "language": "ml", "prompt": "(**Convert dictionary of coordinates to a string for labels.\nParameters\n----------\nselection : dict[Any] -> Any\nReturns\n-------\nstr\n * key1: value1, key2: value2, ...\n*)\nlet selection_to_string (selection : (int, int) list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_93912_selection_to_string.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = selection_to_string in\n  (assert ((candidate dict ) = \"\"));\n  (assert ((candidate [(1, 2); (3, 4); (5, 6); (7, 8)]) = \"2, 4, 6, 8\"));\n  (assert ((candidate [(1, 2); (3, 4)]) = \"2, 4\"));\n  (assert ((candidate [(1, 2)]) = \"2\"));\n  (assert ((candidate [(1, 2); (3, 4); (5, 6)]) = \"2, 4, 6\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_94083_rotate_key", "language": "ml", "prompt": "(**This function is used to adjust the byte position in the temp_key, the bytes of the temp_key are shifted over one\nbytes to the left.\n:param temp_key: A 4 bytes value, only accept numeric object.\n:return: A new 4 bytes value.\n*)\nlet rotate_key (temp_key : int) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_94083_rotate_key.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = rotate_key in\n  (assert ((candidate 65536) = [1; 0; 0; 0]));\n  (assert ((candidate 0) = [0; 0; 0; 0]));\n  (assert ((candidate 0) = [0; 0; 0; 0]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_94301_fmt_jsdoc_union", "language": "ml", "prompt": "(**Returns a JSDoc union of the given type strings.\n*)\nlet fmt_jsdoc_union (type_strings : string list) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_94301_fmt_jsdoc_union.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = fmt_jsdoc_union in\n  (assert ((candidate [\"(string|number)\"; \"(boolean|number)\"]) = \"((string|number)|(boolean|number))\"));\n  (assert ((candidate [\"Number\"; \"boolean\"; \"String\"; \"undefined\"; \"void\"]) = \"(Number|boolean|String|undefined|void)\"));\n  (assert ((candidate [\"String\"]) = \"String\"));\n  (assert ((candidate [\"number\"; \"undefined\"]) = \"(number|undefined)\"));\n  (assert ((candidate [\"\"]) = \"\"));\n  (assert ((candidate [\"Number\"; \"boolean\"]) = \"(Number|boolean)\"));\n  (assert ((candidate [\"string\"; \"null\"]) = \"(string|null)\"));\n  (assert ((candidate [\"String\"; \"Number\"; \"Boolean\"]) = \"(String|Number|Boolean)\"));\n  (assert ((candidate [\"null\"; \"number\"]) = \"(null|number)\"));\n  (assert ((candidate [\"String\"; \"Number\"]) = \"(String|Number)\"));\n  (assert ((candidate [\"number\"; \"undefined\"; \"string\"; \"null\"]) = \"(number|undefined|string|null)\"));\n  (assert ((candidate [\"Number\"; \"Boolean\"; \"String\"; \"Array\"; \"Object\"; \"Function\"]) = \"(Number|Boolean|String|Array|Object|Function)\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_94317_str_to_list", "language": "ml", "prompt": "(**remove [] and whitespace, then create list of integers to return\n*)\nlet str_to_list (string : string) : int list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_94317_str_to_list.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = str_to_list in\n  (assert ((candidate \"[1, 2, 3, 4]\") = [1; 2; 3; 4]));\n  (assert ((candidate \"[1,2,3,4]\") = [1; 2; 3; 4]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_94524__create_mux_ranges", "language": "ml", "prompt": "(**Create a list of ranges based on a list of single values.\nExample:\n * Input:  [1, 2, 3, 5,      7, 8, 9]\n * Output: [[1, 3], [5, 5], [7, 9]]\n*)\nlet _create_mux_ranges (multiplexer_ids : int list) : int list list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_94524__create_mux_ranges.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = _create_mux_ranges in\n  (assert ((candidate [1; 2; 3; 5; 7; 8; 9]) = [[1; 3]; [5; 5]; [7; 9]]));\n  (assert ((candidate [1; 2; 3; 4; 5]) = [[1; 5]]));\n  (assert ((candidate [1; 2]) = [[1; 2]]));\n  (assert ((candidate [1; 2; 3; 4; 6; 7; 8; 9; 10]) = [[1; 4]; [6; 10]]));\n  (assert ((candidate [1; 2; 3]) = [[1; 3]]));\n  (assert ((candidate list range 10) = [[0; 9]]));\n  (assert ((candidate [1; 2; 3; 5; 7; 8; 9]) = [[1; 3]; [5; 5]; [7; 9]]));\n  (assert ((candidate [1; 3; 5; 7; 9]) = [[1; 1]; [3; 3]; [5; 5]; [7; 7]; [9; 9]]));\n  (assert ((candidate [2; 3]) = [[2; 3]]));\n  (assert ((candidate [1; 2; 4; 6; 8]) = [[1; 2]; [4; 4]; [6; 6]; [8; 8]]));\n  (assert ((candidate [2; 4; 6; 8]) = [[2; 2]; [4; 4]; [6; 6]; [8; 8]]));\n  (assert ((candidate list range 2 10) = [[2; 9]]));\n  (assert ((candidate [1; 2; 3; 4; 5; 6; 7; 8; 9; 10; 12; 13]) = [[1; 10]; [12; 13]]));\n  (assert ((candidate [1; 2; 3; 4; 5; 6; 7; 8; 9]) = [[1; 9]]));\n  (assert ((candidate [1; 2; 3; 4]) = [[1; 4]]));\n  (assert ((candidate [1; 2; 3; 4; 5; 6; 7]) = [[1; 7]]));\n  (assert ((candidate [1; 2; 3; 4; 5; 6; 7; 8]) = [[1; 8]]));\n  (assert ((candidate [1; 2; 3; 4; 5; 6; 7; 8; 9; 10]) = [[1; 10]]));\n  (assert ((candidate [1; 2; 3; 4; 5; 6]) = [[1; 6]]));\n  (assert ((candidate [1; 2; 3; 5; 7; 8; 9]) = [[1; 3]; [5; 5]; [7; 9]]));\n  (assert ((candidate [1; 2; 3; 4; 5; 6; 7; 8; 9]) = [[1; 9]]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_94584_contar_palabra", "language": "ml", "prompt": "(**Cuenta cuantas veces se repite una palabra en una cadena de\ntexto.\n:param linea: Cadena de texto.\n:linea type: str\n:param palabra: Palabra a buscar.\n:palabra type: str\n:return: Cuantas veces se repite la palabra en la cadena.\n:rtype: int\n*)\nlet contar_palabra (linea : string) (palabra : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_94584_contar_palabra.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = contar_palabra in\n  (assert ((candidate \"la casa de papelera es de papel\" \"de\") = 2));\n  (assert ((candidate \"Caminando por el camino de la victoria\" \"camino\") = 1));\n  (assert ((candidate \"la casa de papelera es de papel\" \"casa\") = 1));\n  (assert ((candidate \"Caminando por el camino de la victoria\" \"de\") = 1));\n  (assert ((candidate \"Caminando por el camino de la victoria\" \"victoria\") = 1));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_94731_url_to_id", "language": "ml", "prompt": "(**Takes a tweet url and returns its id\n*)\nlet url_to_id (url : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_94731_url_to_id.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = url_to_id in\n  (assert ((candidate \"https://twitter.com/nasa/status/668083631563360256/\") = 668083631563360256));\n  (assert ((candidate \"https://twitter.com/GOP/status/883987787058900992\") = 883987787058900992));\n  (assert ((candidate \"https://twitter.com/Interior/status/1365679211592238592\") = 1365679211592238592));\n  (assert ((candidate \"http://twitter.com/realDonaldTrump/status/883891012282360832\") = 883891012282360832));\n  (assert ((candidate \"http://twitter.com/TheDemocrats/status/883891832571059712\") = 883891832571059712));\n  (assert ((candidate \"http://twitter.com/ThePSF/status/293380700514344496\") = 293380700514344496));\n  (assert ((candidate \"https://twitter.com/dog_rates/status/457937231478969344\") = 457937231478969344));\n  (assert ((candidate \"https://twitter.com/Interior/status/108076710113857283\") = 108076710113857283));\n  (assert ((candidate \"https://twitter.com/dog_rates/status/1234567890123456789\") = 1234567890123456789));\n  (assert ((candidate \"https://twitter.com/dog_rates/status/881533559209541120\") = 881533559209541120));\n  (assert ((candidate \"https://twitter.com/nasa/status/668083631563360256\") = 668083631563360256));\n  (assert ((candidate \"https://twitter.com/dog_rates/status/1456963204405214725\") = 1456963204405214725));\n  (assert ((candidate \"https://twitter.com/dog_rates/status/1228908675299224064\") = 1228908675299224064));\n  (assert ((candidate \"https://twitter.com/ThePSF/status/293380700514344496\") = 293380700514344496));\n  (assert ((candidate \"https://twitter.com/Interior/status/1278747526441191425/\") = 1278747526441191425));\n  (assert ((candidate \"https://twitter.com/dog_rates/status/1000000000000000000000\") = 1000000000000000000000));\n  (assert ((candidate \"https://twitter.com/Interior/status/108076710113857282\") = 108076710113857282));\n  (assert ((candidate \"https://twitter.com/dog_rates/status/1000000000000000000\") = 1000000000000000000));\n  (assert ((candidate \"https://twitter.com/dog_rates/status/1322712625669947906\") = 1322712625669947906));\n  (assert ((candidate \"https://twitter.com/dog_rates/status/1204125929760247808\") = 1204125929760247808));\n  (assert ((candidate \"https://twitter.com/ThePSF/status/1204844046511772737\") = 1204844046511772737));\n  (assert ((candidate \"https://twitter.com/Interior/status/1278747526441191425\") = 1278747526441191425));\n  (assert ((candidate \"https://twitter.com/Interior/status/1278747526441191425/?s=20#fragment\") = 1278747526441191425));\n  (assert ((candidate \"https://twitter.com/Interior/status/108076710113857286\") = 108076710113857286));\n  (assert ((candidate \"https://twitter.com/realDonaldTrump/status/883907451037186050\") = 883907451037186050));\n  (assert ((candidate \"https://twitter.com/Interior/status/108076710113857284\") = 108076710113857284));\n  (assert ((candidate \"https://twitter.com/realDonaldTrump/status/883907451037186051\") = 883907451037186051));\n  (assert ((candidate \"https://twitter.com/Interior/status/1278747526441191425/?s=20\") = 1278747526441191425));\n  (assert ((candidate \"https://twitter.com/realDonaldTrump/status/883907451037186052\") = 883907451037186052));\n  (assert ((candidate \"https://twitter.com/ThePSF/status/1204844046511772737\") = 1204844046511772737));\n  (assert ((candidate \"https://twitter.com/dog_rates/status/1360580986549242368\") = 1360580986549242368));\n  (assert ((candidate \"https://twitter.com/Interior/status/108076710113857281\") = 108076710113857281));\n  (assert ((candidate \"https://twitter.com/dog_rates/status/690096206448278528\") = 690096206448278528));\n  (assert ((candidate \"https://twitter.com/dog_rates/status/0000000000000000000\") = 0));\n  (assert ((candidate \"https://twitter.com/dog_rates/status/889479840728144384\") = 889479840728144384));\n  (assert ((candidate \"https://twitter.com/dog_rates/status/761015783402666496\") = 761015783402666496));\n  (assert ((candidate \"https://twitter.com/dog_rates/status/9999999999999999999\") = 9999999999999999999));\n  (assert ((candidate \"https://twitter.com/dog_rates/status/1234567890123456789\") = 1234567890123456789));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_95589_parse_export_env", "language": "ml", "prompt": "(**Parse environment variables to a dictionary.\nExmple:\n * env_vars = parse_export_env(job.attr_export_env_to_job)\n * primary_file = env_vars['PAS_PRIMARY_FILE']\nArgs:\n * env: Environment variables.\nReturns:\n * Pairs of the name and value of environment variables.\n*)\nlet parse_export_env (env : string) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_95589_parse_export_env.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = parse_export_env in\n  (assert ((candidate \"PAS_ENVIRONMENT=1,PAS_PRIMARY_FILE=1,PAS_CONTEXT_ID=1\") = [(\"PAS_ENVIRONMENT\", \"1\"); (\"PAS_PRIMARY_FILE\", \"1\"); (\"PAS_CONTEXT_ID\", \"1\")]));\n  (assert ((candidate \"PAS_PRIMARY_FILE=\") = [(\"PAS_PRIMARY_FILE\", \"\")]));\n  (assert ((candidate \"PAS_ENVIRONMENT=,PAS_PRIMARY_FILE=,PAS_CONTEXT_ID=\") = [(\"PAS_ENVIRONMENT\", \"\"); (\"PAS_PRIMARY_FILE\", \"\"); (\"PAS_CONTEXT_ID\", \"\")]));\n  (assert ((candidate \"PAS_PRIMARY_FILE=primary_file\") = [(\"PAS_PRIMARY_FILE\", \"primary_file\")]));\n  (assert ((candidate \"A=1,B=2,C=\") = [(\"A\", \"1\"); (\"B\", \"2\"); (\"C\", \"\")]));\n  (assert ((candidate \"A=1,B=2,C=3\") = [(\"A\", \"1\"); (\"B\", \"2\"); (\"C\", \"3\")]));\n  (assert ((candidate \"PAS_PRIMARY_FILE=primary_file1,PAS_PRIMARY_FILE=primary_file2\") = [(\"PAS_PRIMARY_FILE\", \"primary_file2\")]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_957_sparse_add", "language": "ml", "prompt": "(**dict, dict -> dict\nReturns a new dictionary that is the sum of the other two.\n>>>sparse_add(sv1, sv2)\n{0: 5, 1: 6, 2: 9}\n*)\nlet sparse_add (sv1 : (int, int) list) (sv2 : (int, int) list) : (int, int) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_957_sparse_add.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = sparse_add in\n  (assert ((candidate [(1, 2); (3, 3)] []) = [(1, 2); (3, 3)]));\n  (assert ((candidate [] [(1, 2); (3, 3)]) = [(1, 2); (3, 3)]));\n  (assert ((candidate [(0, 1); (1, 2); (2, 3); (4, 1)] [(0, 1); (1, 2); (2, 3)]) = [(0, 2); (1, 4); (2, 6); (4, 1)]));\n  (assert ((candidate [(1, 2); (3, 3)] [(1, 4)]) = [(1, 6); (3, 3)]));\n  (assert ((candidate [] [(0, 1); (1, 2); (2, 3)]) = [(0, 1); (1, 2); (2, 3)]));\n  (assert ((candidate [(0, 1); (1, 2); (3, 3)] [(0, 1); (1, 2); (2, 3)]) = [(0, 2); (1, 4); (2, 3); (3, 3)]));\n  (assert ((candidate [(0, 1); (2, 3)] [(0, 1); (1, 2); (2, 3)]) = [(0, 2); (1, 2); (2, 6)]));\n  (assert ((candidate [(1, 2); (3, 3)] [(3, 4); (5, 6)]) = [(1, 2); (3, 7); (5, 6)]));\n  (assert ((candidate [] []) = []));\n  (assert ((candidate [(0, 1); (1, 2); (2, 3)] []) = [(0, 1); (1, 2); (2, 3)]));\n  (assert ((candidate [] []) = []));\n  (assert ((candidate [(1, 2); (3, 3)] [(4, 5)]) = [(1, 2); (3, 3); (4, 5)]));\n  (assert ((candidate [] [(0, 100)]) = [(0, 100)]));\n  (assert ((candidate [(0, 100)] []) = [(0, 100)]));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_96148_index_from_weekday", "language": "ml", "prompt": "(**Returns a numeric index for day of week based on name of day\n:param weekday: Name of day (e.g. 'Sunday', 'Monday', etc.)\n:return: numeric index\n*)\nlet index_from_weekday (weekday : string) : int =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_96148_index_from_weekday.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = index_from_weekday in\n  (assert ((candidate \"Sunday\") = 0));\n  (assert ((candidate \"Thursday\") = 4));\n  (assert ((candidate \"Saturday\") = 6));\n  (assert ((candidate \"Wednesday\") = 3));\n  (assert ((candidate \"Monday\") = 1));\n  (assert ((candidate \"Tuesday\") = 2));\n  (assert ((candidate \"Friday\") = 5));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_96726_reverse_transform_params", "language": "ml", "prompt": "(**Merge input parameter key and value into one-line string\nArgs:\n * params_in (list): Python list of output params e.g.\n * {\n * \"ParameterKey\": \"principal_role\",\n * \"ParameterValue\": \"$[alfred_ssm_/org/primary/service_catalog/\n * principal/role_arn]\"\n * }\nReturn:\n * params_out (dict): Python dict of input params e.g.\n * {\n * \"principal_role\": \"$[alfred_ssm_/org/primary/service_catalog/\n * principal/role_arn]\"\n * }\n*)\nlet reverse_transform_params (params_in : (string, string) list list) : (string, string) list =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_96726_reverse_transform_params.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = reverse_transform_params in\n  (assert ((candidate [[(\"ParameterKey\", \"principal_role\"); (\"ParameterValue\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\")]; [(\"ParameterKey\", \"role_arn\"); (\"ParameterValue\", \"$[alfred_ssm_/org/primary/service_catalog/deployer/role_arn]\")]]) = [(\"principal_role\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\"); (\"role_arn\", \"$[alfred_ssm_/org/primary/service_catalog/deployer/role_arn]\")]));\n  (assert ((candidate [[(\"ParameterKey\", \"principal_role\"); (\"ParameterValue\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\")]]) = [(\"principal_role\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\")]));\n  (assert ((candidate [[(\"ParameterKey\", \"principal_role\"); (\"ParameterValue\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\")]; [(\"ParameterKey\", \"data_bucket\"); (\"ParameterValue\", \"$[alfred_ssm_/org/primary/data_lake/bucket]\")]]) = [(\"principal_role\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\"); (\"data_bucket\", \"$[alfred_ssm_/org/primary/data_lake/bucket]\")]));\n  (assert ((candidate [[(\"ParameterKey\", \"principal_role\"); (\"ParameterValue\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\")]]) = [(\"principal_role\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\")]));\n  (assert ((candidate [[(\"ParameterKey\", \"empty\"); (\"ParameterValue\", \"\")]]) = [(\"empty\", \"\")]));\n  (assert ((candidate [[(\"ParameterKey\", \"principal_role\"); (\"ParameterValue\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\")]; [(\"ParameterKey\", \"data_bucket\"); (\"ParameterValue\", \"$[alfred_ssm_/org/primary/data_lake/bucket]\")]; [(\"ParameterKey\", \"data_bucket\"); (\"ParameterValue\", \"$[alfred_ssm_/org/primary/data_lake/bucket]\")]]) = [(\"principal_role\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\"); (\"data_bucket\", \"$[alfred_ssm_/org/primary/data_lake/bucket]\")]));\n  (assert ((candidate [[(\"ParameterKey\", \"principal_role\"); (\"ParameterValue\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\")]; [(\"ParameterKey\", \"role_name\"); (\"ParameterValue\", \"$[alfred_ssm_/org/primary/service_catalog/cross_account_access_role/name]\")]]) = [(\"principal_role\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\"); (\"role_name\", \"$[alfred_ssm_/org/primary/service_catalog/cross_account_access_role/name]\")]));\n  (assert ((candidate [[(\"ParameterKey\", \"principal_role\"); (\"ParameterValue\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\")]; [(\"ParameterKey\", \"vpc_cidr\"); (\"ParameterValue\", \"$[alfred_ssm_/org/primary/service_catalog/network/vpc/vpc_cidr]\")]]) = [(\"principal_role\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\"); (\"vpc_cidr\", \"$[alfred_ssm_/org/primary/service_catalog/network/vpc/vpc_cidr]\")]));\n  (assert ((candidate [[(\"ParameterKey\", \"principal_role\"); (\"ParameterValue\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\")]; [(\"ParameterKey\", \"another_role\"); (\"ParameterValue\", \"$[alfred_ssm_/org/primary/service_catalog/another_role_arn]\")]]) = [(\"principal_role\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\"); (\"another_role\", \"$[alfred_ssm_/org/primary/service_catalog/another_role_arn]\")]));\n  (assert ((candidate [[(\"ParameterKey\", \"principal_role\"); (\"ParameterValue\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\")]]) = [(\"principal_role\", \"$[alfred_ssm_/org/primary/service_catalog/principal/role_arn]\")]));\n  (assert ((candidate []) = []));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_97036_string_lower", "language": "ml", "prompt": "(****string_lower(string)** -> return the lowercase value of the string\n* string: (string) string to lower case.\n<code>\n * Example:\n * string_lower('Linux')\n * Returns:\n * 'linux'\n</code>\n*)\nlet string_lower (string : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_97036_string_lower.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = string_lower in\n  (assert ((candidate \"A\") = \"a\"));\n  (assert ((candidate \"\u00a1\") = \"\u00a1\"));\n  (assert ((candidate \"\u00bf\") = \"\u00bf\"));\n  (assert ((candidate \"LINUX1234\") = \"linux1234\"));\n  (assert ((candidate \"`~-_=+[]{}\\|;:'\",<.>/?\") = \"`~-_=+[]{}\\|;:'\",<.>/?\"));\n  (assert ((candidate \"z\") = \"z\"));\n  (assert ((candidate \"Linux1234\") = \"linux1234\"));\n  (assert ((candidate \"LiNuX\") = \"linux\"));\n  (assert ((candidate \"LInux\") = \"linux\"));\n  (assert ((candidate \"!@#$%^&*()\") = \"!@#$%^&*()\"));\n  (assert ((candidate \"linux\") = \"linux\"));\n  (assert ((candidate \"\u01dd\") = \"\u01dd\"));\n  (assert ((candidate \"Linux\") = \"linux\"));\n  (assert ((candidate \"Z\") = \"z\"));\n  (assert ((candidate \"\u0137\") = \"\u0137\"));\n  (assert ((candidate \"\") = \"\"));\n  (assert ((candidate \"lInuX\") = \"linux\"));\n  (assert ((candidate \"\u0133\") = \"\u0133\"));\n  (assert ((candidate \"LinUxB\") = \"linuxb\"));\n  (assert ((candidate \"\u0135\") = \"\u0135\"));\n  (assert ((candidate \"a\") = \"a\"));\n  (assert ((candidate \"linuxB\") = \"linuxb\"));\n  (assert ((candidate \"LinUxB!\") = \"linuxb!\"));\n  (assert ((candidate \"0123456789\") = \"0123456789\"));\n  (assert ((candidate \"Linux!\") = \"linux!\"));\n  (assert ((candidate \"\u0138\") = \"\u0138\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_9742_convert_to_camel", "language": "ml", "prompt": "(**Convert snake case (foo_bar_bat) to camel case (fooBarBat).\nThis is not pythonic, but needed for certain situations\n*)\nlet convert_to_camel (data : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_9742_convert_to_camel.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = convert_to_camel in\n  (assert ((candidate \"foo_bar_bat\") = \"fooBarBat\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_98079_eq_11_dimensionless_hrr_rectangular", "language": "ml", "prompt": "(**Equation 11 in Section 8.3.2.2 PD 7974-1:2019 calculates dimensionless for rectangular fire source.\n:param Q_dot_kW: in kW, fire heat release rate.\n:param rho_0: in kg/m^3, density of ambient air.\n:param c_p_0_kJ_kg_K: in kJ/kg/K, specific heat capacity of ambient air.\n:param T_0: in K, ambient air temperature.\n:param g: in m/s^2, acceleration due to gravity.\n:param L_A: in m, rectangular shape dimension's shorter edge.\n:param L_B: in m, rectangular shape dimension's longer edge.\n:return Q_dot_star_rect: dimensionless, dimensionless heat release rate\n*)\nlet eq_11_dimensionless_hrr_rectangular (Q_dot_kW : float) (rho_0 : float) (c_p_0_kJ_kg_K : float) (T_0 : float) (g : float) (L_A : float) (L_B : float) : float =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_98079_eq_11_dimensionless_hrr_rectangular.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = eq_11_dimensionless_hrr_rectangular in\n  (assert ((candidate 0.0 1.0 1.0 273.15 9.807 2.0 2.0) = 0.0));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
{"name": "HumanEval_99617_unindent", "language": "ml", "prompt": "(**eat leading space in front of lines based on the smallest one\n*)\nlet unindent (str : string) : string =", "doctests": "keep", "original": "/home/elleven/code/multipl-t/MultiPL-E/datasets/../../multipl_e_target_adaptor/stack-clean-python/HumanEval_99617_unindent.py", "prompt_terminology": "verbatim", "tests": "\nlet assertions =\n let candidate = unindent in\n  (assert ((candidate \"\n    line1\n    line2\n    line3\n    line4\n    \") = \"\nline1\nline2\nline3\nline4\n\"));\n  (assert ((candidate \"    This is a\n    multi-line\n    string\n    \") = \"This is a\nmulti-line\nstring\n\"));\n  (assert ((candidate \"\n    line1\n\n    line2\n\n    line3\n    line4\n    \") = \"\nline1\n\nline2\n\nline3\nline4\n\"));\n  (assert ((candidate \"\n\n    line1\n      line2\n    line3\n    line4\n    \") = \"\n\nline1\n  line2\nline3\nline4\n\"));\n  (assert ((candidate \"    This is a\n    multi-line\n    string\n\n    this is also part of the string\n\n        it has a nested indentation\n    \") = \"This is a\nmulti-line\nstring\n\nthis is also part of the string\n\n    it has a nested indentation\n\"));\n  (assert ((candidate \"\n    line1\n      line2\n    line3\n    line4\n    \") = \"\nline1\n  line2\nline3\nline4\n\"));\n  (assert ((candidate \"    This is a\n    multi-line\n    string\n\n    this is also part of the string\n    \") = \"This is a\nmulti-line\nstring\n\nthis is also part of the string\n\"));\n  ()\n", "stop_tokens": ["\n\n", "\n(*", "\ntype"]}
